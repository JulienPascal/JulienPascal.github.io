<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.1.0">
  <meta name="generator" content="Hugo 0.54.0" />

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Julien Pascal, PhD">

  
  
  
    
  
  <meta name="description" content="For a specific project on the housing market (here), I had to analyze thousands of photos. To do that, I used a convolutional neural network (CNN), which is a fancy name for a complicated function that can be &ldquo;trained&rdquo; to recognize patterns in images. In this blog post, I would like to introduce the &ldquo;Hello World&rdquo; of computer vision and CNN: the classification of hand-written digits from the MNIST dataset.">

  
  <link rel="alternate" hreflang="en-us" href="https://julienpascal.github.io/post/cnn/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-BSZS1F0NHL"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-BSZS1F0NHL');
    </script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  
  <link rel="alternate" href="https://julienpascal.github.io/index.xml" type="application/rss+xml" title="Julien Pascal">
  <link rel="feed" href="https://julienpascal.github.io/index.xml" type="application/rss+xml" title="Julien Pascal">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://julienpascal.github.io/post/cnn/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@Juli3nPascal">
  <meta property="twitter:creator" content="@Juli3nPascal">
  
  <meta property="og:site_name" content="Julien Pascal">
  <meta property="og:url" content="https://julienpascal.github.io/post/cnn/">
  <meta property="og:title" content="A Primer on Computer Vision | Julien Pascal">
  <meta property="og:description" content="For a specific project on the housing market (here), I had to analyze thousands of photos. To do that, I used a convolutional neural network (CNN), which is a fancy name for a complicated function that can be &ldquo;trained&rdquo; to recognize patterns in images. In this blog post, I would like to introduce the &ldquo;Hello World&rdquo; of computer vision and CNN: the classification of hand-written digits from the MNIST dataset."><meta property="og:image" content="https://julienpascal.github.io/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2019-12-05T18:53:22&#43;01:00">
  
  <meta property="article:modified_time" content="2019-12-05T18:53:22&#43;01:00">
  

  

  

  <title>A Primer on Computer Vision | Julien Pascal</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Julien Pascal</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#teaching">
            
            <span>Teaching</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#computing">
            
            <span>Computing</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/pdf/Julien_Pascal_Academic_Resume.pdf">
            
            <span>Academic Resume</span>
            
          </a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">A Primer on Computer Vision</h1>

  
  <p class="page-subtitle">In this blog post, I discuss the &lsquo;Hello World&rsquo; of computer vision using Julia and Flux.jl</p>
  

  
    



<meta content="2019-12-05 18:53:22 &#43;0100 CET" itemprop="datePublished">
<meta content="2019-12-05 18:53:22 &#43;0100 CET" itemprop="dateModified">

<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    <time>Dec 5, 2019</time>
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    11 min read
  </span>
  

  
  

  

  
    
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=A%20Primer%20on%20Computer%20Vision&amp;url=https%3a%2f%2fjulienpascal.github.io%2fpost%2fcnn%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fjulienpascal.github.io%2fpost%2fcnn%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fjulienpascal.github.io%2fpost%2fcnn%2f&amp;title=A%20Primer%20on%20Computer%20Vision"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fjulienpascal.github.io%2fpost%2fcnn%2f&amp;title=A%20Primer%20on%20Computer%20Vision"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=A%20Primer%20on%20Computer%20Vision&amp;body=https%3a%2f%2fjulienpascal.github.io%2fpost%2fcnn%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

    







  









  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      

<p>For a specific project on the housing market (<a href="https://julienpascal.github.io/project/rentalmarket/" target="_blank">here</a>), I had to analyze thousands of photos. To do that, I used a <strong>convolutional neural network</strong> (CNN), which is a fancy name for a complicated function that can be &ldquo;trained&rdquo; to recognize patterns in images. In this blog post, I would like to introduce the <strong>&ldquo;Hello World&rdquo;</strong> of computer vision and CNN: the classification of hand-written digits from the <a href="https://en.wikipedia.org/wiki/MNIST_database" target="_blank">MNIST dataset</a>. There are thousands of tutorials on the same topic using Python freely available on the Internet. Instead, let&rsquo;s use Julia and the package <strong>Flux.jl</strong>. Why? Because <strong>Julia is fast</strong>, and if you have millions of images to analyze, the speed up could be substantial compared to Python. The Jupyter notebook used to generate this post can be found <a href="https://github.com/JulienPascal/CNNPrimer" target="_blank">here</a>.</p>

<h2 id="data">Data</h2>

<p>The MNIST dataset contains images of hand-written digits (0 to 9) in grayscale and that are nicely centered. Each pixel is represented by a number in between 0 (black) and 255 (white). Each image is 28 by 28 pixels. One way to represent an image is to see it as a 1d-column vector of 28*28 = 784 pixels. However, this representation ignores the &ldquo;structure&rdquo; of an image: pixels that are close to each others are informative on the digit we are trying to identify. A CNN is a good tool to keep the spatial structure of an image, while avoiding issues linked to the <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" target="_blank">curse of dimensionality</a>: images are noisy and high-dimensional input data.</p>

<h2 id="a-crash-course-on-cnn">A crash course on CNN</h2>

<p>Two of the key ingredients of a CNN are a <strong>convolutional layer</strong> (hence the name) and a <strong>maxpool layer</strong>.</p>

<h3 id="convolutional-layer">Convolutional layer</h3>

<p>A convolutional layer applies a <em>stencil</em> to each point. The output of a convolutional layer is an &ldquo;image&rdquo; of lower dimension, that is informative on some features of the input image (shapes, edges, etc.). The figure below shows how a convolutional layer works:</p>

<p><img src="convolution.gif" alt="alt text" />
source:<a href="https://mitmath.github.io/18337/lecture14/pdes_and_convolutions" target="_blank">https://mitmath.github.io/18337/lecture14/pdes_and_convolutions</a></p>

<h3 id="maxpool-layer">Maxpool layer</h3>

<p>A maxpool layer is a <em>stencil</em> that selects the maximum value within a square. Below is an illustration of a maxpool layer applied to a $ 4 \times 4$ image:</p>

<p><img src="maxpool.gif" alt="alt text" />
source:<a href="https://mauriciocodesso.com/post/convolution-neural-network/" target="_blank">https://mauriciocodesso.com/post/convolution-neural-network/</a></p>

<h3 id="stride-and-padding">Stride and Padding</h3>

<p>When building a CNN, one must specify two hyper parameters: <strong>stride and padding</strong></p>

<ul>
<li><p>When the stride is equal to 1, we move the filters one pixel at a time. When stride is equal to 2, we move the filters two pixel at a time, etc.</p></li>

<li><p>Padding refers to &ldquo;adding zeroes&rdquo; at the border of an image. Padding can be used to control the size of the output volume and helps in keeping information at the border of images</p></li>
</ul>

<p>Below is an example of a $3 \times 3$ filter applied to a $5 \times 5$ input padded with a $1 \times 1$ border of zeros using $2 \times 2$ strides:</p>

<p><img src="padding_strides.gif" alt="alt text" />
source: <a href="http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html" target="_blank">http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html</a></p>

<p>The typical infrastructure of a CNN is first to apply a convolutional layer to the input image, then to use a maxpool layer, before using a fully-connected layer. Several &ldquo;convolutional layer - maxpool layer&rdquo; units can be stacked together before using a fully-connected (FC) layer. Note that an activation layer (often <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" target="_blank">ReLU</a>) is generally inserted between the the convolutional and the maxpool layer.</p>

<p><img src="architecture.png" alt="alt text" />
source: <a href="https://towardsdatascience.com/visualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69" target="_blank">https://towardsdatascience.com/visualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69</a></p>

<h2 id="using-flux-jl">Using Flux.jl</h2>

<p>Flux.jl is a leading machine learning package in the Julia ecosystem. In what follows, we load both the train and the test samples of the MNIST dataset. The train sample is a set of images used to fine-tune the parameters of the CNN, while the test sample contains images used to check that we did not overfit the train sample. A smoking gun for overfitting is when the accuracy in the train sample is much better than the accuracy using images from the test sample.</p>

<pre><code class="language-julia">using Flux, Flux.Data.MNIST, Statistics
using Flux: onehotbatch, onecold, crossentropy, throttle
using Base.Iterators: repeated, partition
using Printf, BSON
using ImageView

# Load labels and images from Flux.Data.MNIST
# Train set: images used to estimate the CNN
train_labels = MNIST.labels(:train)
train_imgs = MNIST.images(:train);

# Test set: images used to see how well the CNN perform &quot;out-of-the-sample&quot;
test_imgs = MNIST.images(:test)
test_labels = MNIST.labels(:test)

print(&quot;Images in the train set: $(size(train_imgs))&quot;)
print(&quot;Images in the test set: $(size(test_imgs))&quot;)

# Visualization of one digit
NROWS, NCOLS = 28, 28
a = reshape(train_imgs[1], NROWS, NCOLS)
</code></pre>

<pre><code>Images in the train set: (60000,)Images in the test set: (10000,)
</code></pre>

<p><img src="CNN_13_1.png" alt="png" /></p>

<h2 id="cnn-architecture">CNN architecture</h2>

<p>Our CNN has the usual CONV-&gt;ReLU-&gt;MaxPool components, before using a FC layer. We use a $1 \times 1$ padding and a stride of $1$ (the default value). The size of input is gradually reduced by using $2 \times 2$ maxpool layers. The default activation in Flux.jl is the function is $ x-&gt;x $. Here, we use the Rectified Linear Unit function (ReLU) instead:</p>

<pre><code class="language-julia">model = Chain(
    # First convolution, operating upon a 28x28 image
    Conv((3, 3), 1=&gt;16, pad=(1,1), relu),
    MaxPool((2,2)), #maxpooling

    # Second convolution, operating upon a 14x14 image
    Conv((3, 3), 16=&gt;32, pad=(1,1), relu),
    MaxPool((2,2)), #maxpooling

    # Third convolution, operating upon a 7x7 image
    Conv((3, 3), 32=&gt;32,pad=(1,1), relu),
    MaxPool((2,2)),

    # Reshape 3d tensor into a 2d one, at this point it should be (3, 3, 32, N)
    # which is where we get the 288 in the `Dense` layer below:
    x -&gt; reshape(x, :, size(x, 4)),
    Dense(288, 10),

    # Softmax to get probabilities
    softmax,
)
</code></pre>

<p>The ReLU activation function is a piece-wise linear function. In the <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" target="_blank">“ImageNet Classification with Deep Convolutional Neural Networks&rdquo;</a> paper by Krizhevsky and coauthors, the authors write:</p>

<blockquote>
<p>we refer to neurons with this nonlinearity as Rectified Linear Units (ReLUs). Deep convolutional neural networks with ReLUs train several times faster than their equivalents with tanh units.</p>
</blockquote>

<p>The ReLU activation function also helps in reducing the practical issues caused by <a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem" target="_blank">the vanishing gradient problem</a>. That is, the failure of the minizimation algorithm used to find the parameters of our CNN. Below is a plot of the ReLU activation function:</p>

<pre><code class="language-julia">xgrid = collect(range(-1, 1, length=100))
plot(xgrid, NNlib.relu.(xgrid), label = &quot;relu(x)&quot;, title=&quot;ReLU activation function&quot;, xlabel=&quot;x&quot;)
</code></pre>

<p><img src="CNN_18_0.svg" alt="svg" /></p>

<h2 id="training">Training</h2>

<h3 id="batching">Batching</h3>

<p>The batch size is a parameter that tells us how many images the network will &ldquo;see&rdquo; at once when &ldquo;training&rdquo;.
In technical terms, when performing gradient descent, we don&rsquo;t use all the information at once (because of memory limitations and because it is not necessarily efficient). The following function generates &ldquo;batches&rdquo; of images:</p>

<pre><code class="language-julia"># Bundle images together with labels and group into minibatchess
function make_minibatch(X, Y, idxs)
    X_batch = Array{Float32}(undef, size(X[1])..., 1, length(idxs))
    for i in 1:length(idxs)
        X_batch[:, :, :, i] = Float32.(X[idxs[i]])
    end
    Y_batch = onehotbatch(Y[idxs], 0:9)
    return (X_batch, Y_batch)
end
# The CNN only &quot;sees&quot; 128 images at each training cycle:
batch_size = 128
mb_idxs = partition(1:length(train_imgs), batch_size)
# train set in the form of batches
train_set = [make_minibatch(train_imgs, train_labels, i) for i in mb_idxs];
# train set in one-go: used to calculate accuracy with the train set
train_set_full = make_minibatch(train_imgs, train_labels, 1:length(train_imgs));
# test set: to check we do not overfit the train data:
test_set = make_minibatch(test_imgs, test_labels, 1:length(test_imgs));
</code></pre>

<h3 id="loss-function-and-minimization">Loss function and minimization</h3>

<p>For the CNN to &ldquo;learn&rdquo; anything at all, it must have a notion of &ldquo;wrong&rdquo; or &ldquo;right&rdquo;. The loss function does exactly that, by quantifying how well the model performs at recognizing digits. When the output is a probability, the <a href="https://en.wikipedia.org/wiki/Cross_entropy" target="_blank">cross entropy</a> loss function is appropriate. The final step is to select an algorithm to minimize the loss function. Here, let&rsquo;s select the <a href="https://arxiv.org/abs/1412.6980" target="_blank">ADAM</a> algorithm, which I understand as some sort of <a href="https://julienpascal.github.io/post/ols_ml/" target="_blank">Stochastic Gradient Descent</a> with momentum and adaptive learning rate:</p>

<pre><code class="language-julia"># `loss()` calculates the crossentropy loss between our prediction `y_hat`
# We augment the data a bit, adding gaussian random noise to our image to make it more robust.
function loss(x, y)
    # Add some noise to the image
    # we reduce the risk of overfitting the train sample by doing so:
    x_aug = x .+ 0.1f0*gpu(randn(eltype(x), size(x)))

    y_hat = model(x_aug)
    return crossentropy(y_hat, y)
end
accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))

# ADAM optimizer
opt = ADAM(0.001);
</code></pre>

<p>This block &ldquo;train&rdquo; (fine-tune the CNN parameter values) the model until a pre-determined accuracy level is reached:</p>

<pre><code class="language-julia">best_acc = 0.0
last_improvement = 0
accuracy_target = 0.97 #Set an accuracy target. When reached, we stop training.
max_epochs = 100 #Maximum
for epoch_idx in 1:100
    global best_acc, last_improvement
    # Train for a single epoch
    Flux.train!(loss, params(model), train_set, opt)

    # Calculate accuracy:
    acc = accuracy(train_set_full...)
    @info(@sprintf(&quot;[%d]: Train accuracy: %.4f&quot;, epoch_idx, acc))

    # Calculate accuracy:
    acc = accuracy(test_set...)
    @info(@sprintf(&quot;[%d]: Test accuracy: %.4f&quot;, epoch_idx, acc))

    # If our accuracy is good enough, quit out.
    if acc &gt;= accuracy_target
        @info(&quot; -&gt; Early-exiting: We reached our target accuracy of $(accuracy_target*100)%&quot;)
        break
    end

    if epoch_idx - last_improvement &gt;= 10
        @warn(&quot; -&gt; We're calling this converged.&quot;)
        break
    end
end
</code></pre>

<pre><code>┌ Info: [1]: Train accuracy: 0.9579
└ @ Main In[14]:12
┌ Info: [1]: Test accuracy: 0.9605
└ @ Main In[14]:16
┌ Info: [2]: Train accuracy: 0.9749
└ @ Main In[14]:12
┌ Info: [2]: Test accuracy: 0.9756
└ @ Main In[14]:16
┌ Info:  -&gt; Early-exiting: We reached our target accuracy of 97.0%
└ @ Main In[14]:20
</code></pre>

<h2 id="predictions">Predictions</h2>

<p>Once the model is trained, predicted values are easily obtained as follows:</p>

<pre><code class="language-julia"># Get predictions and convert data to Array:
pred = Tracker.data(model(test_set[1]));
# Show the first 5 predictions
# One column is an image
# Each row corresponds to the probability of a digit
pred[:,1:5]
# Function to get the row index of the max value:
f1(x) = getindex.(argmax(x, dims=1), 1)
# Final predicted value is the one with the maximum probability:
pred = f1(pred) .- 1; #minus 1 because the first element is 0
</code></pre>

<p>Let&rsquo;s see how the model performs on the test set. Can the CNN recognize digits using images that were not used when training the model? As you can see below, our model does an amazing job at recognizing hand-written digits:</p>

<pre><code class="language-julia">println(&quot;Predicted value = $(pred[1])&quot;)
a = reshape(test_imgs[1], NROWS, NCOLS)
</code></pre>

<pre><code>Predicted value = 7
</code></pre>

<p><img src="CNN_30_1.png" alt="png" /></p>

<pre><code class="language-julia">println(&quot;Predicted value = $(pred[2])&quot;)
a = reshape(test_imgs[2], NROWS, NCOLS)
</code></pre>

<pre><code>Predicted value = 2
</code></pre>

<p><img src="CNN_31_1.png" alt="png" /></p>

<pre><code class="language-julia">println(&quot;Predicted value = $(pred[3])&quot;)
a = reshape(test_imgs[3], NROWS, NCOLS)
</code></pre>

<pre><code>Predicted value = 1
</code></pre>

<p><img src="CNN_32_1.png" alt="png" /></p>

<h3 id="accuracy-checks">Accuracy checks</h3>

<p>We now have a model that seems to do quite a good job in recognizing digits. But can we improve it? If yes, how?
To improve our model, we first need to identify when and why it fails.</p>

<h4 id="confusion-matrix">Confusion matrix</h4>

<p>To do that, a useful reporting
tool is a <strong>confusion matrix</strong>. Each row of a confusion matrix shows instances of the true value, while each column displays instances of the predicted value. Ideally, we would like our model to perfectly predict the outcome. With a perfect model, all instances would be located on the diagonal elements of the confusion matrix.</p>

<p>The last time I checked, <code>Flux.jl</code> did not have an in-built function to calculate confusion matrices. Fortunately, an implementation is available in the package <code>MLBase</code>. The next block of code calculates the confusion matrix and displays it. Most of instances are on located on the diagonal, which is not a surprise given that the accuracy rate for our model is more than $97.0\%$</p>

<pre><code class="language-julia">using MLBase
# Adding 1 to outcome because the index 0 in arrays does not exist in Julia
Cm = confusmat(10, test_labels .+ 1, vec(pred) .+ 1)
</code></pre>

<pre><code>10×10 Array{Int64,2}:
 968     1     1    0    0    4    3    1    2    0
   0  1128     3    0    0    0    1    0    3    0
   3     5  1003    6    1    1    0    6    7    0
   0     0     1  992    0   10    0    2    4    1
   0     1     2    0  972    0    0    1    1    5
   1     0     1    4    0  883    1    1    1    0
   1     4     0    0    1   13  936    0    3    0
   1     7    10    5    0    1    0  986    3   15
   2     0     4    6    4    8    2    4  942    2
   4     4     0    7    7   10    0    8    2  967
</code></pre>

<pre><code class="language-julia"># Normalize output:
Cm  = Cm ./ sum(Cm, dims=2)
# Labels
xs = [string(i) for i = 0:9]
heatmap(xs, xs, Cm, aspect_ratio=1, color=:plasma)
</code></pre>

<p><img src="CNN_41_0.svg" alt="svg" /></p>

<p>To visualize where our model makes mistakes, one can use the optional argument <code>clim</code>, to put an upper bound on
the underlying colormap. For instance, the next plot shows that our model has troubles differencing 7 and 2 or 8 and 2.</p>

<pre><code class="language-julia"># Limits to colormap, so we can see where errors are located:
xs = [string(i) for i = 0:9]
heatmap(xs, xs, Cm, aspect_ratio=1, color=:plasma, clim=(0., 0.01))
</code></pre>

<p><img src="CNN_43_0.svg" alt="svg" /></p>

<h4 id="error-analysis">Error Analysis</h4>

<p>The next block of code displays digits for which our CNN failed:</p>

<pre><code class="language-julia"># indices for errors:
using ImageView, Gtk.ShortNames
mistakes = test_labels .!= vec(pred)
max_images = 5
grid, frames, canvases = canvasgrid((1,max_images)); # 1 row
</code></pre>

<pre><code class="language-julia">k=0#counter for mistakes
for (j, i) in enumerate(mistakes)
    if i == true
        k+=1 # a false value has been found
        println(&quot;Predicted value = $(pred[j])&quot;)
        println(&quot;True value = $(test_labels[j])&quot;)
        imshow(canvases[1,k], test_imgs[j])
        idx = ImageView.annotate!(guidict, AnnotationText(0, 0, &quot;$(pred[j])&quot;, color=RGB(0,0,0), fontsize=3))
    end
    if k &gt;= max_images
        break
    end
end
win = Window(grid);
Gtk.showall(win);
</code></pre>

<pre><code>Predicted value = 5
True value = 9
Predicted value = 5
True value = 6
Predicted value = 4
True value = 8
Predicted value = 3
True value = 2
Predicted value = 7
True value = 2
</code></pre>

<p><img src="false_values.png" alt="alt" /></p>

<p>While it seems obvious that the two digits starting from the left are a 9 and a 6, the remaining 3 elements are not trivial. The 8 in the middle could be easily confused with something else and the two remaining digits are weirdly shaped.</p>

<h2 id="conclusion">Conclusion</h2>

<p>When dealing with images, a convolutional neural network generally does an amazing job at recognizing patterns. This blog post was a non-technical introduction to the topic. While Python is the tool of predilection in machine learning (Keras, TensorFlow, etc.), my guess is that Julia will get increasingly popular because Julia is both easy to use and fast.</p>

<h2 id="references">References</h2>

<ul>
<li>This blog post is heavily based on this Flux.jl tutorial: <a href="https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl" target="_blank">https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl</a></li>
<li>On the links between CNN and PDEs: <a href="https://mitmath.github.io/18337/lecture14/pdes_and_convolutions" target="_blank">https://mitmath.github.io/18337/lecture14/pdes_and_convolutions</a></li>
<li>A full course on CNN. Most of the content is available online: <a href="http://cs231n.github.io/convolutional-networks/" target="_blank">http://cs231n.github.io/convolutional-networks/</a></li>
</ul>

    </div>

    


<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/machine-learning/">Machine Learning</a>
  
  <a class="badge badge-light" href="/tags/computer-vision/">Computer Vision</a>
  
</div>




    
      






  







<div class="media author-card" itemscope itemtype="http://schema.org/Person">
  
  
  <img class="portrait mr-3" src="/author/admin/avatar_hu3ebf584d0e96ded762042713d38b4f6f_6501895_250x250_fill_q90_lanczos_center.jpg" itemprop="image" alt="Avatar">
  

  <div class="media-body">
    <h5 class="card-title" itemprop="name"><a href="/authors/admin">Julien Pascal, PhD</a></h5>
    <h6 class="card-subtitle">Economist</h6>
    
    <ul class="network-icon" aria-hidden="true">
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://twitter.com/Juli3nPascal" target="_blank" rel="noopener">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://github.com/JulienPascal" target="_blank" rel="noopener">
          <i class="fab fa-github"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://www.linkedin.com/in/julien-pascal-62a322aa/" target="_blank" rel="noopener">
          <i class="fab fa-linkedin"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://medium.com/@julien.pascal" target="_blank" rel="noopener">
          <i class="fab fa-medium"></i>
        </a>
      </li>
      
    </ul>
  </div>
</div>



      
      
    

    

    


  </div>
</article>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    &copy; 2017 Julien Pascal &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/julia.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/shell.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.d7381f2d79e6271d4da28f474f49096c.js"></script>

  </body>
</html>

