<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Julien Pascal on Julien Pascal</title>
    <link>https://julienpascal.github.io/</link>
    <description>Recent content in Julien Pascal on Julien Pascal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Julien Pascal</copyright>
    <lastBuildDate>Wed, 03 Dec 2025 15:51:54 +0100</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>A generalization of the Parameterized Expectations Algorithm</title>
      <link>https://julienpascal.github.io/publication/el_2025/</link>
      <pubDate>Wed, 03 Dec 2025 15:51:54 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/publication/el_2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Heterogeneity, Macroeconomic Dynamics, and Monetary Policy: Theoretical and Computational Perspectives</title>
      <link>https://julienpascal.github.io/publication/jes_2025/</link>
      <pubDate>Mon, 01 Dec 2025 15:51:54 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/publication/jes_2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Generalization of the Parameterized Expectation Algorithm</title>
      <link>https://julienpascal.github.io/post/bc_mc_pea/</link>
      <pubDate>Mon, 01 Dec 2025 08:00:00 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/bc_mc_pea/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;This blog post is about my work on a &lt;em&gt;generalization of the Parameterized Expectations Algorithm&lt;/em&gt;, available &lt;a href=&#34;https://doi.org/10.1016/j.econlet.2025.112790&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The Parameterized Expectations Algorithm (PEA) is a classic computational approach to numerically &amp;ldquo;solve&amp;rdquo; economic models with rational expectations, i.e. finding an approximate solution. Usually, to solve economic models of this type, one has to find a policy function (e.g. how much to consume today, given a current level of capital) that satisfies a functional equation that holds in expectation (e.g. the Euler equation). The PEA flips this idea on its head: if we know the expectation term, we can recover the unknown policy function. For several reasons, this works better this way.&lt;/p&gt;

&lt;p&gt;In my view, the paper &lt;em&gt;A Generalization of the Parameterized Expectations Algorithm&lt;/em&gt; can be read from two angles:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TL;DR 1 [Practical side]:&lt;/strong&gt; This paper is a variance-reduced version of standard PEA that uses multiple innovation draws per state vector. The optimal number of innovation draws (given a fixed computational budget constraint) is calculated in closed form using only a small number of hyperparameters.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TL;DR 2 [Theoretical side]:&lt;/strong&gt; This paper shows that there is a deep connection between the modern neural network (NN) computational approaches (e.g. &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/10.1111/iere.12575&#34; target=&#34;_blank&#34;&gt;Deep Equilibrium Nets&lt;/a&gt;; &lt;a href=&#34;https://doi.org/10.1016/j.jmoneco.2021.07.004&#34; target=&#34;_blank&#34;&gt;All-in-One Operator&lt;/a&gt;; &lt;a href=&#34;https://doi.org/10.1016/j.jedc.2024.104853&#34; target=&#34;_blank&#34;&gt;bc-MC Operator&lt;/a&gt; and the old-school PEA. This connection can be summarized as: NN + bc-MC operator + backpropagation â‰ˆ multi-innovation-draws PEA + OLS.&lt;/p&gt;

&lt;p&gt;On the one hand, the result of &lt;em&gt;TL;DR 2&lt;/em&gt; is expected, because both approaches share many features (Monte Carlo integration, focus on the ergodic set for the state vector). On the other hand, this could be surprising because there are also substantial differences: NNs are highly non-linear and their parameters are tuned using gradient descent and backpropagation, while the PEA typically relies on a linear or log-linear model, where the parameters are calculated using linear or non-linear least squares.&lt;/p&gt;

&lt;h2 id=&#34;i-theory&#34;&gt;I. Theory&lt;/h2&gt;

&lt;h3 id=&#34;setting&#34;&gt;Setting&lt;/h3&gt;

&lt;p&gt;In many cases, solving an economic model involves finding the parameter vector $\theta$ that minimizes a loss function of the form:&lt;/p&gt;

&lt;p&gt;$$ L(\theta) = E_{s} \Big( \Big[ E_{\varepsilon}(f(s, \varepsilon | \theta )) \Big]^2 \Big) $$&lt;/p&gt;

&lt;p&gt;where $s$ is a state vector, $\varepsilon$ a zero-mean random innovation vector and $f(.)$ a function that depends on the model. The expectation with respect to $\varepsilon$ is the usual expectation that shows up in Euler equations. The expectation with respect to the state vector $s$ is a bit more unusual, because we usually think about numerically solving an economic model using a fixed grid for $s$. Here we are saying: &amp;ldquo;I want to find $\theta$ such that the Euler equation holds, for all economically relevant values of the state vector $s$&amp;ldquo;, in the sense of minimizing the expected squared Euler residual over the ergodic distribution of states.&lt;/p&gt;

&lt;p&gt;Focusing on the ergodic distribution is a nice feature because large parts of the state space are actually never visited or visited with very small probability. Here, we enforce accuracy where the economy actually spends time, rather than uniformly over an arbitrary grid.&lt;/p&gt;

&lt;p&gt;With the NN computational approaches, $\theta$ is usually the parameter vector of a large NN (sometimes called &amp;ldquo;weights and biases&amp;rdquo;), that outputs the endogenous decision of agents (e.g. consumption functions of $A$ agents). The parameter vector $\theta$ can be calculated using gradient descent, using the update rule:&lt;/p&gt;

&lt;p&gt;$$ \theta_{i+1} = \theta_{i} - \gamma \nabla_{\theta} L(\theta_{i}) $$&lt;/p&gt;

&lt;p&gt;Where the gradient $\nabla_{\theta} L(\theta_{i})$ can be efficiently calculated using automatic differentiation and backpropagation, as long as you use Pytorch, Tensorflow, or something similar.&lt;/p&gt;

&lt;h3 id=&#34;single-or-double-monte-carlo&#34;&gt;Single or double Monte Carlo?&lt;/h3&gt;

&lt;p&gt;The loss function $L(\theta)$ contains two nested expectations. The &amp;ldquo;outside&amp;rdquo; expectation $E_{s}$ is standard and we approximate it using Monte Carlo integration (i.e. drawing $M$ samples and calculating the average: $E_{s} \approx 1/M \sum_{i=1}^{M}$).&lt;/p&gt;

&lt;p&gt;There is a subtle point for the &amp;ldquo;inside&amp;rdquo; (conditional on $s$) expectation $E_{\varepsilon}$. If the exogenous innovation vector $\varepsilon$ has discrete support (e.g. discrete Markov chain), $E_{\varepsilon}$ can be calculated exactly. For continuous distributions, one may use a deterministic quadrature scheme (e.g. Gauss-Hermite quadrature).&lt;/p&gt;

&lt;p&gt;However, if $\varepsilon$ is high-dimensional and/or continuous, one may instead use Monte Carlo integration to approximate the &amp;ldquo;inside&amp;rdquo; expectation operator ($E_{\varepsilon} \approx 1/N \sum_{i=1}^{N}$). The subtlety comes from the fact that taking the square of the empirical mean creates a bias, because of the variance formula $Var(X) = E(X^2) - E(X)^2 \Leftrightarrow E(X^2) = E(X)^2 + Var(X)$. A simple workaround consists in taking two independent copies of $\varepsilon$, denoted by $\varepsilon^1$ and $\varepsilon^2$, and using the fact that for independent variables, the product of expectations is the expectation of the product: $E[X_1 \times  X_2] = E[X_1] \times E[X_2] = E[X] \times E[X] = E[X]^2$. This is the trick behind the &lt;a href=&#34;https://doi.org/10.1016/j.jmoneco.2021.07.004&#34; target=&#34;_blank&#34;&gt;All-in-One Operator&lt;/a&gt;, which, applied to the loss function above, gives:&lt;/p&gt;

&lt;p&gt;$$ L_{M}(\theta) = \frac{1}{M} \sum_{m=1}^{M} f(s_m, \varepsilon^{1}_m | \theta ) f(s_m, \varepsilon^{2}_m | \theta ) $$&lt;/p&gt;

&lt;p&gt;But nothing prevents you from using more independent copies of $\varepsilon$. For instance, using three copies, one has $ \frac{1}{3}E[X_1 \times  X_2] + \frac{1}{3}E[X_1 \times  X_3] + \frac{1}{3}E[X_2 \times  X_3] = \frac{1}{3}  E[X]^2 +  \frac{1}{3}  E[X]^2 + \frac{1}{3}  E[X]^2 = E[X]^2$. One may even take $N$ independent copies of $\varepsilon$, in which case you get the &lt;a href=&#34;https://doi.org/10.1016/j.jedc.2024.104853&#34; target=&#34;_blank&#34;&gt;bc-MC Operator&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;$$ L_{M,N}(\theta) = \frac{2}{MN(N-1)} \sum_{m=1}^{M } \sum_{1\leq i &amp;lt; j}^{N} f(s_m, \varepsilon^{i}_m | \theta ) f(s_m, \varepsilon^{j}_m | \theta ) $$&lt;/p&gt;

&lt;p&gt;Using more independent copies tends to reduce the integration error, at the cost of adding more computing time.&lt;/p&gt;

&lt;h3 id=&#34;what-about-the-pea&#34;&gt;What about the PEA?&lt;/h3&gt;

&lt;p&gt;The PEA is easier to present using an example. Consider for instance a representative household choosing consumption $c_t$ and next period&amp;rsquo;s capital $k_{t+1}$ to maximize expected utility:&lt;/p&gt;

&lt;p&gt;$$
\max_{(c_t,k_{t+1})_{t=0}^{\infty}} \; E_0 \sum_{t=0}^\infty \beta^t \frac{c_t^{1-\sigma} - 1}{1-\sigma}
$$&lt;/p&gt;

&lt;p&gt;subject to the resource constraint:
$$
k_{t+1} = z_t k_t^{\alpha} - c_t + (1-\delta)k_t
$$&lt;/p&gt;

&lt;p&gt;and the law of motion for TFP:
$$
\log(z_{t+1}) = \rho \log(z_t) + \varepsilon_{t+1}
$$&lt;/p&gt;

&lt;p&gt;The associated FOC is:
$$ c_t^{-\sigma} = \beta E_t \big( c_{t+1}^{-\sigma} \left[\alpha z_{t+1} k_{t+1}^{\alpha-1} + 1-\delta \right] \big) $$&lt;/p&gt;

&lt;p&gt;which can also be rewritten as:&lt;/p&gt;

&lt;p&gt;$$
\frac{c_{t}^{-\sigma} - c_{ss}^{-\sigma}}{c_{ss}^{-\sigma}} = E_t \big( \beta \big(\frac{c_{t+1}}{c_{ss}} \big)^{-\sigma} \left[\alpha z_{t+1} k_{t+1}^{\alpha-1} + 1-\delta \right]  - 1 \big)
$$&lt;/p&gt;

&lt;p&gt;Now define $E_t[\phi_{t+1}]$ as the right-hand side of the previous equation. That is,&lt;/p&gt;

&lt;p&gt;$$
\phi_{t+1} \equiv \beta \big(\frac{c_{t+1}}{c_{ss}} \big)^{-\sigma} \left[\alpha z_{t+1} k_{t+1}^{\alpha-1} + 1-\delta \right] - 1
$$&lt;/p&gt;

&lt;p&gt;Note that if we know the value of the conditional expectation, we can recover the implied current consumption using:&lt;/p&gt;

&lt;p&gt;$c_t = c_{ss} (1 + E_t[\phi_{t+1}])^{-1/\sigma}$&lt;/p&gt;

&lt;p&gt;Knowing the current consumption, we can iterate the model forward and keep repeating this process. Yet, we do not know $E_t[\phi_{t+1}]$, so it appears that we are stuck.&lt;/p&gt;

&lt;p&gt;One solution is to assume that the conditional expectation is a linear function of some selected state variables:
$$
\phi_{t+1}(\theta) = \theta_0 + \theta_1 \log k_t + \theta_2 \log z_t + \theta_3 (\log k_t)^2 + \theta_4 (\log z_t)^2 + \theta_5 \log k_t \times \log z_t + \epsilon_t $$&lt;/p&gt;

&lt;p&gt;or more compactly written as:
$$ \phi_{t+1}(\theta) = s_{t}^{T} \theta + \epsilon_t $$&lt;/p&gt;

&lt;p&gt;The PEA then proceeds in two steps:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;For a given vector $\theta^{(i)}$, simulate the economy forward and store the data&lt;/li&gt;
&lt;li&gt;Given the data from step 1, update $\theta^{(i)}$ using a convex combination $\theta^{(i+1)} = \gamma \theta^{(i)} + (1 - \gamma) \theta^{OLS}$, where $\theta^{OLS}$ is the ordinary least squares estimate (OLS) of regressing $\phi_{t+1}(\theta^{(i)})$ on the state vector $s_t$.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This process is repeated until the parameter is no longer meaningfully updated: $d(\theta^{(i+1)}, \theta^{(i)}) \leq \text{tol}$, where $\text{tol}$ is a small real number, meaning that the actual guess for the conditional expectation matches the realized values.&lt;/p&gt;

&lt;p&gt;For future reference, note that $\theta^{OLS}$ solves the normal equations:&lt;/p&gt;

&lt;p&gt;$$
\frac{-2}{T} \sum_{t=1}^{T} s_t \Big( \phi_{t+1}(\theta^{(i)}) - s_t^{T} \theta^{OLS} \Big) = 0
$$&lt;/p&gt;

&lt;h3 id=&#34;back-to-the-bc-mc-operator&#34;&gt;Back to the bc-MC operator&lt;/h3&gt;

&lt;p&gt;As said previously, when using NN, the gradient of the loss function can be easily and efficiently calculated using backpropagation, as long as one uses the appropriate software (e.g. Pytorch, Tensorflow). Let&amp;rsquo;s now consider what happens when we want to calculate the gradient $\nabla_{\theta} L_{M,N}(\theta)$ &amp;ldquo;manually&amp;rdquo;. But let&amp;rsquo;s do that under two &amp;ldquo;PEA-style&amp;rdquo; restrictions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;$f(s_m, \varepsilon^{i}_m | \theta ) = g(s_m, \varepsilon^{i}_m | \theta) - h(s_m, | \theta)$,&lt;/li&gt;
&lt;li&gt;$h(s_m, | \theta) = s_m^T \theta$.
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first assumption is a separability assumption, which implies that when the loss function is equal to zero, $h(.)$ is the conditional expectation $ E_{ \varepsilon} [ g(s_m, \varepsilon^{i}_m | \theta) ]$. The second assumption asserts that this conditional expectation is a linear function of the state vector $s_m$. After some intermediate calculations (see the &lt;a href=&#34;https://doi.org/10.1016/j.econlet.2025.112790&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt;), one gets that the gradient is given by:&lt;/p&gt;

&lt;p&gt;$$
\nabla_{\theta} L_{M,N}(\theta) = \frac{-2}{M} \sum_{m=1}^{M} s_m \Big( \Big[ \frac{1}{N} \sum_{i=1}^{N} g(s_m, \varepsilon^{i}_m | \theta) \Big]- s_m^{T} \theta^{OLS} \Big) + R_{M,N}(\theta)
$$&lt;/p&gt;

&lt;p&gt;Note that the first term is identical to OLS normal equations above, where the dependent variable is an average over $N$ realizations $g(s_m, .)$. If we draw a single innovation per realization of the state vector ($N=1$), we are back to standard PEA.&lt;/p&gt;

&lt;p&gt;The second term $R_{M,N}(\theta)$ is a bit nasty. It captures the fact that we are aiming at a &amp;ldquo;moving target&amp;rdquo;: the conditional expectation is not a simple &amp;ldquo;fixed&amp;rdquo; independent variable; it also depends on the parameter $\theta$ we are trying to estimate. Fortunately, it is equal to zero in expectation at stationary points of the gradient ($\nabla_{\theta} L_{M,N}(\theta^{*}) = 0$). Practically, this means that we can focus on minimizing the first part of $\nabla_{\theta} L_{M,N}(\theta)$ (the &amp;ldquo;averaged OLS problem&amp;rdquo;), which is no more than a simple OLS regression of $y_m = \frac{1}{N} \sum_{i=1}^{N} g(s_m, \varepsilon^{i}_m | \theta)$ on $s_m$. Hence, we are back to the PEA, with the possibility of more accurately calculating the conditional expectation using more innovation draws.&lt;/p&gt;

&lt;h3 id=&#34;variance-reduction-under-a-computational-budget-constraint&#34;&gt;Variance reduction under a computational budget constraint&lt;/h3&gt;

&lt;p&gt;At this stage, it is not necessarily obvious that using more innovation draws per state is really needed. If more accuracy is needed when estimating $\theta$ at the OLS stage, why don&amp;rsquo;t we simply simulate longer series in step 1 of the PEA? Or said differently, let&amp;rsquo;s increase $M$ and call it a day. Spoiler alert: the reason is that there are asymmetries between drawing more state and innovation vectors, which I discuss below.&lt;/p&gt;

&lt;p&gt;First, note that drawing more state vectors is essentially a serial computation, because the state of the economy today depends on what happened yesterday. Instead, drawing more innovation vectors can be easily realized in parallel (given the current state, future realizations can be explored using a parallel for loop). This point is not even mentioned or used in the paper.&lt;/p&gt;

&lt;p&gt;Second, there are asymmetric costs between simulating the economy and the OLS step. Simulating the economy forward with $M$ steps, while using $N$ independent innovation draws per state vector, has a computational complexity of $O(MN)$. The computational complexity of the OLS estimator with $M$ observations and $k$ explanatory variables is approximately $O(Mk^2)$. Hence, increasing the length of the simulation ($M$) comes with a penalty at the OLS stage, which is not the case for increasing $N$, because additional innovation draws are first averaged before being used at the OLS stage. This discussion implies the following timing model ($T$ in seconds) for the full simulation + OLS package:&lt;/p&gt;

&lt;p&gt;$$ T = \alpha_0 + \alpha_{M} M + \alpha_{MN} M N $$&lt;/p&gt;

&lt;p&gt;Third, in general the distribution of the innovation vector is known, while the ergodic distribution of the state vector is unknown and only sequentially approximated during the minimization process. This matters because with known distributions, we can use low-discrepancy sequences to approximate $E_{\varepsilon}$ instead of using simple random draws.&lt;/p&gt;

&lt;p&gt;The above equation gives us a good model on how computing time changes with $M$ and $N$. The parameters $\alpha_{M}$ and $\alpha_{MN}$ can be estimated by varying $M$ and $N$ and using an OLS regression.&lt;/p&gt;

&lt;p&gt;We also need to understand how the choice of $M$ and $N$ impacts the accuracy of our numerical solution. In the paper, under the assumption that the state vectors are &lt;strong&gt;i.i.d&lt;/strong&gt;, I show that the expected average squared forecast error of the OLS model is proportional to:&lt;/p&gt;

&lt;p&gt;$$ \frac{1}{N^{\alpha}} \frac{k}{M - k - 1} $$.&lt;/p&gt;

&lt;p&gt;where $\alpha$ is between 1 (for standard random sampling) and 2 (low-discrepancy sequence in an ideal case).&lt;/p&gt;

&lt;p&gt;To simplify things, let&amp;rsquo;s consider the &lt;strong&gt;random sampling case&lt;/strong&gt; ($\alpha = 1$). Under that assumption, if one minimizes the expected average squared forecast error of the OLS model for a given computational budget $T$, one finds:&lt;/p&gt;

&lt;p&gt;$$ M^{\star} = \sqrt{\frac{(T - \alpha_{0}) (k+1)}{\alpha_{M}}}$$
$$ N^{\star} = \frac{\alpha_{M}}{\alpha_{MN}} \big( \frac{M^{\star}}{k+1} - 1 \big)$$&lt;/p&gt;

&lt;p&gt;where we have to round these numbers to the nearest positive integers. See the paper for the general case where $\alpha \neq 1$. The formula is more convoluted, but still manageable.&lt;/p&gt;

&lt;p&gt;The equation for $M^{\star}$ makes sense. If the cost of the OLS step decreases ($\alpha_{M}$ lower), the optimal length of the simulation ($M^{\star}$) increases. If the linear model for the conditional expectation has more explanatory variables ($k$), the optimal length of the simulation must increase.&lt;/p&gt;

&lt;p&gt;The equation for $N^{\star}$ is also intuitive. If the cost of the simulation step decreases ($\alpha_{MN}$ lower), the optimal length of the simulation ($N^{\star}$) increases.&lt;/p&gt;

&lt;p&gt;Note that the special case &amp;ldquo;standard PEA&amp;rdquo; ($N^{\star}=1$) does occur when $\alpha_{M} \rightarrow 0$. But in general $N^{\star} \approx \frac{\alpha_{M}}{\alpha_{MN}} \frac{M^{\star}}{k+1} $ is often bigger than 1.&lt;/p&gt;

&lt;h3 id=&#34;extension-to-serially-correlated-state-vectors&#34;&gt;Extension to serially correlated state vectors&lt;/h3&gt;

&lt;p&gt;The i.i.d. assumption for the state vectors is a bit too restrictive. Often, data comes from serially correlated series. For instance, the logarithm of TFP is often assumed to be AR(1):&lt;/p&gt;

&lt;p&gt;$$ \log(z_{t+1}) = \rho \log(z_{t}) + \varepsilon_{t+1} $$&lt;/p&gt;

&lt;p&gt;with $ | \rho |&amp;lt; 1 $ and $\varepsilon$ an i.i.d. zero-mean Gaussian random variable. Under the assumption that the state vector $s_t$ has such an AR(1) structure, with persistence parameter $ | \rho |&amp;lt; 1 $, the new optimal value for $M$ is given by:&lt;/p&gt;

&lt;p&gt;$$ M^{\star \star} = M^{\star}\frac{1 + \rho^2}{1 - \rho^2} $$&lt;/p&gt;

&lt;p&gt;This point appears in the Online Appendix of the paper.&lt;/p&gt;

&lt;p&gt;The serial correlation correction term $\frac{1 + \rho^2}{1 - \rho^2}$ increases the optimal value for $M$. This makes sense, because with serially correlated observations, each realization of $s_t$ is less information-rich (it is correlated with $s_{t-1}$). The larger the value for $|\rho|$, the bigger this correction term is.&lt;/p&gt;

&lt;h3 id=&#34;extension-to-log-linear-models&#34;&gt;Extension to log-linear models&lt;/h3&gt;

&lt;p&gt;Often, economic models are such that the &lt;strong&gt;logarithm&lt;/strong&gt; of the conditional expectation is a linear function of the state vector. Or more generally, it is linear in a continuous transformation of the state vector denoted by $x_t$ (e.g. taking logs):&lt;/p&gt;

&lt;p&gt;$E_{\varepsilon}\left[g(\boldsymbol{s}_t, \varepsilon) \mid \boldsymbol{s}_t \right] = \exp(\boldsymbol{x}_t&amp;rsquo; \boldsymbol{\theta})$.&lt;/p&gt;

&lt;p&gt;Fortunately, we can reuse the above framework, as discussed in the Online Appendix.&lt;/p&gt;

&lt;p&gt;At the OLS regression step, we can simply regress $\log(y_m)$ on $x_t$, where $y_m = \frac{1}{N} \sum_{i=1}^{N} g(s_m, \varepsilon^{i}_m | \theta)$, as before.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;ii-numerical-example-a-model-with-a-borrowing-constraint&#34;&gt;II. Numerical example: a model with a borrowing constraint&lt;/h2&gt;

&lt;p&gt;The PEA gracefully handles economic models with inequality constraints, so let&amp;rsquo;s study a standard consumption-savings problem, complicated by an occasionally binding investment constraint. The trick is to treat the Lagrange multiplier on the occasionally binding investment constraint as a residual variable that can be adjusted ex post.&lt;/p&gt;

&lt;p&gt;A central planner chooses consumption $c_t$ and next period&amp;rsquo;s capital $k_{t+1}$ to maximize expected lifetime utility&lt;/p&gt;

&lt;p&gt;$$
\max_{(c_t, k_{t+1})_{t=0}^{\infty}} \; E_0 \sum_{t=0}^\infty \beta^t \frac{c_t^{1-\sigma}-1}{1-\sigma}
$$&lt;/p&gt;

&lt;p&gt;subject to:&lt;/p&gt;

&lt;p&gt;1) a resource constraint:
  $$
  k_{t+1} = z_t k_t^\alpha - c_t + (1-\delta)k_t,
  $$&lt;/p&gt;

&lt;p&gt;2) a constraint on investment:
  $$
  k_{t+1} \geq (1-\delta)k_t,
  $$&lt;/p&gt;

&lt;p&gt;3) the law of motion for TFP:
  $$
  \log(z_{t+1}) = \rho \log(z_t) + \varepsilon_{t+1}.
  $$&lt;/p&gt;

&lt;p&gt;The associated FOCs are:
$$
c_t^{-\sigma} - \mu_t = \beta E_t \big( c_{t+1}^{-\sigma} \left[\alpha z_{t+1} k_{t+1}^{\alpha-1} + 1-\delta \right] - \mu_{t+1} (1 - \delta) \big), &lt;br /&gt;
$$&lt;/p&gt;

&lt;p&gt;$$
\mu_t ( k_{t+1} - (1-\delta)k_t) = 0
$$&lt;/p&gt;

&lt;p&gt;$$
\mu_t \geq 0
$$&lt;/p&gt;

&lt;h4 id=&#34;expectation-function-e-t-phi-t-1&#34;&gt;Expectation function $E_t[\phi_{t+1}]$:&lt;/h4&gt;

&lt;p&gt;Let us consider:
$$
\phi_{t+1} \equiv \beta  \Big( c_{t+1}^{-\sigma} \left[\alpha z_{t+1} k_{t+1}^{\alpha-1} + 1-\delta \right] - \mu_{t+1} (1 - \delta)
\Big)$$&lt;/p&gt;

&lt;p&gt;When the investment constraint does not bind ($\mu_t = 0$), the above FOC equation can be written as:&lt;/p&gt;

&lt;p&gt;$$ c_t^{-\sigma} = E&lt;em&gt;t[\phi&lt;/em&gt;{t+1}] $$&lt;/p&gt;

&lt;p&gt;So if we know $ E_t[\phi_{t+1}]$, we can find the implied consumption today. As in standard PEA, let&amp;rsquo;s assume a parametric expression for the conditional expectation. Let&amp;rsquo;s use the following log-log model:&lt;/p&gt;

&lt;p&gt;$$
\log(E_t[\phi_{t+1}]) = \theta_0 + \theta_1 \log k_t + \theta_2 \log z_t + \theta_3 \left(\log k_t\right)^2 + \theta_4 \left(\log z_t\right)^2 + \theta_5 \log k_t \cdot \log z_t = \boldsymbol{s}_t&amp;rsquo; \boldsymbol{\theta}
$$&lt;/p&gt;

&lt;h4 id=&#34;implied-consumption&#34;&gt;Implied consumption&lt;/h4&gt;

&lt;p&gt;Under the assumption that the constraint does not bind ($\mu_t = 0$), consumption in the current period is given by:&lt;/p&gt;

&lt;p&gt;$$
\tilde{c}_t = \exp(\boldsymbol{s}_t&amp;rsquo; \boldsymbol{\theta})^{-1/\sigma}
$$&lt;/p&gt;

&lt;p&gt;This consumption choice $\tilde{c}_t$ implies a savings choice: $\tilde{k}_{t+1} = z_t k_t^\alpha - \tilde{c}_t + (1-\delta)k_t$.&lt;/p&gt;

&lt;p&gt;Two cases can occur:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;If $\tilde{k}_{t+1} \geq (1-\delta)k_t$, then the irreversible investment constraint does not bind:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;$$ c_t = \tilde{c}_t $$
  $$ k_{t+1} = \tilde{k}_{t+1} $$
  $$ \mu_t = 0 $$&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;If $\tilde{k}_{t+1} &amp;lt; (1-\delta)k_t$, then the irreversible investment constraint binds and we recover $c_t$ from the budget constraint:
$$ c_t  = z_t k_t^\alpha $$
$$ k_{t+1}  = (1-\delta)k_t $$
$$ \mu_t &amp;gt; 0 $$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In case 2, the value of the Lagrange multiplier is then:&lt;/p&gt;

&lt;p&gt;$$
\mu_t = c_t^{-\sigma} - \beta E_t \big( c_{t+1}^{-\sigma} \left[\alpha z_{t+1} k_{t+1}^{\alpha-1} + 1-\delta \right] - \mu_{t+1} (1 - \delta) \big) \approx c_t^{-\sigma} - \exp(\boldsymbol{s}_t&amp;rsquo; \boldsymbol{\theta})
$$&lt;/p&gt;

&lt;p&gt;provided that $\exp(\boldsymbol{s}_t&amp;rsquo; \boldsymbol{\theta})$ correctly approximates the conditional expectation.&lt;/p&gt;

&lt;p&gt;Below is some code in Python that solves this model using this approach.&lt;/p&gt;

&lt;h4 id=&#34;packages-and-types&#34;&gt;Packages and Types&lt;/h4&gt;

&lt;p&gt;Let&amp;rsquo;s load the required packages and create a Class for convenience (some elements are useless, a clean-up is needed at some point).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import matplotlib.pyplot as plt

import random
import scipy.stats
import chaospy  ## for quadrature
from itertools import product
import os
import re
import subprocess
import shutil

import time
import pandas as pd
import numpy as np
from math import sqrt
from matplotlib import pyplot as plt
import matplotlib.cm as cm
import matplotlib.colors as mcolors
import matplotlib.ticker as mticker

import seaborn as sns; sns.set()
from tqdm import tqdm as tqdm
import datetime
from typing import Tuple
class Vector: pass
from scipy.stats import norm

import torch
from torch import nn
from torch.utils.data import DataLoader, Subset, Dataset, TensorDataset
from torch.nn.utils import clip_grad_norm_

# To create copies of NN
import copy
import matplotlib.ticker as mtick
# To use sparse kronecker product
from scipy import sparse

import itertools
# Interpolations
from scipy.interpolate import LinearNDInterpolator
import matplotlib.pyplot as plt
from scipy.interpolate import griddata
from scipy.interpolate import RegularGridInterpolator

# Regressions
import statsmodels.formula.api as smf
import statsmodels.api as sm
from statsmodels.stats.diagnostic import het_breuschpagan
lowess = sm.nonparametric.lowess

import quantecon as qe
from interpolation import interp
from quantecon.optimize import brentq
from numba import njit

import matplotlib.cm as cm
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.ticker import MaxNLocator

import platform,socket,re,uuid,json,psutil,logging, cpuinfo, shutil

from scipy.stats import chi2
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Store economic and bc-MC-PEA parameters
class MyParams():
    &amp;quot;&amp;quot;&amp;quot;
    N: number of draws for innovation vector (per state vector)
    M: number of draws for the state vector
    ...
    &amp;quot;&amp;quot;&amp;quot;
    def __init__(self, N, M, lr, optimizer, nb_epochs, order_gauss,
                 beta, alpha, gamma, delta, std_tfp, rho_tfp,
                 regression_two_steps, feasible_GLS, effective_sample_size):
        # Economic model parameters
        self.beta = beta # Discount factor (patience)
        self.alpha = alpha # Capital share in production
        self.gamma = gamma # CRRA coefficient
        self.one_min_gamma = 1 - gamma #pre-compute
        # depreciation rate capital
        self.delta = delta
        # Standard deviation exo random variables
        self.std_tfp = std_tfp #0.01
        # Mean value exo random variables
        self.mean_tfp = 1.0
        # Persistence params
        self.rho_tfp = rho_tfp # Persistence log TFP values
        # Non stochastic steady state calculations
        self.kss = ((1 - self.beta * (1 - self.delta)) / (self.alpha * self.beta)) ** (1 / (self.alpha - 1))
        self.std_k = 0 #std. dev capital
        self.css = self.kss**self.alpha - self.delta*self.kss
        self.std_c = 0 #std. dev consumption
        self.zss = 1
        self.std_z = 0
        self.tol_c = 1e-3 #to prevent negative consumption
        # Dependent variable in level or log
        self.formula = &amp;quot;&amp;quot;
        # Options for OLS regression
        self.center_dep_var = False #True #False #demean
        self.normalize_dep_var = False #True #False #divide by std. dev
        self.nb_expl_vars = 10   # including constant
        if self.nb_expl_vars not in (4, 6, 10):
            raise ValueError( f&amp;quot;nb_expl_vars must be one of (4, 6, 10); got {self.nb_expl_vars}&amp;quot;  )
        self.basis = 2          # 1: monomial, 2: Chebyshev
        if self.basis not in (1, 2):
            raise ValueError( f&amp;quot;basis must be either 1 (monomial) or 2 (Chebyshev); got {self.basis}&amp;quot; )
        self.regression_two_steps = regression_two_steps #Use the two-step regression described in appendix (approximation to full GLS)
        self.feasible_GLS = feasible_GLS #
        if self.regression_two_steps and self.feasible_GLS:
            raise RuntimeError(&amp;quot;Both regression_two_steps and feasible_GLS are True. Choose one of the options.&amp;quot;)
        # Correction for serial correlation in dependent variables
        self.effective_sample_size = effective_sample_size
        self.nb_shocks = 1
        ## State: Distribution of wealth + TFP (no persistence depreciation shocks)
        self.dim_state = 2
        ## Input for neural net
        self.dim_input = 2
        self.dim_output = 1
        # Nb agents:
        self.nb_agents = 1 #One representative household
        # Functions
        ## Utility
        if self.gamma != 1:
            self.u = lambda c: (1/self.one_min_gamma)*(c**(self.one_min_gamma) - 1)
        else:
            self.u = lambda c: torch.log(c)
        self.u_prime =  lambda c: c**(-self.gamma)
        self.u_prime_inv =  lambda c: c**(-(1/self.gamma))
        # bc-MC hyperparameters
        self.N = N #number of iid shocks used for each value of the state vector
        self.M = M #number of iid realization of the state vector
        self.MN = int(M*N)
        # To keep constant the number of function evaluations
        self.T = int((M*N)/2) #number
        self.distribution_shocks = &amp;quot;Normal&amp;quot; #&amp;quot;Normal&amp;quot; #Lognormal
        # Learning parameters
        self.lr = lr
        self.momentum = 0.9 #momentum for SGD with momentum
        self.optimizer = optimizer #&amp;quot;Adam&amp;quot; #default: #Adam or SGD or SWA
        self.freq_gamma = 0.95 #When using a scheduler for the learning rate, lr_{t} = freq_gamma*lr_{t-1}
        self.use_scheduler = False #If true, use a scheduler for the learning rate
        self.nb_epochs = nb_epochs
        self.freq_scheduler = 1000
        # GAUSSIAN QUADRATURE
        ## INNOVATION VECTOR
        strr = &amp;quot;chaospy.Normal(0, self.std_tfp)&amp;quot;
        self.distrib = eval(&#39;chaospy.J({})&#39;.format(strr))
        self.order_gauss = order_gauss
        nodes, weights = chaospy.generate_quadrature(self.order_gauss, self.distrib, rule = &amp;quot;gaussian&amp;quot;, sparse=True) #dist(self.order_gauss, self.distrib, rule = &amp;quot;gaussian&amp;quot;, sp=True)
        self.nodes = nodes
        self.nodes_flat =  self.nodes.flatten() #make 1d array
        self.weights = weights
        self.weights_torch = torch.tensor(weights)
        self.nodes_torch = torch.tensor(np.transpose(self.nodes)) #column=dim. Row=observation
        # Save the number of points for the guassian quadrature:
        self.N_gaussian = len(self.weights_torch)
        # Implied number of points for the current space (T=MN/2 &amp;lt;-&amp;gt; M = 2T/N)
        self.M_gaussian = int((2*self.T)/self.N_gaussian)
        self.MN_gaussian = self.N_gaussian*self.M_gaussian
        # Repeat nodes to match the number of function evaluations for the expectation
        self.nodes_torch_repeated = self.nodes_torch.repeat(self.M_gaussian, 1)


def show_params(params, limited=True):
    &amp;quot;&amp;quot;&amp;quot;
    Function to display parameter values
    &amp;quot;&amp;quot;&amp;quot;
    print(&amp;quot;learning rate: {}&amp;quot;.format(params.lr))
    print(&amp;quot;nb epochs: {}&amp;quot;.format(params.nb_epochs))
    print(&amp;quot;M: {}&amp;quot;.format(params.M))
    print(&amp;quot;N: {}&amp;quot;.format(params.N))
    print(&amp;quot;MN: {}&amp;quot;.format(params.MN))
    print(&amp;quot;T: {}&amp;quot;.format(params.T))
    print(&amp;quot;optimizer_chosen: {}&amp;quot;.format(params.optimizer))
    print(&amp;quot;use_scheduler: {}&amp;quot;.format(params.use_scheduler))
    print(&amp;quot;center_dep_var: {}&amp;quot;.format(params.center_dep_var))
    print(&amp;quot;normalize_dep_var: {}&amp;quot;.format(params.normalize_dep_var))
    print(&amp;quot;nb_expl_vars: {}&amp;quot;.format(params.nb_expl_vars))
    print(&amp;quot;basis: {}&amp;quot;.format(params.basis))
    print(&amp;quot;regression_two_steps: {}&amp;quot;.format(params.regression_two_steps))
    print(&amp;quot;feasible_GLS: {}&amp;quot;.format(params.feasible_GLS))
    print(&amp;quot;effective_sample_size: {}&amp;quot;.format(params.effective_sample_size))

# Plotting options
plot_scale = 0.75
plt.rcParams[&amp;quot;figure.figsize&amp;quot;] = (plot_scale*16, plot_scale*9)
# Controlling fontsizes
SMALL_SIZE = 12
MEDIUM_SIZE = SMALL_SIZE + 2
BIGGER_SIZE =  SMALL_SIZE + 4
plt.rcParams[&#39;legend.fontsize&#39;] = MEDIUM_SIZE
dpi_chosen=600 #control the quality of .png
linewidth_chosen = 2

# Current working directory
current_wd = os.getcwd()
output_extension = &amp;quot;example_1&amp;quot;
output_folder = output_extension + &amp;quot;/&amp;quot;
print(output_folder)

# Create folder if does not exist:
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;example_1/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s initialize an instance of MyParams():&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Economic Parameter. 
beta_chosen = 0.95 #discount factor
alpha_chosen = 0.3 #production params
std_tfp_chosen = 0.14 # Std log TFP. High value for constraint to bind
gamma_chosen = 1.0 #CRRA parameter
rho_chosen = 0.8 #persistence TFP
delta_chosen = 0.1 #depreciation rate

# bc-MC-PEA hyperparamters
M_chosen = 200 #Nb draws state vector
N_chosen = 2 #Nb draws innovation vector for each realization of the state vector
lr_chosen = 1e-5 #1e-4 #4 #1e-4 #3 #5 #1e-3 #default: 1e-4 #3 #Learning rate. Useful when using gradient descent instead of OLS
nb_epochs_chosen = 2000 #
order_gauss_chosen = 5 #number of Gaussian nodes for integration wrt to innovation vector
optimizer_chosen = &amp;quot;Adam&amp;quot; 

# bc-MC-PEA Options
regression_two_steps_chosen = False
feasible_GLS_chosen = False
effective_sample_size_chosen = True

# Extra hyperparamters (not used here)
mu_chosen = 1e-5 
mu_threshold = 1e-10 
mu_decay_chosen = 1.0 
use_Lookahead_chosen = False #Lookahead optimizer

params = MyParams(N_chosen, M_chosen, lr_chosen, optimizer_chosen,
                  nb_epochs_chosen, order_gauss_chosen,
                  beta_chosen, alpha_chosen, gamma_chosen, delta_chosen,
                  std_tfp_chosen, rho_chosen,
                  regression_two_steps_chosen,
                  feasible_GLS_chosen, effective_sample_size_chosen)

show_params(params)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;learning rate: 1e-05
nb epochs: 2000
M: 200
N: 2
MN: 400
T: 200
optimizer_chosen: Adam
use_scheduler: False
center_dep_var: False
normalize_dep_var: False
nb_expl_vars: 10
basis: 2
regression_two_steps: False
feasible_GLS: False
effective_sample_size: True
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;initialization&#34;&gt;Initialization&lt;/h4&gt;

&lt;p&gt;We use the following update rule for finding $\theta^{*}$:&lt;/p&gt;

&lt;p&gt;$\theta^{(i+1)} = \gamma \theta^{(i)} + (1 - \gamma) \theta^{OLS}$, with $\gamma \in (0,1)$.&lt;/p&gt;

&lt;p&gt;We need a starting value $\theta^{(0)}$.&lt;/p&gt;

&lt;p&gt;Here, let&amp;rsquo;s solve the model &lt;strong&gt;without&lt;/strong&gt; the irreversible investment constraint using a &lt;strong&gt;1st order-linearization&lt;/strong&gt; and use some simulated data to estimate $\theta^{(0)}$. This is easy to do thanks to Dynare and this gives us a reasonable starting point.&lt;/p&gt;

&lt;p&gt;Below is a somewhat hacky way to get Dynare within Python:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I write the .mod file of the model without the irreversible investment constraint to disk,&lt;/li&gt;
&lt;li&gt;I call Octave and Dynare to solve and simulate the model at 1st order.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For this to work, &lt;strong&gt;you need to have Octave and Dynare installed on your machine&lt;/strong&gt; (it&amp;rsquo;s free and open source, see the section &amp;ldquo;Using Dynare with Octave&amp;rdquo; &lt;a href=&#34;https://www.dynare.org/resources/quick_start/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; ).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fname = &amp;quot;neogrowth.mod&amp;quot;
dirpath = os.getcwd()  # Get the current working directory
fpath = os.path.join(dirpath, fname)

# Content of the .mod file.
file_content_1 = &amp;quot;&amp;quot;&amp;quot;
% optimal_growth.mod
% Dynare file for the standard optimal growth model (first-order approximation)

var k c z;
varexo eps;

parameters beta gamma alpha delta rho sigma_eps;

% Parameter values
beta      = {beta};
gamma     = {gamma};      % CRRA coefficient
alpha     = {alpha};
delta     = {delta};
rho       = {rho_tfp};
sigma_eps = {std_tfp};

model;
% Euler equation (after substituting the marginal utility condition)
c^(-gamma) = beta * c(+1)^(-gamma) * ( alpha * z(+1) * k^(alpha-1) + 1 - delta );

% Resource constraint (law of motion for capital)
k = z * k(-1)^alpha - c + (1-delta)*k(-1);

% Technology process (AR(1) in logs)
log(z) = rho*log(z(-1)) + eps;

end;

initval;
% Initial guesses for the steady state
k   = ((alpha*beta)/(1 - beta*(1-delta)))^(1/(1-alpha));
c   = ((alpha*beta)/(1 - beta*(1-delta)))^(alpha/(1-alpha)) - delta*(((alpha*beta)/(1 - beta*(1-delta)))^(alpha/(1-alpha)));
z   = 1;
eps = 0;
end;

steady;
check;

shocks;
var eps = sigma_eps^2;
end;

% IRF
stoch_simul(order=1, irf=100);

% SIMULATED SERIES
stoch_simul(periods=50000);
&amp;quot;&amp;quot;&amp;quot;.format(beta = params.beta, alpha = params.alpha,  gamma = params.gamma,
           delta = params.delta, std_tfp = params.std_tfp, rho_tfp = params.rho_tfp)

file_content = file_content_1
# Concat stings
# Write the content to the file
with open(fpath, &amp;quot;w&amp;quot;) as file:
    file.write(file_content)

# Write to disk an Octave script to solve and simulate the model
file_content_1 = r&amp;quot;&amp;quot;&amp;quot;
if exist(&#39;OCTAVE_VERSION&#39;, &#39;builtin&#39;)

    function T = cell2table(C, varargin)
        if nargin &amp;gt; 1
            opts = varargin{2};
            varname = opts{1};
        else
            varname = &#39;Var1&#39;;
        end
        T = struct();
        for i = 1:size(C,2)
            T.(varname) = C(:,i);
        end
    end

    function T = struct2table(S, varargin)
        T = S;
    end

    function T = array2table(A, varargin)
        if nargin &amp;gt; 1
            opts = varargin{2};
            varnames = opts{1};
        else
            nvars = size(A,2);
            varnames = cell(1, nvars);
            for i = 1:nvars
                varnames{i} = sprintf(&#39;Var%d&#39;, i);
            end
        end

        T = struct();
        for i = 1:size(A,2)
            if iscell(varnames)
                fieldname = varnames{i};
            else
                fieldname = varnames;
            end
            T.(fieldname) = A(:,i);
        end
    end

    function writetable(T, filename)
        fid = fopen(filename, &#39;w&#39;);
        fields = fieldnames(T);

        % Write header
        for i = 1:length(fields)
            fprintf(fid, &#39;%s&#39;, fields{i});
            if i &amp;lt; length(fields)
                fprintf(fid, &#39;,&#39;);
            else
                fprintf(fid, &#39;\n&#39;);
            end
        end

        % Number of rows
        nRows = length(T.(fields{1}));

        % Write data
        for row = 1:nRows
            for col_idx = 1:length(fields)
                col = T.(fields{col_idx});
                value = col(row,:);
                if iscell(col)
                    fprintf(fid, &#39;%s&#39;, col{row});
                elseif ischar(value)
                    fprintf(fid, &#39;%s&#39;, strtrim(value));
                elseif isnumeric(value)
                    fprintf(fid, &#39;%g&#39;, value);
                else
                    error(&#39;writetable: unsupported data type in column %d&#39;, col_idx);
                end

                if col_idx &amp;lt; length(fields)
                    fprintf(fid, &#39;,&#39;);
                else
                    fprintf(fid, &#39;\n&#39;);
                end
            end
        end

        fclose(fid);
    end



end

% Go to working directory
% cd &#39;/content&#39;;

% Run Dynare
dynare neogrowth.mod noclearall

% Postprocess
k_pos = strmatch(&#39;k&#39;, M_.endo_names, &#39;exact&#39;);
c_pos = strmatch(&#39;c&#39;, M_.endo_names, &#39;exact&#39;);
z_pos = strmatch(&#39;z&#39;, M_.endo_names, &#39;exact&#39;);

var_positions = [k_pos; c_pos; z_pos];
Sim_series = oo_.endo_simul(var_positions, :)&#39;;
var_names = M_.endo_names_long(var_positions, :);

if ~exist(&#39;output/Linearization&#39;, &#39;dir&#39;)
    mkdir(&#39;output/Linearization&#39;);
end

% Save steady state values manually
var_list = cellstr(oo_.var_list);  % Variable names
ss_values = oo_.mean;              % Steady state values

fid = fopen(&#39;output/Linearization/SS_values.csv&#39;, &#39;w&#39;);
fprintf(fid, &#39;Variable,MeanValue\n&#39;);  % Header

for i = 1:length(var_list)
    fprintf(fid, &#39;%s,%g\n&#39;, var_list{i}, ss_values(i));
end

fclose(fid);


% Save simulated series
%Sim_table = array2table(Sim_series, &#39;VariableNames&#39;, cellstr(var_names));
%writetable(Sim_table, &#39;output/Linearization/Sim_series.csv&#39;);

% Save Sim_series manually
csvwrite(&#39;output/Linearization/Sim_series_only_data.csv&#39;, Sim_series);

% Also write header separately
fid = fopen(&#39;output/Linearization/Sim_series.csv&#39;, &#39;w&#39;);
fprintf(fid, &#39;k,c,z\n&#39;); % header with variable names

data = Sim_series; % already transposed correctly (observations x variables)

for i = 1:size(data,1)
    fprintf(fid, &#39;%g,%g,%g\n&#39;, data(i,1), data(i,2), data(i,3));
end

fclose(fid);

% State-space matrices
A = oo_.dr.ghx(oo_.dr.inv_order_var(M_.state_var&#39;), :);
B = oo_.dr.ghu(oo_.dr.inv_order_var(M_.state_var&#39;), :);
control = (1:size(oo_.dr.ghu,1))&#39;;
state = M_.state_var&#39;;
for j = 1:length(state)
    control(control == state(j)) = [];
end
C = oo_.dr.ghx(oo_.dr.inv_order_var(control), :);
D = oo_.dr.ghu(oo_.dr.inv_order_var(control), :);

S_variables_names = M_.endo_names(state,:);
X_variables_names = M_.endo_names(control,:);
shocks_names = M_.exo_names;

% Save variable names
writetable(cell2table(cellstr(S_variables_names)), &#39;output/Linearization/state_variables_names.csv&#39;);
writetable(cell2table(cellstr(X_variables_names)), &#39;output/Linearization/control_variables_names.csv&#39;);
writetable(cell2table(cellstr(shocks_names)), &#39;output/Linearization/exo_variables_names.csv&#39;);

% Save matrices A, B, C, D
csvwrite(&#39;output/Linearization/A.csv&#39;, A);
csvwrite(&#39;output/Linearization/B.csv&#39;, B);
csvwrite(&#39;output/Linearization/C.csv&#39;, C);
csvwrite(&#39;output/Linearization/D.csv&#39;, D);

% Simulations with shocks
len_T = 10;
e1 = zeros(len_T, 1);
e1(1) = 1.0;
horizon = length(e1) + 1;
shocks = zeros(M_.exo_nbr, horizon);
shocks(strcmp(cellstr(shocks_names), &#39;eps&#39;), 2:horizon) = e1;
Ssim = zeros(length(state), horizon);
Xsim = zeros(length(control), horizon);

for j = 2:horizon
    Ssim(:,j) = A * Ssim(:,j-1) + B * shocks(:,j);
    Xsim(:,j) = C * Ssim(:,j-1) + D * shocks(:,j);
end

csvwrite(&#39;output/Linearization/Ssim.csv&#39;, Ssim&#39;);
csvwrite(&#39;output/Linearization/Xsim.csv&#39;, Xsim&#39;);
&amp;quot;&amp;quot;&amp;quot;

fname = &amp;quot;solve_neogrowth_octave.m&amp;quot;
dirpath = os.getcwd()  # Get the current working directory
fpath = os.path.join(dirpath, fname)

file_content = file_content_1
# Concat stings
# Write the content to the file
with open(fpath, &amp;quot;w&amp;quot;) as file:
    file.write(file_content)

    
print(&amp;quot;Calculating linearized model using Octave Dynare&amp;quot;)
# Call Octave &amp;amp; Dynare
!octave solve_neogrowth_octave.m

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Calculating linearized model using Octave Dynare
Starting Dynare (version 6.0).
Calling Dynare with arguments: noclearall
Starting preprocessing of the model file ...
Found 3 equation(s).
Evaluating expressions...
Computing static model derivatives (order 1).
Normalizing the static model...
Finding the optimal block decomposition of the static model...
2 block(s) found:
  1 recursive block(s) and 1 simultaneous block(s).
  the largest simultaneous block has 2 equation(s)
                                 and 2 feedback variable(s).
Computing dynamic model derivatives (order 2).
Normalizing the dynamic model...
Finding the optimal block decomposition of the dynamic model...
2 block(s) found:
  1 recursive block(s) and 1 simultaneous block(s).
  the largest simultaneous block has 2 equation(s)
                                 and 2 feedback variable(s).
Preprocessing completed.
Preprocessing time: 0h00m00s.

STEADY-STATE RESULTS:

k        2.62575
c        1.07333
z        1

EIGENVALUES:
         Modulus             Real        Imaginary
             0.8              0.8                0
           0.838            0.838                0
           1.256            1.256                0
       6.646e+17        6.646e+17                0

There are 2 eigenvalue(s) larger than 1 in modulus for 2 forward-looking variable(s)
The rank condition is verified.


MODEL SUMMARY

  Number of variables:         3
  Number of stochastic shocks: 1
  Number of state variables:   2
  Number of jumpers:           2
  Number of static variables:  0


MATRIX OF COVARIANCE OF EXOGENOUS SHOCKS
Variables         eps
eps          0.019600

POLICY AND TRANSITION FUNCTIONS
                                   k               c               z
Constant                    2.625746        1.073331        1.000000
k(-1)                       0.838003        0.214628               0
z(-1)                       0.686992        0.381732        0.800000
eps                         0.858741        0.477165        1.000000


THEORETICAL MOMENTS
VARIABLE         MEAN  STD. DEV.   VARIANCE
k              2.6257     0.8267     0.6834
c              1.0733     0.2591     0.0671
z              1.0000     0.2333     0.0544



MATRIX OF CORRELATIONS
Variables         k       c       z
k            1.0000  0.9876  0.7354
c            0.9876  1.0000  0.8327
z            0.7354  0.8327  1.0000



COEFFICIENTS OF AUTOCORRELATION
Order          1       2       3       4       5
k         0.9806  0.9358  0.8755  0.8067  0.7344
c         0.9626  0.9064  0.8393  0.7671  0.6939
z         0.8000  0.6400  0.5120  0.4096  0.3277

MODEL SUMMARY

  Number of variables:         3
  Number of stochastic shocks: 1
  Number of state variables:   2
  Number of jumpers:           2
  Number of static variables:  0


MATRIX OF COVARIANCE OF EXOGENOUS SHOCKS
Variables         eps
eps          0.019600

POLICY AND TRANSITION FUNCTIONS
                                   k               c               z
Constant                    2.627763        1.071313        1.000000
(correction)                0.002018       -0.002018               0
k(-1)                       0.838003        0.214628               0
z(-1)                       0.686992        0.381732        0.800000
eps                         0.858741        0.477165        1.000000
k(-1),k(-1)                -0.006461       -0.013885               0
z(-1),k(-1)                 0.087580        0.034525               0
z(-1),z(-1)                -0.040418       -0.066454       -0.080000
eps,eps                     0.473559        0.194394        0.500000
k(-1),eps                   0.109475        0.043157               0
z(-1),eps                   0.757695        0.311030        0.800000


MOMENTS OF SIMULATED VARIABLES
VARIABLE              MEAN       STD. DEV.        VARIANCE        SKEWNESS        KURTOSIS
k                 2.803683        0.859478        0.738702        1.011294        2.092793
c                 1.110625        0.255746        0.065406        0.671535        0.805383
z                 1.019190        0.233502        0.054523        0.706720        0.814589


CORRELATION OF SIMULATED VARIABLES
VARIABLE         k       c       z
k           1.0000  0.9824  0.7169
c           0.9824  1.0000  0.8282
z           0.7169  0.8282  1.0000


AUTOCORRELATION OF SIMULATED VARIABLES
VARIABLE         1       2       3       4       5
k           0.9788  0.9302  0.8654  0.7927  0.7174
c           0.9579  0.8965  0.8250  0.7499  0.6752
z           0.7827  0.6114  0.4776  0.3748  0.2973
Total computing time : 0h00m03s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, let&amp;rsquo;s load the simulated series and estimate our first first $\theta^{(0)}$:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#Load simulated data and fit linear model
SS_values = pd.read_csv(&amp;quot;output/Linearization/SS_values.csv&amp;quot;)
print(SS_values)

Sim_series = pd.read_csv(&amp;quot;output/Linearization/Sim_series.csv&amp;quot;)
print(Sim_series)

# Load the data
Sim_series = pd.read_csv(&amp;quot;output/Linearization/Sim_series.csv&amp;quot;)

## Simulate realization conditional expectation
Sim_series[&#39;c_plus_1&#39;] = Sim_series[&#39;c&#39;].shift(-1)
Sim_series[&#39;z_plus_1&#39;] = Sim_series[&#39;z&#39;].shift(-1)
Sim_series[&#39;k_plus_1&#39;] = Sim_series[&#39;k&#39;].shift(-1)
# Conditional expectation
Sim_series[&#39;cond_exp&#39;] = params.beta  * (Sim_series[&#39;c_plus_1&#39;]**(-params.gamma)) * ( params.alpha * Sim_series[&#39;z_plus_1&#39;] * Sim_series[&#39;k_plus_1&#39;]**(params.alpha - 1) + 1 - params.delta )
# Production
Sim_series[&#39;cash&#39;] = Sim_series[&#39;z&#39;] * Sim_series[&#39;k&#39;]**params.alpha + (1 - params.delta)*Sim_series[&#39;k&#39;] - Sim_series[&#39;c&#39;]
# Log tfp
Sim_series[&#39;a&#39;] = np.log(Sim_series[&#39;z&#39;])
params.std_z = np.std(Sim_series[&#39;z&#39;])

# Centered vars
Sim_series[&#39;c_demeaned&#39;] = Sim_series[&#39;c&#39;] - params.css
Sim_series[&#39;a_demeaned&#39;] = Sim_series[&#39;a&#39;] # mean is 0
Sim_series[&#39;z_demeaned&#39;] = Sim_series[&#39;z&#39;] - params.zss
Sim_series[&#39;k_demeaned&#39;] = Sim_series[&#39;k&#39;] - params.kss

# Normalize vars:
params.std_c = np.std(Sim_series[&#39;c&#39;])
params.std_a = np.std(Sim_series[&#39;a&#39;])
params.std_z = np.std(Sim_series[&#39;z&#39;])
params.std_k = np.std(Sim_series[&#39;k&#39;])

Sim_series[&#39;c_normalized&#39;] = Sim_series[&#39;c_demeaned&#39;]/params.std_c
Sim_series[&#39;a_normalized&#39;] = Sim_series[&#39;a_demeaned&#39;]/params.std_a
Sim_series[&#39;z_normalized&#39;] = Sim_series[&#39;z_demeaned&#39;]/params.std_z
Sim_series[&#39;k_normalized&#39;] = Sim_series[&#39;k_demeaned&#39;]/params.std_k

fig, (ax1, ax2, ax3) = plt.subplots(1, 3)
fig.suptitle(&#39;Log variables&#39;)
ax1.hist(np.log(Sim_series[&#39;c&#39;]))
ax1.set_title(&amp;quot;Log c&amp;quot;)
ax2.hist(Sim_series[&#39;a&#39;])
ax2.set_title(&amp;quot;a (log z)&amp;quot;)
ax3.hist(np.log(Sim_series[&#39;k&#39;]))
ax3.set_title(&amp;quot;Log k&amp;quot;)
plt.show()

fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)
fig.suptitle(&#39;Normalized variables&#39;)
ax1.hist(Sim_series[&#39;c_normalized&#39;])
ax1.set_title(&amp;quot;c normalized&amp;quot;)
ax2.hist(Sim_series[&#39;a_normalized&#39;])
ax2.set_title(&amp;quot;a normalized&amp;quot;)
ax3.hist(Sim_series[&#39;k_normalized&#39;])
ax3.set_title(&amp;quot;k normalized&amp;quot;)
ax4.hist(Sim_series[&#39;z_normalized&#39;])
ax4.set_title(&amp;quot;z normalized&amp;quot;)
plt.show()

# Create a dataframe:
df_Dynare = pd.DataFrame({&#39;k&#39;: Sim_series[&#39;k&#39;], &#39;z&#39;: Sim_series[&#39;z&#39;], &#39;a&#39;: Sim_series[&#39;a&#39;],
                          &#39;k_demeaned&#39;: Sim_series[&#39;k_demeaned&#39;], &#39;a_demeaned&#39;: Sim_series[&#39;a_demeaned&#39;], &#39;z_demeaned&#39;: Sim_series[&#39;z_demeaned&#39;],
                          &#39;k_normalized&#39;: Sim_series[&#39;k_normalized&#39;], &#39;a_normalized&#39;: Sim_series[&#39;a_normalized&#39;], &#39;z_normalized&#39;: Sim_series[&#39;z_normalized&#39;],
                          &#39;cond_exp&#39;:  Sim_series[&#39;cond_exp&#39;],
                          &#39;log_cond_exp&#39;:  np.log(Sim_series[&#39;cond_exp&#39;])})

print(df_Dynare.head())

# If required, transform explanatory variables (demean, normalize)
if (params.center_dep_var == True) &amp;amp; (params.normalize_dep_var == True):
    x1_chosen = &amp;quot;k_normalized&amp;quot;
    x2_chosen = &amp;quot;a_normalized&amp;quot;
elif (params.center_dep_var == True) &amp;amp; (params.normalize_dep_var == False):
    x1_chosen = &amp;quot;k_demeaned&amp;quot;
    x2_chosen = &amp;quot;a_demeaned&amp;quot;
else:
    x1_chosen = &amp;quot;np.log(k)&amp;quot;
    x2_chosen = &amp;quot;a&amp;quot;

# OLS formula to use, which depends on the number of explanatory variables and on the basis function used. 
if params.nb_expl_vars == 4:
    # only main + interaction
    formula_OLS = (
        f&amp;quot;log_cond_exp ~ &amp;quot;
        f&amp;quot;{x1_chosen} + {x2_chosen} + {x1_chosen}*{x2_chosen}&amp;quot;
    )

elif params.nb_expl_vars == 6:
    if params.basis == 1:
        # monomial up to degree 2
        formula_OLS = (
            f&amp;quot;log_cond_exp ~ &amp;quot;
            f&amp;quot;{x1_chosen} + {x2_chosen} + {x1_chosen}*{x2_chosen} + &amp;quot;
            f&amp;quot;I({x1_chosen}**2) + I({x2_chosen}**2)&amp;quot;
        )
    else:
        # Chebyshev up to order 2
        formula_OLS = (
            f&amp;quot;log_cond_exp ~ &amp;quot;
            f&amp;quot;{x1_chosen} + {x2_chosen} + {x1_chosen}*{x2_chosen} + &amp;quot;
            f&amp;quot;I({x1_chosen}**2 - 1) + I({x2_chosen}**2 - 1)&amp;quot;
        )

elif params.nb_expl_vars == 10:
    if params.basis == 1:
        # monomial up to degree 3
        formula_OLS = (
            f&amp;quot;log_cond_exp ~ &amp;quot;
            f&amp;quot;{x1_chosen} + {x2_chosen} + {x1_chosen}*{x2_chosen} + &amp;quot;
            f&amp;quot;I({x1_chosen}**2) + I({x2_chosen}**2) + &amp;quot;
            f&amp;quot;I({x1_chosen}**3) + I({x1_chosen}**2*{x2_chosen}) + &amp;quot;
            f&amp;quot;I({x1_chosen}*{x2_chosen}**2) + I({x2_chosen}**3)&amp;quot;
        )
    else:
        # Chebyshev up to order 3
        formula_OLS = (
            f&amp;quot;log_cond_exp ~ &amp;quot;
            f&amp;quot;{x1_chosen} + {x2_chosen} + {x1_chosen}*{x2_chosen} + &amp;quot;
            f&amp;quot;I({x1_chosen}**2 - 1) + I({x2_chosen}**2 - 1) + &amp;quot;
            f&amp;quot;I(4*{x1_chosen}**3 - 3*{x1_chosen}) + &amp;quot;
            f&amp;quot;I(4*{x2_chosen}**3 - 3*{x2_chosen}) + &amp;quot;
            f&amp;quot;I(({x1_chosen}**2 - 1)*{x2_chosen}) + &amp;quot;
            f&amp;quot;I({x1_chosen}*({x2_chosen}**2 - 1))&amp;quot;
        )

else:
    raise ValueError(
        f&amp;quot;nb_expl_vars must be one of 4,6,10; got {params.nb_expl_vars}&amp;quot;
    )

# estimate model using OLS
model = smf.ols(formula=formula_OLS, data=df_Dynare).fit()

print(model.summary())
plt.hist(model.resid)
plt.show()

coeff_vector = model.params
print(coeff_vector)

coeff_array_0 = model.params.values
print(coeff_array_0)

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  Variable  MeanValue
0        k    2.80368
1        c    1.11063
2        z    1.01919
             k         c         z
0      2.49443  0.995207  0.843225
1      2.49373  1.029550  0.971857
2      2.45133  1.005590  0.921800
3      2.48612  1.036100  1.005670
4      2.58609  1.082710  1.089010
...        ...       ...       ...
49995  2.63105  1.044140  0.895067
49996  2.56844  1.036660  0.925521
49997  2.73110  1.141380  1.176080
49998  2.76882  1.122660  1.060340
49999  2.81345  1.137810  1.075140

[50000 rows x 3 columns]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;bc-MC-PEA_10_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;bc-MC-PEA_10_2.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         k         z         a  k_demeaned  a_demeaned  z_demeaned  \
0  2.49443  0.843225 -0.170521   -0.131316   -0.170521   -0.156775   
1  2.49373  0.971857 -0.028547   -0.132016   -0.028547   -0.028143   
2  2.45133  0.921800 -0.081427   -0.174416   -0.081427   -0.078200   
3  2.48612  1.005670  0.005654   -0.139626    0.005654    0.005670   
4  2.58609  1.089010  0.085269   -0.039656    0.085269    0.089010   

   k_normalized  a_normalized  z_normalized  cond_exp  log_cond_exp  
0     -0.152851     -0.756166     -0.671641  0.972367     -0.028022  
1     -0.153666     -0.126588     -0.120568  0.989717     -0.010337  
2     -0.203019     -0.361083     -0.335017  0.971439     -0.028977  
3     -0.162524      0.025072      0.024291  0.937091     -0.064975  
4     -0.046159      0.378120      0.381329  0.896667     -0.109071  
                            OLS Regression Results                            
==============================================================================
Dep. Variable:           log_cond_exp   R-squared:                       0.959
Model:                            OLS   Adj. R-squared:                  0.959
Method:                 Least Squares   F-statistic:                 1.315e+05
Date:                Wed, 14 Jan 2026   Prob (F-statistic):               0.00
Time:                        11:39:46   Log-Likelihood:                 82307.
No. Observations:               49999   AIC:                        -1.646e+05
Df Residuals:                   49989   BIC:                        -1.645e+05
Df Model:                           9                                         
Covariance Type:            nonrobust                                         
=========================================================================================================
                                            coef    std err          t      P&amp;gt;|t|      [0.025      0.975]
---------------------------------------------------------------------------------------------------------
Intercept                                 0.3344      0.075      4.482      0.000       0.188       0.481
np.log(k)                                -0.4777      0.071     -6.747      0.000      -0.616      -0.339
a                                        -0.3446      0.076     -4.545      0.000      -0.493      -0.196
np.log(k):a                               0.1172      0.065      1.805      0.071      -0.010       0.244
I(np.log(k) ** 2 - 1)                    -0.1504      0.029     -5.183      0.000      -0.207      -0.094
I(a ** 2 - 1)                             0.0180      0.044      0.406      0.685      -0.069       0.105
I(4 * np.log(k) ** 3 - 3 * np.log(k))     0.0122      0.002      5.189      0.000       0.008       0.017
I(4 * a ** 3 - 3 * a)                     0.0118      0.006      1.999      0.046       0.000       0.023
I((np.log(k) ** 2 - 1) * a)              -0.0273      0.031     -0.873      0.383      -0.089       0.034
I(np.log(k) * (a ** 2 - 1))              -0.0580      0.043     -1.362      0.173      -0.142       0.026
==============================================================================
Omnibus:                      209.185   Durbin-Watson:                   1.991
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              212.146
Skew:                          -0.155   Prob(JB):                     8.57e-47
Kurtosis:                       3.072   Cond. No.                     3.12e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.12e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;bc-MC-PEA_files/bc-MC-PEA_10_4.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Intercept                                0.334417
np.log(k)                               -0.477687
a                                       -0.344563
np.log(k):a                              0.117191
I(np.log(k) ** 2 - 1)                   -0.150438
I(a ** 2 - 1)                            0.018025
I(4 * np.log(k) ** 3 - 3 * np.log(k))    0.012195
I(4 * a ** 3 - 3 * a)                    0.011829
I((np.log(k) ** 2 - 1) * a)             -0.027310
I(np.log(k) * (a ** 2 - 1))             -0.058041
dtype: float64
[ 0.3344173  -0.47768687 -0.34456269  0.11719071 -0.15043791  0.01802458
  0.01219452  0.01182905 -0.02730956 -0.05804076]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;estimation-of-the-computational-cost-model-t-alpha-0-alpha-m-m-alpha-mn-m-n&#34;&gt;Estimation of the computational cost model $ T = \alpha_0 + \alpha_{M} M + \alpha_{MN} M N $&lt;/h4&gt;

&lt;p&gt;In order to use the formulas for $M^{\star}$ and $N^{\star}$, we also need the values for $\alpha_M$ and $\alpha_{MN}$.&lt;/p&gt;

&lt;p&gt;One approach is to actually try different values for $(M,N)$, store the computing time, and then use OLS to estimate $\alpha_{M}$ and $\alpha_{MN}$. This is what I do for the paper (see &lt;a href=&#34;https://github.com/JulienPascal/bc-MC-PEA/blob/main/3.irreversible_investment/irreversible_investment_Colab_9.ipynb&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Here, let&amp;rsquo;s use a shortcut. Let&amp;rsquo;s pretend we already know the ratio $\frac{\alpha_M}{\alpha_{MN}}$ and that we are using a given value for $M$ (e.g. $M = 1000$). The above formulas, using the serial correlation correction term, tell us that the optimal corresponding choice for $N$ is given by:&lt;/p&gt;

&lt;p&gt;$$ N^{\star} = \frac{\alpha_{M}}{\alpha_{MN}} \big(\frac{1 - \rho^2}{1 + \rho^2} \frac{M}{k+1} - 1 \big)$$&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/JulienPascal/bc-MC-PEA/blob/main/3.irreversible_investment/irreversible_investment_Colab_9.ipynb&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt;, I find that $\frac{\alpha_{M}}{\alpha_{MN}} \approx 4.175$. Note that this ratio obviously depends on the model you consider and on the actual software implementation. Here, let&amp;rsquo;s use a rough estimate for $\frac{\alpha_{M}}{\alpha_{MN}} \approx 4$. If you do not know this ratio and you do not want to estimate it, you may even use rough guesses (e.g. $\frac{\alpha_{M}}{\alpha_{MN}} = 1$).&lt;/p&gt;

&lt;p&gt;Below is a function that returns such a $N^{\star}$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def optimal_N(alpha_ratio: float, rho: float, M: int, k: int) -&amp;gt; int:
    # Correct for serial correlation in state vector
    rho_sq = rho ** 2
    serial_correction = (1 - rho_sq) / (1 + rho_sq)
    
    N_star = alpha_ratio * (serial_correction * ( M / (k + 1) ) - 1)

    # Warning if implied value is negative
    if N_star &amp;lt; 0:
        min_M = (k + 1) * (1 + rho_sq) / (1 - rho_sq)
        print(f&amp;quot;Warning: Implied N* = {N_star:.2f} is negative. &amp;quot;
              f&amp;quot;M = {M} is too small given rho = {rho}. &amp;quot;
              f&amp;quot;Consider using M &amp;gt; {min_M:.0f}.&amp;quot;)
    
    return max(1, round(N_star))

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Below, let&amp;rsquo;s use several values for $M$. We then calculate $N^{*}$ based on the above formula.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;alpha_ratio = 4.0 

list_N        = []
list_M        = []
list_optimal  = []

list_target_M = list(np.array([500, 1e3, 1e4, 1e5, 1e6, 2*1e6]).astype(int))
list_N_temp = [1]

# Create all comnbinations between lists
df_MN = pd.DataFrame(list(product(list_target_M, list_N_temp)), columns=[&#39;M&#39;, &#39;N&#39;])
df_MN[&amp;quot;is_optimal&amp;quot;] = 0


# No add theoretical optimum 
for M_vals in list_target_M:
    # Skip large values for M
    if M_vals &amp;gt; 1e4:
        continue
    # 4) compute the theoretical optimum 
    N_opt = optimal_N(alpha_ratio, params.rho_tfp, M_vals, params.nb_expl_vars)
    M_opt = M_vals
    
    print(f&amp;quot;M*: {M_opt}&amp;quot;)
    print(f&amp;quot;N*: {N_opt}&amp;quot;)

    # 5) append the optimal point
    list_N.append(int(np.maximum(1, N_opt)))
    list_M.append(int(M_opt))
    list_optimal.append(1)

# 6) build DataFrame
df_MN_opt = pd.DataFrame({
    &amp;quot;M&amp;quot;:           list_M,
    &amp;quot;N&amp;quot;:           list_N,
    &amp;quot;is_optimal&amp;quot;:  list_optimal,
})

df_MN = pd.concat([df_MN_opt, df_MN])
df_MN.head(10)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;M*: 500
N*: 36
M*: 1000
N*: 76
M*: 10000
N*: 794
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;M&lt;/th&gt;
      &lt;th&gt;N&lt;/th&gt;
      &lt;th&gt;is_optimal&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;500&lt;/td&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1000&lt;/td&gt;
      &lt;td&gt;76&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;10000&lt;/td&gt;
      &lt;td&gt;794&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;500&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1000&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;10000&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;100000&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1000000&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;2000000&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h4 id=&#34;jit-compiled-functions&#34;&gt;jit-compiled functions&lt;/h4&gt;

&lt;p&gt;Below are jit-compiled functions to run the PEA efficiently.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@njit
def fill_X_row(X, i, x1, x2, nb_expl_vars, basis):
    &amp;quot;&amp;quot;&amp;quot;
    Fill row i of the design matrix X in place, using either
      - basis=1 : monomial basis
      - basis=2 : Chebyshev basis
    up to nb_expl_vars terms (4, 6 or 10).

    After calling this, X[i,:] will be set.
    &amp;quot;&amp;quot;&amp;quot;
    if nb_expl_vars == 4:
        # simple cross basis
        X[i, :] = np.array([1, x1, x2, x1*x2])
        return

    if basis == 1:
        # â€”â€” Monomial basis â€”â€”
        if nb_expl_vars == 6:
            # total degree â‰¤2
            X[i, :] = np.array([
                1,
                x1,
                x2,
                x1 * x2,
                x1**2,
                x2**2
            ])
        elif nb_expl_vars == 10:
            # total degree â‰¤3
            X[i, :] = np.array([
                1,
                x1,
                x2,
                x1 * x2,
                x1**2,
                x2**2,
                x1**3,
                x1**2 * x2,
                x1 * x2**2,
                x2**3
            ])
        else:
            raise ValueError(
                f&amp;quot;Monomial basis with nb_expl_vars={nb_expl_vars} not supported&amp;quot;
            )

    elif basis == 2:
        # â€”â€” Chebyshev basis â€”â€”
        if nb_expl_vars == 6:
            # order â‰¤2 Chebyshev: T_i(x)T_j(y), i+jâ‰¤2
            X[i, :] = np.array([
                1,                   # T0(x)T0(y)
                x1,                  # T1(x)T0(y)
                x2,                  # T0(x)T1(y)
                x1 * x2,             # T1(x)T1(y)
                (x1**2 - 1),         # T2(x)T0(y)
                (x2**2 - 1)          # T0(x)T2(y)
            ])
        elif nb_expl_vars == 10:
            # order â‰¤3 Chebyshev: T_i(x)T_j(y), i+jâ‰¤3
            X[i, :] = np.array([
                1,                     # T0(x)T0(y)
                x1,                    # T1(x)T0(y)
                x2,                    # T0(x)T1(y)
                x1 * x2,               # T1(x)T1(y)
                (x1**2 - 1),           # T2(x)T0(y)
                (x2**2 - 1),           # T0(x)T2(y)
                (4*x1**3 - 3*x1),      # T3(x)T0(y)
                (4*x2**3 - 3*x2),      # T0(x)T3(y)
                (x1**2 - 1) * x2,      # T2(x)T1(y)
                x1 * (x2**2 - 1)       # T1(x)T2(y)
            ])
        else:
            raise ValueError(
                f&amp;quot;Chebyshev basis with nb_expl_vars={nb_expl_vars} not supported&amp;quot;
            )

    else:
        raise ValueError(f&amp;quot;Unknown basis={basis}; must be 1 or 2&amp;quot;)


@njit
def clamp(arr, low, high):
    &amp;quot;&amp;quot;&amp;quot;
    Element-wise clamp of `arr` between `low` and `high`.
    Equivalent to np.clip(arr, low, high). np.clip has trouble with jit compilation.
    &amp;quot;&amp;quot;&amp;quot;
    return np.minimum(np.maximum(arr, low), high)


@njit
def fill_X_next(Xv, x1, x2, nb_expl_vars, basis):
    &amp;quot;&amp;quot;&amp;quot;
    Inâ€place fill of Xv (shape = (nb_expl_vars,)) for a single point (x1,x2),
    using monomial basis (basis=1) or Chebyshev basis (basis=2),
    with nb_expl_vars in {4,6,10}.
    &amp;quot;&amp;quot;&amp;quot;
    # 4â€term cross basis
    if nb_expl_vars == 4:
        Xv[0] = 1.0
        Xv[1] = x1
        Xv[2] = x2
        Xv[3] = x1 * x2
        return

    if basis == 1:
        # â€”â€” Monomial â€”â€”
        if nb_expl_vars == 6:
            # [1, x1, x2, x1*x2, x1^2, x2^2]
            Xv[0] = 1.0
            Xv[1] = x1
            Xv[2] = x2
            Xv[3] = x1 * x2
            Xv[4] = x1 * x1
            Xv[5] = x2 * x2
            return
        else:
            # nb_expl_vars == 10
            # [1, x1, x2, x1*x2, x1^2, x2^2, x1^3, x1^2*x2, x1*x2^2, x2^3]
            Xv[0] = 1.0
            Xv[1] = x1
            Xv[2] = x2
            Xv[3] = x1 * x2
            Xv[4] = x1 * x1
            Xv[5] = x2 * x2
            Xv[6] = x1 * x1 * x1
            Xv[7] = x1 * x1 * x2
            Xv[8] = x1 * x2 * x2
            Xv[9] = x2 * x2 * x2
            return

    else:
        # â€”â€” Chebyshev â€”â€”
        if nb_expl_vars == 6:
            # [1, x1, x2, x1*x2, x1^2-1, x2^2-1]
            Xv[0] = 1.0
            Xv[1] = x1
            Xv[2] = x2
            Xv[3] = x1 * x2
            Xv[4] = x1 * x1 - 1.0
            Xv[5] = x2 * x2 - 1.0
            return
        else:
            # nb_expl_vars == 10
            # [1, x1, x2, x1*x2, x1^2-1, x2^2-1,
            #  4x1^3-3x1, 4x2^3-3x2, (x1^2-1)*x2, x1*(x2^2-1)]
            Xv[0] = 1.0
            Xv[1] = x1
            Xv[2] = x2
            Xv[3] = x1 * x2
            Xv[4] = x1 * x1 - 1.0
            Xv[5] = x2 * x2 - 1.0
            Xv[6] = 4.0*x1*x1*x1 - 3.0*x1
            Xv[7] = 4.0*x2*x2*x2 - 3.0*x2
            Xv[8] = (x1*x1 - 1.0) * x2
            Xv[9] = x1 * (x2*x2 - 1.0)
            return


@njit
def simulate_path_N_inplace(
    M: int,
    init: int,
    kss: float,
    e: np.ndarray,
    E: np.ndarray,
    b0: np.ndarray,
    beta: float,
    gamma: float,
    alpha: float,
    delta: float,
    rho_tfp: float,
    N: int,
    nb_expl_vars: int,
    tol_c: float,
    center_dep_var: bool,
    normalize_dep_var: bool,
    basis: int,
    a: np.ndarray,
    k: np.ndarray,
    mu: np.ndarray,
    y: np.ndarray,
    production: np.ndarray,
    inv: np.ndarray,
    cash: np.ndarray,
    c: np.ndarray,
    X: np.ndarray,
    X_next: np.ndarray,
    y_temp: np.ndarray
) -&amp;gt; None:
    &amp;quot;&amp;quot;&amp;quot;
    Simulates one path of the model using a Parameterized Expectations Algorithm (PEA)
    with in-place mutation of pre-allocated arrays. JIT-compiled with numba for maximum performance.

    All outputs are written directly into the provided arrays; no value is returned.
    &amp;quot;&amp;quot;&amp;quot;
    slong = M + init

    # To ensure consumption is a least tol_c
    E_max = tol_c**(-gamma)

    # Set value for constant vector
    X[:, 0] = 1.0

    # Initialize state
    k[0] = kss
    a[0] = 0.0
    for i in range(1, slong):
        a[i] = rho_tfp * a[i-1] + e[i]

    for i in range(0, slong):
        # Compute regressors x1, x2
        x1 = np.log(k[i])
        x2 = a[i]

        # Fill in X[i] for OLS regression y = X*b
        fill_X_row(X, i, x1, x2, nb_expl_vars, basis)

        # Cash-in-hand and consumption decision
        production[i] = np.exp(a[i]) * k[i] ** alpha
        cash[i] = production[i] + (1 - delta) * k[i]

        # Consumption, if current constraint on investment does not bind:
        ## Dot product
        scalar = np.dot(X[i, :], b0)

        #E_t_tilde = clamp(np.exp(scalar), production[i]**(-gamma), E_max)
        E_t_tilde = np.exp(scalar)
        c[i] = E_t_tilde ** (-1 / gamma)

        # Update guess, after calculating investment
        inv[i] = production[i] - c[i]
        if inv[i] &amp;gt; 0:
            k[i+1] = cash[i] - c[i]
            mu[i] = 0.0
        else:
            k[i+1] = (1 - delta) * k[i]
            c[i] = production[i]
            mu[i] = c[i]**( - gamma ) - E_t_tilde

        # Only do MC expectation for i &amp;gt;= init. No need for burnin phase
        if i &amp;gt;= init:
            # Prepare next-period terms (precalculation of terms that do not depend on j)
            term1 = alpha * k[i+1]**(alpha - 1.0)
            term2 = k[i+1] ** alpha
            a_tilde = rho_tfp * a[i]

            x1_next = np.log(k[i+1])

            # Monte Carlo expectation
            for j in range(N):
                a_next = a_tilde + E[i, j]
                # production next period:
                production_next = np.exp(a_next) * term2

                x2_next = a_next

                fill_X_next(X_next, x1_next, x2_next, nb_expl_vars, basis)
                scalar_next = np.dot(X_next, b0)

                # Consumption next period, assuming constraint does not bind:
                #E_next_tilde = clamp(np.exp(scalar_next), production_next ** (-gamma), E_max)
                E_next_tilde = np.exp(scalar_next)
                c_next = E_next_tilde ** (-1 / gamma)

                # Update guess, after calculating investment
                inv_next = production_next - c_next
                if inv_next &amp;gt; 0:
                    # non-binding
                    mu_next = 0
                else:
                    # binding
                    c_next = production_next
                    mu_next = c_next**( - gamma ) - E_next_tilde

                ## g2(s,e)
                y_temp[j] =  ( c_next**( -gamma ) ) * ( np.exp(a_next) * term1 + 1.0 - delta ) + mu_next * (1.0 - delta)

            # Final aggregation
            s = 0.0
            for j in range(N):
                s += y_temp[j]

            y[i] = np.log( beta * (s / N) )


@njit
def evaluate_IE_and_EEE_Gauss_path_inplace(
    slong: int,
    kss: float,
    e: np.ndarray,
    b0: np.ndarray,
    beta: float,
    gamma: float,
    alpha: float,
    delta: float,
    rho_tfp: float,
    number_nodes: int,
    quadrature_nodes: np.ndarray,
    quadrature_weights: np.ndarray,
    nb_expl_vars: int,
    tol_c: float,
    center_dep_var: bool,
    normalize_dep_var: bool,
    basis: int,
    # Preallocated arrays for in-place mutation:
    a: np.ndarray,            # shape (slong,)
    k: np.ndarray,            # shape (slong+1,)
    mu: np.ndarray,           # shape (slong+1,)
    production: np.ndarray,   # shape (slong,)
    inv: np.ndarray,          # shape (slong,)
    IE: np.ndarray,           # shape (slong,)
    EEE: np.ndarray,          # shape (slong,)
    cash: np.ndarray,         # shape (slong,)
    c: np.ndarray,            # shape (slong,)
    X: np.ndarray,            # shape (slong, nb_expl_vars)
    X_next: np.ndarray,       # shape (nb_expl_vars,)
    linear_model: np.ndarray, # shape (slong,)
    y_temp1: np.ndarray,      # shape (number_nodes,)
) -&amp;gt; None:

    &amp;quot;&amp;quot;&amp;quot;
    In-place computation of MSIE (IE) and Euler equation errors (EEE)
    along a single simulated path using Gaussâ€“Hermite quadrature.

    All output arrays (a, k, IE, EEE, cash, c, X, X_next, linear_model,
    y_temp1, y_temp2) must be pre-allocated to the correct shape.
    &amp;quot;&amp;quot;&amp;quot;
    # Clear values
    a[:] = 0.0
    k[:] = 0.0
    mu[:] = 0.0
    production[:] = 0.0
    inv[:] = 0.0
    IE[:] = 0.0
    EEE[:] = 0.0
    cash[:] = 0.0
    c[:] = 0.0
    X[:,:] = 0.0
    X_next[:] = 0.0
    linear_model[:] = 0.0
    y_temp1[:] = 0.0

    # To ensure consumption is a least tol_c
    E_max = tol_c**(-gamma)

    # Set initial state
    k[0] = kss
    a[0] = 0.0

    # AR(1) TFP path
    for i in range(1, slong):
        a[i] = rho_tfp * a[i - 1] + e[i]



    # Main loop
    for i in range(slong):
        # 1) build current regressors x1,x2
        x1 = np.log(k[i])
        x2 = a[i]

        # 2) fill X[i]
        fill_X_row(X, i, x1, x2, nb_expl_vars, basis)

        # 3) cash, linear prediction, consumption, and k forward
        production[i] = np.exp(a[i]) * k[i] ** alpha
        cash[i] = production[i] + (1 - delta) * k[i]

        # inline dot(X[i], b0)
        scalar = np.dot(X[i, :], b0)

        linear_model[i] = scalar
        #E_t_tilde = clamp(np.exp(linear_model[i]), production[i]**(-gamma), E_max)
        E_t_tilde = np.exp(linear_model[i])
        c[i] = E_t_tilde ** (-1 / gamma)

        # Update guess, after calculating investment
        inv[i] = production[i] - c[i]
        if inv[i] &amp;gt; 0:
            k[i+1] = cash[i] - c[i]
            mu[i] = 0.0
        else:
            k[i+1] = (1 - delta) * k[i]
            c[i] = production[i]
            mu[i] = c[i]**( - gamma ) - E_t_tilde

        # Precompute nextâ€period quantities
        x1_next = np.log(k[i+1])

        term1 = alpha * (k[i+1] ** (alpha - 1.0))
        term2 = k[i+1] ** alpha
        a_tilde = rho_tfp * a[i]

        # 4) Quadrature loop
        for j in range(number_nodes):
            a_next = a_tilde + quadrature_nodes[j]

            # production next period:
            production_next = np.exp(a_next) * term2

            x2_next = a_next

            # inline dot(X_next, b0)

            # Consumption next period, assuming constraint does not bind:
            fill_X_next(X_next, x1_next, x2_next, nb_expl_vars, basis)
            scalar_next = np.dot(X_next, b0)

            E_next_tilde = np.exp(scalar_next)
            c_next = E_next_tilde ** (-1 / gamma)

            # Update guess, after calculating investment
            inv_next = production_next - c_next
            if inv_next &amp;gt; 0:
                # non-binding
                mu_next = 0
            else:
                # binding
                c_next = production_next
                mu_next = c_next**( - gamma ) - E_next_tilde

            # Monte-Carlo expectation terms:
            ## RHS of Euler equation
            y_temp1[j] = beta * ( ( c_next ** ( - gamma ) ) * ( np.exp(a_next) * term1 + 1.0 - delta ) + mu_next * (1.0 - delta) )

        # 5) Weighted averages &amp;amp; fill IE, EEE
        s1 = 0.0
        for j in range(number_nodes):
            s1 += quadrature_weights[j] * y_temp1[j]

        #Integration error: log(E_t) - x&#39; beta. E_t calculated using Gaussian intergration.
        IE[i]  = np.log(s1) - linear_model[i]
        #Euler equation error: 1 - (1/c_t)*(E_t()^{-1/gamma})
        EEE[i] = 1.0 - (1.0 / c[i]) * ( ( s1  + mu[i] ) **(-1.0 / gamma))



&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;time-accuracy-tradeoff&#34;&gt;Time &amp;amp; Accuracy tradeoff&lt;/h4&gt;

&lt;p&gt;In the next block of code, I run standard PEA ($N=1$) and bc-MC-PEA ($N=N^{\star}$) for different choices of $M$.
I store total computing time, as well as accuracy measurements. For each choice of $(M, N)$, I do that several times in a row and calculate average values. This is because:&lt;/p&gt;

&lt;p&gt;1) PEA and bc-MC-PEA are stochastic methods&lt;/p&gt;

&lt;p&gt;2) timing involves measurement errors.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#### ----------------------------------
tol = 1e-8 # tolerance on parameter vector
gam = 1.0  # smoothing parameter between two iterations
max_iter = 50 # max number of iterations
redraw_shocks_every = 1000 #redraw new realizations of innovations (new state and innovation vectors)
init = 100 #burnin (drop first observation for OLS estimation)

slong_test = 50000
init_test = 100 #burnin for test simulation (when measuring accuracy)
nb_tot_reps = 5 #nb of repetitions, to smooth out randomness and potential issues with measuring timing
init = 100 #burnin
# Preallocate arrays for test
a_test            = np.zeros(slong_test)
k_test            = np.zeros(slong_test+1)
mu_test           = np.zeros(slong_test+1)
production_test   = np.zeros(slong_test)
inv_test          = np.zeros(slong_test)
IE           = np.zeros(slong_test)
EEE          = np.zeros(slong_test)
cash_test         = np.zeros(slong_test)
c_test            = np.zeros(slong_test)
X_test            = np.zeros((slong_test, params.nb_expl_vars))
X_next_test       = np.zeros(params.nb_expl_vars)
linear_model_test = np.zeros(slong_test)
y_temp1_test      = np.zeros(len(params.nodes_flat))

# to store restults
results = []
np.random.seed(42)

# Loop over (M,N)
for idx, row in df_MN.iterrows():
    M = row[&#39;M&#39;]
    N = row[&#39;N&#39;]
    is_optimal = row[&#39;is_optimal&#39;]
    # Repeat experiment several times
    for nb_rep in range(nb_tot_reps):
        #np.random.seed(nb_rep)
        # Innovations for the out-sample test
        e_test = params.std_tfp * np.random.randn(slong_test) #New shocks

        slong = init + M

        b0_current = coeff_array_0.copy()  # initial guess 

        # innovation for state vector (not used directly in simulation here
        # for M large, no need to redraw many times.
        e = params.std_tfp * np.random.randn(slong)
        # extra draws for each state: shape (slong, N)
        E = params.std_tfp * np.random.randn(slong, N)

        # Preallocate arrays
        a = np.zeros(slong)
        k      = np.zeros(slong + 1)    # capital path (slong+1 because we update k[i+1])
        mu     = np.zeros(slong + 1)    # Lagrange multiplier on investment constraint
        y_out      = np.zeros(slong)    # simulated y
        production = np.zeros(slong)    # production
        inv = np.zeros(slong)           # investment
        cash     = np.zeros(slong)      # cash in hand
        c = np.zeros(slong)             # consumption
        X_data      = np.zeros((slong, params.nb_expl_vars))   # regressor matrix (6 variables)
        X_next = np.zeros(params.nb_expl_vars) # regressor, next period
        y_temp = np.zeros(N)            # temporary array for innovations

        # Warmup (compilation) first go
        simulate_path_N_inplace(M, init, params.kss, e, E, b0_current,
                                params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, N,
                                params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,
                                a, k, mu, y_out, production, inv, cash, c, X_data, X_next, y_temp)

        iter_num = 1
        crit = 1.0
        # Run a fixed number of iterations (or use while crit &amp;gt; tol)
        start_time = time.perf_counter()
        while iter_num &amp;lt; max_iter:
            if iter_num % redraw_shocks_every == 0:
                e[:], E[:,:] = generate_random_arrays(slong, N, params.std_tfp)

            # Simulation:
            simulate_path_N_inplace(M, init, params.kss, e, E, b0_current,
                                params.beta, params.gamma, params.alpha, params.delta, params.rho_tfp, N,
                                params.nb_expl_vars, params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,
                                a, k, mu, y_out, production, inv, cash, c, X_data, X_next, y_temp)

            # Remove burnin and last period
            X_reg = X_data[init:-1, :]
            y_reg = y_out[init:-1]
            # OLS
            bt, _, _, _ = np.linalg.lstsq(X_reg, y_reg, rcond=None)
            # Parameter update
            b_new = gam * bt + (1 - gam) * b0_current
            crit = np.max(np.abs(b_new - b0_current))
            b0_current = b_new.copy()
            #print(&amp;quot;Iteration:&amp;quot;, iter_num, &amp;quot;Conv. crit.:&amp;quot;, crit)
            iter_num += 1
        end_time = time.perf_counter()
        elapsed = end_time - start_time

        # print(f&amp;quot;Iter {nb_rep}. M = {M}, N = {N}, elapsed time: {elapsed} seconds&amp;quot;)
        # Compute residuals and In-sample MSE.
        Res = y_reg - np.dot(X_reg, b0_current)
        MSE = np.mean(Res ** 2)

        # Mean squared integration error and EEE
        evaluate_IE_and_EEE_Gauss_path_inplace(slong_test, params.kss,
                                         e_test, b0_current, params.beta, params.gamma, params.alpha,
                                         params.delta, params.rho_tfp, len(params.nodes_flat),
                                         params.nodes_flat, params.weights, params.nb_expl_vars,
                                         params.tol_c, params.center_dep_var, params.normalize_dep_var, params.basis,
                                         a_test, k_test, mu_test, production_test, inv_test,
                                         IE, EEE, cash_test, c_test, X_test, X_next_test, linear_model_test,
                                         y_temp1_test)


        MSIE = np.mean(IE[init_test:-1]**2)
        A_EEE = np.mean(np.abs(EEE[init_test:-1]))

        # Store the results in a dictionary
        results.append({
            &amp;quot;repetition&amp;quot;: nb_rep,
            &amp;quot;k&amp;quot;: params.nb_expl_vars,
            &amp;quot;M&amp;quot;: M,
            &amp;quot;N&amp;quot;: N,
            &amp;quot;Time&amp;quot;: elapsed,
            &amp;quot;MSE&amp;quot;: MSE,
            &amp;quot;MSIE&amp;quot;: MSIE,
            &amp;quot;A_EEE&amp;quot;: A_EEE,
            &amp;quot;is_optimal&amp;quot;: is_optimal
        })
        
    print(&amp;quot;Final iteration M:&amp;quot;, M, &amp;quot;Iterations:&amp;quot;, iter_num, &amp;quot;OLS MSE:&amp;quot;, MSE, &amp;quot;MISE:&amp;quot;, MSIE, &amp;quot;Average EEE:&amp;quot;, A_EEE)
    print(&amp;quot;Final b0:&amp;quot;, b0_current)

# Create a Pandas DataFrame from the results
df_results_2 = pd.DataFrame(results)
df_results_2.to_csv(output_folder + &amp;quot;df_results_2.csv&amp;quot;)
print(df_results_2.head())
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Final iteration M: 500 Iterations: 50 OLS MSE: 6.39689620736686e-05 MISE: 6.979887652063562e-06 Average EEE: 0.0015655538850610894
Final b0: [ 0.16247757 -0.24985331 -0.76061818  0.25599638 -0.07506965 -0.16968142
  0.00688403 -0.02032964 -0.12008197  0.17564347]
Final iteration M: 1000 Iterations: 50 OLS MSE: 3.796981261039479e-05 MISE: 3.19778695810395e-06 Average EEE: 0.001112133816018006
Final b0: [-0.09056384 -0.01856654 -1.01221979  0.43950113 -0.13488526 -0.35173479
  0.01100738 -0.04441094 -0.19709003  0.33839319]
Final iteration M: 10000 Iterations: 50 OLS MSE: 6.542653166420021e-06 MISE: 2.9566529603752238e-06 Average EEE: 0.001055960821718564
Final b0: [-0.04979799 -0.05504875 -0.97966892  0.40987097 -0.11831992 -0.32878382
  0.00979378 -0.04387424 -0.18413251  0.31862007]
Final iteration M: 500 Iterations: 50 OLS MSE: 0.0022142019493280383 MISE: 0.00012135434094234673 Average EEE: 0.00668642546122861
Final b0: [ 0.82229268 -0.90739086 -0.53642172 -0.18030242  0.33838932 -0.09953621
 -0.02229608 -0.10234907  0.09603063  0.09430634]
Final iteration M: 1000 Iterations: 50 OLS MSE: 0.0025993825788082916 MISE: 4.058952136372577e-05 Average EEE: 0.003625722738373235
Final b0: [ 0.02385481 -0.16811925 -0.63398239  0.03385158 -0.07134272 -0.34193687
  0.0082259  -0.04745522 -0.02632164  0.29541885]
Final iteration M: 10000 Iterations: 50 OLS MSE: 0.0024508247787179416 MISE: 1.1136421709113198e-05 Average EEE: 0.0016576982242947937
Final b0: [ 0.2617814  -0.36112256 -0.66835186  0.16369622 -0.03247485 -0.11747232
  0.00252398 -0.01751672 -0.05608633  0.1099069 ]
Final iteration M: 100000 Iterations: 50 OLS MSE: 0.002393585822859449 MISE: 5.4760625776998754e-06 Average EEE: 0.0013227092630956365
Final b0: [-0.01766254 -0.10006983 -0.93743997  0.39022456 -0.11801585 -0.29676254
  0.00994274 -0.03508161 -0.16897343  0.27758845]
Final iteration M: 1000000 Iterations: 50 OLS MSE: 0.00238513101035928 MISE: 4.479321593683236e-06 Average EEE: 0.001291546782524435
Final b0: [-0.03491625 -0.07837509 -0.95125539  0.39424473 -0.11779865 -0.30922358
  0.00942587 -0.03916162 -0.17295513  0.29344339]
Final iteration M: 2000000 Iterations: 50 OLS MSE: 0.002384620757014956 MISE: 5.775545032534041e-06 Average EEE: 0.0013630658243780791
Final b0: [-0.02917404 -0.08457067 -0.9441379   0.39027564 -0.11913959 -0.30199118
  0.00948944 -0.03804026 -0.17036995  0.28607765]
   repetition   k    M   N      Time       MSE      MSIE     A_EEE  is_optimal
0           0  10  500  36  0.050169  0.000073  0.000015  0.002113           1
1           1  10  500  36  0.047353  0.000073  0.000005  0.001379           1
2           2  10  500  36  0.046689  0.000075  0.000009  0.001008           1
3           3  10  500  36  0.044587  0.000071  0.000009  0.001108           1
4           4  10  500  36  0.045598  0.000064  0.000007  0.001566           1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As illustrated below, the bc-MC-PEA outfperforms the standard PEA, even when using a rough estimate for the ratio $\frac{\alpha_{M}}{\alpha_{MN}}$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def compute_pareto_front(df, time_col=&#39;Time&#39;, mse_col=&#39;MSIE&#39;):
    &amp;quot;&amp;quot;&amp;quot;
    Compute Paretor frontier
    &amp;quot;&amp;quot;&amp;quot;
    # Sort by Time ascending
    df_sorted = df.sort_values(by=time_col, ascending=True)

    # List to store the Pareto front
    pareto_points = []

    # Keep track of the lowest MSE encountered so far
    best_mse_so_far = float(&#39;inf&#39;)

    for idx, row in df_sorted.iterrows():
        mse_val = row[mse_col]
        if mse_val &amp;lt; best_mse_so_far:
            pareto_points.append(row)
            best_mse_so_far = mse_val

    return pd.DataFrame(pareto_points)

df_results_2[&amp;quot;log_N&amp;quot;]    = np.log(df_results_2[&amp;quot;N&amp;quot;])
df_results_2[&amp;quot;log_M&amp;quot;]    = np.log(df_results_2[&amp;quot;M&amp;quot;])
df_results_2[&amp;quot;log_MN&amp;quot;]   = np.log(df_results_2[&amp;quot;M&amp;quot;] * df_results_2[&amp;quot;N&amp;quot;])

df_results_2[&amp;quot;MN_label&amp;quot;] = df_results_2[&amp;quot;M&amp;quot;].astype(&amp;quot;str&amp;quot;) + &amp;quot;-&amp;quot; + df_results_2[&amp;quot;N&amp;quot;].astype(&amp;quot;str&amp;quot;)
df_results_average_2 = df_results_2.groupby(&amp;quot;MN_label&amp;quot;).mean().reset_index()
# Save to disk
df_results_average_2.to_csv(output_folder + &amp;quot;df_results_average_2.csv&amp;quot;)

# Focus on standard PEA (N = 1).
df_one = df_results_average_2[df_results_average_2[&#39;N&#39;] == 1]
df_one = df_one.sort_values(&#39;Time&#39;)

# Now highlight the optimal points
optimal_df = df_results_average_2[df_results_average_2[&#39;is_optimal&#39;] == 1]

for (col, long_name) in zip([&#39;MSIE&#39;, &#39;A_EEE&#39;], [&#39;MSIE&#39;, &#39;Average EEE&#39;]):
    # Compute Pareto frontier
    pareto_df = compute_pareto_front(df_results_average_2, mse_col=col)
    # Log or linear plots
    for nb in [0]:
        plt.figure(figsize=(8,6))
        sns.scatterplot(data=df_results_average_2, x=&#39;Time&#39;, y=col, alpha=0.7)
        plt.plot(pareto_df[&#39;Time&#39;], pareto_df[col], &#39;r-o&#39;, label=&#39;Pareto Frontier&#39;)
         
        plt.scatter(optimal_df[&#39;Time&#39;], optimal_df[col],
                    marker=&#39;*&#39;, s=250, c=&#39;red&#39;,
                    edgecolors=&#39;black&#39;, linewidths=1,
                    label=&#39;Optimal (M, N)&#39;)
        
        plt.plot(df_one[&#39;Time&#39;], df_one[col], &#39;b&#39;, label=&#39;Frontier N = 1&#39;)
        plt.scatter(df_one[&#39;Time&#39;], df_one[col],
                    marker=&#39;+&#39;, s=250, c=&#39;b&#39;, linewidths=1,
                    label=&#39;N = 1&#39;)
        
        plt.xlabel(&#39;Time (seconds)&#39;)
        plt.ylabel(long_name)
        if nb == 0:
            plt.yscale(&#39;log&#39;)
            plt.xscale(&#39;log&#39;)
        plt.title(f&#39;Time vs. {long_name}, Colored by N&#39;)
        plt.legend(loc= &amp;quot;upper right&amp;quot;)
        plt.grid(True)
        plt.savefig(output_folder + f&amp;quot;Time_vs_MSIE_{nb}.pdf&amp;quot;, dpi=300)
        plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;bc-MC-PEA_20_0.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;bc-MC-PEA_20_1.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;iii-conclusion&#34;&gt;III. Conclusion&lt;/h2&gt;

&lt;p&gt;To reiterate what was said in the introduction, this paper can be read from two perspectives. On the practical side, the bc-MC-PEA can be seen as a practical recipe to get more accurate numerical solutions to economic models (at a constant computational budget) if one is already using the PEA. The method itself does not require massive coding skills and is easy to implement if one is willing to use a rough guess for the ratio $\frac{\alpha_{M}}{\alpha_{MN}}$.&lt;/p&gt;

&lt;p&gt;On the theoretical side, I find it interesting that the PEA and its generalization can be seen as originating from a more general optimal estimator (the bc-MC operator). In my view, this creates a bridge between modern computational economics, which often uses complex neural networks and backpropagation to train them, and classic computational economics, for instance PEA + OLS.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Julien Pascal, A generalization of the Parameterized Expectations Algorithm, Economics Letters, Volume 259, 2026, 112790, ISSN 0165-1765, &lt;a href=&#34;https://doi.org/10.1016/j.econlet.2025.112790&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.1016/j.econlet.2025.112790&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To cite this work:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@article{PASCAL2026112790,
title = {A generalization of the Parameterized Expectations Algorithm},
journal = {Economics Letters},
volume = {259},
pages = {112790},
year = {2026},
issn = {0165-1765},
doi = {https://doi.org/10.1016/j.econlet.2025.112790},
url = {https://www.sciencedirect.com/science/article/pii/S0165176525006275},
author = {Julien Pascal}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>The bias-corrected Monte Carlo operator</title>
      <link>https://julienpascal.github.io/post/bc_mc/</link>
      <pubDate>Wed, 01 May 2024 08:00:00 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/bc_mc/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In this blog post, I am going to present my recent work on the &lt;strong&gt;bias-corrected Monte Carlo&lt;/strong&gt; operator, or more compactly &amp;ldquo;bc-MC operator&amp;rdquo;, which was recently published &lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0165188924000459&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; in the JEDC. In this paper, I propose a new methodology to combine &lt;strong&gt;Monte Carlo&lt;/strong&gt; and &lt;strong&gt;neural networks&lt;/strong&gt; to solve large scale economic models. In this blog post, my goal is to give an intuitive description of this method.&lt;/p&gt;

&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;

&lt;h3 id=&#34;structure-of-economic-models&#34;&gt;Structure of economic models&lt;/h3&gt;

&lt;p&gt;In many cases, solving an economic model involves finding a policy function $g(.)$, which is a mapping from a state vector $s$ to a decision vector $a$. Usually, it is assumed that the economy is hit by random disturbances, which is usually modelled as zero-mean innovation vector $\varepsilon$, often considered to be normally distributed. The policy function $g(.)$ is such that the following stochastic equation holds:&lt;/p&gt;

&lt;p&gt;$$ E_{\varepsilon}(f(s, \varepsilon)) = 0 $$&lt;/p&gt;

&lt;p&gt;where $f(.)$ depends implicitly on the policy function $g(.)$ and on the particularities of the model under consideration. It looks a bit abstract, but we can usually write economic models in that form. For instance, in macroeconomic models, you usually have an Euler equation that can be written as such.&lt;/p&gt;

&lt;p&gt;Here, let&amp;rsquo;s assume that we restrict ourselves to policy functions that depend on a parameter vector $\theta$: $g(. |\theta)$. Further, let&amp;rsquo;s assume that we use a multilayer perceptron for the policy function, so that the elements of $\theta$ are actually the weights and biases of that specific neural network. Now, the problem is in many ways much simpler, because it consists in finding a finite-size vector $\theta$, rather than finding a function, which is an infinite-dimensional object:&lt;/p&gt;

&lt;p&gt;$$ E_{\varepsilon}(f(s, \varepsilon | \theta )) = 0 $$&lt;/p&gt;

&lt;p&gt;We want the equation above to be true for all values of $s$. The common way to proceed is to define a grid for $s$ and to find $g(. |\theta)$ such that the previous equation holds on these grid points. For off-grid point values, interpolation schemes can be used. This is fine when $s$ is low-dimensional, but if $s$ is high-dimensional, the curse of dimensionality is going to bite: the number of grid points grows exponentially with the dimension of $s$, not linearly. The trick here is treat $s$ as a random variable, living within an ergodic set $S$ and to solve the following problem:&lt;/p&gt;

&lt;p&gt;$$ E_{s} \Big( \Big[ E_{\varepsilon}(f(s, \varepsilon | \theta )) \Big]^2 \Big) = 0 $$&lt;/p&gt;

&lt;p&gt;This probabilistic formulation works well even if $s$ is high-dimensional, because we have numerical methods that can handle high-dimensional expectations. In particular, we have Monte Carlo integration, which consists in approximating expectations using sample means.&lt;/p&gt;

&lt;p&gt;Now define $L(\theta)$ as the left-hand side of the previous equation:&lt;/p&gt;

&lt;p&gt;$$ L(\theta) = E_{s} \Big( \Big[ E_{\varepsilon}(f(s, \varepsilon | \theta )) \Big]^2 \Big) $$&lt;/p&gt;

&lt;p&gt;One way to find $\theta$ is to use the gradient descent algorithm, which is an iterative method. We start with a random guess for $\theta$, denoted $\theta_{i}$, and we update the guess using the information contained in the gradient of $L$ evaluated at $\theta_i$ denoted by $\nabla_{\theta} L(\theta_i)$, which is the direction of the steepest ascent. Because we are minimizing a function, we take a small step $\gamma$ in the opposite direction of the gradient:&lt;/p&gt;

&lt;p&gt;$$ \theta_{i+1} = \theta_{i} - \gamma \nabla_{\theta} L(\theta_{i}) $$&lt;/p&gt;

&lt;p&gt;Below is an example of gradient descent for the function $x^2 + 2 y^2$. As expected, we iteratively converge to the minimum of this simple function, at $(0,0)$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Illustration of gradient descent using Python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from IPython.display import Image

# Define the function and its gradient
def f(x, y, a=1, b=2):
    return a*x**2 + b*y**2

def grad_f(x, y, a=1, b=2):
    return a*2*x, b*2*y

# Parameters
alpha = 0.1  # Learning rate
n_iterations = 25 #Number of steps

# Initial point
x, y = -10, -8
trajectory = []

# Gradient Descent Algorithm
for _ in range(n_iterations):
    trajectory.append((x, y))
    dx, dy = grad_f(x, y)
    x -= alpha * dx
    y -= alpha * dy

# Setting up the visualization
x_vals = np.linspace(-10, 10, 400)
y_vals = np.linspace(-10, 10, 400)
X, Y = np.meshgrid(x_vals, y_vals)
Z = f(X, Y)

fig, ax = plt.subplots(figsize=(8, 8))
CS = ax.contour(X, Y, Z, levels=np.logspace(-1, 3, 20), cmap=&#39;viridis&#39;)
ax.plot(0, 0, &#39;ro&#39;)  # Mark the minimum

# Animation function
def update(frame):
    ax.cla()
    ax.contour(X, Y, Z, levels=np.logspace(-1, 3, 20), cmap=&#39;viridis&#39;)
    ax.plot(0, 0, &#39;ro&#39;)  # Minimum
    # Current point and arrow
    x, y = trajectory[frame]
    dx, dy = grad_f(x, y)
    # Direction of update
    ax.arrow(x, y, -alpha * dx, -alpha * dy, head_width=0.5, head_length=0.5, fc=&#39;k&#39;, ec=&#39;k&#39;)
    ax.set_xlim([-10, 10])
    ax.set_ylim([-10, 10])
    ax.set_title(f&amp;quot;Gradient Descent Algorithm for $x^2 + 2y^2$. Iteration {frame + 1}&amp;quot;)

ani = FuncAnimation(fig, update, frames=n_iterations, repeat=False)
ani.save(&#39;gradient_descent.gif&#39;, writer=&#39;imagemagick&#39;, fps=1)
plt.close()

Image(url=&#39;gradient_descent.gif&#39;)  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;gradient_descent.gif&#34;/&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-bc-mc-operator&#34;&gt;The bc-MC operator&lt;/h3&gt;

&lt;p&gt;As it is now clear from the previous visual illustration, knowledge of the gradient of the loss function is enough to find numerically a solution of our economic model, at least a local one (for the gradient descent algorithm to converge to a global minimum, we usually need the function to be convex over its domain).&lt;/p&gt;

&lt;p&gt;One difficulty here is that we cannot compute the expectations appearing in $L(\theta) = E_{s} \Big( \Big[ E_{\varepsilon}(f(s, \varepsilon | \theta )) \Big]^2 \Big)$. However, as suggested before, we can use Monte Carlo integration, which consists in using sample means to approximate expectations:&lt;/p&gt;

&lt;p&gt;$$ L^{B}_{M,N}(\theta) = \frac{1}{M} \sum_{m=1}^{M}\Big[ \frac{1}{N} \sum_{n=1}^{N} f(s_m, \varepsilon_n | \theta ) \Big]^2 $$&lt;/p&gt;

&lt;p&gt;Clearly, this is an &lt;a href=&#34;https://en.wikipedia.org/wiki/Estimator&#34; target=&#34;_blank&#34;&gt;estimator&lt;/a&gt; of $L(\theta)$ that makes a lot of sense. However, because of some unpleasant arithmetic regarding the &lt;a href=&#34;https://journals.sagepub.com/doi/abs/10.1177/0008068319750115&#34; target=&#34;_blank&#34;&gt;estimation the square of the mean&lt;/a&gt;, this is a biased one.&lt;/p&gt;

&lt;p&gt;Start with the formula for the variance $Var(X) = E(X^2) - E(X)^2 \Leftrightarrow E(X^2) = E(X)^2 + Var(X)$. Using this formula&lt;/p&gt;

&lt;p&gt;$$ E_{\varepsilon}\Big[ \Big(\frac{1}{N} \sum_{n=1}^{N} f(s_m, \varepsilon_n | \theta ) \Big)^2 \Big] = \Big( E_{\varepsilon}\Big[ \frac{1}{N} \sum_{n=1}^{N} f(s_m, \varepsilon_n | \theta ) \Big] \Big)^2 + Var_{\varepsilon} \Big( \frac{1}{N} \sum_{n=1}^{N} f(s_m, \varepsilon_n | \theta ) \Big) $$&lt;/p&gt;

&lt;p&gt;Using the linearity of the expectation operator, and the fact that $Var(a X) = a^2 V(X)$, one gets:&lt;/p&gt;

&lt;p&gt;$$ E_{\varepsilon}\Big[ \Big(\frac{1}{N} \sum_{n=1}^{N} f(s_m, \varepsilon_n | \theta ) \Big)^2 \Big] = \mu_{s_m}^2 + \frac{\sigma_{s_m}^2}{N} $$&lt;/p&gt;

&lt;p&gt;In words, one gets the square of the mean, plus a bias term equal to the variance of $f$ (conditional on $s = s_m$) divided by $N$. Fortunately for us, there exists an unbiased estimator of the variance, given by the sample variance. An easy way to neutralize the bias is to subtract the sample variance (divided by N):&lt;/p&gt;

&lt;p&gt;$$ L^{U}_{M,N}(\theta) = \frac{1}{M} \sum_{m=1}^{M }\Big( \Big[ \frac{1}{N}  \sum_{n=1}^{N} f(s_m, \varepsilon_n | \theta ) \Big]^2
 - \frac{S_m^2}{N} \Big) $$&lt;/p&gt;

&lt;p&gt;The term &amp;ldquo;bc-MC operator&amp;rdquo; comes from bias correction.&lt;/p&gt;

&lt;p&gt;The previous expression can be rewritten as:&lt;/p&gt;

&lt;p&gt;$$ L^{U}_{M,N}(\theta) = \frac{2}{MN(N-1)} \sum_{m=1}^{M} \sum_{1 \leq i &amp;lt; j}^{N} f(s_m, \varepsilon^{i}_m | \theta ) f(s_m, \varepsilon^{j}_m | \theta ) $$&lt;/p&gt;

&lt;p&gt;where $\varepsilon^{i}$ and $\varepsilon^{j}$ are i.i.d. shocks with the same distribution as $\varepsilon$. This expression is more convenient because it can be written as a sparse matrix multiplication:&lt;/p&gt;

&lt;p&gt;$$ L^{U}_{M,N}(\theta) = \frac{2}{MN(N-1)} f&amp;rsquo; \Lambda f $$&lt;/p&gt;

&lt;p&gt;where $\Lambda$ is a sparse matrix. More specifically&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$f$ is MN column vector such that $f&amp;rsquo; = (f(s_1, \varepsilon^{1}_1), &amp;hellip;, f(s_1, \varepsilon^{N}_1), f(s_2, \varepsilon^{1}_2), &amp;hellip;, f(s_2, \varepsilon^{N}_2), &amp;hellip;, f(s_M, \varepsilon^{N}_M))$&lt;/li&gt;
&lt;li&gt;$\Lambda = I_{M} \otimes U_{N}$ is $MN \times MN$ sparse matrix, with $ I_{M}$ the $M \times M$ identity matrix and $U_{N}$ a $N \times N$ upper triangular matrix whose diagonal elements are equal to zero, while the entries above the main diagonal are all equal to one. The symbol $\otimes$ denotes the Kronecker product.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This expression can be very efficiently calculated using Python and Pytorch, with no loops involved.&lt;/p&gt;

&lt;h3 id=&#34;minimum-variance-unbiased-estimator&#34;&gt;Minimum Variance Unbiased Estimator&lt;/h3&gt;

&lt;p&gt;Actually, under certain conditions on the economic model under consideration, I show that $L^{U}_{M,N}(\theta)$ it the Minimum Variance Unbiased Estimator (MVUE) of the loss function $L(\theta)$. That is, if one is willing to only consider unbiased estimators of $L(\theta)$, then $L^{U}_{M,N}(\theta)$ is the one with the lowest variance. In the paper, I use the &lt;a href=&#34;https://en.wikipedia.org/wiki/Lehmann%E2%80%93Scheff%C3%A9_theorem&#34; target=&#34;_blank&#34;&gt;Lehmann-ScheffÃ© theorem&lt;/a&gt;. This theorem states that any estimator that is unbiased for a given unknown quantity and that depends on the data only through a complete, sufficient statistic is the unique best unbiased estimator of that quantity.&lt;/p&gt;

&lt;p&gt;But there is another simpler proof, if one is willing to only consider estimators that &lt;strong&gt;linearly&lt;/strong&gt; combine estimators of the square of means (conditional on $s=s_m$), denoted by $E_m$&lt;/p&gt;

&lt;p&gt;$$ L_{a} = \sum_{m=1}^{M} a_m E_m $$&lt;/p&gt;

&lt;p&gt;It is easy to show that for $L_{a}$ to be the MVUE of $L(\theta)$, its must be a linear combination of MVUEs for the square of means, denoted by $\tilde{E}_m$&lt;/p&gt;

&lt;p&gt;$$ L_{a} = \sum_{m=1}^{M} a_m \tilde{E}_m $$&lt;/p&gt;

&lt;p&gt;The proof relies on the &lt;a href=&#34;https://pages.stat.wisc.edu/~shao/stat610/stat610-04.pdf&#34; target=&#34;_blank&#34;&gt;following lemma&lt;/a&gt;: &amp;ldquo;An unbiased estimator $T(X)$ of $h(\theta)$ is UMVUE iff $T(X)$ is uncorrelated with all unbiased estimators of 0&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;It is clear here that taking unbiased estimators for $E_m$ will result in $L_{a}$ being unbiased as well, by linearity of the expectation operator. Then, we can consider an unbiased estimator of $0$, denoted by $U$:&lt;/p&gt;

&lt;p&gt;$$ Cov(\sum_{m=1}^{M} a_m \tilde{E}_m, U) =  \sum_{m=1}^{M} a_m cov(\tilde{E}_m, U) = 0 $$&lt;/p&gt;

&lt;p&gt;where $cov(\tilde{E}_m, U) = 0$, because each $\tilde{E}_m$ is itself a MVUE by assumption. We still have to determine the optimal values for the $a_m$, under the constraint that they all sum up to one. Now, as long as the estimators $\tilde{E}_m$ have equal variance, the optimal way to select the coefficient $a_m$ is to use equal weighting: $a_m = \frac{1}{M}$ (otherwise, one may use &lt;a href=&#34;https://en.wikipedia.org/wiki/Inverse-variance_weighting&#34; target=&#34;_blank&#34;&gt;inverse-variance weighting&lt;/a&gt;, as we do with weighted least squares):&lt;/p&gt;

&lt;p&gt;$$ L_{a} = \frac{1}{M} \sum_{m=1}^{M} \tilde{E}_m $$&lt;/p&gt;

&lt;p&gt;For an i.i.d sample normally distributed with finite variance, the &lt;a href=&#34;https://journals.sagepub.com/doi/abs/10.1177/0008068319750115&#34; target=&#34;_blank&#34;&gt;MVUE of the square of the mean&lt;/a&gt; is the square of the empirical mean, minus the sample variance divided by the sample size. Said differently, we are back to the expression for the bc-MC operator, exactly as before:&lt;/p&gt;

&lt;p&gt;$$ L_{a} =  \frac{1}{M} \sum_{m=1}^{M }\Big( \Big[ \frac{1}{N}  \sum_{n=1}^{N} f(s_m, \varepsilon_n | \theta ) \Big]^2
 - \frac{S_m^2}{N} \Big) $$&lt;/p&gt;

&lt;h3 id=&#34;choice-of-the-hyperparameters-m-and-n&#34;&gt;Choice of the hyperparameters $M$ and $N$&lt;/h3&gt;

&lt;p&gt;One question that remains open is the optimal choice of the hyperparameters $M$ and $N$. In an ideal world in which computations are costless, we would like to take $M$ and $N$ to infinity. But in practice, the bc-MC estimator involves evaluating $f(s_m, \varepsilon_n)$ MN times, before combining these values using the formula $\frac{2}{MN(N-1)} f&amp;rsquo; \Lambda f $. A natural starting point for a &amp;ldquo;computational budget&amp;rdquo; consists in considering a multiple of $MN$, even if more sophisticated techniques could be used.&lt;/p&gt;

&lt;p&gt;If you do that, you will find the variance of the loss (for a given $\theta$) can be written as $\frac{1}{MN} \times h(M, N, \theta) $, where $h(M, N, \theta)$ can be estimated using simulated data from the model (propositions 4-6 in the paper). Said differently, for a given &amp;ldquo;computational budget&amp;rdquo;, we can find the best combination of $M$ and $N$ such that $h(M, N, \theta)$ is minimized. We can train the neural network (update the value for $\theta$), while simultaneously changing the values for $M$ and $N$.&lt;/p&gt;

&lt;p&gt;Note that if $N=2$ all the time, then we have&lt;/p&gt;

&lt;p&gt;$$ L^{U}_{M,N}(\theta) = \frac{1}{M} \sum_{m=1}^{M} f(s_m, \varepsilon^{1}_m | \theta ) f(s_m, \varepsilon^{2}_m | \theta ) $$&lt;/p&gt;

&lt;p&gt;which is an estimator that was already suggested in &lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0304393221000799&#34; target=&#34;_blank&#34;&gt;this paper&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;review-of-applications&#34;&gt;Review of applications&lt;/h3&gt;

&lt;p&gt;In the paper, I start with the really simple &lt;a href=&#34;https://github.com/JulienPascal/bc-MC_Operator/tree/main/6.Brock_Mirman_Colab&#34; target=&#34;_blank&#34;&gt;Brock-Mirman Stochastic Growth Model from 1972&lt;/a&gt;. For this model, we get a closed-form solution for the policy function and we can very sharply characterize the best choice for the hyperparameters $M$ and $N$. So it is good warm-up.&lt;/p&gt;

&lt;p&gt;A more interesting application is &lt;a href=&#34;https://github.com/JulienPascal/bc-MC_Operator/blob/main/9.large_scale_model_2/bc-MC-consumption-savings_large_scale_1.ipynb&#34; target=&#34;_blank&#34;&gt;consumption-savings model with a borrowing constraint&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But you can also apply this methodology to &lt;a href=&#34;https://github.com/JulienPascal/bc-MC_Operator/blob/main/10.OLG_model/OLG.ipynb&#34; target=&#34;_blank&#34;&gt;OLG models&lt;/a&gt; with a large number of different age groups.&lt;/p&gt;

&lt;p&gt;Probably the next step would be to use the methodology for a Krusell-Smith model.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Julien Pascal, Artificial neural networks to solve dynamic programming problems: A bias-corrected Monte Carlo operator,
Journal of Economic Dynamics and Control, Volume 162, 2024, 104853, ISSN 0165-1889,
&lt;a href=&#34;https://doi.org/10.1016/j.jedc.2024.104853&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.1016/j.jedc.2024.104853&lt;/a&gt;. (&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0165188924000459&#34; target=&#34;_blank&#34;&gt;https://www.sciencedirect.com/science/article/pii/S0165188924000459&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To cite this work:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@article{PASCAL2024104853,
title = {Artificial neural networks to solve dynamic programming problems: A bias-corrected Monte Carlo operator},
journal = {Journal of Economic Dynamics and Control},
volume = {162},
pages = {104853},
year = {2024},
issn = {0165-1889},
doi = {https://doi.org/10.1016/j.jedc.2024.104853},
url = {https://www.sciencedirect.com/science/article/pii/S0165188924000459},
author = {Julien Pascal}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Artificial Neural Networks to solve dynamic programming problems: a bias-corrected Monte Carlo operator</title>
      <link>https://julienpascal.github.io/publication/bc-mc-2024/</link>
      <pubDate>Mon, 01 Apr 2024 15:51:54 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/publication/bc-mc-2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>(In)efficient commuting and migration choices: Theory and policy in an urban search model</title>
      <link>https://julienpascal.github.io/publication/mpp_rsue_2023/</link>
      <pubDate>Wed, 26 Jul 2023 15:51:54 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/publication/mpp_rsue_2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Numerical Approximation of Expectations Squared</title>
      <link>https://julienpascal.github.io/post/integral_squared/</link>
      <pubDate>Sat, 03 Sep 2022 18:00:00 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/integral_squared/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Recently, I came across a simple question that led me through a quite interesting rabbit hole. The question is very simple (and very niche), but the analysis involves key results from statistical theory and numerical analysis (the Central Limit Theorem, the Delta method, and the second-order Delta method, Monte Carlo integration).&lt;/p&gt;

&lt;p&gt;Here is the seemingly innocent (and slightly bizarre) question:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Context:&lt;/strong&gt; One is interested in evaluating the square of an expectation $E\Big[g(X) \Big]^2 = \big(\int_{a}^{b} g(x) f_X(x) dx \Big)^2 = \mu^2$, where $\mu$ is an unknown quantity &lt;strong&gt;&amp;ldquo;close to zero&amp;rdquo;&lt;/strong&gt;. Note that the integral squared can be rewritten as $\big(\int_{a}^{b} g(x) f_X(x) dx \Big)^2  = \int_{a}^{b} \int_{a}^{b} g(x) g(y) f_X(x) f_Y(y) dx dy $. Transforming the square of an integral into a double integral is a standard trick, that is for instance used when calculating the &lt;a href=&#34;https://en.wikipedia.org/wiki/Gaussian_integral&#34; target=&#34;_blank&#34;&gt;Gaussian integral&lt;/a&gt;. Let&amp;rsquo;s say one want to numerically approximate $\mu^2$ using &lt;a href=&#34;https://en.wikipedia.org/wiki/Monte_Carlo_integration&#34; target=&#34;_blank&#34;&gt;Monte Carlo integration&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Question:&lt;/strong&gt; Is it better to approximate $\mu^2$ using the square of the Monte Carlo estimator $\big(\frac{1}{N} \sum_{i=1}^{N} f(x_i) \Big)^2$, or the Monte Carlo estimator based on the double integral: $\frac{1}{N} \sum_{i=1}^{N} f(x_i) f(y_i) $? Here the sample ${x_i}$ and ${y_i}$ are i.i.d random variables with density f(.). The random variables ${x_i}$ and ${y_i}$ have the same density function, but they are drawn independently from each other.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;i-consistency&#34;&gt;I. Consistency&lt;/h2&gt;

&lt;p&gt;Notice that both estimators are &lt;a href=&#34;https://en.wikipedia.org/wiki/Consistent_estimator&#34; target=&#34;_blank&#34;&gt;consistent&lt;/a&gt;. That is, as we increase $N$, the estimators converges in probability to the true value of the parameter $\mu^2$.&lt;/p&gt;

&lt;p&gt;In what follows, I use the notation $\mu$ to refer to $E\Big[f(X) \Big]$ and $\sigma^2$ to $Var\Big[f(X) \Big]$.&lt;/p&gt;

&lt;h3 id=&#34;estimator-big-frac-1-n-sum-i-1-n-f-x-i-big-2&#34;&gt;Estimator $\big(\frac{1}{N} \sum_{i=1}^{N} f(x_i) \Big)^2$&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.mit.edu/~kircher/sim.pdf&#34; target=&#34;_blank&#34;&gt;We know that Monte Carlo estimator are consistent&lt;/a&gt;: So $\frac{1}{N} \sum_{i=1}^{N} f(x_i)  \overset{p}{\to} \mu$. Because the function $x \rightarrow x^2$ is continuous on $R$, the &lt;a href=&#34;https://en.wikipedia.org/wiki/Continuous_mapping_theorem&#34; target=&#34;_blank&#34;&gt;continuous mapping theorem&lt;/a&gt; implies that  $\Big(\frac{1}{N} \sum_{i=1}^{N} f(x_i)\Big)^2  \overset{p}{\to} \mu^2$.&lt;/p&gt;

&lt;h3 id=&#34;estimator-frac-1-n-sum-i-1-n-f-x-i-f-y-i&#34;&gt;Estimator $\frac{1}{N} \sum_{i=1}^{N} f(x_i) f(y_i) $&lt;/h3&gt;

&lt;p&gt;Once again, we know that Monte Carlo estimator are consistent. So $\frac{1}{N} \sum_{i=1}^{N} f(x_i) f(y_i) \overset{p}{\to} \int_{a}^{b} \int_{a}^{b} g(x) g(y) f_X(x) f_Y(y) dx dy = \big(\int_{a}^{b} g(x) f_X(x) dx \Big)^2  = \mu^2$.&lt;/p&gt;

&lt;p&gt;Hence, both estimators get closer to the true value as we increase the number of draws N.&lt;/p&gt;

&lt;h2 id=&#34;ii-bias&#34;&gt;II. Bias&lt;/h2&gt;

&lt;p&gt;Interestingly, $\big(\frac{1}{N} \sum_{i=1}^{N} f(x_i) \Big)^2$ has a small sample bias, while $\frac{1}{N} \sum_{i=1}^{N} f(x_i) f(y_i) $ does not.&lt;/p&gt;

&lt;h3 id=&#34;estimator-big-frac-1-n-sum-i-1-n-f-x-i-big-2-1&#34;&gt;Estimator $\big(\frac{1}{N} \sum_{i=1}^{N} f(x_i) \Big)^2$&lt;/h3&gt;

&lt;p&gt;$$ E[ \big(\frac{1}{N} \sum_{i=1}^{N} f(x_i) \Big)^2] = \big(E [\frac{1}{N} \sum_{i=1}^{N} f(x_i)] \Big)^2 + Var(\frac{1}{N} \sum_{i=1}^{N} f(x_i))$$&lt;/p&gt;

&lt;p&gt;$$ E[ \big(\frac{1}{N} \sum_{i=1}^{N} f(x_i) \Big)^2] = \mu^2 + \frac{\sigma^2}{N} $$&lt;/p&gt;

&lt;p&gt;$$ Bias(\big(\frac{1}{N} \sum_{i=1}^{N} f(x_i) \Big)^2) = \frac{\sigma^2}{N} $$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Question for the careful reader:&lt;/strong&gt; How can you remove the bias? (See the answer below).&lt;/p&gt;

&lt;h3 id=&#34;estimator-frac-1-n-sum-i-1-n-f-x-i-f-y-i-1&#34;&gt;Estimator $\frac{1}{N} \sum_{i=1}^{N} f(x_i) f(y_i) $&lt;/h3&gt;

&lt;p&gt;$$ E [\frac{1}{N} \sum_{i=1}^{N} f(x_i) f(y_i)] = \frac{1}{N} \sum_{i=1}^{N} E[f(x_i) f(y_i)]  $$&lt;/p&gt;

&lt;p&gt;$$ = \frac{1}{N} \sum_{i=1}^{N} E[f(x_i)] E[ f(y_i)]  $$&lt;/p&gt;

&lt;p&gt;$$ = \mu^2  $$&lt;/p&gt;

&lt;p&gt;$$ Bias(\frac{1}{N} \sum_{i=1}^{N} f(x_i) f(y_i) ) = 0 $$&lt;/p&gt;

&lt;p&gt;Where, going from the first line to the second is based on the fact that $X$ and $Y$ are independent random variables. However, the bias is just one part of the whole story. To see which estimator is better, we also need to investigate their variance.&lt;/p&gt;

&lt;h2 id=&#34;iii-variance-case-mu-0&#34;&gt;III. Variance. Case $\mu &amp;gt; 0$&lt;/h2&gt;

&lt;h3 id=&#34;estimator-big-frac-1-n-sum-i-1-n-f-x-i-big-2-2&#34;&gt;Estimator $\big(\frac{1}{N} \sum_{i=1}^{N} f(x_i) \Big)^2$&lt;/h3&gt;

&lt;p&gt;Note that the value $\bar{X_n} = \frac{1}{N} \sum_{i=1}^{N} f(x_i) $ is the sample mean. The &lt;a href=&#34;https://en.wikipedia.org/wiki/Central_limit_theorem&#34; target=&#34;_blank&#34;&gt;Central Limit Theorem&lt;/a&gt; implies that:&lt;/p&gt;

&lt;p&gt;$$\sqrt{N} \frac{(\bar{X_n} - \mu)}{\sigma} \overset{d}{\to} N(0,1)$$&lt;/p&gt;

&lt;p&gt;To get the (asymptotic) variance of $\bar{X_n}^2$, one may use the &lt;a href=&#34;https://en.wikipedia.org/wiki/Delta_method&#34; target=&#34;_blank&#34;&gt;delta method&lt;/a&gt;. The delta method states that if there is a sequence of random variables $X_n$ satisfying:&lt;/p&gt;

&lt;p&gt;$$\sqrt{N} (\bar{X_n} - \theta) \overset{d}{\to} N(0,\sigma^2)$$&lt;/p&gt;

&lt;p&gt;with $\theta$ and $\sigma^2$ finite valued constants. Assume that $g$ is a function with continuous first derivative, satisfying the property that $g&amp;rsquo;(\theta)$ is &lt;strong&gt;non-zero valued&lt;/strong&gt;. Then,&lt;/p&gt;

&lt;p&gt;$$\sqrt{N} (g(\bar{X_n}) - g(\theta)) \overset{d}{\to} N(0,\sigma^2 [g&amp;rsquo;(\theta)]^2)$$&lt;/p&gt;

&lt;p&gt;Here $g(x) = x^2$, $g&amp;rsquo;(x) = 2x$, so the delta method implies that:&lt;/p&gt;

&lt;p&gt;$$\sqrt{N} (\bar{X_n}^2 - \mu^2) \overset{d}{\to} N(0,4\mu^2 \sigma^2)$$.&lt;/p&gt;

&lt;h3 id=&#34;estimator-frac-1-n-sum-i-1-n-f-x-i-f-y-i-2&#34;&gt;Estimator $\frac{1}{N} \sum_{i=1}^{N} f(x_i) f(y_i) $&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s use the notation $\bar{XY}_n = \frac{1}{N} \sum_{i=1}^{N} f(x_i) f(y_i) $. Once again, the &lt;a href=&#34;https://en.wikipedia.org/wiki/Central_limit_theorem&#34; target=&#34;_blank&#34;&gt;Central Limit Theorem&lt;/a&gt; implies that:&lt;/p&gt;

&lt;p&gt;$$\sqrt{N} (\bar{XY}_n - \mu^2) \overset{d}{\to} N(0, \sigma_{XY}^2)$$&lt;/p&gt;

&lt;p&gt;with $\sigma_{XY}^2 = Var(\bar{XY}_n)$.&lt;/p&gt;

&lt;p&gt;If $X$ and $Y$ are independent random variables, then $Var(XY) = Var(X)Var(Y) + Var(X)(E[Y]^2) + Var(Y)(E[X]^2)$.&lt;/p&gt;

&lt;p&gt;Here $Var(X) = Var(Y) = \sigma$, and $E[X] = E[Y] = \mu$, so the above equation simplifies to:&lt;/p&gt;

&lt;p&gt;$$ Var(XY) = \sigma^4 + 2 \mu^2 \sigma^2 $$.&lt;/p&gt;

&lt;h3 id=&#34;comparison-var-bar-xy-n-vs-var-bar-x-n-2&#34;&gt;Comparison $Var(\bar{XY}_n)$ vs $Var(\bar{X}_n^2)$&lt;/h3&gt;

&lt;p&gt;For large values of $\mu$, the estimator $\bar{XY}_n$ has smaller variance. However, when $\mu$ is small, $\bar{X_n}$ has a smaller variance. This property is illustrated below by plotting the function  $\mu \rightarrow (\sigma^4 + 2\mu^2\sigma^2) - 4\mu^2\sigma^2$ for different choices of $\sigma$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Plots
using LaTeXStrings
using Distributions
gr()

N = 100
grid_sigma = collect(range(0, 1.0, length=N))
grid_mu = collect(range(0, 1.0, length=N))
grid_mu_smaller = collect(range(0, 0.25, length=N))
diff = zeros(N,N)


f(mu, sigma) = (sigma.^4 .+ (2.0.*mu.^2).*(sigma.^2)) .- 4.0 .*(mu.^2).*(sigma.^2)

#p = plot(grid_mu, grid_sigma, (x,y) -&amp;gt; f(x,y), st = :contourf, xlabel=L&amp;quot;\mu&amp;quot;, ylabel=L&amp;quot;\sigma&amp;quot;, fill=true)
p0 = plot(grid_mu, x -&amp;gt; 0.0, label=L&amp;quot;0&amp;quot;, linestyle=:dash, ylabel=L&amp;quot;(\sigma^4 + 2\mu^2\sigma^2) - 4\mu^2\sigma^2&amp;quot;)
plot!(p0, grid_mu, x -&amp;gt; f(x,1.0), xlabel=L&amp;quot;\mu&amp;quot;, label=L&amp;quot;f(\mu, \sigma=1.0)&amp;quot;)
plot!(p0, grid_mu, x -&amp;gt; f(x,0.75), xlabel=L&amp;quot;\mu&amp;quot;, label=L&amp;quot;f(\mu, \sigma=0.75)&amp;quot;)
plot!(p0, grid_mu, x -&amp;gt; f(x,0.5), xlabel=L&amp;quot;\mu&amp;quot;, label=L&amp;quot;f(\mu, \sigma=0.5)&amp;quot;)

p1 = plot(grid_mu_smaller, x -&amp;gt; 0.0, label=L&amp;quot;0&amp;quot;, linestyle=:dash, ylabel=L&amp;quot;(\sigma^4 + 2\mu^2\sigma^2) - 4\mu^2\sigma^2&amp;quot;)
plot!(p1, grid_mu_smaller, x -&amp;gt; f(x,0.25), xlabel=L&amp;quot;\mu&amp;quot;, label=L&amp;quot;f(\mu, \sigma=0.25)&amp;quot;)
plot!(p1, grid_mu_smaller, x -&amp;gt; f(x,0.20), xlabel=L&amp;quot;\mu&amp;quot;, label=L&amp;quot;f(\mu, \sigma=0.20)&amp;quot;)
plot!(p1, grid_mu_smaller, x -&amp;gt; f(x,0.15), xlabel=L&amp;quot;\mu&amp;quot;, label=L&amp;quot;f(\mu, \sigma=0.15)&amp;quot;)

plot(p0, p1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Integral_Squared_6_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In the block of code below, I estimate $\bar{XY}_n$ and $\bar{X}_n^2$ in two cases. First, I assume that $X$ is normally distributed with mean $\mu$ and unit variance. In this case, we do not even need the central limit theorem, because the sum of iid Normal variables is also normally distributed. In the second case, I assume that $X$ is uniformly distributed $Uni(\mu-1, \mu+1)$, in which case the mean of $X$ is equal to $\mu$.&lt;/p&gt;

&lt;p&gt;As illustrated below, in both instances $\bar{X}_n^2$ has a smaller variance than $\bar{XY}_n$. The figure also underlines that even when $X$ is not normally distributed, the CLT kicks in and the above analysis provides a good estimate of the small sample behavior of our estimators.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;N = 5000 #number of draws
N_replicate = 5000 #number of replications for the distribution of the estimator
list_plots = [] #to store plots
sigma = 1.0 #variance when simulating from Normal

for (index_distribution, distribution) in enumerate([&amp;quot;Normal&amp;quot;, &amp;quot;Uniform&amp;quot;])
    for (index_mu, mu) in enumerate([0.20, 0.10, 0.05])

        #println(mu)

        if distribution == &amp;quot;Normal&amp;quot;
            d_x = Normal(mu, sigma)
            d_x1 = Normal(mu, sigma)
            d_x2 = Normal(mu, sigma)
        else
            d_x = Uniform(-1,1) + mu
            d_x1 = Uniform(-1,1) + mu
            d_x2 = Uniform(-1,1) + mu
        end

        # f(x) = x
        distristribution_square = zeros(N_replicate) # (mean(x))^2
        distristribution_square_centered = zeros(N_replicate) # (mean(x))^2 - mu^2
        distristribution_product_centered = zeros(N_replicate) # (mean(x1 x2) - mu^2

        # Stats on f(X)
        distristribution_std_f = zeros(N_replicate) #std f(X)
        distristribution_mean_f = zeros(N_replicate) #mean f(X)
        distribution_var_f = zeros(N_replicate) #var f(X)

        distristribution_product_std = zeros(N_replicate)
        distristribution_product_mean = zeros(N_replicate)

        for i=1:N_replicate

            draws_x = rand(d_x, N)
            draws_x1 = rand(d_x1, N)
            draws_x2 = rand(d_x2, N)

            distristribution_square[i] = mean(draws_x .- mu)^2
            distristribution_square_centered[i] = sqrt(N)*(mean(draws_x)^2 - mu^2)
            distristribution_product_centered[i] = sqrt(N)*(mean(draws_x1.*draws_x2) - mu^2)

            # Stats on f(X)
            distristribution_std_f[i] = std(draws_x)
            distristribution_mean_f[i] = mean(draws_x)
            distribution_var_f[i] = var(draws_x)

            distristribution_product_std[i] = std(draws_x1.*draws_x2)
            distristribution_product_mean[i] = mean(draws_x1.*draws_x2)

        end

        # Mean of certain statistics
        mu_fX = mean(distristribution_mean_f)
        sigma_fX = mean(distristribution_std_f)
        variance_fX = mean(distribution_var_f)

        # Empirical sigmas
        # Var(XY)
        var_n0_empirical = variance_fX^2 + variance_fX*(2*mu_fX^2)

        # Var(X^2)
        var_n1_empirical = (4*mu_fX^2*sigma_fX^2)        

        # Theoretical sigmas when using Normal draws
        var_n0 = sigma^2 * sigma^2 + sigma^2*(2*mu^2)
        var_n1 = (4*mu^2*sigma^2)

        pdf_normal_0 = Normal(0, sqrt(var_n0_empirical))
        pdf_normal_1 = Normal(0, sqrt(var_n1_empirical))

        # Plotting
        show_legend = false
        if index_mu == 2 &amp;amp;&amp;amp; index_distribution == 1
            show_legend = true
        end
        title_name = &amp;quot;&amp;quot;
        if index_distribution == 1
            title_name = &amp;quot;N($(mu), $(sigma))&amp;quot;
        else
            title_name = &amp;quot;U(-1, 1) + $(mu)&amp;quot;
        end

        p1 = histogram(distristribution_product_centered, label=L&amp;quot;$\sqrt{N}(\bar{X_1 X_2}_{n} - \mu^2 ) $&amp;quot;, normalize=true, alpha=0.5)
        histogram!(p1, distristribution_square_centered, label=L&amp;quot;$\sqrt{N}(\bar{X}_{n}^2 - \mu^2 )$&amp;quot;, normalize=true, alpha=0.5, title=title_name)

        plot!(p1, minimum(distristribution_product_centered):0.1:maximum(distristribution_product_centered), x-&amp;gt; pdf(pdf_normal_0, x), label=L&amp;quot;$N(0, \sigma^4 + 2\mu^2\sigma^2)$&amp;quot;)
        plot!(p1, minimum(distristribution_square_centered):0.1:maximum(distristribution_square_centered), x-&amp;gt; pdf(pdf_normal_1, x), label=L&amp;quot;$N(0, 4 \mu^2 \sigma^2)$&amp;quot;, legend = show_legend)
        push!(list_plots, p1)

    end

end

plot(list_plots[1], list_plots[2], list_plots[3], list_plots[4], list_plots[5], list_plots[6])
plot!(size=(1000,600))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Integral_Squared_8_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;iv-variance-case-mu-0&#34;&gt;IV. Variance. Case $\mu = 0$&lt;/h2&gt;

&lt;p&gt;The limit case $\mu = 0$ deserves a special treatment. Indeed, for the delta method to applies, the condition that $gâ€²(\theta)$ is &lt;strong&gt;non-zero valued&lt;/strong&gt; must hold. However with $g(\theta) = \theta^2$, $g&amp;rsquo;(0) = 2\times0=0$.&lt;/p&gt;

&lt;p&gt;In that context, the second-order delta method applies:&lt;/p&gt;

&lt;h3 id=&#34;second-order-delta-method&#34;&gt;Second order delta method&lt;/h3&gt;

&lt;p&gt;Consider a sequence of random variables $X_n$ satisfying:&lt;/p&gt;

&lt;p&gt;$$\sqrt{N} (\bar{X_n} - \theta) \overset{d}{\to} N(0,\sigma^2)$$&lt;/p&gt;

&lt;p&gt;with $\theta$ and $\sigma^2$ finite valued constants. Assume that $g$ is a function with continuous first and second derivatives, satisfying the property that $g&amp;rsquo;(\theta) = 0$ and $g&amp;rdquo;(\theta) \neq 0$. Then:&lt;/p&gt;

&lt;p&gt;$$N (g(\bar{X_n}) - g(\theta)) \overset{d}{\to} \sigma^2 \frac{g&amp;rdquo;(\theta)}{2} \chi^2(1)$$&lt;/p&gt;

&lt;p&gt;So applying the second order delta method with $g(\theta) = \theta^2$ and $\mu=0$ gives us:&lt;/p&gt;

&lt;p&gt;$$N (\bar{X_n}^2) \overset{d}{\to} \sigma^2 \chi^2(1)$$&lt;/p&gt;

&lt;p&gt;Using the fact that $Var(\chi^2(1)) = 2$ and rearranging terms gives:&lt;/p&gt;

&lt;p&gt;$$ Var(\bar{X_n}^2) \approx \frac{2 \sigma^4}{N^2}$$&lt;/p&gt;

&lt;p&gt;This approximation should get increasingly better as $N$ increases.&lt;/p&gt;

&lt;h3 id=&#34;comparison-var-bar-xy-n-vs-var-bar-x-n-2-1&#34;&gt;Comparison $Var(\bar{XY}_n)$ vs $Var(\bar{X}_n^2)$&lt;/h3&gt;

&lt;p&gt;When $\mu=0$:&lt;/p&gt;

&lt;p&gt;$$Var(\bar{XY}_n) = \frac{\sigma^4}{N}$$&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;$$Var(\bar{X_n}^2) = \frac{2\sigma^4}{N^2}$$&lt;/p&gt;

&lt;p&gt;Because of the $N^2$ at the denominator, we see that $\bar{X_n}^2$ converges much faster than $\bar{XY}_n$. This property is illustrated on the plot below, in which I do the same exercice as before, but with $\mu=0$. Note that I show the histogram of $\sqrt{N}(\bar{X_1 X_2}_{n} - \mu^2 )$ versus $N(\bar{X}^2_{n} - \mu^2 )$ (scaling with $\sqrt{N}$ versus $N$).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;N = 1000#number of draws
N_replicate = 5000 #number of replications for the distribution of the estimator
list_plots = []
sigma=1.0 #variance when simulating from Normal

for (index_distribution, distribution) in enumerate([&amp;quot;Normal&amp;quot;, &amp;quot;Uniform&amp;quot;])
    for (index_mu, mu) in enumerate([0.0])

        if distribution == &amp;quot;Normal&amp;quot;
            d_x = Normal(mu, sigma)
            d_x1 = Normal(mu, sigma)
            d_x2 = Normal(mu, sigma)
        else
            d_x = Uniform(-1,1) + mu
            d_x1 = Uniform(-1,1) + mu
            d_x2 = Uniform(-1,1) + mu
        end

        # f(x) = x
        distristribution_square = zeros(N_replicate) # (mean(x))^2
        distristribution_square_centered = zeros(N_replicate) # (mean(x))^2 - mu^2
        distristribution_product_centered = zeros(N_replicate) # (mean(x1 x2) - mu^2

        # Stats on f(X)
        distristribution_std_f = zeros(N_replicate) #std f(X)
        distristribution_mean_f = zeros(N_replicate) #mean f(X)
        distribution_var_f = zeros(N_replicate) #var f(X)

        distristribution_product_std = zeros(N_replicate)
        distristribution_product_mean = zeros(N_replicate)

        for i=1:N_replicate

            draws_x = rand(d_x, N)
            draws_x1 = rand(d_x1, N)
            draws_x2 = rand(d_x2, N)

            distristribution_square[i] = mean(draws_x .- mu)^2
            distristribution_square_centered[i] = N*(mean(draws_x)^2 - mu^2)/sigma
            distristribution_product_centered[i] = sqrt(N)*(mean(draws_x1.*draws_x2) - mu^2)

            # Stats on f(X)
            distristribution_std_f[i] = std(draws_x)
            distristribution_mean_f[i] = mean(draws_x)
            distribution_var_f[i] = var(draws_x)

            distristribution_product_std[i] = std(draws_x1.*draws_x2)
            distristribution_product_mean[i] = mean(draws_x1.*draws_x2)

        end

        # Mean of certain statistics
        mu_fX = mean(distristribution_mean_f)
        sigma_fX = mean(distristribution_std_f)
        variance_fX = mean(distribution_var_f)

        # Empirical sigmas
        # Var(XY)
        var_n0_empirical = variance_fX^2 + variance_fX*(2*mu_fX^2)

        pdf_normal_0 = Normal(0, sqrt(var_n0_empirical))
        pdf_chisq_1 = Chisq(1)

        # Plotting
        show_legend = false
        if index_mu == 1 &amp;amp;&amp;amp; index_distribution == 2
            show_legend = true
        end
        title_name = &amp;quot;&amp;quot;
        if index_distribution == 1
            title_name = &amp;quot;N($(mu), $(sigma))&amp;quot;
        else
            title_name = &amp;quot;U(-1, 1) + $(mu)&amp;quot;
        end

        p1 = histogram(distristribution_product_centered, label=L&amp;quot;$\sqrt{N}(\bar{X_1 X_2}_{n} - \mu^2 ) $&amp;quot;, normalize=true, alpha=0.5)
        histogram!(p1,distristribution_square_centered, label=L&amp;quot;$N(\bar{X}_{n}^2 - \mu^2)/\sigma^2$&amp;quot;, normalize=true, alpha=0.5, title=title_name)

        plot!(p1, minimum(distristribution_product_centered):0.1:maximum(distristribution_product_centered), x-&amp;gt; pdf(pdf_normal_0, x), label=L&amp;quot;$N(0, \sigma^4 + 2\mu^2\sigma^2)$&amp;quot;)
        plot!(p1, 0.001:0.01:maximum(distristribution_square_centered), x-&amp;gt; pdf(pdf_chisq_1, x), label=L&amp;quot;$\chi^2(1)$&amp;quot;, legend = show_legend)
        push!(list_plots, p1)

    end

end

plot(list_plots[1], list_plots[2])
plot!(size=(1000,300))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Integral_Squared_11_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;v-mean-squared-error&#34;&gt;V. Mean Squared Error&lt;/h2&gt;

&lt;p&gt;To measure the quality of an estimator, it is common to use the mean squared error (MSE). In plain English, the mean squared error measures the average squared difference between the estimated values and the actual value:&lt;/p&gt;

&lt;p&gt;$$ MSE(\hat{\theta}) = E_{\theta} [ (\hat{\theta} - \theta)^2] $$&lt;/p&gt;

&lt;p&gt;The MSE has the appealing property that it is equal to the variance of the estimator, plus the bias squared:&lt;/p&gt;

&lt;p&gt;$$ MSE(\hat{\theta}) = V [ \hat{\theta} ] + Bias(\hat{\theta})^2$$&lt;/p&gt;

&lt;p&gt;Fortunately, we have already done the heavy lifting by calculating the biases and the variances of the estimators.
Collecting the previous results, we have.&lt;/p&gt;

&lt;h3 id=&#34;case-mu-0&#34;&gt;Case $\mu &amp;gt;0 $&lt;/h3&gt;

&lt;p&gt;$$ MSE(\bar{X}^2_n) = \frac{\sigma^4 + 4N \mu^2 \sigma^2}{N^2} $$&lt;/p&gt;

&lt;p&gt;$$ MSE(\bar{XY}_n) = \frac{\sigma^4 + 2 \mu^2 \sigma^2}{N} $$&lt;/p&gt;

&lt;h3 id=&#34;case-mu-0-1&#34;&gt;Case $\mu = 0$&lt;/h3&gt;

&lt;p&gt;$$ MSE(\bar{X}^2_n) = \frac{3 \sigma^4}{N^2}$$&lt;/p&gt;

&lt;p&gt;$$ MSE(\bar{XY}_n) = \frac{\sigma^4}{N} $$&lt;/p&gt;

&lt;p&gt;It is easy to see that when $\mu$ is close or equal to 0, it is better to use $\bar{X}^2_n$ instead $\bar{XY}_n$. In the next section, I check that numerically with some examples.&lt;/p&gt;

&lt;h2 id=&#34;vi-numerical-illustration&#34;&gt;VI. Numerical illustration&lt;/h2&gt;

&lt;h3 id=&#34;case-mu-0-2&#34;&gt;Case $\mu = 0$&lt;/h3&gt;

&lt;p&gt;The takeaway of the previous sections is that if we suspect $\mu$ in a neighborhood of 0, one is better off using $\bar{X_n}^2$ instead of $\bar{XY}_n$.&lt;/p&gt;

&lt;p&gt;Now I compare the accuracy of both approaches for a numerical integration exercice. For instance, let&amp;rsquo;s approximate the integral:&lt;/p&gt;

&lt;p&gt;$$ \Big(\int_{-\infty}^{+\infty} x^3 \frac{1}{\sqrt{2\pi}}  \exp(\frac{-1}{2}x^2) dx \Big)^2 $$&lt;/p&gt;

&lt;p&gt;The true value of the integral is known to be &lt;strong&gt;zero&lt;/strong&gt; (odd central moment of a normally distributed random variable). The left panel in the next graph shows the mean squared error for $\bar{X}^2_n$ and $\bar{XY}_n$. As expected given the previous sections, $\bar{X}^2_n$ provides a much better approximation to $\mu^2$ than $\bar{XY}_n$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;grid_N = [100, 1000, 10000, 100000, 1000000]
N_replicate = 1000 #number of replications for the distribution of the estimator

# To store stats values
distristribution_mean = zeros(length(grid_N), N_replicate)
distristribution_var = zeros(length(grid_N), N_replicate)
distristribution_var_product = zeros(length(grid_N), N_replicate)
distristribution_square_mean = zeros(length(grid_N), N_replicate)
distristribution_product_mean = zeros(length(grid_N), N_replicate)

# Store stats on distribution of values for each replication

distristribution_mean_var = zeros(length(grid_N))
distristribution_mean_var_product = zeros(length(grid_N))
distristribution_square_average = zeros(length(grid_N))
distristribution_square_var = zeros(length(grid_N))

distristribution_product_average = zeros(length(grid_N))
distristribution_product_var = zeros(length(grid_N))

# To store stats on Mean Squared Error (MSE)
distristribution_square_MSE_average = zeros(length(grid_N))
distristribution_square_MSE_var = zeros(length(grid_N))

distristribution_product_MSE_average = zeros(length(grid_N))
distristribution_product_MSE_var = zeros(length(grid_N))


mu = 0
sigma = 1.0 #variance when simulating from Normal
f(x) = x.^3

for (index_N, N) in enumerate(grid_N)

    d_x = Normal(mu, sigma)
    d_x1 = Normal(mu, sigma)
    d_x2 = Normal(mu, sigma)

    for i=1:N_replicate

        draws_x = rand(d_x, N)
        draws_x1 = rand(d_x1, N)
        draws_x2 = rand(d_x2, N)

        distristribution_mean[index_N, i] = mean(f(draws_x)) #mean f(x)
        distristribution_var[index_N, i] = var(f(draws_x)) #variance of f(x)
        distristribution_var_product[index_N, i] = var(f(draws_x1).*f(draws_x2)) #variance of f(x1)*f(x2)
        distristribution_square_mean[index_N, i] = mean(f(draws_x))^2
        distristribution_product_mean[index_N, i] = mean(f(draws_x1).*f(draws_x2))

    end

    #Stats across different replications
    # Variance estimator
    # E(x^2)
    distristribution_mean_var[index_N] = mean(distristribution_var[index_N, :]) #average of variances
    distristribution_mean_var_product[index_N] = mean(distristribution_var_product[index_N, :]) #average of variances of products
    distristribution_square_var[index_N] = var(distristribution_square_mean[index_N, :])
    distristribution_square_average[index_N] = mean(distristribution_square_mean[index_N, :])

    # E(xy)
    distristribution_product_var[index_N] = var(distristribution_product_mean[index_N, :])
    distristribution_product_average[index_N] = mean(distristribution_product_mean[index_N, :])

    # Mean squared error
    # Note that here the true value is 0
    # E(x^2)
    distristribution_square_MSE_var[index_N] = var((distristribution_square_mean[index_N, :]).^2)
    distristribution_square_MSE_average[index_N] = mean((distristribution_square_mean[index_N, :]).^2)

    # E(xy)
    distristribution_product_MSE_var[index_N] = var(distristribution_product_mean[index_N, :].^2)
    distristribution_product_MSE_average[index_N] = mean(distristribution_product_mean[index_N, :].^2)


end

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Plot for the expected value
p0 = plot(log10.(grid_N), log10.(distristribution_square_MSE_average), label=L&amp;quot;Empirical $\bar{X}^2_n$&amp;quot;, xlabel=L&amp;quot;$log_{10}(N)$&amp;quot;)
plot!(log10.(grid_N), log10.(distristribution_product_MSE_average),  label =L&amp;quot;Empirical $\bar{XY}_n$&amp;quot;, xlabel=L&amp;quot;$log_{10}(N)$&amp;quot;, ylabel=L&amp;quot;$log_{10}(MSE)$&amp;quot;)
plot!(log10.(grid_N), log10.((distristribution_mean_var.^2 )./(grid_N)), label=L&amp;quot;$\sigma^4/N$&amp;quot;, linestyle=:dash, linewidth=2.0)
plot!(log10.(grid_N), log10.((3.0 .* distristribution_mean_var.^2 )./(grid_N.^2)), label=L&amp;quot;$3\sigma^4/N^2$&amp;quot;, title=&amp;quot;Mean Squared Error&amp;quot;, linestyle=:dash, linewidth=2.0)

# Plot for the variance
p1 = plot(log10.(grid_N), log10.(distristribution_square_var), label=L&amp;quot;Empirical $\bar{X}^2_n$&amp;quot;, xlabel=L&amp;quot;$log_{10}(N)$&amp;quot;)
plot!(p1, log10.(grid_N), log10.(distristribution_product_var),  label =L&amp;quot;Empirical $\bar{XY}_n$&amp;quot;, xlabel=L&amp;quot;$log_{10}(N)$&amp;quot;)
# Variance absolute value of $\bar{XY}_n$
# Using Jensen&#39;s inequality, it is slightly below the variance of $\bar{XY}_n$
# plot!(p1, log10.(grid_N), log10.(var(abs.(distristribution_product_mean), dims=2)),  label =L&amp;quot;$|\bar{XY}_n|$&amp;quot;, xlabel=L&amp;quot;$log_{10}(N)$&amp;quot;)
plot!(p1, log10.(grid_N), log10.((2.0 .* distristribution_mean_var.^2 )./(grid_N.^2)), label=L&amp;quot;$2\sigma^4/N^2$&amp;quot;, linestyle=:dash, linewidth=2.0)
plot!(p1, log10.(grid_N), log10.((distristribution_mean_var.^2 )./(grid_N)), label=L&amp;quot;$\sigma^4/N$&amp;quot;, title=&amp;quot;Variance Estimator&amp;quot;, ylabel=L&amp;quot;$log_{10}(Variance)$&amp;quot;, linestyle=:dash, linewidth=2.0)


plot(p0, p1)
plot!(size=(800,400))

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Integral_Squared_15_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The log scale of the previous graph does not do justice to the difference that exists between both estimators.
So in the next graph, I keep a linear scale. The blue line is the average value for a given $N$. This graph makes obvious $\bar{X}_n$ converges much quicker to $\mu^2$ than $\bar{XY}_n$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;grid_N = collect(range(100, 100000, step=1000))
N_replicate = 100 #number of replications for the distribution of the estimator

distristribution_square_mean = zeros(length(grid_N), N_replicate)
distristribution_product_mean = zeros(length(grid_N), N_replicate)

# Distribution of values for each replication
distristribution_square_average = zeros(length(grid_N))
distristribution_square_var = zeros(length(grid_N))

distristribution_product_average = zeros(length(grid_N))
distristribution_product_var = zeros(length(grid_N))


mu = 0
sigma=1.0 #variance when simulating from Normal
f(x) = x.^3

for (index_N, N) in enumerate(grid_N)

    d_x = Normal(mu, sigma)
    d_x1 = Normal(mu, sigma)
    d_x2 = Normal(mu, sigma)

    for i=1:N_replicate

        draws_x = rand(d_x, N)
        draws_x1 = rand(d_x1, N)
        draws_x2 = rand(d_x2, N)

        distristribution_square_mean[index_N, i] = mean(f(draws_x))^2
        distristribution_product_mean[index_N, i] = mean(f(draws_x1).*f(draws_x2))

    end

    #Stats across different replications
    # E(x^2)
    distristribution_square_average[index_N] = mean(distristribution_square_mean[index_N, :])

    # E(xy)
    distristribution_product_average[index_N] = mean(distristribution_product_mean[index_N, :])

end

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;min_val = minimum(distristribution_product_mean)
max_val = maximum(distristribution_product_mean)
p0 = scatter(grid_N, distristribution_square_mean, legend=false,title=L&amp;quot;$\bar{X}^2_n$&amp;quot;, xlabel=L&amp;quot;$N$&amp;quot;, alpha=0.5, ylims=(min_val, max_val ))
plot!(p0, grid_N, distristribution_square_average, label=&amp;quot;mean&amp;quot;, ylims=(min_val, max_val ), linewidth=2.0, color=&amp;quot;blue&amp;quot;, xrotation = 15)
p1 = scatter(grid_N, distristribution_product_mean, legend=false,title=L&amp;quot;$\bar{XY}_n$&amp;quot;, xlabel=L&amp;quot;$N$&amp;quot;, ylims=(min_val, max_val ))
plot!(p1, grid_N, distristribution_product_average, label=&amp;quot;mean&amp;quot;, ylims=(min_val, max_val ), linewidth=2.0, color=&amp;quot;blue&amp;quot;, xrotation = 15)
plot(p0, p1)
plot!(size=(800,600))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Integral_Squared_18_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;case-mu-small&#34;&gt;Case $\mu$ small&lt;/h3&gt;

&lt;p&gt;In practice, we do not know for sure that $\mu$ is exactly equal to zero. However, we know that $\mu$ is &amp;ldquo;close to zero&amp;rdquo;. Are we still better off using $\bar{X}^2_n$ instead of $\bar{XY}_n$?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;grid_N = [10, 100, 1000, 10000, 100000, 1000000]
N_replicate = 1000 #number of replications for the distribution of the estimator

# To store stats values
distristribution_mean = zeros(length(grid_N), N_replicate)
distristribution_var = zeros(length(grid_N), N_replicate)
distristribution_var_product = zeros(length(grid_N), N_replicate)
distristribution_square_mean = zeros(length(grid_N), N_replicate)
distristribution_product_mean = zeros(length(grid_N), N_replicate)

# Store stats on distribution of values for each replication
distristribution_mean_average = zeros(length(grid_N))
distristribution_mean_var = zeros(length(grid_N))
distristribution_mean_var_product = zeros(length(grid_N))
distristribution_square_average = zeros(length(grid_N))
distristribution_square_var = zeros(length(grid_N))

distristribution_product_average = zeros(length(grid_N))
distristribution_product_var = zeros(length(grid_N))

# To store stats on Mean Squared Error (MSE)
distristribution_square_MSE_average = zeros(length(grid_N))
distristribution_square_MSE_var = zeros(length(grid_N))

distristribution_product_MSE_average = zeros(length(grid_N))
distristribution_product_MSE_var = zeros(length(grid_N))


true_value = sqrt(0.01)
mu = true_value  #mean normal
sigma = 1.0 #variance when simulating from Normal
f(x) = x

distribution = &amp;quot;Uniform&amp;quot; # Choice between Normal(mu, sigma) or Uniform(-1,1) + mu

for (index_N, N) in enumerate(grid_N)

    if distribution == &amp;quot;Normal&amp;quot;
        d_x = Normal(mu, sigma)
        d_x1 = Normal(mu, sigma)
        d_x2 = Normal(mu, sigma)
    else
        d_x = Uniform(-1,1) + mu
        d_x1 = Uniform(-1,1) + mu
        d_x2 = Uniform(-1,1) + mu
    end

    for i=1:N_replicate

        draws_x = rand(d_x, N)
        draws_x1 = rand(d_x1, N)
        draws_x2 = rand(d_x2, N)

        distristribution_mean[index_N, i] = mean(f(draws_x)) #mean f(x)
        distristribution_var[index_N, i] = var(f(draws_x)) #variance of f(x)

        distristribution_var_product[index_N, i] = var(f(draws_x1).*f(draws_x2)) #variance of f(x1)*f(x2)
        distristribution_square_mean[index_N, i] = mean(f(draws_x))^2
        distristribution_product_mean[index_N, i] = mean(f(draws_x1).*f(draws_x2))

    end

    #Stats across different replications
    # Average of mean
    distristribution_mean_average[index_N] = mean(mean(distristribution_mean[index_N, :]))

    # Variance estimator
    # E(x^2)
    distristribution_mean_var[index_N] = mean(distristribution_var[index_N, :]) #average of variances
    distristribution_mean_var_product[index_N] = mean(distristribution_var_product[index_N, :]) #average of variances of products

    distristribution_square_var[index_N] = var(distristribution_square_mean[index_N, :])
    distristribution_square_average[index_N] = mean(distristribution_square_mean[index_N, :])

    # E(xy)
    distristribution_product_var[index_N] = var(distristribution_product_mean[index_N, :])
    distristribution_product_average[index_N] = mean(distristribution_product_mean[index_N, :])

    # Mean squared error
    # Note that here the true value is 0
    # E(x^2)
    distristribution_square_MSE_var[index_N] = var((distristribution_square_mean[index_N, :] .- true_value^2).^2)
    distristribution_square_MSE_average[index_N] = mean((distristribution_square_mean[index_N, :] .- true_value^2).^2)

    # E(xy)
    distristribution_product_MSE_var[index_N] = var((distristribution_product_mean[index_N, :] .- true_value^2).^2)
    distristribution_product_MSE_average[index_N] = mean((distristribution_product_mean[index_N, :] .- true_value^2).^2)


end


&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Plot for the expected value
p0 = plot(log10.(grid_N), log10.(distristribution_square_MSE_average), label=L&amp;quot;$Empirical \bar{X}^2_n$&amp;quot;, xlabel=L&amp;quot;$log_{10}(N)$&amp;quot;)
plot!(log10.(grid_N), log10.(distristribution_product_MSE_average),  label =L&amp;quot;$Empirical \bar{XY}_n$&amp;quot;, xlabel=L&amp;quot;$log_{10}(N)$&amp;quot;, ylabel=L&amp;quot;$log_{10}(MSE)$&amp;quot;)
plot!(log10.(grid_N), log10.((distristribution_mean_var.^2 + 2 .* distristribution_mean_average.^2 .* distristribution_mean_var)./(grid_N)), label=L&amp;quot;$(\sigma^4  + 2 \mu^2 \sigma^2)/N$&amp;quot;, linestyle=:dash, linewidth=2.0)
plot!(log10.(grid_N), log10.((3.0 .* distristribution_mean_var.^2 )./(grid_N.^2)), label=L&amp;quot;$3\sigma^4/N^2$&amp;quot;, title=&amp;quot;Mean Squared Error&amp;quot;, linestyle=:dash, linewidth=2.0)
plot!(log10.(grid_N), log10.((distristribution_mean_var.^2 + 4 .* grid_N .* distristribution_square_average .* distristribution_mean_var)./(grid_N.^2)), label=L&amp;quot;$\frac{\sigma^4 + 4N \mu^2 \sigma^2}{N^2}$&amp;quot;, title=&amp;quot;Mean Squared Error&amp;quot;, linestyle=:dash, linewidth=2.0)


# Plot for the variance
p1 = plot(log10.(grid_N), log10.(distristribution_square_var), label=L&amp;quot;$Empirical \bar{X}^2_n$&amp;quot;, xlabel=L&amp;quot;$log_{10}(N)$&amp;quot;)
plot!(p1, log10.(grid_N), log10.(distristribution_product_var),  label =L&amp;quot;Empirical $\bar{XY}_n$&amp;quot;, xlabel=L&amp;quot;$log_{10}(N)$&amp;quot;)
plot!(p1, log10.(grid_N), log10.((2.0 .* distristribution_mean_var.^2 )./(grid_N.^2)), label=L&amp;quot;$2\sigma^4/N^2$&amp;quot;, linestyle=:dash, linewidth=2.0)
plot!(p1, log10.(grid_N), log10.((distristribution_mean_var.^2 + 2 .* distristribution_mean_average.^2 .* distristribution_mean_var)./(grid_N)), label=L&amp;quot;$(\sigma^4  + 2 \mu^2 \sigma^2)/N$&amp;quot;, title=&amp;quot;Variance Estimator&amp;quot;, ylabel=L&amp;quot;$log_{10}(Variance)$&amp;quot;, linestyle=:dash, linewidth=2.0)
plot!(log10.(grid_N), log10.((4 .* distristribution_square_average .* distristribution_mean_var)./(grid_N)), label=L&amp;quot;$\frac{4 \mu^2 \sigma^2}{N}$&amp;quot;, linestyle=:dash, linewidth=2.0)


plot(p0, p1)
plot!(size=(800,400))

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Integral_Squared_21_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Below is another example with a &lt;strong&gt;linear scale&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;grid_N = collect(range(10, 1000, step=10))
N_replicate = 100 #number of replications for the distribution of the estimator

distristribution_square_mean = zeros(length(grid_N), N_replicate)
distristribution_product_mean = zeros(length(grid_N), N_replicate)

# Distribution of values for each replication
distristribution_square_average = zeros(length(grid_N))
distristribution_square_var = zeros(length(grid_N))

distristribution_product_average = zeros(length(grid_N))
distristribution_product_var = zeros(length(grid_N))


mu = true_value
sigma=1.0 #variance when simulating from Normal
f(x) = x

distribution = &amp;quot;Uniform&amp;quot; # Choice between Normal(mu, sigma) or Uniform(-1,1) + mu

for (index_N, N) in enumerate(grid_N)

    if distribution == &amp;quot;Normal&amp;quot;
        d_x = Normal(mu, sigma)
        d_x1 = Normal(mu, sigma)
        d_x2 = Normal(mu, sigma)
    else
        d_x = Uniform(-1,1) + mu
        d_x1 = Uniform(-1,1) + mu
        d_x2 = Uniform(-1,1) + mu
    end

    for i=1:N_replicate

        draws_x = rand(d_x, N)
        draws_x1 = rand(d_x1, N)
        draws_x2 = rand(d_x2, N)

        distristribution_square_mean[index_N, i] = mean(f(draws_x))^2
        distristribution_product_mean[index_N, i] = mean(f(draws_x1).*f(draws_x2))

    end

    #Stats across different replications
    # E(x^2)
    distristribution_square_average[index_N] = mean(distristribution_square_mean[index_N, :])

    # E(xy)
    distristribution_product_average[index_N] = mean(distristribution_product_mean[index_N, :])

end

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;min_val = minimum(distristribution_product_mean)
max_val = maximum(distristribution_product_mean)
p0 = scatter(grid_N, distristribution_square_mean, legend=false,title=L&amp;quot;$\bar{X}^2_n$&amp;quot;, xlabel=L&amp;quot;$N$&amp;quot;, alpha=0.5, ylims=(min_val, max_val ))
plot!(p0, grid_N, distristribution_square_average, label=&amp;quot;mean&amp;quot;, ylims=(min_val, max_val ), linewidth=3.0, color=&amp;quot;blue&amp;quot;, xrotation = 15)
plot!(grid_N, x -&amp;gt; mu^2, label=L&amp;quot;\mu^2&amp;quot;, linestyle = :dash, linewidth=3.0)
p1 = scatter(grid_N, distristribution_product_mean, legend=false,title=L&amp;quot;$\bar{XY}_n$&amp;quot;, xlabel=L&amp;quot;$N$&amp;quot;, ylims=(min_val, max_val ))
plot!(p1, grid_N, distristribution_product_average, label=&amp;quot;mean&amp;quot;, ylims=(min_val, max_val ), linewidth=3.0, color=&amp;quot;blue&amp;quot;, xrotation = 15)
plot!(p1, grid_N, x -&amp;gt; mu^2, label=L&amp;quot;\mu^2&amp;quot;, linestyle = :dash, linewidth=3.0)
plot(p0, p1)
plot!(size=(800,600))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Integral_Squared_24_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Based on a comparison of the mean squared error, $\big(\frac{1}{N} \sum_{i=1}^{N} f(x_i) \Big)^2$ is a &lt;strong&gt;better&lt;/strong&gt; estimator than $\frac{1}{N} \sum_{i=1}^{N} f(x_i) f(y_i) $
&lt;strong&gt;when $\mu^2$ is small&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Why should we care? In some applications, we aim at finding a function $f$ that minimizes the square of an expectation: $\big(E[f(X)]\big)^2$. Numerical methods can find $\hat{f}$ such that $\big(E[\hat{f}(X)]\big)^2 \approx 0$. In general, no closed-form solution is available for the expectation, so one must use numerical methods. For instance, Monte Carlo integration. Hence, the question of $\bar{X}_n^2$ vs $\bar{XY}_n$ appears quite naturally in that context.&lt;/p&gt;

&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;versioninfo()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Julia Version 1.7.1
Commit ac5cc99908 (2021-12-22 19:35 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-12.0.1 (ORCJIT, skylake)
Environment:
  JULIA_NUM_THREADS = 4
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;extra&#34;&gt;Extra&lt;/h2&gt;

&lt;p&gt;We can also use the &lt;strong&gt;Minimum Variance Unbiased Estimator (MVUE)&lt;/strong&gt; of $\mu^2$, which is&lt;/p&gt;

&lt;p&gt;$$  T_2 = \big(\frac{1}{N} \sum_{i=1}^{N} f(x_i) \Big)^2 - \frac{S^2}{N}$$&lt;/p&gt;

&lt;p&gt;Where $S^2$ is the &lt;strong&gt;sample variance&lt;/strong&gt;. It is unbiased because $S^2$ is an unbiased estimator of of $\sigma^2$. We saw above that the bias for $\bar{X}^2_n$ was $\frac{\sigma^2}{N}$.&lt;/p&gt;

&lt;p&gt;$$ V(T_2) = Var(\bar{X_n}^2) + Var(\frac{S^2}{N}) - \frac{2}{N} Cov(\bar{X_n}^2, S^2)$$&lt;/p&gt;

&lt;p&gt;Using the Cauchy-Schwarz inequality:&lt;/p&gt;

&lt;p&gt;$$ V(T_2) \leq Var(\bar{X_n}^2) + Var(\frac{S^2}{N}) + \frac{2}{N} \sqrt{Var(\bar{X_n}^2)Var(S^2)}$$&lt;/p&gt;

&lt;p&gt;We have seen above that for N sufficiently large, $Var(\bar{X_n}^2) \approx \frac{4\mu^2\sigma^2}{N}$.
The variance of the sample variance is $Var(S^2) = \frac{\sigma^4}{N}(\kappa - 1 + \frac{2}{N-1})$, with $\kappa$ the kurtosis. Hence,&lt;/p&gt;

&lt;p&gt;$$ V(T_2) \leq \frac{4\mu^2\sigma^2}{N} + \frac{\sigma^4}{N^3}(\kappa - 1 + \frac{2}{N-1}) + \frac{4\mu\sigma^3}{N^2}\sqrt{\kappa - 1 + \frac{2}{N-1}}  $$&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Things get simpler if one assumes &lt;strong&gt;Normality&lt;/strong&gt; for $f(x)$. First, normality implies that $\bar{X_n}$ and $S^2$ are independent (see &lt;a href=&#34;https://en.wikipedia.org/wiki/Basu%27s_theorem&#34; target=&#34;_blank&#34;&gt;Basus&amp;rsquo;s theorem&lt;/a&gt;). Thus $\bar{X_n}^2$ and $S^2$ are independent, because $x-&amp;gt;x^2$ is a measurable function on its domain. Then $Var(S^2) = \frac{2\sigma^4}{N-1}$. We also a formula for $Var(\bar{X_n}^2)$ in the normal case:&lt;/p&gt;

&lt;p&gt;$$ Var(\bar{X_n}^2) = \frac{4\mu^2\sigma^2}{N} \big( 1 + \frac{\sigma^2}{2n \mu^2}\big)$$&lt;/p&gt;

&lt;p&gt;source: &lt;a href=&#34;https://journals.sagepub.com/doi/abs/10.1177/0008068319750115&#34; target=&#34;_blank&#34;&gt;https://journals.sagepub.com/doi/abs/10.1177/0008068319750115&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Hence, with the normality assumption we have:&lt;/p&gt;

&lt;p&gt;$$ Var(T_2) = \frac{4\mu^2\sigma^2}{N} + \frac{2\sigma^4}{N (N-1)}$$&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Now let&amp;rsquo;s do a final comparison of MSE in the &lt;strong&gt;Normal case&lt;/strong&gt;. Also, let&amp;rsquo;s only use $N/2$ draws for $\bar{XY}_n$, &lt;strong&gt;to keep constant the number of time we call the function $f(.)$&lt;/strong&gt; in the code ($\bar{XY}_n$ uses twice as much function calls, because we use two independent series of shocks).&lt;/p&gt;

&lt;p&gt;$$ MSE(\bar{XY}_n) = 2 \frac{\sigma^4 + 2 \mu^2 \sigma^2}{N} = \frac{4\mu^2\sigma^2}{N} + \frac{2\sigma^4}{N}$$&lt;/p&gt;

&lt;p&gt;$$ MSE(\bar{X}^2_n) = \frac{4\mu^2\sigma^2}{N} + \frac{3\sigma^4}{N^2} $$&lt;/p&gt;

&lt;p&gt;$$ MSE(T_2) = \frac{4\mu^2\sigma^2}{N} + \frac{2\sigma^4}{N (N-1)} $$&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;When $N=2$, $MSE(\bar{XY}_n) = MSE(T_2)$. For $N&amp;gt;2$, $MSE(\bar{XY}_n) &amp;gt; MSE(T_2)$&lt;/li&gt;
&lt;li&gt;When $N=2$, $MSE(\bar{X}^2_n) &amp;lt; MSE(T_2)$. When $N \geq 3$, $MSE(\bar{X}^2_n) \geq MSE(T_2)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So if one only looks at the MSE, the suggestion is to use:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$\bar{X}^2_n$ when $N=2$&lt;/li&gt;
&lt;li&gt;$T_2$ when $N\geq 3$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;Integral_Squared_31_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;grid_N = [2, 4, 10, 100, 1000, 10000, 100000]
N_replicate = 10000 #number of replications for the distribution of the estimator

# To store stats values
distristribution_mean = zeros(length(grid_N), N_replicate)
distristribution_var = zeros(length(grid_N), N_replicate)
distristribution_var_product = zeros(length(grid_N), N_replicate)
distristribution_square_mean = zeros(length(grid_N), N_replicate)
distribution_T2 = zeros(length(grid_N), N_replicate)
distristribution_product_mean = zeros(length(grid_N), N_replicate)

# Store stats on distribution of values for each replication
distristribution_mean_average = zeros(length(grid_N))
distristribution_mean_var = zeros(length(grid_N))
distristribution_mean_var_product = zeros(length(grid_N))
distristribution_square_average = zeros(length(grid_N))
distristribution_square_var = zeros(length(grid_N))

distristribution_product_average = zeros(length(grid_N))
distristribution_product_var = zeros(length(grid_N))

# To store stats on Mean Squared Error (MSE)
distristribution_square_MSE_average = zeros(length(grid_N))
distristribution_square_MSE_var = zeros(length(grid_N))

distristribution_product_MSE_average = zeros(length(grid_N))
distristribution_product_MSE_var = zeros(length(grid_N))

distristribution_T2_MSE_var = zeros(length(grid_N))
distristribution_T2_MSE_average = zeros(length(grid_N))

true_value = sqrt(0.1)
mu = true_value  #mean normal
sigma = 1.0 #variance when simulating from Normal
f(x) = x

distribution = &amp;quot;Normal&amp;quot; #&amp;quot;Uniform&amp;quot; # Choice between Normal(mu, sigma) or Uniform(-1,1) + mu

for (index_N, N) in enumerate(grid_N)

    N2 = Int(N/2) #to keep the number of function evaluations constant

    if distribution == &amp;quot;Normal&amp;quot;
        d_x = Normal(mu, sigma)
        d_x1 = Normal(mu, sigma)
        d_x2 = Normal(mu, sigma)
    else
        d_x = Uniform(-1,1) + mu
        d_x1 = Uniform(-1,1) + mu
        d_x2 = Uniform(-1,1) + mu
    end

    for i=1:N_replicate

        draws_x = rand(d_x, N)
        draws_x1 = rand(d_x1, N2)
        draws_x2 = rand(d_x2, N2)

        distristribution_mean[index_N, i] = mean(f(draws_x)) #mean f(x)
        distristribution_var[index_N, i] = var(f(draws_x)) #variance of f(x)

        distristribution_var_product[index_N, i] = var(f(draws_x1).*f(draws_x2)) #variance of f(x1)*f(x2)
        distristribution_square_mean[index_N, i] = mean(f(draws_x))^2
        distribution_T2[index_N, i] = mean(f(draws_x))^2 - (var(f(draws_x))/N)
        distristribution_product_mean[index_N, i] = mean(f(draws_x1).*f(draws_x2))

    end

    #Stats across different replications
    # Average of mean
    distristribution_mean_average[index_N] = mean(mean(distristribution_mean[index_N, :]))

    # Variance estimator
    # E(x^2)
    distristribution_mean_var[index_N] = mean(distristribution_var[index_N, :]) #average of variances
    distristribution_mean_var_product[index_N] = mean(distristribution_var_product[index_N, :]) #average of variances of products

    distristribution_square_var[index_N] = var(distristribution_square_mean[index_N, :])
    distristribution_square_average[index_N] = mean(distristribution_square_mean[index_N, :])

    # E(xy)
    distristribution_product_var[index_N] = var(distristribution_product_mean[index_N, :])
    distristribution_product_average[index_N] = mean(distristribution_product_mean[index_N, :])

    # Mean squared error
    # Note that here the true value is 0
    # E(x^2)
    distristribution_square_MSE_var[index_N] = var((distristribution_square_mean[index_N, :] .- true_value^2).^2)
    distristribution_square_MSE_average[index_N] = mean((distristribution_square_mean[index_N, :] .- true_value^2).^2)

    # E(xy)
    distristribution_product_MSE_var[index_N] = var((distristribution_product_mean[index_N, :] .- true_value^2).^2)
    distristribution_product_MSE_average[index_N] = mean((distristribution_product_mean[index_N, :] .- true_value^2).^2)

    # E(x^2) - S^2/N
    distristribution_T2_MSE_var[index_N] = var((distribution_T2[index_N, :] .- true_value^2).^2)
    distristribution_T2_MSE_average[index_N] = mean((distribution_T2[index_N, :] .- true_value^2).^2)


end

# Plot for the expected value
p0 = plot(log10.(grid_N), log10.(distristribution_square_MSE_average), label=L&amp;quot;$Empirical \bar{X}^2_n$&amp;quot;, xlabel=L&amp;quot;$log_{10}(N)$&amp;quot;)
plot!(log10.(grid_N), log10.(distristribution_product_MSE_average),  label =L&amp;quot;$Empirical \bar{XY}_n$&amp;quot;, xlabel=L&amp;quot;$log_{10}(N)$&amp;quot;, ylabel=L&amp;quot;$log_{10}(MSE)$&amp;quot;)
plot!(log10.(grid_N), log10.(distristribution_T2_MSE_average),  label =L&amp;quot;$Empirical T_{2,n}$&amp;quot;, xlabel=L&amp;quot;$log_{10}(N)$&amp;quot;, ylabel=L&amp;quot;$log_{10}(MSE)$&amp;quot;)
vline!([log10.(3)], label=L&amp;quot;$log_{10}(3)$&amp;quot;)
plot!(log10.(grid_N), log10.(2*(distristribution_mean_var.^2 + 2 .* distristribution_mean_average.^2 .* distristribution_mean_var)./(grid_N)), label=L&amp;quot;$2(\sigma^4  + 2 \mu^2 \sigma^2)/N$&amp;quot;, linestyle=:dash, linewidth=2.0)
#plot!(log10.(grid_N), log10.((3.0 .* distristribution_mean_var.^2 )./(grid_N.^2)), label=L&amp;quot;$3\sigma^4/N^2$&amp;quot;, title=&amp;quot;Mean Squared Error&amp;quot;, linestyle=:dash, linewidth=2.0)
plot!(log10.(grid_N), log10.((4 .* distristribution_mean_average.^2 .* distristribution_mean_var)./(grid_N) + (2.0 .* distristribution_mean_var.^2 )./(grid_N.*(grid_N .- 1))), label=L&amp;quot;$\frac{4 \mu^2 \sigma^2}{N} + \frac{2 \sigma^4}{N(N-1)}$&amp;quot;, title=&amp;quot;Mean Squared Error&amp;quot;, linestyle=:dash, linewidth=2.0)
plot!(log10.(grid_N), log10.((4 .* distristribution_mean_average.^2 .* distristribution_mean_var)./(grid_N) + (3.0 .* distristribution_mean_var.^2 )./(grid_N.^2)), label=L&amp;quot;$\frac{4 \mu^2 \sigma^2}{N} + \frac{3 \sigma^4}{N^2}$&amp;quot;, title=&amp;quot;Mean Squared Error&amp;quot;, linestyle=:dash, linewidth=2.0)

plot!(size=(800,400))
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>The Curse of Dimensionality and Adaptive Sparse Grids</title>
      <link>https://julienpascal.github.io/post/asg/</link>
      <pubDate>Sat, 12 Feb 2022 08:00:00 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/asg/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Curse_of_dimensionality&#34; target=&#34;_blank&#34;&gt;curse of dimensionality&lt;/a&gt;&lt;/strong&gt; is at the heart of dynamic programming. And dynamic programming is the cornerstone of modern economic theory. But what is the curse of dimensionality exactly? The aim of this blog post is to answer this question and to show one method that alleviates this curse: &lt;strong&gt;adaptive sparse grids&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TL;DR: adaptive sparse grids help you to limit the bite of the curse of dimensionality&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;You can download the notebook for this post &lt;a href=&#34;https://github.com/JulienPascal/Adaptive_Sparse_Grids&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;i-theory-the-curse-of-dimensionality&#34;&gt;I. Theory: the curse of dimensionality&lt;/h2&gt;

&lt;h3 id=&#34;i-a-problem-the-curse-of-dimensionality&#34;&gt;I. A. Problem: the curse of dimensionality&lt;/h3&gt;

&lt;p&gt;The behavior of an optimizing agent can be summarized by a Bellman equation of the form:&lt;/p&gt;

&lt;p&gt;$$ V(x,z) = \max_{c \in \Gamma(x,z)}[ F(x,c,z) + \beta E_{z&amp;rsquo;|z}[ V(T(x,c), z&amp;rsquo;) ]$$&lt;/p&gt;

&lt;p&gt;where $x$ is a &lt;strong&gt;non-random&lt;/strong&gt; state variable and $z$ is a &lt;strong&gt;random&lt;/strong&gt; variable following a Markov process. Both $x$ and $z$ are to be understood as vectors. The function $\Gamma(.)$ represents the set of possible actions given a current state and the function $T(.)$ captures the transition from one state to another when an action is taken. The variable $\beta$ is a discount factor striclty smaller than one and the $E$ represent an expectation operator.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s now assume that we know the policy function that dictates the optimal behavior of the agent $c^{\star} = g(x,z)$, so we can ignore the max operator and rewrite the above as:&lt;/p&gt;

&lt;p&gt;$$ V(x,z) = F(x,c^{\star},z) + \beta E_{z&amp;rsquo;|z}[ V(T(x,c^{\star}), z&amp;rsquo;) ]$$&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Now let&amp;rsquo;s leave the theoretical world. In practice one needs to &lt;strong&gt;discretize (x,z) on a grid using a finite number of points&lt;/strong&gt;. Let&amp;rsquo;s assume that the deterministic part of the state variable has $n$ dimensions and that the stochastic element has $z$ dimensions. For the sake of simplicity, let&amp;rsquo;s assume that we use $k$ points along each dimension. To evaluate $V(x,z)$, $k^{n+z}$ operations are needed to evaluate $F(x,c^{\star},z)$ on the grid.&lt;/p&gt;

&lt;p&gt;Things get even worse if we look at the second element of the right-hand-side of the above equation: the conditional expectation. In the present context, a conditional expectation is &amp;ldquo;simply&amp;rdquo; a multidimensional integral. From a numerical standpoint, a multidimensional integral can be approximated using &lt;a href=&#34;https://en.wikipedia.org/wiki/Gaussian_quadrature&#34; target=&#34;_blank&#34;&gt;Gaussian quadrature&lt;/a&gt;. Once again, for the sake of simplicity let&amp;rsquo;s assume we use $\omega$ nodes along each dimension for $z$. Then, Gaussian quadrature implies $w^z$ function evaluations for $V(.)$ for each point on the grid. So a grand total of $k^{n+z}w^{z}$ function evaluations, which is equal to $\exp[(n+z)log(k)+ zlog(w)]$.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;From the formula $\exp[(n+z)log(k)+ zlog(w)]$, I see two main takeaways:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Get rid of useless dimensions&lt;/strong&gt;. Yes, I know it&amp;rsquo;s obvious, but the formula makes it clear. Dimensions show up linearly within the exponential function, while the number of discretization points enters logarithmically. We can save computation time by being smart for the choice of grid points, but the smartest move is to get rid of useless dimensions.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Stochastic variables are more costly&lt;/strong&gt;. Once again it&amp;rsquo;s obvious, but I like the formalism that the formula brings. Stochastic variables matter for today ($zlog(k)$), but also for tomorrow ($zlog(w)$). The choice of quadrature nodes is important ($log(w)$), but a reduction in $z$ would even be better.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now let&amp;rsquo;s plot the number of function evaluations necessary for the conditional expectation as a function of the number of dimensions for x and z (holding the number of grid points and the quadrature nodes constant). As illustrated below, &lt;strong&gt;things get out of hand quite rapidly&lt;/strong&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Plots

function curse(n,z; k=10, w=5)
    exp((n+z)*log(k) + z*log(w))
end

p1 = plot(1:3, 1:3, (n,z) -&amp;gt; curse(n,z), st=:surface, xlabel=&amp;quot;n&amp;quot;, ylabel=&amp;quot;z&amp;quot;)
p2 = plot(1:3, n -&amp;gt; curse(n,1), label=&amp;quot;curse(n,1)&amp;quot;, xlabel=&amp;quot;n&amp;quot;)
p3 = plot(1:3, z -&amp;gt; curse(1,z), label=&amp;quot;curse(1,z)&amp;quot;, xlabel=&amp;quot;z&amp;quot;)

p = plot(p1, p2, p3)
display(p)
println(&amp;quot;Millions of function evaluations for curse(3,3): $(round(curse(3,3)/(10^6), digits = 2))&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ASG_2_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Millions of function evaluations for curse(3,3): 125.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;i-b-one-solution-adaptive-sparse-grids&#34;&gt;I.B. One solution: Adaptive Sparse Grids&lt;/h3&gt;

&lt;p&gt;One solution brought to the field of Economics by &lt;a href=&#34;https://johannesbrumm.com/wp-content/uploads/2017/09/Brumm-Scheidegger-2017-ECTA.pdf&#34; target=&#34;_blank&#34;&gt;Brumm and Scheidegger (2017)&lt;/a&gt; is to use &lt;strong&gt;adaptive sparse grids&lt;/strong&gt;. Adaptive sparse grids combine two ideas:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Sparse&lt;/strong&gt; grids are based on the idea that when it comes to extrapolation power, not all grid points are born equal. Some grid points are to some extent redundant and can be avoided.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Adaptive&lt;/strong&gt; sparse grids use a sparse grid as a starting point. Additional points are then added to the (sparse) grid in regions of high curvature.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now let&amp;rsquo;s look at how a sparse grid adapts to the curvature of the following &lt;strong&gt;non-smooth function&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;$$ f(x,y) = \frac{1}{|0.5 - x^4 - y^4| + 0.1} $$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Packages and helper functions
using AdaptiveSparseGrids
using Random
using Distributions
using IterTools
using DataFrames
using NBInclude
@nbinclude(&amp;quot;utils.ipynb&amp;quot;)

# Example taken from here: https://github.com/jacobadenbaum/AdaptiveSparseGrids.jl
# I made small modifications along the way
# Bounds
lb  = zeros(2)
ub  = ones(2)

# True function to approximate:
f(x) = 1.0/(abs(0.5 - x[1]^4 - x[2]^4) + 0.1)

# Construct approximation:
fun = AdaptiveSparseGrid(f, lb, ub,
                         max_depth = 10,    # The maximum depth of basis elements in each dimension
                         tol = 0.01)        # Add nodes when min(abs(alpha/f(x)), abs(alpha)) &amp;lt; tol

xy_grid = extract_grid(fun)
p1=scatter(xy_grid[:,1],xy_grid[:,2], m=(:black,2),title=&amp;quot;Sparse grid&amp;quot;, xlabel=L&amp;quot;x&amp;quot;, ylabel=L&amp;quot;y&amp;quot;)
p2 = plot(xy_grid[:,1],xy_grid[:,2], [fun(xy_grid[i,:]) for i in 1:size(xy_grid,1)], m=(:black,2),title=&amp;quot;Sparse grid&amp;quot;, xlabel=L&amp;quot;x&amp;quot;, ylabel=L&amp;quot;y&amp;quot;, zlabel=L&amp;quot;f(x,y)&amp;quot;, st=:scatter3d)
plot(p1, p2, legend=false)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ASG_4_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ii-application&#34;&gt;II. Application&lt;/h2&gt;

&lt;p&gt;Alright, back to Economics. We will focus on the model of the labour market by &lt;a href=&#34;https://www.aeaweb.org/articles?id=10.1257/aer.20131118&#34; target=&#34;_blank&#34;&gt;Lise and Robin&lt;/a&gt;. You can take a look at the original paper, or at my previous post &lt;a href=&#34;https://julienpascal.github.io/post/ann_2/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. &amp;ldquo;Solving the model&amp;rdquo; involves finding the function $S(.)$ solving the following equation:&lt;/p&gt;

&lt;p&gt;$$ S(x,y,z) = s(x,y,z) + \frac{1 - \delta}{1 + r} E_{z&amp;rsquo;|z} [ max(S(x,y,z&amp;rsquo;), 0) ] $$&lt;/p&gt;

&lt;h3 id=&#34;ii-a-value-function-iteration-with-a-dense-grid&#34;&gt;II. A. Value function iteration with a dense grid&lt;/h3&gt;

&lt;p&gt;For more details on value function iteration with a dense grid, you can look at my &lt;a href=&#34;https://julienpascal.github.io/post/ann_2/&#34; target=&#34;_blank&#34;&gt;former post here&lt;/a&gt;. The two blocks of code below solve for the unknow function
$S(.)$ and plot the results for a dense grid.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Type defined in &amp;quot;utils.ipynb&amp;quot;
p = Params(nx=21, ny=21, nz=10);
# Solve by dense value function iteration
# function defined in &amp;quot;utils.ipynb&amp;quot;
@time S_dense = solve_VFI(p, max_iter = 5000)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Iter 1312 Convergence reached
 64.575871 seconds (581.92 M allocations: 25.137 GiB, 7.04% gc time, 1.06% compilation time)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Reshape the grid
vals_grid = zeros(size(p.x_grid,1)*size(p.y_grid,1)*size(p.z_grid,1), 3)
for (i, (x, y, z)) in enumerate(product(p.x_grid, p.y_grid, p.z_grid))
    vals_grid[i, 1] = x
    vals_grid[i, 2] = y
    vals_grid[i, 3] = z
end

# Plot dense VFI
p1=scatter(vals_grid[:,1], vals_grid[:,2],m=(2),title=&amp;quot;Dense grid&amp;quot;, xlabel=L&amp;quot;x&amp;quot;, ylabel=L&amp;quot;y&amp;quot;)
p2 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; S_dense([x; y; 1.0])[1], label = &amp;quot;f(x)&amp;quot;, st=:surface)
plot!(vals_grid[:,1], vals_grid[:,2], [S_dense([vals_grid[i,1]; vals_grid[i,2]; 1.0])[1] for i in 1:size(vals_grid,1)], label = &amp;quot;f(x)&amp;quot;, st=:scatter3d)
title!(L&amp;quot;S(x,y,z=1) Dense&amp;quot;)
xlabel!(L&amp;quot;x&amp;quot;)
ylabel!(L&amp;quot;y&amp;quot;)

plot(p1, p2, legend=false)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ASG_7_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;ii-c-adaptive-sparse-grid&#34;&gt;II.C. Adaptive sparse grid&lt;/h3&gt;

&lt;p&gt;Now let&amp;rsquo;s solve the same problem using the methodology described in &lt;a href=&#34;https://johannesbrumm.com/wp-content/uploads/2017/09/Brumm-Scheidegger-2017-ECTA.pdf&#34; target=&#34;_blank&#34;&gt;Brumm and Scheidegger (2017)&lt;/a&gt; (without the fancy parallelism that they use). The idea is to &lt;strong&gt;start with a sparse grid&lt;/strong&gt; and to &lt;strong&gt;add points to the grid where the
function is non-smooth&lt;/strong&gt;. The following block of code does that and compare the results obtained previously with the dense grid. Both methods yield same results, despite the sparse grid having fewer points.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# A. Initialization of the RHS
function init_guess(x, p)
    p.s_xyz(x[1], x[2], x[3]) + ((1.0 - p.delta)/(1.0 + p.r))*max(0.0, p.s_xyz(x[1], x[2], x[3]))
end

# Construct our approximation (this will evaluate f at the needed points, using
# all available threads)
fun = AdaptiveSparseGrid(x -&amp;gt; init_guess(x, p), p.lower_bound, p.upper_bound,
                         max_depth = 5,    # The maximum depth of basis elements in
                                            # each dimension
                         tol = 0.015)        # Add nodes when
                                            # min(abs(alpha/f(x)), abs(alpha)) &amp;lt; tol
fun_init = deepcopy(fun)
xyz_grid = extract_grid(fun)
pred_old = [fun(xyz_grid[i,:]) for i in 1:size(xyz_grid,1)]

# B. Function that calculate the RHS of the Bellman equation, given the guess from the previous iteration
function RHS(x, p, fun_old)

    vals = zeros(p.nb_nodes, 3)
    for (k, innovation) in enumerate(p.nodes_E)
        vals[k,1] = x[1]
        vals[k,2] = x[2]
        #Have to use min(max()) to stay within the boundaries (no extrapolation allowed)
        vals[k,3] = min(max(fun.bounds[3,1], (x[3].^p.rho).*exp.(innovation)), fun.bounds[3,2])
    end

    p.s_xyz(x[1], x[2], x[3]) + ((1.0 - p.delta)/(1.0 + p.r)).*sum(p.weigths_E.*max.(0.0, [fun_old(vals[i,:]) for i in 1:size(vals, 1) ]))

end

# C. Solve the problem with adaptive sparse grid
# parameters for VFI
tol_VF = 1e-8 #tolerance for VFI
max_iter_VF = 5000 #max iterations for VFI
show_every = max_iter_VF #display difference
# initialize values
fun_old = deepcopy(fun_init)
pred_old = [fun_old(xyz_grid[i,:]) for i in 1:size(xyz_grid,1)]
max_depth = 5 #max depth for sparse grid
tol = 0.015 #tolerance on sparse grid

@time begin
    # Initialize
    for i = 1:max_iter_VF

        fun = AdaptiveSparseGrid(x -&amp;gt; RHS(x, p, fun_old), p.lower_bound, p.upper_bound,
                         max_depth = max_depth,    # The maximum depth of basis elements in
                                            # each dimension
                         tol = tol)        # Add nodes when
                                            # min(abs(alpha/f(x)), abs(alpha)) &amp;lt; tol

        # Prediction on fixed grid
        pred_new = [fun(xyz_grid[i,:]) for i in 1:size(xyz_grid,1)]

        # DISTANCE
        # Check on fixed grid
        diff= maximum(abs.(pred_new .- pred_old))
        if mod(i, show_every) == 0
            println(&amp;quot;Iter $(i) Diff : $(diff)&amp;quot;)
            println(&amp;quot;Max nb points on sparse grid: $(length(fun.nodes))&amp;quot;)
        end

        if diff &amp;lt; tol_VF
            println(&amp;quot;Iter $(i) Convergence reached&amp;quot;)
            break
        end

        #UPDATE
        pred_old = copy(pred_new)
        fun_old = deepcopy(fun)

    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Iter 1297 Convergence reached
 61.046396 seconds (435.68 M allocations: 17.780 GiB, 3.44% gc time, 0.96% compilation time)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Plot output
p1 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; S_dense([x; y; 1.0])[1], label = &amp;quot;f(x)&amp;quot;, st=:contour)
title!(L&amp;quot;S(x,y,z=1) Dense&amp;quot;)
xlabel!(L&amp;quot;x&amp;quot;)
ylabel!(L&amp;quot;y&amp;quot;)

# Initialization function
xyz_grid = extract_grid(fun)
p2 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; fun([x;y;1.0]), label = &amp;quot;f(x)&amp;quot;, st=:contour)
title!(L&amp;quot;S(x,y,z=1) Sparse&amp;quot;)
xlabel!(L&amp;quot;x&amp;quot;)
ylabel!(L&amp;quot;y&amp;quot;)

ratio = 9/16
width = 800
pp = plot(p1, p2, size = (width, width*ratio))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ASG_11_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;ii-d-sparse-grid-versus-dense-grid&#34;&gt;II.D. Sparse grid versus dense grid&lt;/h3&gt;

&lt;p&gt;As illustrated below, the sparse grid puts &lt;strong&gt;more points where the function $S(.)$ changes sign&lt;/strong&gt; (in the top left and the bottom right parts of the (x-y) space). It matters because the sign of $S(.)$ determines whether or not a job is feasible for a worker of type $x$ and a firm of productivity $y$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p1=scatter(xyz_grid[:,1], xyz_grid[:,2], m=(:black,2),title=&amp;quot;Sparse grid&amp;quot;, xlabel=L&amp;quot;x&amp;quot;, ylabel=L&amp;quot;y&amp;quot;)
p2=scatter(xyz_grid[:,1], xyz_grid[:,3], m=(:black,2),title=&amp;quot;Sparse grid&amp;quot;, xlabel=L&amp;quot;x&amp;quot;, ylabel=L&amp;quot;z&amp;quot;)
p3=scatter(xyz_grid[:,2], xyz_grid[:,3], m=(:black,2),title=&amp;quot;Sparse grid&amp;quot;, xlabel=L&amp;quot;y&amp;quot;, ylabel=L&amp;quot;z&amp;quot;)
p4 = plot(xyz_grid[:,1], xyz_grid[:,2], [fun(xyz_grid[i,:]) for i in 1:size(xyz_grid,1)], m=(:black,2),title=&amp;quot;Sparse grid&amp;quot;, st=:scatter3d, xlabel=L&amp;quot;x&amp;quot;, ylabel=L&amp;quot;y&amp;quot;, zlabel=L&amp;quot;S(x,y,z)&amp;quot;)
plot(p1, p2, p3, p4, legend=false, title=&amp;quot;Number points: $(size(xyz_grid, 1))&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ASG_13_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;ii-e-accuracy&#34;&gt;II.E. Accuracy&lt;/h3&gt;

&lt;p&gt;Looking at the mean squared error, or the median squared error, the adaptive sparse grid method is &lt;strong&gt;more accurate&lt;/strong&gt;. This holds despite the fact that the sparse grid has approximately &lt;strong&gt;four time less points&lt;/strong&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#Random draws from space
nb_draws = 1000
x_grid_rand = rand(Uniform(p.lower_bound[1], p.upper_bound[1]), nb_draws)
y_grid_rand = rand(Uniform(p.lower_bound[2], p.upper_bound[2]), nb_draws)
z_grid_rand = rand(Uniform(p.lower_bound[3], p.upper_bound[3]), nb_draws);

#LHS
LHS_dense = zeros(nb_draws)
LHS_sparse = zeros(nb_draws)
for (index, (xValue, yValue, zValue)) in enumerate(zip(x_grid_rand, y_grid_rand, z_grid_rand))
    LHS_dense[index] = S_dense([xValue; yValue; zValue])
    LHS_sparse[index] = fun([xValue; yValue; zValue])
end

#RHS
RHS_dense = zeros(nb_draws)
RHS_sparse = zeros(nb_draws)
for (index, (xValue, yValue, zValue)) in enumerate(zip(x_grid_rand, y_grid_rand, z_grid_rand))
    RHS_dense[index] = p.s_xyz(xValue, yValue, zValue) + ((1.0 - p.delta)/(1.0 + p.r)).*sum(p.weigths_E.*[max.(0.0, S_dense([xValue; yValue; (zValue.^p.rho).*exp.(innovation)])) for innovation in p.nodes_E])
    RHS_sparse[index] = RHS([xValue, yValue, zValue], p, fun)
end

err_dense = LHS_dense - RHS_dense
err_sparse = LHS_sparse - RHS_sparse

p1 = histogram(err_dense, label=&amp;quot;Error VFI dense&amp;quot;)
p2 = histogram(err_sparse, label=&amp;quot;Error VFI sparse&amp;quot;)
plot(p1, p2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ASG_15_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;df = DataFrame(Method = [&amp;quot;VFI Dense&amp;quot;, &amp;quot;VFI Sparse&amp;quot;],
                MEAN_SE = [mean(err_dense).^2, mean(err_sparse).^2],
                MEDIAN_SE = [median(err_dense).^2, median(err_sparse).^2],
                MAX_SE = [maximum(err_dense).^2, maximum(err_sparse).^2],
                MIN_SE = [minimum(err_dense).^2, minimum(err_sparse).^2],
                NB_Points = [size(vals_grid,1), size(xyz_grid,1)])

&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;data-frame&#34;&gt;&lt;p&gt;2 rows Ã— 6 columns&lt;/p&gt;&lt;table class=&#34;data-frame&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;Method&lt;/th&gt;&lt;th&gt;MEAN_SE&lt;/th&gt;&lt;th&gt;MEDIAN_SE&lt;/th&gt;&lt;th&gt;MAX_SE&lt;/th&gt;&lt;th&gt;MIN_SE&lt;/th&gt;&lt;th&gt;NB_Points&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th title=&#34;String&#34;&gt;String&lt;/th&gt;&lt;th title=&#34;Float64&#34;&gt;Float64&lt;/th&gt;&lt;th title=&#34;Float64&#34;&gt;Float64&lt;/th&gt;&lt;th title=&#34;Float64&#34;&gt;Float64&lt;/th&gt;&lt;th title=&#34;Float64&#34;&gt;Float64&lt;/th&gt;&lt;th title=&#34;Int64&#34;&gt;Int64&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;1&lt;/th&gt;&lt;td&gt;VFI Dense&lt;/td&gt;&lt;td&gt;3.5566e-7&lt;/td&gt;&lt;td&gt;1.8067e-8&lt;/td&gt;&lt;td&gt;0.00135398&lt;/td&gt;&lt;td&gt;6.68973e-8&lt;/td&gt;&lt;td&gt;4410&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;2&lt;/th&gt;&lt;td&gt;VFI Sparse&lt;/td&gt;&lt;td&gt;7.1713e-8&lt;/td&gt;&lt;td&gt;1.63528e-8&lt;/td&gt;&lt;td&gt;0.0010258&lt;/td&gt;&lt;td&gt;0.000577696&lt;/td&gt;&lt;td&gt;1644&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;When no closed-form solution is available, the curse of dimensionality makes the use of &amp;ldquo;brute-force methods&amp;rdquo; (e.g. value function iteration on a dense grid) unpractical/unfeasible. Using Adaptive sparse grids is one promising way to work with high-dimensional models.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://johannesbrumm.com/wp-content/uploads/2017/09/Brumm-Scheidegger-2017-ECTA.pdf&#34; target=&#34;_blank&#34;&gt;Brumm, Johannes, and Simon Scheidegger&lt;/a&gt;. &amp;ldquo;Using adaptive sparse grids to solve highâ€dimensional dynamic models.&amp;rdquo; Econometrica 85.5 (2017): 1575-1612.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;related-packages&#34;&gt;Related packages&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/jacobadenbaum/AdaptiveSparseGrids.jl&#34; target=&#34;_blank&#34;&gt;AdaptiveSparseGrids&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/floswald/Tasmanian.jl&#34; target=&#34;_blank&#34;&gt;Tasmanian.jl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;version&#34;&gt;Version&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;versioninfo()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Julia Version 1.7.1
Commit ac5cc99908 (2021-12-22 19:35 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-12.0.1 (ORCJIT, skylake)
Environment:
  JULIA_NUM_THREADS = 4
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Artificial Neural Networks to Solve Economic Models</title>
      <link>https://julienpascal.github.io/post/ann_2/</link>
      <pubDate>Mon, 03 Jan 2022 18:00:00 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/ann_2/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In &lt;a href=&#34;https://julienpascal.github.io/post/ann_1/&#34; target=&#34;_blank&#34;&gt;a previous post&lt;/a&gt;, I discussed why Artificial Neural Networks (ANN) are very popular tools: (i) they can approximate a very large set of functions (ii) they work well in high-dimensional spaces (iii) we can train them efficiently using gradient descent (even better if you have a GPU). In the application part, I showed how to use them in practice using &lt;a href=&#34;https://julialang.org/&#34; target=&#34;_blank&#34;&gt;Julia&lt;/a&gt; and &lt;a href=&#34;https://github.com/FluxML/Flux.jl&#34; target=&#34;_blank&#34;&gt;Flux.jl&lt;/a&gt; with two toy examples.&lt;/p&gt;

&lt;p&gt;Now it&amp;rsquo;s time to be a bit more ambitious. In my previous post, we could sample from the function we wanted to approximate. However, in many instances we cannot simply do that. &lt;strong&gt;The unknown element&lt;/strong&gt; is the &lt;strong&gt;function we want to approximate&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TL;DR: ANN work well to approximate unknown functions.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The notebook for this post is available &lt;a href=&#34;https://github.com/JulienPascal/ANN_Flux&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;i-theory&#34;&gt;I. Theory&lt;/h2&gt;

&lt;p&gt;The cornerstone of Macro and Labour Economics is the dynamic optimization problem, in which an agent chooses a series of actions, taking account a set of constraints and the evolution of the state of the economy. A classical example is the a central planner deciding &lt;a href=&#34;https://en.wikipedia.org/wiki/Ramsey%E2%80%93Cass%E2%80%93Koopmans_model&#34; target=&#34;_blank&#34;&gt;how much to save and consume&lt;/a&gt; at any point in time. Another example would be &lt;a href=&#34;https://www.jstor.org/stable/2297896&#34; target=&#34;_blank&#34;&gt;a worker searching for a job and deciding which job to accept and when to resign&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;These types of problems naturally lend themselves to the following &lt;a href=&#34;https://en.wikipedia.org/wiki/Bellman_equation&#34; target=&#34;_blank&#34;&gt;Bellman equation&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;$$ V(x,z) = \max_{c \in \Gamma(x,z)}[ F(x,c,z) + \beta E[ V(T(x,c), z&amp;rsquo;) ]$$&lt;/p&gt;

&lt;p&gt;where $x$ is a known state variable and $z$ is a random variable following a Markov process. Both $x$ and $z$ are vectors. The function $\Gamma(.)$ represents the set of possible actions given a current state and the function $T(.)$ captures the transition from one state to another when an action is taken. The variable $\beta$ is a discount factor strictly smaller than one and the $E$ represent an expectation operator.&lt;/p&gt;

&lt;p&gt;I do not want to delve too much into the fascinating theory of optimal control. The point is that the unknown is the function $V(.)$. Given the good properties of ANN mentioned above, one may be tempted to use them to approximate the true $V(.)$. And this is exactly what we are going to do.&lt;/p&gt;

&lt;h2 id=&#34;ii-application&#34;&gt;II. Application&lt;/h2&gt;

&lt;p&gt;For the application, let&amp;rsquo;s focus on the model of the labour market of &lt;a href=&#34;https://www.aeaweb.org/articles?id=10.1257/aer.20131118&#34; target=&#34;_blank&#34;&gt;Lise and Robin 2017&lt;/a&gt;.Why? Because I have worked a lot with this model &lt;a href=&#34;https://www.theses.fr/2020IEPP0013&#34; target=&#34;_blank&#34;&gt;during my PhD&lt;/a&gt; and also because the model has really nice properties. The model features &lt;strong&gt;heterogeneous firms, workers&lt;/strong&gt; (one can think of large versus small firms and workers with different skills) and &lt;strong&gt;business cycle fluctuations&lt;/strong&gt; (booms and busts). Despite the underlying complexity, the model lends itself to a pretty simple Bellman equation:&lt;/p&gt;

&lt;p&gt;$$ S(x,y,z) = s(x,y,z) + \frac{1 - \delta}{1 + r} E_{z&amp;rsquo;|z} [ max(S(x,y,z&amp;rsquo;), 0) ] $$&lt;/p&gt;

&lt;p&gt;where $x$ is the worker&amp;rsquo;s type; $y$ the firm&amp;rsquo;s type; $z$ the aggregate (stochastic) state of the economy; $\delta$ the probability that a current job is going to be destroyed next period for exogenous reasons and $r$ the interest rate. The function $s(x,y,z)$ captures the value of net output when a worker of type $x$ works with a firm of type $y$ when the state of the economy is $z$. If the job is not productive enough, workers and firms decide to separate, which happens when $S(x,y,z) &amp;lt; 0$. This is why there is a max operator within the expectation operator.&lt;/p&gt;

&lt;p&gt;What we want to do is to use an ANN such that:&lt;/p&gt;

&lt;p&gt;$$ ANN(x,y,z|\theta) = s(x,y,z) + \frac{1 - \delta}{1 + r} E_{z&amp;rsquo;|z} [ ANN(x,y,z&amp;rsquo;|\theta), 0) ] $$&lt;/p&gt;

&lt;p&gt;Note that this equation can be rewritten as:&lt;/p&gt;

&lt;p&gt;$$ ANN(x,y,z|\theta) - s(x,y,z) - \frac{1 - \delta}{1 + r} E_{z&amp;rsquo;|z} [ ANN(x,y,z&amp;rsquo;|\theta), 0) ] = 0$$&lt;/p&gt;

&lt;p&gt;Our approximation is not going to be 100 percent perfect. But we can hope to find a good value of $\theta$ by minimizing the Mean Squared Error&lt;/p&gt;

&lt;p&gt;$$ \frac{1}{n}\sum(y_i - \hat{y}_i)^2 $$&lt;/p&gt;

&lt;p&gt;where $y_i$ is 0 everywhere and $\hat{y}_i = ANN(x_i,y_i,z_i|\theta) - \frac{1 - \delta}{1 + r} E_{z_i&amp;rsquo;|z_i} [ ANN(x_i,y_i,z_i&amp;rsquo;|\theta), 0) ] - s(x_i,y_i,z_i)$. Here the index $i$ captures the idea that we are going to draw several points from the space $X \times Y \times Z$&lt;/p&gt;

&lt;h3 id=&#34;ii-a-preliminaries&#34;&gt;II. A. Preliminaries&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s load useful packages and define a structure (using &lt;a href=&#34;https://github.com/mauro3/Parameters.jl&#34; target=&#34;_blank&#34;&gt;Parameters.jl&lt;/a&gt;) to hold parameter values and primitive functions of the model.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Random
using DataFrames
using DataStructures
using Statistics
using Plots
using IterTools
using Flux
using Flux.Data: DataLoader
using ProgressMeter
using Parameters
using Expectations
using Distributions
using Surrogates
using LinearAlgebra
using LaTeXStrings
using Interpolations
using BenchmarkTools
using Parameters
using StatsPlots
using Kronecker
using SparseArrays
using CUDA
gr()

if CUDA.has_cuda()
    device = gpu
    @info &amp;quot;GPU available&amp;quot;
else
    device = cpu
    @info &amp;quot;GPU not available&amp;quot;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;â”Œ Info: GPU not available
â”” @ Main In[120]:30
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@with_kw struct Params
    x_min::Float64 = 0.0
    x_max::Float64 = 1.0
    y_min::Float64 = 0.0
    y_max::Float64 = 1.0
    nx::Int64 = 21 # grid points for human capital
    ny::Int64 = 21 # grid points for firm productivity
    dt::Float64 = 1.0/52.0 # length of a period in years
    r::Float64 = (1.0 + 0.05)^dt - 1.0 # interest rate
    delta::Float64 = 0.0127012273 #job destrution rate
    epsilon::Float64 = 0.001 # distance to stay away from bounds of the interval
    x_grid = collect(range(x_min + epsilon, x_max - epsilon, length = nx))
    y_grid = collect(range(y_min + epsilon, y_max - epsilon, length = nx))
    # log of aggregate shocks are AR(1):
    # ln(zt) = rho*ln(zt-1) + e_k
    # with e_k distributed as N(0,psi^2)
    # and psi = sigma*sqrt(1-rhoÂ²)
    rho::Float64 = 0.9997369438 #persitence parameter
    sigma::Float64 = 0.0714488990 #volatility parameter
    psi::Float64 = sigma*sqrt(1.0 - rho^2) #std dev. of innovation term
    distrib_innovation::Any = Normal(0, psi) #0 mean and std = psi
    nb_nodes::Int64 = 10 #number nodes for the expectation
    E::Any = expectation(distrib_innovation, n = nb_nodes) #expectation operator
    nodes_E = nodes(E) #nodes for expectation
    weigths_E = weights(E) #weights for expectation
    f0::Float64     =    6.0873503685 # market production parameter
    f1::Float64     =    0.0025488557 # market production parameter
    f2::Float64     =    2.0529182143 # market production parameter
    f3::Float64     =    -0.1400252578 # market production parameter
    f4::Float64     =    8.0349795180 # market production parameter
    f5::Float64     =    -1.9072145913 # market production parameter
    f6::Float64     =    6.5961298483 # market production parameter
    b0::Float64     = 0.7 # home production parameter
    p_xyz::Function = (x, y, z) -&amp;gt; f0*z*(f1 + f2*x + f3*y + f4*(x^2) + f5*(y^2) + f6*x*y)*dt #value of market production
    b_x::Function = (x) -&amp;gt; b0*p_xyz(x, x, 1.0) #value of market production
    s_xyz::Function = (x,y,z) -&amp;gt; p_xyz(x,y,z) - b_x(x) #surplus
    # VECTORIZED FUNCTIONS
    # input of the form:
    # row: observation
    # column: dimension
    p_xyz_v::Function = x -&amp;gt; f0.*x[:,3].*(f1 .+ f2.*x[:,1] .+ f3.*x[:,2] .+ f4.*(x[:,1].^2) .+ f5.*(x[:,2].^2) .+ f6.*x[:,1].*x[:,2]).*dt #value of market production
    b_x_v::Function = x -&amp;gt; b0.*f0.*1.0.*(f1 .+ f2.*x[:,1] .+ f3.*x[:,1] .+ f4.*(x[:,1].^2) .+ f5.*(x[:,1].^2) .+ f6.*x[:,1].*x[:,1]).*dt #value of market production
    s_xyz_v::Function = x -&amp;gt; p_xyz_v(x) .- b_x_v(x) #surplus
    # VECTORIZED FUNCTIONS
    # input of the form:
    # row: dimension
    # column: observation
    p_xyz_r::Function = x -&amp;gt; f0.*x[3, :].*(f1 .+ f2.*x[1, :] .+ f3.*x[2,:] .+ f4.*(x[1,:].^2) .+ f5.*(x[2,:].^2) .+ f6.*x[1,:].*x[2,:]).*dt #value of market production
    b_x_r::Function = x -&amp;gt; b0.*f0.*1.0.*(f1 .+ f2.*x[1,:] .+ f3.*x[1,:] .+ f4.*(x[1,:].^2) .+ f5.*(x[1,:].^2) .+ f6.*x[1,:].*x[1,:]).*dt #value of market production
    s_xyz_r::Function = x -&amp;gt; p_xyz_r(x) .- b_x_r(x) #surplus
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p = Params();
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ii-b-value-function-iteration&#34;&gt;II. B. Value function iteration&lt;/h3&gt;

&lt;p&gt;To check the accuracy of the ANN approach, we will also use another &amp;ldquo;legacy&amp;rdquo; method to find another approximation for $S(x,y,z)$. The traditional way is to use &lt;strong&gt;Value Function Iteration (VFI)&lt;/strong&gt;. For a detailed treatment, the textbook of &lt;a href=&#34;https://www.google.com/search?q=Recursive+methods+in+economic+dynamics&amp;amp;client=ubuntu&amp;amp;hs=q3T&amp;amp;sa=X&amp;amp;channel=fs&amp;amp;sxsrf=AOaemvLsI7n9lOLie8RSVfOPi0l2weq7Pg:1641306887162&amp;amp;tbm=isch&amp;amp;source=iu&amp;amp;ictx=1&amp;amp;fir=GH2dBz2E9vFPDM%252CzAM-vlBogjsh7M%252C%252Fm%252F0cgvb6c&amp;amp;vet=1&amp;amp;usg=AI4_-kQJc5H3CV04Yfys38GSbnPN50KV5A&amp;amp;ved=2ahUKEwi-xOfPqJj1AhWySvEDHWK1BeUQ_B16BAgbEAI&amp;amp;biw=1232&amp;amp;bih=626&amp;amp;dpr=1.5#imgrc=GH2dBz2E9vFPDM&#34; target=&#34;_blank&#34;&gt;Stockey and Lucas&lt;/a&gt; is a must-read. For explanations with codes, I suggest &lt;a href=&#34;https://julia.quantecon.org/dynamic_programming/optgrowth.html&#34; target=&#34;_blank&#34;&gt;QuantEcon&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;VFI, as suggested by the name, is an iterated procedure that converges to the true function. One starts by assuming a function $V^{(0)}$. Then one applies the &amp;ldquo;right-hand-side operator&amp;rdquo; of the Bellman equation to get $V^{(1)}$:&lt;/p&gt;

&lt;p&gt;$ V^{(1)}(x,y,z) = s(x,y,z) + \frac{1 - \delta}{1 + r} E_{z&amp;rsquo;|z} [ max(V^{(0)}(x,y,z&amp;rsquo;), 0) ]$&lt;/p&gt;

&lt;p&gt;In practice, one must calculate $V^{(n)}(x,y,z)$ on a grid. Off-grid points can be obtained by linear interpolation. After some time, the distance between $V^{(n)}(x,y,z)$ and $V^{(n-1)}(x,y,z)$ is small and the procedure may be stopped.&lt;/p&gt;

&lt;h4 id=&#34;grid-considerations-unconditional-distribution-of-z&#34;&gt;Grid considerations: unconditional distribution of z?&lt;/h4&gt;

&lt;p&gt;As explained above, to use VFI, one must define a grid. For the values of $x$ and $y$, representing workers&amp;rsquo; and firms&amp;rsquo; heterogeneity, any bounded interval could do the job. Let&amp;rsquo;s follow the original paper and assume that both $x$ and $y$ are in $[0,1]$.&lt;/p&gt;

&lt;p&gt;Defining a good grid for $z$ requires a bit more work. In the model of &lt;a href=&#34;https://www.aeaweb.org/articles?id=10.1257/aer.20131118&#34; target=&#34;_blank&#34;&gt;Lise and Robin 2017&lt;/a&gt;, the log (natural logarithm) of the aggregate state $z$ follows an AR(1) process:&lt;/p&gt;

&lt;p&gt;$log(z_{t}) = \rho log(z_{t-1}) + \epsilon_{t}$&lt;/p&gt;

&lt;p&gt;with $\epsilon_{t}$ normally distributed with variance $\psi \equiv \sigma \times \sqrt(1.0 - \rho^2)$.&lt;/p&gt;

&lt;p&gt;This implies that the unconditional distribution of $log(z)$ is normally distributed with mean 0 and variance $\sigma$. Or said differently, $z$ is $Lognormal(0, \sigma)$. In the block of code below, we check this fact by comparing some simulated data and the pdf of a $Lognormal(0, \sigma)$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;Nt = 20000000 #number of draws
d = Normal(0, p.psi)
innov = rand(d, Nt)
log_z = zeros(Nt)
z = zeros(Nt)
log_z[1] = 1.0
for t=2:Nt
    log_z[t] = p.rho*log_z[t-1] + innov[t]
end
z = exp.(log_z)
d_log_normal = LogNormal(0.0, p.sigma)

density(z, label=&amp;quot;data&amp;quot;)
plot!(minimum(z):0.01:maximum(z), x -&amp;gt; pdf(d_log_normal, x), label=&amp;quot;LogNormal&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ANN_2_11_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Most of the time, $z$ is going to be between the 5th and the 95th percentile of $Lognormal(0, \sigma)$. Hence, we define the grid for $z$ to be $[P5, P95]$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;P5 = quantile(d_log_normal, 0.05)
P95 = quantile(d_log_normal, 0.95)
println(&amp;quot;P5: $(P5); P95: $(P95)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;P5: 0.8891200789438004; P95: 1.1247074761689282
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#Sampling for training
n_samples_xy = 10; #number of draws for the x and y dimensions
n_samples_z = 10; #number of draws for the z dimension
lower_bound = [0.0, 0.0, P5]
upper_bound = [1.0, 1.0, P95]

x_grid = collect(range(lower_bound[1], upper_bound[1], length=n_samples_xy))
y_grid = collect(range(lower_bound[2], upper_bound[2], length=n_samples_xy))
z_grid = collect(range(lower_bound[3], upper_bound[3], length=n_samples_z))

nodes_xyz = (x_grid, y_grid, z_grid, ); #for package Interpolations
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;value-function-iteration&#34;&gt;Value function iteration&lt;/h4&gt;

&lt;p&gt;The following block of code uses the VFI algorithm and displays the final results. The value function $S(x,y,z)$ is a non-linear transformation of the value of net output of the job $s(x,y,z)$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;V_old = zeros(n_samples_xy, n_samples_xy, n_samples_z)
V_new = zeros(n_samples_xy, n_samples_xy, n_samples_z)

# Initial guess
for (zIndex, zValue) in enumerate(z_grid)
    for (yIndex, yValue) in enumerate(y_grid)
        for (xIndex, xValue) in enumerate(x_grid)
            V_old[xIndex, yIndex, zIndex] = p.s_xyz(xValue, yValue, zValue) + ((1.0 - p.delta)/(1.0 + p.r))*max(0.0, p.s_xyz(xValue, yValue, zValue))
        end
    end
end

itp = interpolate(nodes_xyz, V_old, Gridded(Linear()))
etp = extrapolate(itp, Line())
V_old_interpolated = (x) -&amp;gt; etp(x[1], x[2], x[3])

max_iter = 5000
tol = 10^-8

@time begin
    # Initialize
    for i = 1:max_iter

        for (zIndex, zValue) in enumerate(z_grid)
            for (yIndex, yValue) in enumerate(y_grid)
                for (xIndex, xValue) in enumerate(x_grid)
                    V_new[xIndex, yIndex, zIndex] = p.s_xyz(xValue, yValue, zValue) + ((1.0 - p.delta)/(1.0 + p.r)).*sum(p.weigths_E.*[max.(0.0, V_old_interpolated([xValue; yValue; (zValue.^p.rho).*exp.(innovation)])) for innovation in p.nodes_E])
                end
            end
        end

        # DISTANCE
        diff= maximum(abs.(V_new .- V_old))
        if mod(i, 100) == 0
            println(&amp;quot;Iter $(i) Diff : $(diff)&amp;quot;)
        end

        if diff &amp;lt; tol
            println(&amp;quot;Iter $(i) Convergence reached&amp;quot;)
            break
        end

        #UPDATE
        V_old = copy(V_new)
        itp = interpolate(nodes_xyz, V_old, Gridded(Linear()))
        etp = extrapolate(itp, Line())
        V_old_interpolated = (x) -&amp;gt; etp(x[1], x[2], x[3])

    end
end

# Plot output for trained neural network
p1 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; V_old_interpolated([x; y; 1.0])[1], label = &amp;quot;f(x)&amp;quot;, st=:surface)
title!(L&amp;quot;S(x,y,z=1)&amp;quot;)
xlabel!(L&amp;quot;x&amp;quot;)
ylabel!(L&amp;quot;y&amp;quot;)

# Initialization function
p2 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; p.s_xyz(x, y, 1.0), label = &amp;quot;f(x)&amp;quot;, st=:surface)
title!(L&amp;quot;s(x,y,z=1)&amp;quot;)
xlabel!(L&amp;quot;x&amp;quot;)
ylabel!(L&amp;quot;y&amp;quot;)

p3 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; V_old_interpolated([x; y; 1.0])[1], label = &amp;quot;f(x)&amp;quot;, st=:contour)
title!(L&amp;quot;S(x,y,z=1)&amp;quot;)
xlabel!(L&amp;quot;x&amp;quot;)
ylabel!(L&amp;quot;y&amp;quot;)

p4 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; p.s_xyz(x, y, 1.0), label = &amp;quot;f(x)&amp;quot;, st=:contour)
title!(L&amp;quot;s(x,y,z=1)&amp;quot;)
xlabel!(L&amp;quot;x&amp;quot;)
ylabel!(L&amp;quot;y&amp;quot;)

ratio = 9/16
width = 800
pp = plot(p1, p2, p3, p4, size = (width, width*ratio))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Iter 100 Diff : 0.18062930117157094
Iter 200 Diff : 0.04545706889411605
Iter 300 Diff : 0.011441422819899572
Iter 400 Diff : 0.002880196260427681
Iter 500 Diff : 0.0007251468880724588
Iter 600 Diff : 0.00018259564639322434
Iter 700 Diff : 4.598479092265961e-5
Iter 800 Diff : 1.1582340917470901e-5
Iter 900 Diff : 2.9176678424391866e-6
Iter 1000 Diff : 7.350753179480307e-7
Iter 1100 Diff : 1.8521812705785123e-7
Iter 1200 Diff : 4.6675602050072484e-8
Iter 1300 Diff : 1.1763880536364013e-8
Iter 1312 Convergence reached
 43.861711 seconds (266.61 M allocations: 12.326 GiB, 3.34% gc time, 0.15% compilation time)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ANN_2_16_1.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;ii-c-bellman-ann&#34;&gt;II.C. Bellman - ANN&lt;/h3&gt;

&lt;p&gt;When doing value function iteration, one does not have to vectorize the code. However, I have learned the hard-way that it matters quite a lot when switching to the ANN approach, especially if you aim to use a GPU. So let&amp;rsquo;s tackle this problem right now.&lt;/p&gt;

&lt;p&gt;The trick is to realize that the expectation operator is just a large weighted average, which can be represented by a matrix multiplication when grid points are chosen carefully.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s consider all the value of $S(x,y,z)$ from the grid, arranged in a large row vector of dimension $(1; n_x \times n_y \times n_z)$ : $$ \small \begin{pmatrix}
S(x_1,y_1, z_1) &amp;amp; S(x_2,y_1, z_1) &amp;amp; &amp;hellip; &amp;amp; S(x_{nx},y_1, z_1) &amp;amp; S(x_{1},y_2, z_1) &amp;amp; &amp;hellip; &amp;amp; S(x_{nx},y_{ny}, z_{nz}) \end{pmatrix}$$&lt;/p&gt;

&lt;p&gt;Using this convention, one can verify that the initial Bellman equation can be written as:&lt;/p&gt;

&lt;p&gt;$$ \small \begin{pmatrix}
S(x_1,y_1, z_1) &amp;amp; S(x_2,y_1, z_1) &amp;amp; &amp;hellip; &amp;amp; S(x_{nx},y_{ny}, z_{nz})
\end{pmatrix} = \begin{pmatrix}s(x_1,y_1, z_1) &amp;amp; s(x_2,y_1, z_1) &amp;amp; &amp;hellip; &amp;amp; s(x_{nx},y_{ny}, z_{nz}) \end{pmatrix} + \frac{1 - \delta}{1 + r} \begin{pmatrix}
S(x_1,y_1, z_1&amp;rsquo;|z_1) &amp;amp; S(x_1,y_1, z_2&amp;rsquo;|z_1) &amp;amp; &amp;hellip; &amp;amp; S(x_1,y_1, z_{nz&amp;rsquo;}|z_1) &amp;amp; S(x_2,y_1, z_{1&amp;rsquo;}|z_1) &amp;amp; &amp;hellip; &amp;amp; S(x_{nx},y_{ny}, z_{nz&amp;rsquo;}|z_{nz}) \end{pmatrix} \times W
$$&lt;/p&gt;

&lt;p&gt;where $W$ is large (sparse) matrix of dimension $(n_x \times n_y \times n_z \times n_{z&amp;rsquo;}; n_x \times n_y \times n_z)$ containing the weights to approximate the expectation operator:&lt;/p&gt;

&lt;p&gt;$$ \small
W \equiv \begin{pmatrix} w1 &amp;amp; w2 &amp;amp; &amp;hellip; &amp;amp; w_{nz&amp;rsquo;} &amp;amp; 0 &amp;amp; &amp;hellip; &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; &amp;hellip; &amp;amp; 0 &amp;amp; w1 &amp;amp; w2 &amp;amp; &amp;hellip; &amp;amp; w_{nz&amp;rsquo;} &amp;amp; 0 &amp;amp; &amp;hellip; 0 \\ 0 &amp;amp; 0 &amp;amp; &amp;hellip; &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; &amp;hellip; &amp;amp; 0 &amp;amp; w1 &amp;amp; w2 &amp;amp; &amp;hellip; &amp;amp; w_{nz&amp;rsquo;} \end{pmatrix}^T
$$&lt;/p&gt;

&lt;p&gt;For this vectorized approach to work, we need to define two grids:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;one grid for the &amp;ldquo;today&amp;rsquo;s part&amp;rdquo;:
$\small \begin{pmatrix} S(x_1,y_1, z_1) &amp;amp; S(x_2,y_1, z_1) &amp;amp; &amp;hellip; &amp;amp; S(x_{nx},y_{ny}, z_{nz}) \end{pmatrix} $ and $\begin{pmatrix}s(x_1,y_1, z_1) &amp;amp; s(x_2,y_1, z_1) &amp;amp; &amp;hellip; &amp;amp; s(x_{nx},y_{ny}, z_{nz}) \end{pmatrix}$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;one grid for the &amp;ldquo;expectation part&amp;rdquo; (the value of $z$ tomorrow depends on the value today) $\small \begin{pmatrix} S(x_1,y_1, z_1&amp;rsquo;|z_1) &amp;amp; S(x_1,y_1, z_2&amp;rsquo;|z_1) &amp;amp; &amp;hellip; &amp;amp; S(x_1,y_1, z_{nz&amp;rsquo;}|z_1) &amp;amp; S(x_2,y_1, z_{1&amp;rsquo;}|z_1) &amp;amp; &amp;hellip; &amp;amp; S(x_{nx},y_{ny}, z_{nz&amp;rsquo;}|z_{nz}) \end{pmatrix}$&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I also define some grid points that are not used for the gradient descent phase (the &amp;ldquo;test set&amp;rdquo;). These points allow us to verify that we are not overfitting the training sample.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;nb_dim = 3

#-------------------------------------------------------------
# Train set
#-------------------------------------------------------------
# Grid for the LHS
# Grid (1, nx * ny * nz )
grid_1 = zeros(nb_dim, n_samples_xy*n_samples_xy*n_samples_z);

index = 1
for (xValue, yValue, zValue) in product(x_grid, y_grid, z_grid)
    grid_1[1, index] = xValue
    grid_1[2, index] = yValue
    grid_1[3, index] = zValue
    index+=1
end

# Grid for the RHS (calculate expectations)
# Grid (1, nx * ny * nz * nz&#39;)
grid_2 = zeros(nb_dim, n_samples_xy*n_samples_xy*n_samples_z*p.nb_nodes);

# Populate grid_2
index = 1
for (xValue, yValue, zValue) in product(x_grid, y_grid, z_grid)
    for (innovation_index, innovation) in enumerate(p.nodes_E)
        grid_2[1, index] = xValue
        grid_2[2, index] = yValue
        grid_2[3, index] = (zValue.^p.rho).*exp.(innovation)
        index+=1
    end
end

#-------------------------------------------------------------
# Test set
#-------------------------------------------------------------
# Sampling for test
n_samples_test = 1000
grid_test_1 = zeros(nb_dim, n_samples_test);

index = 1
for (xValue, yValue, zValue) in Surrogates.sample(n_samples_test, lower_bound, upper_bound, SobolSample())
    grid_test_1[1, index] = xValue
    grid_test_1[2, index] = yValue
    grid_test_1[3, index] = zValue
    index+=1
end

grid_test_2 = zeros(nb_dim, n_samples_xy*n_samples_xy*n_samples_z*p.nb_nodes);

# Populate grid_test_2
index = 1
for (xValue, yValue, zValue) in zip(grid_test_1[1,:], grid_test_1[2,:], grid_test_1[3,:])
    for (innovation_index, innovation) in enumerate(p.nodes_E)
        grid_test_2[1, index] = xValue
        grid_test_2[2, index] = yValue
        grid_test_2[3, index] = (zValue.^p.rho).*exp.(innovation)
        index+=1
    end
end

# To calculate the expectation
W = sparse(kronecker(Matrix(I, n_samples_xy*n_samples_xy*n_samples_z, n_samples_xy*n_samples_xy*n_samples_z), p.weigths_E));
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Define the neural network layers
# Specify our model
dim_input = 3
dim_ouptut = 1

Q1 = 300;
Q2 = 100;
Q3 = 10;

activation_f = relu;

model = Chain(Dense(dim_input,Q1,activation_f),
            Dense(Q1,Q2,activation_f),
            Dense(Q2,Q3,activation_f),
            Dense(Q3,dim_ouptut,identity));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Check one pass of the gradient:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;ps = Flux.params(model)
y = zeros(1, size(grid_1, 2))
s_xyz_r = transpose(p.s_xyz_r(grid_1)) #precalculate net output on grid

@time begin
    gs = gradient(() -&amp;gt; Flux.Losses.mse(model(grid_1) - s_xyz_r + ((1.0 - p.delta)/(1.0 + p.r)).*max.(0.0, model(grid_2))*W, y), ps)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;initializing-the-model&#34;&gt;Initializing the model&lt;/h4&gt;

&lt;p&gt;We can start with random coefficients and try to solve for the function S(.) directly.
However, it is better to initialize the coefficients of the ANN to match a not too far-fetched guess:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;lr = 0.001 # learning rate when batchsize = 1000
opt = ADAM(lr)

epochs_training = 100 # Define the number of epochs
trainingLosses = zeros(epochs_training); # Keep track of the training progress
testLosses = zeros(epochs_training); # Test on data not used in the training

ps = Flux.params(model) #initialize weigths
p_bar = Progress(epochs_training; desc = &amp;quot;Training in progress&amp;quot;); # Creates a progress bar
showProgress = true

y = zeros(1, size(grid_1, 2))
s_xyz_r = transpose(p.s_xyz_r(grid_1)) #precalculate net output on grid
s_xyz_r_test = transpose(p.s_xyz_r(grid_test_1)) #precalculate net output on test grid

# Training loop
@time for ii in 1:epochs_training

    gs = gradient(() -&amp;gt; Flux.Losses.mse(model(grid_1) - s_xyz_r - ((1.0 - p.delta)/(1.0 + p.r)).*max.(0.0, s_xyz_r), y), ps)# compute gradient
    Flux.Optimise.update!(opt, ps, gs) # update parameters


    if showProgress
        trainingLosses[ii] = Flux.Losses.mse(model(grid_1) - s_xyz_r - ((1.0 - p.delta)/(1.0 + p.r)).*max.(0.0, s_xyz_r), y)
        testLosses[ii] = Flux.Losses.mse(model(grid_test_1) - s_xyz_r_test - ((1.0 - p.delta)/(1.0 + p.r)).*max.(0.0, s_xyz_r_test), y)
        next!(p_bar; showvalues = [(:epochs, ii), (:logloss, log.(trainingLosses[ii])), (:loglosstest, log.(testLosses[ii]))], valuecolor = :grey)
    end

end


&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;â”Œ Warning: ProgressMeter by default refresh meters with additional information in IJulia via `IJulia.clear_output`, which clears all outputs in the cell.
â”‚  - To prevent this behaviour, do `ProgressMeter.ijulia_behavior(:append)`.
â”‚  - To disable this warning message, do `ProgressMeter.ijulia_behavior(:clear)`.
â”” @ ProgressMeter /home/julien/.julia/packages/ProgressMeter/Vf8un/src/ProgressMeter.jl:620
[32mTraining in progress100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:07[39m
[39m  epochs:       100[39m
[39m  logloss:      -6.198231731362997[39m
[39m  loglosstest:  -6.480455135391009[39m


  7.398687 seconds (285.46 k allocations: 2.889 GiB, 5.29% gc time, 5.06% compilation time)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;init_f = (x,y,z) -&amp;gt; p.s_xyz(x,y,z) .+ ((1.0 - p.delta)/(1.0 + p.r)).*max.(0.0, p.s_xyz(x,y,z))

gr()
# Plot output for trained neural network
p1 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; model([x; y; 1.0])[1], label = &amp;quot;f(x)&amp;quot;, st=:surface)
title!(&amp;quot;ANN&amp;quot;)
xlabel!(&amp;quot;x&amp;quot;)
ylabel!(&amp;quot;y&amp;quot;)

# Plot training loss
p2 = plot(1:epochs_training, log.(trainingLosses), label = &amp;quot;Train set&amp;quot;, linewidth = 2)
plot!(1:epochs_training, log.(testLosses), label = &amp;quot;Test set&amp;quot;, linewidth = 2)
title!(&amp;quot;Log Training Loss&amp;quot;)
xlabel!(&amp;quot;Epoch&amp;quot;)
ylabel!(L&amp;quot;\log(\textrm{Loss})&amp;quot;)

# Plot training loss
# Plot output for trained neural network
p3 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; init_f(x, y, 1.0), label = &amp;quot;f(x)&amp;quot;, st=:surface)
title!(&amp;quot;Initial Guess&amp;quot;)
xlabel!(&amp;quot;x&amp;quot;)
ylabel!(&amp;quot;y&amp;quot;)

# Plot training loss
# Plot output for trained neural network
p4 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; model([x; y; 1.0])[1] - init_f(x, y, 1.0), label = &amp;quot;f(x)&amp;quot;, st=:surface)
title!(&amp;quot;Initial Guess - VFI&amp;quot;)
xlabel!(&amp;quot;x&amp;quot;)
ylabel!(&amp;quot;y&amp;quot;)


ratio = 9/16
width = 800
pp = plot(p1, p2, p3, p4, size = (width, width*ratio))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ANN_2_24_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;solving-the-real-problem&#34;&gt;Solving the real problem&lt;/h4&gt;

&lt;p&gt;Now that the coefficients are initialized, let&amp;rsquo;s tackle the real problem:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;lr = 0.001 # learning rate
opt = ADAM(lr)

epochs_training = 1000 # Define the number of epochs
trainingLosses = zeros(epochs_training); # Keep track of the training progress
testLosses = zeros(epochs_training); # Test on data not used in the training

ps = Flux.params(model) #initialize weigths
p_bar = Progress(epochs_training; desc = &amp;quot;Training in progress&amp;quot;); # Creates a progress bar
showProgress = true

y = zeros(1, size(grid_1, 2))
s_xyz_r = transpose(p.s_xyz_r(grid_1)) #precalculate net output on grid
s_xyz_r_test = transpose(p.s_xyz_r(grid_test_1)) #precalculate net output on test grid

# Training loop
@time for ii in 1:epochs_training

    gs = gradient(() -&amp;gt; Flux.Losses.mse(model(grid_1) - s_xyz_r - ((1.0 - p.delta)/(1.0 + p.r)).*max.(0.0, model(grid_2))*W, y), ps)# compute gradient
    Flux.Optimise.update!(opt, ps, gs) # update parameters

    if showProgress
        trainingLosses[ii] = Flux.Losses.mse(model(grid_1) - s_xyz_r - ((1.0 - p.delta)/(1.0 + p.r)).*max.(0.0, model(grid_2))*W, y)
        testLosses[ii] = Flux.Losses.mse(model(grid_test_1) - s_xyz_r_test - ((1.0 - p.delta)/(1.0 + p.r)).*max.(0.0, model(grid_test_2))*W, y)
        next!(p_bar; showvalues = [(:epochs, ii), (:logloss, log.(trainingLosses[ii])), (:loglosstest, log.(testLosses[ii]))], valuecolor = :grey)
    end

end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;â”Œ Warning: ProgressMeter by default refresh meters with additional information in IJulia via `IJulia.clear_output`, which clears all outputs in the cell.
â”‚  - To prevent this behaviour, do `ProgressMeter.ijulia_behavior(:append)`.
â”‚  - To disable this warning message, do `ProgressMeter.ijulia_behavior(:clear)`.
â”” @ ProgressMeter /home/julien/.julia/packages/ProgressMeter/Vf8un/src/ProgressMeter.jl:620
[32mTraining in progress100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:08:47[39m
[39m  epochs:       1000[39m
[39m  logloss:      -7.247630080617367[39m
[39m  loglosstest:  -7.022159208051979[39m


527.918020 seconds (2.05 M allocations: 380.917 GiB, 0.84% gc time, 0.08% compilation time)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Training on the full problem is succesfull, as illustrated on the graphs below. It is hard to see meaningfull differences between
VFI and the ANN methods.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;gr()
# Plot output for trained neural network
p1 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; model([x; y; 1.0])[1], label = &amp;quot;f(x)&amp;quot;, st=:surface)
title!(&amp;quot;ANN&amp;quot;)
xlabel!(&amp;quot;x&amp;quot;)
ylabel!(&amp;quot;y&amp;quot;)

# Plot training loss
p2 = plot(1:epochs_training, log.(trainingLosses), label = &amp;quot;Train set&amp;quot;, linewidth = 2)
plot!(1:epochs_training, log.(testLosses), label = &amp;quot;Test set&amp;quot;, linewidth = 2)
title!(&amp;quot;Log Training Loss&amp;quot;)
xlabel!(&amp;quot;Epoch&amp;quot;)
ylabel!(L&amp;quot;\log(\textrm{Loss})&amp;quot;)

# Plot training loss
# Plot output for trained neural network
p3 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; V_old_interpolated([x; y; 1.0])[1], label = &amp;quot;f(x)&amp;quot;, st=:surface)
title!(&amp;quot;VFI&amp;quot;)
xlabel!(&amp;quot;x&amp;quot;)
ylabel!(&amp;quot;y&amp;quot;)

# Plot training loss
# Plot output for trained neural network
p4 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; model([x; y; 1.0])[1] - V_old_interpolated([x; y; 1.0])[1], label = &amp;quot;f(x)&amp;quot;, st=:surface)
title!(&amp;quot;ANN - VFI&amp;quot;)
xlabel!(&amp;quot;x&amp;quot;)
ylabel!(&amp;quot;y&amp;quot;)


ratio = 9/16
width = 800
pp = plot(p1, p2, p3, p4, size = (width, width*ratio))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ANN_2_28_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;zValue = 1.0

p1 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; model([x; y; zValue])[1], label = &amp;quot;f(x)&amp;quot;, st=:contour)
title!(&amp;quot;ANN&amp;quot;)
xlabel!(&amp;quot;x&amp;quot;)
ylabel!(&amp;quot;y&amp;quot;)

p2 = plot(p.x_grid, p.y_grid, (x, y) -&amp;gt; V_old_interpolated([x,y, zValue]), label = &amp;quot;f(x)&amp;quot;, st=:contour)
title!(&amp;quot;VFI&amp;quot;)
xlabel!(&amp;quot;x&amp;quot;)
ylabel!(&amp;quot;y&amp;quot;)

plot(p1, p2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ANN_2_29_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;accuracy-tests&#34;&gt;Accuracy tests&lt;/h4&gt;

&lt;p&gt;Accuracy of VFI versus ANN approaches can be assessed by looking at off-grid points.
In the present setting, VFI outperforms the ANN approach. However, I conjecture that in a high-dimensional setting the opposite would be true (in a high-dimensional setting, VFI probably would not be possible in the first place). Also, one could increase the number of epochs and get better results.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#VFI
#LHS
LHS = zeros(size(grid_test_1, 2))
index = 1
for (xValue, yValue, zValue) in zip(grid_test_1[1, :], grid_test_1[2, :], grid_test_1[3,:])
    LHS[index] = V_old_interpolated([xValue; yValue; zValue])
    index+=1
end


#RHS
RHS = zeros(size(grid_test_1, 2))
index = 1
for (xValue, yValue, zValue) in zip(grid_test_1[1, :], grid_test_1[2, :], grid_test_1[3,:])
    RHS[index] = p.s_xyz(xValue, yValue, zValue) + ((1.0 - p.delta)/(1.0 + p.r)).*sum(p.weigths_E.*[max.(0.0, V_old_interpolated([xValue; yValue; (zValue.^p.rho).*exp.(innovation)])) for innovation in p.nodes_E])
    index+=1
end

#ANN
error_ANN = model(grid_test_1) - transpose(p.s_xyz_r(grid_test_1)) - ((1.0 - p.delta)/(1.0 + p.r)).*max.(0.0, model(grid_test_2)*W)
error_ANN = transpose(error_ANN)
p1 = histogram(LHS - RHS, label=&amp;quot;errors VFI&amp;quot;)
p2 = histogram(error_ANN, label=&amp;quot;errors ANN&amp;quot;)
plot(p1, p2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ANN_2_31_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;df = DataFrame(Method = [&amp;quot;VFI&amp;quot;, &amp;quot;ANN&amp;quot;],
                MSE = [mean(LHS .- RHS).^2, mean(error_ANN).^2],
                MDSE = [median(LHS .- RHS).^2, median(error_ANN).^2],
                MAXSE = [maximum(LHS .- RHS).^2, maximum(error_ANN).^2],
                MINSE = [minimum(LHS .- RHS).^2, minimum(error_ANN).^2])

df
&lt;/code&gt;&lt;/pre&gt;

&lt;table class=&#34;data-frame&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;Method&lt;/th&gt;&lt;th&gt;MSE&lt;/th&gt;&lt;th&gt;MDSE&lt;/th&gt;&lt;th&gt;MAXSE&lt;/th&gt;&lt;th&gt;MINSE&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;String&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;p&gt;2 rows Ã— 5 columns&lt;/p&gt;&lt;tr&gt;&lt;th&gt;1&lt;/th&gt;&lt;td&gt;VFI&lt;/td&gt;&lt;td&gt;1.99895e-6&lt;/td&gt;&lt;td&gt;3.47266e-7&lt;/td&gt;&lt;td&gt;0.00288945&lt;/td&gt;&lt;td&gt;1.5217e-6&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;2&lt;/th&gt;&lt;td&gt;ANN&lt;/td&gt;&lt;td&gt;7.47681e-5&lt;/td&gt;&lt;td&gt;1.37991e-5&lt;/td&gt;&lt;td&gt;0.035538&lt;/td&gt;&lt;td&gt;0.00108539&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this blog post, I showed how ANN can be used to find unknown functions satisfying a Bellman equation.&lt;/p&gt;

&lt;p&gt;The code presented here is more a &lt;strong&gt;proof-of-concept than a production-ready release&lt;/strong&gt;. A first obvious improvement is to train the ANN on a &lt;strong&gt;GPU instead of a CPU&lt;/strong&gt;. Using the free version of &lt;a href=&#34;https://colab.research.google.com/&#34; target=&#34;_blank&#34;&gt;Google Colab&lt;/a&gt;, I am getting an almost 10x time improvement. A second improvement would be to use more diverse set of points for the ANN. While VFI requires a fixed grid to make sense, the ANN is a grid-less method. The training phase would benefit from more mixing in the input points.&lt;/p&gt;

&lt;p&gt;As a final remark, I chose on purpose a problem which is a bit simpler than the full general problem, in which one must also find the policy function that comes with the unknown value function. I am wondering if some of the insights described in the &lt;a href=&#34;https://www.nature.com/articles/nature16961&#34; target=&#34;_blank&#34;&gt;Alpha Go paper&lt;/a&gt; could apply in the present setting.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Artificial Neural Networks as universal function approximators</title>
      <link>https://julienpascal.github.io/post/ann_1/</link>
      <pubDate>Sun, 28 Nov 2021 18:00:00 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/ann_1/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Artificial Neural networks&lt;/strong&gt; (ANN) are very trendy at the moment, and rightly so.&lt;/p&gt;

&lt;p&gt;They are being used everywhere in big tech companies. For instance, when you use Google translate, or when recommandations appear on your Netflix feed, complex artificial neural networks are being used behind the scene. Behind the success of &lt;a href=&#34;https://en.wikipedia.org/wiki/AlphaGo&#34; target=&#34;_blank&#34;&gt;Alpha Go&lt;/a&gt; at the game of &lt;a href=&#34;https://www.washingtonpost.com/news/innovations/wp/2016/03/15/what-alphagos-sly-move-says-about-machine-creativity/&#34; target=&#34;_blank&#34;&gt;Go against Lee Sedol&lt;/a&gt;, an ANN was used to identify the next best move.&lt;/p&gt;

&lt;p&gt;ANN are also increasingly being used in Economic modeling, as exemplified by two recent publications:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0304393221000799&#34; target=&#34;_blank&#34;&gt;Deep learning for solving dynamic economic models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nber.org/system/files/working_papers/w26302/w26302.pdf&#34; target=&#34;_blank&#34;&gt;Financial Frictions and the Wealth Distribution&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this blog article, I discuss the reasons behind the popularity of neural networks&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Spoiler alert:&lt;/strong&gt; It has to do with ANN being &lt;strong&gt;universal function approximators.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;As usual, I like to include Julia code to illustrate how things work in practice. My tool of choice is &lt;a href=&#34;https://julialang.org/&#34; target=&#34;_blank&#34;&gt;Julia&lt;/a&gt; because
it is really fast and it is an increasingly popular programming language. For machine learning tasks, &lt;a href=&#34;https://github.com/FluxML/Flux.jl&#34; target=&#34;_blank&#34;&gt;Flux.jl&lt;/a&gt; is a really good option, so let&amp;rsquo;s use it as well. You can download the code &lt;a href=&#34;https://github.com/JulienPascal/ANN_Flux&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;i-some-theory&#34;&gt;I. Some theory&lt;/h2&gt;

&lt;h3 id=&#34;architecture&#34;&gt;Architecture&lt;/h3&gt;

&lt;p&gt;If you ended up here, you probably have already some knowledge about what an artificial neural network is. So I will be brief. In a nutshell, a neural network is made of several interconnected layers. Each layer is constituted of nodes. Nodes between adjacent layers exchange information between each others. The way the nodes communicate between each others is captured by parameter values associated to each nodes.&lt;/p&gt;

&lt;p&gt;See the graph below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ANN.png&#34; alt=&#34;Drawing&#34; style=&#34;width: 400px;&#34;/&gt;&lt;/p&gt;

&lt;p&gt;Source: &lt;a href=&#34;https://en.wikipedia.org/wiki/Artificial_neural_network#/media/File:Artificial_neural_network.svg&#34; target=&#34;_blank&#34;&gt;https://en.wikipedia.org/wiki/Artificial_neural_network#/media/File:Artificial_neural_network.svg&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;An artificial neural network mimics at a high level what the brain does. The brain is composed of neurons and neurons are connected to each others via synapses. Our brain is very good at recognizing patterns, so one might hope that an artificial neural network could be a good pattern-recognition machine.&lt;/p&gt;

&lt;p&gt;In practice, it is the case. Even better, we have some theorems that tell us that ANN are really, really good.&lt;/p&gt;

&lt;h3 id=&#34;universal-approximation-theorems&#34;&gt;Universal approximation theorems&lt;/h3&gt;

&lt;p&gt;Let me describe two important papers. Below, I reproduce some selected parts of their abstracts:&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/0893608089900208&#34; target=&#34;_blank&#34;&gt;Hornik Stinchcombe and White (1989)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;ldquo;This paper rigorously establishes that &lt;strong&gt;standard multilayer feedforward networks with as few as one hidden layer&lt;/strong&gt; using arbitrary squashing functions &lt;strong&gt;are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy&lt;/strong&gt;, provided sufficiently many hidden units are available. In this sense, &lt;strong&gt;multilayer feedforward networks are a class of universal approximators.&lt;/strong&gt;&amp;ldquo;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.stat.yale.edu/~arb4/publications_files/UniversalApproximationBoundsForSuperpositionsOfASigmoidalFunction.pdf&#34; target=&#34;_blank&#34;&gt;Barron (1993)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;ldquo;&lt;strong&gt;It  is  shown  that  feedforward networks with one layer of sigmoidal nonlinearities achieve integrated  squared  error  of order  O(1/n),  where  n  is  the  number  of  nodes.&lt;/strong&gt;  [&amp;hellip;]  For the class of functions  examined  here, the approximation rate  and  the  parsimony  of  the  parameterization  of  the  networks  are
&lt;strong&gt;surprisingly  advantageous  in high-dimensional settings.&lt;/strong&gt;&amp;ldquo;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The paper by &lt;strong&gt;Hornik Stinchcombe and White (1989)&lt;/strong&gt; tells us that a very large class of functions can be approximated by an ANN with the architecture we presented above. The underlying function we aim to approximate is only required to be &amp;ldquo;Borel measurable&amp;rdquo; (from one finite dimensional space to another), which contains pretty much all the useful functions you use in Economics (continuous functions from one finite dimensional space to another are Borel measurable functions).&lt;/p&gt;

&lt;p&gt;The paper by &lt;strong&gt;Barron (1993)&lt;/strong&gt; tells us that ANN are particularly good approximators when working with many dimensions.
Said differently, ANN can help to mitigate the &lt;a href=&#34;https://en.wikipedia.org/wiki/Curse_of_dimensionality&#34; target=&#34;_blank&#34;&gt;curse of dimensionality&lt;/a&gt;. One way to understand the curse of dimensionality is that the number of points needed to approximate a function grows exponentially with the number of dimensions, not linearly. We would like to explain complex phenomenon, with many dimensions and interactions, but traditional approximation methods generally do poorly in such settings.&lt;/p&gt;

&lt;p&gt;Put together, these results tell us that ANN are very good function approximators, even when the number of dimensions is high.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;ii-application&#34;&gt;II. Application&lt;/h2&gt;

&lt;p&gt;Now let&amp;rsquo;s see two applications. To warm up, we will start with a smooth and nice function to approximate.
Then we will move to a more complex function.&lt;/p&gt;

&lt;h3 id=&#34;ii-a-easy-function&#34;&gt;II. A. Easy function&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s load some useful packages and define the function we would like to approximate&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Dependencies
using Flux
using Plots
using LinearAlgebra
using ProgressMeter
using Statistics
using LaTeXStrings
using Surrogates
gr()

# Define function that we would like to learn with our neural network
f(x) = x[1].^2 + x[2].^2
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;f (generic function with 1 method)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A function is an infinite-dimensional object. But we need a finite number of values to train our neural network.
To that, let&amp;rsquo;s create a sample of points from an interval (I use &lt;a href=&#34;https://en.wikipedia.org/wiki/Sobol_sequence&#34; target=&#34;_blank&#34;&gt;Sobol sampling&lt;/a&gt;) and then
evaluate the value of the true function for these points.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;n_samples = 100
lower_bound = [-1.0, -1.0]
upper_bound = [1.0, 1.0]

xys = Surrogates.sample(n_samples, lower_bound, upper_bound, SobolSample())
rawInputs = xys
rawOutputs = [[f(xy)] for xy in xys] # Compute outputs for each input
trainingData = zip(rawInputs, rawOutputs);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now is the fun part of deciding the architecture of our ANN.
I choose two hidden layers. The number of nodes for the first layer is
imposed by the dimension of the input (a 2d vector), as well the dimension of
the final node (a scalar). We still have to choose the number of nodes in between.
For the first hidden layer I choose 784 nodes, and 50 for the second hidden layer.
To be fair, these choices are a bit random (I was influenced by the &lt;a href=&#34;https://fluxml.ai/Flux.jl/stable/training/training/&#34; target=&#34;_blank&#34;&gt;Flux.jl tutorial here&lt;/a&gt;). Feel free to experiment with different values.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Define the neural network layers (this defines a function called model(x))
# Specify our model
dim_input = 2
dim_ouptut = 1
Q1 = 784;
Q2 = 50;

# Two inputs, one output
model = Chain(Dense(2,Q1,relu),
            Dense(Q1,Q2,relu),
            Dense(Q2,1,identity));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we define a &lt;strong&gt;loss function&lt;/strong&gt;, which measures the accuracy of the approximation.
The smaller the loss, the better. We use the &lt;a href=&#34;https://en.wikipedia.org/wiki/Mean_squared_error&#34; target=&#34;_blank&#34;&gt;mean squared error&lt;/a&gt; loss function. The name of the game is to find the parameter values that minimize the loss function.
One way to do minimize the loss function is to use the &lt;strong&gt;gradient descent algorithm&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Here is an intuitive explanation of gradient descent. Imagine that you are on a top of a mountain at that there is a
lot of fog that prevents you from seeing far away. You really want to go down. What should you do?&lt;/p&gt;

&lt;p&gt;One strategy is to look at where you stand and evaluate the direction of the steepest descent in the &lt;strong&gt;neighborhood of your location&lt;/strong&gt; (you can&amp;rsquo;t see far away). Then take a step in that direction. Then repeat the process. If the mountain is &amp;ldquo;well-behaved&amp;rdquo; (it has no local minima), you will manage to go down the mountain, even though you were just using local information at every step. (Go the very bottom of this blog post to see an illustration of gradient descent on a really easy problem).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Define loss function and weights
loss(x, y) = Flux.Losses.mse(model(collect(x)), y)

lr = 0.001 # learning rate

# V1. Gradient descent
opt = Descent(lr)

# V2. ADAM
#decay = 0.9
#momentum =0.999
#opt = ADAM(lr, (decay, momentum))

epochs = 1000 # Define the number of epochs
trainingLosses = zeros(epochs);# Initialize a vector to keep track of the training progress
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next is the most rewarding step: &lt;strong&gt;the training part&lt;/strong&gt;. The following block of code
does gradient descent. The function &lt;code&gt;Flux.train!&lt;/code&gt; uses all the observations
we have in our sample once. Because one iteration is not enough to reach a minimum,
we repeat the process several &lt;code&gt;epochs&lt;/code&gt;. After each epoch, we calculate the mean squared
error to see how well the model does.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;ps = Flux.params(model) #initialize weigths
p = Progress(epochs; desc = &amp;quot;Training in progress&amp;quot;); # Creates a progress bar
showProgress = true

# Training loop
@time for ii in 1:epochs

    Flux.train!(loss, ps, trainingData, opt)

    # Update progress indicator
    if showProgress
        trainingLosses[ii] = mean([loss(x,y) for (x,y) in trainingData])
        next!(p; showvalues = [(:loss, trainingLosses[ii]), (:logloss, log10.(trainingLosses[ii]))], valuecolor = :grey)
    end

end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;â”Œ Warning: ProgressMeter by default refresh meters with additional information in IJulia via `IJulia.clear_output`, which clears all outputs in the cell.
â”‚  - To prevent this behaviour, do `ProgressMeter.ijulia_behavior(:append)`.
â”‚  - To disable this warning message, do `ProgressMeter.ijulia_behavior(:clear)`.
â”” @ ProgressMeter /home/julien/.julia/packages/ProgressMeter/Vf8un/src/ProgressMeter.jl:620
[32mTraining in progress100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:24[39m
[39m  loss:     0.00017162366528025578[39m
[39m  logloss:  -3.7654228272565655[39m


 24.753884 seconds (41.00 M allocations: 37.606 GiB, 6.56% gc time, 0.48% compilation time)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next plot shows a surface plot for the original function and the value returned by the ANN (the dots).
Results are quite good. The top right graph displays the value of the loss function as the training takes place.
Gradient descent seems to work well, because the loss function decreases in a nice and monotonic manner. The bottom plot displays the surface plot for the trained ANN.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;nb_points = 100
grid_x = collect(range(lower_bound[1], upper_bound[1], length= nb_points))
grid_y = collect(range(lower_bound[2], upper_bound[2], length= nb_points))

grid_x_random = [xy[1] for xy in xys]
grid_y_random = [xy[2] for xy in xys]

Zs = [model([x,y])[1] for (x, y) in zip(grid_x_random, grid_y_random)];

# Plot output for trained neural network
p1 = plot(grid_x, grid_y, (x, y) -&amp;gt; f([x,y]), label = &amp;quot;f(x)&amp;quot;, st=:surface)
scatter!(p1, grid_x_random, grid_y_random, Zs, label=&amp;quot;ANN&amp;quot;)
title!(&amp;quot;Original function&amp;quot;)
xlabel!(L&amp;quot;x&amp;quot;)
ylabel!(L&amp;quot;y&amp;quot;)


# Plot training loss
p2 = plot(1:epochs, log.(trainingLosses), label = &amp;quot;&amp;quot;, linewidth = 2)
title!(&amp;quot;Training Loss&amp;quot;)
xlabel!(&amp;quot;Epoch&amp;quot;)
ylabel!(L&amp;quot;\log(\textrm{Loss})&amp;quot;)

# Neural network
p3 = plot(grid_x, grid_y, (x, y) -&amp;gt; model([x,y])[1], label = &amp;quot;f(x)&amp;quot;, st=:surface)
title!(&amp;quot;Trained Neural Network&amp;quot;)
xlabel!(L&amp;quot;x&amp;quot;)
ylabel!(L&amp;quot;y&amp;quot;)

ratio = 9/16
width = 800
pp = plot(p1, p2, p3, size = (width, width*ratio))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ANN_1_12_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;ii-b-more-challenging-function&#34;&gt;II.B. More challenging function&lt;/h3&gt;

&lt;p&gt;Ok, so our ANN works with a simple function, which is reassuring.
Let&amp;rsquo;s now turn to a more challenging function. For instance,
we can try to approximate the &lt;a href=&#34;https://en.wikipedia.org/wiki/Ackley_function&#34; target=&#34;_blank&#34;&gt;Ackley function&lt;/a&gt;, which
is a slightly crazy function often used to test minimization algorithms (it has a global minimum at the origin).&lt;/p&gt;

&lt;p&gt;Even with a more complex function, our ANN does a great job a approximating the true function, as you can see on the graph below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function ackley(x; e = exp(1), a = 10.0, b = -0.2, c=2.0*Ï€)
    #a, b, c = 10.0, -0.2, 2.0*Ï€
    len_recip = inv(length(x))
    sum_sqrs = zero(eltype(x))
    sum_cos = sum_sqrs
    for i in x
        sum_cos += cos(c*i)
        sum_sqrs += i^2
    end
    return -a * exp(b * sqrt(len_recip*sum_sqrs)) - exp(len_recip*sum_cos) + a + e
end

n_samples = 1000
lower_bound = [-2.0, -2.0]
upper_bound = [2.0, 2.0]
xys = Surrogates.sample(n_samples, lower_bound, upper_bound, SobolSample())
rawInputs = xys

rawOutputs = [[ackley(xy)] for xy in xys] # Compute outputs for each input
trainingData = zip(rawInputs, rawOutputs);

# Define the neural network layers (this defines a function called model(x))
# Specify our model
Q1 = 784;
Q2 = 50;
Q3 = 10;

# Two inputs, one output
model = Chain(Dense(2,Q1,relu),
            Dense(Q1,Q2,relu),
            Dense(Q2,1,identity));

# Define loss function and weights
loss(x, y) = Flux.Losses.mse(model(collect(x)), y)
ps = Flux.params(model)

# Train the neural network
epochs = 1000
showProgress = true
lr = 0.001 # learning rate

# V1. Gradient descent
opt = Descent(lr)

# V2. ADAM
#decay = 0.9
#momentum =0.999
#opt = ADAM(lr, (decay, momentum))

trainingLosses = zeros(epochs) # Initialize vectors to keep track of training
p = Progress(epochs; desc = &amp;quot;Training in progress&amp;quot;) # Creates a progress bar

@time for ii in 1:epochs

    Flux.train!(loss, ps, trainingData, opt)

    # Update progress indicator
    if showProgress
        trainingLosses[ii] = mean([loss(x,y) for (x,y) in trainingData])
        next!(p; showvalues = [(:loss, trainingLosses[ii]), (:logloss, log10.(trainingLosses[ii]))], valuecolor = :grey)
    end

end


&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;â”Œ Warning: ProgressMeter by default refresh meters with additional information in IJulia via `IJulia.clear_output`, which clears all outputs in the cell.
â”‚  - To prevent this behaviour, do `ProgressMeter.ijulia_behavior(:append)`.
â”‚  - To disable this warning message, do `ProgressMeter.ijulia_behavior(:clear)`.
â”” @ ProgressMeter /home/julien/.julia/packages/ProgressMeter/Vf8un/src/ProgressMeter.jl:620
[32mTraining in progress100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:04:02[39m
[39m  loss:     0.01753345824641543[39m
[39m  logloss:  -1.7561324165239636[39m


242.064635 seconds (407.63 M allocations: 375.931 GiB, 6.81% gc time, 0.04% compilation time)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;nb_points = 100
grid_x = collect(range(lower_bound[1], upper_bound[1], length= nb_points))
grid_y = collect(range(lower_bound[2], upper_bound[2], length= nb_points))

grid_x_random = [xy[1] for xy in xys]
grid_y_random = [xy[2] for xy in xys]

Zs = [model([x,y])[1] for (x, y) in zip(grid_x_random, grid_y_random)];

# Plot output for trained neural network
p1 = plot(grid_x, grid_y, (x, y) -&amp;gt; ackley([x,y]), label = &amp;quot;f(x)&amp;quot;, st=:surface)
# Show somes points, not all of them (otherwise hard to see anything)
scatter!(p1, grid_x_random[1:100], grid_y_random[1:100], Zs[1:100], label=&amp;quot;ANN&amp;quot;)
title!(&amp;quot;Original Function&amp;quot;)
xlabel!(L&amp;quot;x&amp;quot;)
ylabel!(L&amp;quot;y&amp;quot;)


# Plot training loss
p2 = plot(1:epochs, log.(trainingLosses), label = &amp;quot;&amp;quot;, linewidth = 2)
title!(&amp;quot;Training Loss&amp;quot;)
xlabel!(&amp;quot;Epoch&amp;quot;)
ylabel!(L&amp;quot;\log(\textrm{Loss})&amp;quot;)


# Plot output for trained neural network
p3 = plot(grid_x, grid_y, (x, y) -&amp;gt; model([x,y])[1], label = &amp;quot;f(x)&amp;quot;, st=:surface)
title!(&amp;quot;Trained Neural Network&amp;quot;)
xlabel!(L&amp;quot;x&amp;quot;)
ylabel!(L&amp;quot;y&amp;quot;)

ratio = 9/16
width = 800
pp = plot(p1, p2, p3, size = (width, width*ratio))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ANN_1_15_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Artificial Neural Network are universal function approximators. This blog post showed how to start using ANN to approximate relatively simple functions.&lt;/p&gt;

&lt;p&gt;When trying to solve an economic model, one often has to find an unknown function that satisfies a number of
restrictions. In a subsequent post, I wish to describe how an ANN can be used to find such an unknown function.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;extra-gradient-descent-visually&#34;&gt;Extra: gradient descent visually&lt;/h3&gt;

&lt;p&gt;Below is an illustration of gradient descent.
We want to find the minimum of the function &lt;code&gt;J(x)=x^2&lt;/code&gt; and we start
at the point &lt;code&gt;-20&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The algorithm proceeds iteratively:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Calculate the &lt;strong&gt;gradient&lt;/strong&gt; at the current value. This gives us the direction
of the maximum change for the function &lt;code&gt;J&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Because we are looking for a &lt;strong&gt;minimum&lt;/strong&gt; and not a maximum, take a step in the opposite
direction of the maximum change&lt;/li&gt;
&lt;li&gt;Repeat steps 1-2&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using GradDescent
#Code from here: https://jacobcvt12.github.io/GradDescent.jl/stable/
#I made only slight modifications to the original code

# objective function and gradient of objective function
J(x) = x^2
dJ(x) = 2*x

# number of epochs
epochs = 150

# instantiation of Adagrad optimizer with learning rate of 2
opt = Adagrad(Î·=2.0)

# initial value for x (usually initialized with a random value)
x = -20.0 #initial position on the function
values_x = zeros(epochs) #initialization
value_y = zeros(epochs) #initialization
iter_x = zeros(epochs) #initialization

for i in 1:epochs
    # Save values for plotting
    values_x[i] = x
    value_y[i] = J(x)
    iter_x[i] = i

    # calculate the gradient wrt to the current x
    g = dJ(x)

    # change to the current x
    Î´ = update(opt, g)
    x -= Î´
end

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see on the plot below, we start from the left hand side and then we make some quite big moves
to the right. As time passes, the points go from yellow to darker colors.
After about 150 iterations, we are very close to the true minimum at 0.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;plot(values_x, value_y, label=&amp;quot;J(x)&amp;quot;)
scatter!(values_x, value_y, marker_z = iter_x, color = cgrad(:thermal, rev = true), label=&amp;quot;Position&amp;quot;, colorbar_title=&amp;quot;Iteration&amp;quot;)
xlabel!(L&amp;quot;x&amp;quot;)
ylabel!(L&amp;quot;J(x)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;ANN_1_20_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Young&#39;s method (2010) to simulate a cross-section</title>
      <link>https://julienpascal.github.io/post/young_2010/</link>
      <pubDate>Mon, 18 Jan 2021 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/young_2010/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Solving economic models involves (i) finding the &lt;strong&gt;optimal response of individuals&lt;/strong&gt; given the state of the economy (the policy functions); (ii) given the policy functions, &lt;strong&gt;simulating the model&lt;/strong&gt;. While usually one must show great ingenuity and creativity for the former, the latter is often seen as trivial and not even mentioned. However, in this notebook I describe a simulation procedure that deserves to be advertised. Namely, I describe &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v34y2010i1p36-41.html&#34; target=&#34;_blank&#34;&gt;Young&amp;rsquo;s method (2010)&lt;/a&gt; to simulate a large number (infinity) of individuals. The code can be downloaded &lt;a href=&#34;https://github.com/JulienPascal/Simulate_Cross-section&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;why-should-we-care&#34;&gt;Why should we care?&lt;/h2&gt;

&lt;p&gt;In economies with heterogeneous agents, often there is no such thing as a &lt;a href=&#34;https://en.wikipedia.org/wiki/Representative_agent#:~:text=Economists%20use%20the%20term%20representative,the%20same%20type%20are%20identical.&#34; target=&#34;_blank&#34;&gt;representative agent&lt;/a&gt;. Generally, one must follow a large number of individuals. For instance, one may be interested in knowing how the average wage responds to an increase in labor productivity. If workers are different (in terms of skills, experience, firms in which they work, etc.), one must take into consideration changes in individuals&amp;rsquo; wages to determine how the average wage moves.&lt;/p&gt;

&lt;h2 id=&#34;the-method&#34;&gt;The method&lt;/h2&gt;

&lt;p&gt;The method avoids simulating a panel of agents. Instead, the idea is to simulate directly the distribution.
In practice, one chooses a grid $[w_1, w_2, &amp;hellip;, w_N]$&lt;/p&gt;

&lt;p&gt;If a measure $m$ of workers choose to consume $w$, with $w \in [w_{n}, w_{n+1}]$, then the mass assigned to the grid point $w_{n}$ is equal to $m \times p$ and the mass assigned to the grid point $w_{n+1}$ is $m \times (1 - p)$ with&lt;/p&gt;

&lt;p&gt;$$ p = 1 - \frac{w - w_{n}}{w_{n+1} - w_{n}} $$&lt;/p&gt;

&lt;p&gt;If $w$ is very close to $w_{n}$, then most of the mass $m$ will be assigned to this point. In the limit case, if $w$ is equal to $w_{n}$, $100$ percent of the mass is assigned to $w_{n}$.&lt;/p&gt;

&lt;p&gt;Simple, right? The code below is an implementation of &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v34y2010i1p36-41.html&#34; target=&#34;_blank&#34;&gt;Young&amp;rsquo;s method (2010)&lt;/a&gt; using &lt;a href=&#34;https://julialang.org/&#34; target=&#34;_blank&#34;&gt;Julia&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;implementation&#34;&gt;Implementation&lt;/h2&gt;

&lt;h3 id=&#34;preliminaries&#34;&gt;Preliminaries&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s first start by loading a few packages and declaring auxiliaries functions. In particular, given a value $w$ we need a function that returns the closest value $w_k$, where $w_k$ is picked from given grid $w_1, w_2, &amp;hellip;, w_N$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Plots
using Distributions
using StatsBase

# Matlab like function
function linspace(z_start::Real, z_end::Real, z_n::Int64)
    return collect(range(z_start,stop=z_end,length=z_n))
end

# Not my function. Credit to: https://discourse.julialang.org/t/findnearest-function/4143/4
function closest_index(a::Vector,x::Real)

    if isempty(a) == true
      error(&amp;quot;xGrid is empty in function closest_index.&amp;quot;)
    end

    if isnan(x) == true
      error(&amp;quot;val is NaN in function closest_index.&amp;quot;)
    end

   idx = searchsortedfirst(a,x)
   if (idx==1); return idx; end
   if (idx&amp;gt;length(a)); return length(a); end
   if (a[idx]==x); return idx; end
   if (abs(a[idx]-x) &amp;lt; abs(a[idx-1]-x))
      return idx
   else
      return idx-1
   end
end

# Returns best index and best value
function closest_value_and_index(xGrid::Vector, val::Real)

    # get index
    ibest = closest_index(xGrid, val)

    # Return best value on grid, and the corresponding index
    return xGrid[ibest], ibest

end

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;approximate-a-distribution-with-a-single-mass-point&#34;&gt;Approximate a distribution with a single mass point&lt;/h3&gt;

&lt;p&gt;To warm up, let&amp;rsquo;s see how the method works when the true underlying distribution is constituted of &lt;strong&gt;a single mass point&lt;/strong&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;## True Value
w = 2.5    #True value
mass = 1.0 #Mass at the true value

## Approximation
nW=10 #Number of grid points
w_grid=linspace(0.0, 4.0, nW) #Location of grid points
hw_grid=zeros(nW); #Initialization

w_min = minimum(w_grid) #Upper bound for the grid
w_max = maximum(w_grid) #Lower bound for the grid
nW = length(w_grid) #Number of points on the grid

# Project true value on the grid:
(wValue_proj, wIndex_proj) = closest_value_and_index(w_grid, w)

# To store the location of the value below and above the true value:
wIndex_below = 0
wIndex_above = 0

# If the true value is above the projection
if w &amp;gt;= wValue_proj
    wIndex_below = wIndex_proj
    wIndex_above = wIndex_proj + 1
# If the true value is below the projection
elseif w &amp;lt; wValue_proj
    wIndex_below = wIndex_proj -1
    wIndex_above = wIndex_proj
end

# Boundary cases
if wIndex_proj == 1
    wIndex_below = 1
    wIndex_above = 2
elseif wIndex_proj == nW
    wIndex_below = nW - 1
    wIndex_above = nW
end

# Special case 1: w &amp;lt; w_min
if w &amp;lt;= w_min
    p = 1
elseif w &amp;gt;= w_max
# Special case 2: w &amp;gt; w_max
    p = 0
else
    p = 1.0 - ((w - w_grid[wIndex_below])/(w_grid[wIndex_above] - w_grid[wIndex_below]))
    p = min(1.0, max(0.0, p))
end

# Spread the mass:
# 1. Point below
hw_grid[wIndex_below] += p*mass

# 2. Point above:
hw_grid[wIndex_above] += (1.0 - p)*mass;

p0 =bar(w_grid, hw_grid, label = &amp;quot;Mass on grid&amp;quot;)
plot!(p0, [w], seriestype = :vline, label=&amp;quot;True value&amp;quot;, linewidth = 4)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Young_2010_12_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the true distribution (in orange) and the approximation (in blue).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Because the true value is not a point of our grid (that would be a miracle), the mass is spread between the two closest points. However, we still get the mean right. We will see below that this property extends to distributions with supports constituted of several points:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;println(&amp;quot;True mean $(w)&amp;quot;)
println(&amp;quot;Approximate mean $(round(mean(w_grid, weights(hw_grid./sum(hw_grid))), digits = 4))&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True mean 2.5
Approximate mean 2.5
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;approximate-a-multi-point-distribution&#34;&gt;Approximate a multi-point distribution&lt;/h3&gt;

&lt;p&gt;Now, let&amp;rsquo;s see how well &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v34y2010i1p36-41.html&#34; target=&#34;_blank&#34;&gt;Young&amp;rsquo;s method (2010)&lt;/a&gt; works when the true underlying distribution has positive mass for &lt;strong&gt;a finite number of points&lt;/strong&gt;. To keep things pretty, let&amp;rsquo;s assume that the true distribution has the shape of a Normal distribution, but we truncate the tails.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;Nw_true = 10 #Number of points with positive mass
w_true_lb = 1.0 #lower bound
w_true_ub = 3.0 #upper bound
w_true = linspace(w_true_lb, w_true_ub, Nw_true)
d = truncated(Normal((w_true_lb + w_true_ub)/2), w_true_lb, w_true_ub)
mass_true = pdf.(d, w_true)
mass_true = mass_true./sum(mass_true);
p0 = bar(w_true, mass_true, label=&amp;quot;Mass true value&amp;quot;)
display(p0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Young_2010_17_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the mass for each point on the (true) grid.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;w_min = minimum(w_grid)
w_max = maximum(w_grid)
nW = length(w_grid)

hw_grid=zeros(nW);


for (wIndexTrue, w) in enumerate(w_true)

    mass = mass_true[wIndexTrue] #mass

    # Project true value on the grid:
    (wValue_proj, wIndex_proj) = closest_value_and_index(w_grid, w)

    # To store the location of the value below and above the true value:
    wIndex_below = 0
    wIndex_above = 0

    # If the true value is above the projection
    if w &amp;gt;= wValue_proj
        wIndex_below = wIndex_proj
        wIndex_above = wIndex_proj + 1
    # If the true value is below the projection
    elseif w &amp;lt; wValue_proj
        wIndex_below = wIndex_proj -1
        wIndex_above = wIndex_proj
    end

    # Boundary cases
    if wIndex_proj == 1
        wIndex_below = 1
        wIndex_above = 2
    elseif wIndex_proj == nW
        wIndex_below = nW - 1
        wIndex_above = nW
    end

    # Special case 1: w &amp;lt; w_min
    if w &amp;lt;= w_min
        p = 1
    elseif w &amp;gt;= w_max
    # Special case 2: w &amp;gt; w_max
        p = 0
    else
        p = 1.0 - ((w - w_grid[wIndex_below])/(w_grid[wIndex_above] - w_grid[wIndex_below]))
        p = min(1.0, max(0.0, p))
    end

    p = 1.0 - ((w - w_grid[wIndex_below])/(w_grid[wIndex_above] - w_grid[wIndex_below]))
    p = min(1.0, max(0.0, p))

    # Spread the mass:
    # 1. Point below
    hw_grid[wIndex_below] += p*mass

    # 2. Point above:
    hw_grid[wIndex_above] += (1.0 - p)*mass

end

bar(w_grid, hw_grid, label=&amp;quot;Mass on grid&amp;quot;)
bar!(w_true, mass_true, label=&amp;quot;Mass true value&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Young_2010_18_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the true distribution (in orange) and the approximation (in blue).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;A good property of &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v34y2010i1p36-41.html&#34; target=&#34;_blank&#34;&gt;Young&amp;rsquo;s method (2010)&lt;/a&gt; is that, &lt;strong&gt;as long as the grid is wide enough&lt;/strong&gt; to so that true values fall within it, &lt;strong&gt;the mean of the true underlying distribution is preserved&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;println(&amp;quot;True mean $(round(mean(w_true, weights(mass_true./sum(mass_true))), digits = 4))&amp;quot;)
println(&amp;quot;Approximate mean $(round(mean(w_grid, weights(hw_grid./sum(hw_grid))), digits = 4))&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True mean 2.0
Approximate mean 2.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, there are some &lt;strong&gt;approximation errors&lt;/strong&gt; when &lt;strong&gt;higher moments&lt;/strong&gt; are involved such as the variance, or when calculating &lt;strong&gt;percentiles&lt;/strong&gt;. But the finest the grid, the better the approximation gets.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;println(&amp;quot;True median $(round(quantile(w_true, weights(mass_true./sum(mass_true)), 0.5), digits = 4))&amp;quot;)
println(&amp;quot;Approximate median $(round(quantile(w_grid, weights(hw_grid./sum(hw_grid)), 0.5), digits = 4))&amp;quot;)

println(&amp;quot;True variance $(round(var(w_true, weights(mass_true./sum(mass_true))), digits = 4))&amp;quot;)
println(&amp;quot;Approximate variance $(round(var(w_grid, weights(hw_grid./sum(hw_grid))), digits = 4))&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True median 1.9567
Approximate median 1.8519
True variance 0.3465
Approximate variance 0.3836
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;using-a-panel-of-agents&#34;&gt;Using a panel of agents&lt;/h3&gt;

&lt;p&gt;Alternatively, one may use a large number of agents to approximate the true underlying distribution. The idea is that if the number of agents is large enough, the &lt;a href=&#34;https://en.wikipedia.org/wiki/Central_limit_theorem&#34; target=&#34;_blank&#34;&gt;central limit theorem&lt;/a&gt; will kick in. The issue is that we need a large number of agents to get the approximation right, as illustrated below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;nb_agents = 1000
w_agents = rand(d, nb_agents);

println(&amp;quot;True mean $(round(mean(w_true, weights(mass_true./sum(mass_true))), digits = 4))&amp;quot;)
println(&amp;quot;Approximate mean $(round(mean(w_agents), digits = 4))&amp;quot;)

println(&amp;quot;True median $(round(quantile(w_true, weights(mass_true./sum(mass_true)), 0.5), digits = 4))&amp;quot;)
println(&amp;quot;Approximate median $(round(quantile(w_agents, 0.5), digits = 4))&amp;quot;)

println(&amp;quot;True variance $(round(var(w_true, weights(mass_true./sum(mass_true))), digits = 4))&amp;quot;)
println(&amp;quot;Approximate variance $(round(var(w_agents), digits = 4))&amp;quot;)

p0 = bar(w_true, mass_true, label=&amp;quot;Mass true value&amp;quot;)
p1 = histogram(w_agents, label=&amp;quot;Mass panel&amp;quot;)
plot(p0,p1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True mean 2.0
Approximate mean 1.9955
True median 1.9567
Approximate median 1.9971
True variance 0.3465
Approximate variance 0.2754
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Young_2010_25_1.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the true distribution (on the left) and the approximation (on the right).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;With 1000 agents, the approximation is not exceptional. Let&amp;rsquo;s try to increase the number of agents. The following plot shows that the approximation gets better as we increase the number of agents, but a very
large number of agents is needed:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;w_agents = []
grid_agents = collect(1000:1000:100000)
mean_agents = zeros(length(grid_agents))
std_agents = zeros(length(grid_agents))

for (i, nb_agents) in enumerate(grid_agents)
    push!(w_agents, rand(d, nb_agents))
    mean_agents[i] = mean(w_agents[i])
    std_agents[i] = std(w_agents[i])
end

CI = 1.960.*std_agents./sqrt.(grid_agents); #95% confidence interval. t-test is approximately a z-test because large number of agents.
p0 = plot(grid_agents, mean_agents, ribbon = CI, label = &amp;quot;approximate mean&amp;quot;)
plot!(p0,[mean(w_true, weights(mass_true./sum(mass_true)))], linetype = :hline, label = &amp;quot;true mean&amp;quot;, linestyle = :dash)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Young_2010_27_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the empirical mean calculated using the panel and the true value, for different sizes of the panel.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;When possible, simulating directly a distribution instead of using a panel is a good idea. &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v34y2010i1p36-41.html&#34; target=&#34;_blank&#34;&gt;Young&amp;rsquo;s method (2010)&lt;/a&gt;
allows to do that, while preserving the mean of the true distribution.&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Young, Eric R. &amp;ldquo;Solving the incomplete markets model with aggregate uncertainty using the Krusellâ€“Smith algorithm and non-stochastic simulations.&amp;rdquo; Journal of Economic Dynamics and Control 34.1 (2010): 36-41.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Aiyagari Model with Aggregate Uncertainty</title>
      <link>https://julienpascal.github.io/post/aiyagariaggregateuncertainty/</link>
      <pubDate>Tue, 19 May 2020 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/aiyagariaggregateuncertainty/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The Bewley-Huggett-Aiyagari-ImohoroÄŸlu economies are the workhorse of modern macroeconomics. In these economies, markets are &amp;ldquo;incomplete&amp;rdquo;. Agents cannot fully insure against risk and decide to self-insure by holding a safe asset to smooth their consumption (see &lt;a href=&#34;https://mitpress.mit.edu/books/recursive-macroeconomic-theory-fourth-edition&#34; target=&#34;_blank&#34;&gt;Ljungqvist and Sargent (2018)&lt;/a&gt; for a textbook treatment of this topic).&lt;/p&gt;

&lt;p&gt;In this post, I consider the model of Aiyagari (1994). While the original model abstracts from aggregate fluctuations, Economists have since developed several techniques to simulate out-of-steady-state dynamics for this class of models.&lt;/p&gt;

&lt;p&gt;Here, I use a methodology that is quite general. It is a &lt;strong&gt;3-step procedure&lt;/strong&gt;, which proceeds as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Solve for the non-stochastic steady-state&lt;/li&gt;
&lt;li&gt;Perturbe the model around its non-stochastic steady-state&lt;/li&gt;
&lt;li&gt;Use the perturbation to calculate out-of-steady-state dynamics&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I use the &lt;a href=&#34;https://julienpascal.github.io/post/genbkm/&#34; target=&#34;_blank&#34;&gt;BKM and GenBKM&lt;/a&gt; algorithms for step 2 and 3, which means that the only theoretical tool needed is &lt;strong&gt;backward induction&lt;/strong&gt; (i.e. knowing the value tomorrow, what is the value today?).&lt;/p&gt;

&lt;p&gt;What are the cons of the methodology presented here? First, the methodology assumes a &lt;strong&gt;small aggregate shock&lt;/strong&gt;. An implicit assumption is that aggregate shocks do not modify the value of the non-stochastic steady-state. Said differently, the cycle does not change the trend, &lt;a href=&#34;https://www.youtube.com/watch?v=K2X1GiTaxHw&#34; target=&#34;_blank&#34;&gt;which seems to be violated in some instances&lt;/a&gt;. If the shock is large, the value of steady-state may be altered and the methodology presented here is not adequate. An example of a large shock could be the disruption caused by COVID-19.&lt;/p&gt;

&lt;p&gt;This methodology also fails when the non-stochastic steady-state is not relevant for the dynamic economy. This can problematic in portfolio choice problems, in which portfolios are indeterminate when aggregate uncertainty vanishes (see &lt;a href=&#34;https://hal-sciencespo.archives-ouvertes.fr/hal-00972801/document&#34; target=&#34;_blank&#34;&gt;Coeurdacier et al (2011)&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;On the pro side, the methodology presented here is fast (orders of magnitude faster than &lt;a href=&#34;https://notes.quantecon.org/submission/5bb58d1e11611400157fdc8d&#34; target=&#34;_blank&#34;&gt;Krusell-Smith (1998)&lt;/a&gt;) and transparent. The code can be &lt;a href=&#34;https://github.com/JulienPascal/AiyagariAggregateUncertainty&#34; target=&#34;_blank&#34;&gt;downloaded here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;i-the-model&#34;&gt;I. The Model&lt;/h2&gt;

&lt;p&gt;In the model of Aiyagari (1994), there is continuum of agents each maximizing an infinite flow of discounted utility:&lt;/p&gt;

&lt;p&gt;$$ E_{0} \sum_{t=0}^{\infty} \beta^t U(c_t) $$&lt;/p&gt;

&lt;p&gt;subject to the constraint that consumption plus savings in period $t$ (the left hand side of the next equation) is equal to labor earnings plus savings inherited from the last period (the right hand side of the next equation):&lt;/p&gt;

&lt;p&gt;$$ c_t + a_{t+1} = w_t l_t + (1 + r_t) a_t $$&lt;/p&gt;

&lt;p&gt;The variable $l_t$ captures idiosyncratic risk in labor earnings and could be interpreted as unemployment risk. We also make the assumptions that consumption cannot be negative and that agents cannot borrow more than a certain amount $B$:&lt;/p&gt;

&lt;p&gt;$$ c_t \geq 0 $$&lt;/p&gt;

&lt;p&gt;$$ a_t \geq -B $$&lt;/p&gt;

&lt;p&gt;The behavior of firms can be summarized by a representative firm hiring workers and capital:&lt;/p&gt;

&lt;p&gt;$$ Y_t = z_t K_t^{\alpha} L_t^{1-\alpha} $$&lt;/p&gt;

&lt;p&gt;where $Y_t$ is total output, $K_t$ is the aggregate capital level and $L_t$ is the aggregate labor supply. The variables $w_t$ and $r_t$ are pinned down each period by the first order conditions (FOCs) of the representative firm. Note that at the non-stochastic steady-state $z_t = z_{SS} = 1$ (by definition) and both $w_t$ and $r_t$ are constant. Importantly, because agents have to take into consideration the value of $w_t$ and $r_t$ when making decisions, the cross-sectional distribution of agents across capital and idiosyncratic states matters (through the FOCs of the representative firm).&lt;/p&gt;

&lt;h2 id=&#34;ii-methodology&#34;&gt;II. Methodology&lt;/h2&gt;

&lt;p&gt;To solve for individual policy functions, I use the endogenous grid method (EGM) of Carroll (2006). The main idea of this method is to start from the end-of-period level of capital. Using the Euler equation, one may recover the beginning-of-period consumption and level of capital without using a root-finding algorithm.&lt;/p&gt;

&lt;p&gt;To determine the non-stochastic equilibrium, I solve for the fixed-point problem over the aggregate capital level $f(K*) = 0$ using &lt;a href=&#34;https://en.wikipedia.org/wiki/Brent%27s_method&#34; target=&#34;_blank&#34;&gt;Brent&amp;rsquo;s method&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To calculate the response of the economy to one-period unforeseen aggregate shock (an &amp;ldquo;MIT shock&amp;rdquo;), I use a standard backward-forward &lt;a href=&#34;https://en.wikipedia.org/wiki/Shooting_method&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;shooting&amp;rdquo; method&lt;/a&gt;:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;holding constant the path of aggregate capital level $(K_t)_{t=1}^{T}$, calculate the policy functions&lt;/li&gt;
&lt;li&gt;holding constant the policy functions, calculate the path of aggregate capital level $(K_t)_{t=1}^{T}$&lt;/li&gt;
&lt;li&gt;repeat until convergence of the path for aggregate capital level $(K_t)_{t=1}^{T}$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To simulate out-of-steady-state dynamics, I use the &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v89y2018icp68-92.html&#34; target=&#34;_blank&#34;&gt;BKM algorithm&lt;/a&gt;, which relies on the assumption that the response of the economy to an aggregate shock $d_t$ is &lt;strong&gt;linear&lt;/strong&gt; with respect to the &lt;strong&gt;aggregate state&lt;/strong&gt; $z_t$:&lt;/p&gt;

&lt;p&gt;$$ d_t = z_t d(1, 0, 0, &amp;hellip;) + z_{t-1}d(0, 1, 0, &amp;hellip;) + z_{t-2}d(0, 0, 1, &amp;hellip;) + &amp;hellip; $$&lt;/p&gt;

&lt;p&gt;or more compactly:&lt;/p&gt;

&lt;p&gt;$$ d_t = \sum_{k=0}^{+\infty} z_{t-k} d_{k} $$&lt;/p&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;p&gt;$$ d_{1} = d(1,0,0,&amp;hellip;)$$
$$ d_{2} = d(0,1,0,&amp;hellip;)$$
$$ d_{3} = d(0,0,1,&amp;hellip;)$$&lt;/p&gt;

&lt;p&gt;That is, the evolution of equilibrium variables is a moving average of past shocks. However, by calculating several trajectories after an MIT shock, one sees that linearity assumption is slightly violated. Hence, I use the &lt;a href=&#34;https://irihs.ihs.ac.at/id/eprint/4500/&#34; target=&#34;_blank&#34;&gt;GenBKM algorithm&lt;/a&gt;, which is a refinement of the BKM algorithm taking into consideration these slight violations of linearity.&lt;/p&gt;

&lt;h2 id=&#34;iii-implementation&#34;&gt;III. Implementation&lt;/h2&gt;

&lt;p&gt;These ideas are implemented using &lt;a href=&#34;https://julialang.org/&#34; target=&#34;_blank&#34;&gt;Julia&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;versioninfo()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Julia Version 1.3.0
Commit 46ce4d7933 (2019-11-26 06:09 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ii-a-dependencies&#34;&gt;II. A Dependencies&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Distributions
using Plots
using DataFrames
using Random
using ForwardDiff
using LinearAlgebra
using Interpolations
using DataFrames
using Optim
Random.seed!(1234);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using NBInclude #To load stuct and functions from other notebooks
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@nbinclude(&amp;quot;utils.ipynb&amp;quot;) #mutable structs and primitive functions for the model
@nbinclude(&amp;quot;RBC.ipynb&amp;quot;)   #Aiyagari model, without the borrowing constraint (standard RBC)
@nbinclude(&amp;quot;EGM.ipynb&amp;quot;)   #implementation of the EGM method
@nbinclude(&amp;quot;SteadyState.ipynb&amp;quot;) #to calculate the non-stochastic steady-state
@nbinclude(&amp;quot;GenBKM.ipynb&amp;quot;) #to simulate the stochastic model using the GenBKM algorithm
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ii-b-steady-state&#34;&gt;II.B Steady-state&lt;/h3&gt;

&lt;h4 id=&#34;finding-the-steady-state-value-of-capital&#34;&gt;Finding the steady-state value of capital&lt;/h4&gt;

&lt;p&gt;Finding the non-stochastic equilibrium is a fixed-point problem over the aggregate capital level $f(K*) = 0$, which can be solved using &lt;a href=&#34;https://en.wikipedia.org/wiki/Brent%27s_method&#34; target=&#34;_blank&#34;&gt;Brent&amp;rsquo;s method&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p = Params() #struct with model parameters
z_ss = 1.0 #aggregate productivity at the non-stochastic steady-state
@time oo = optimize(K -&amp;gt; eq_K(K,p), 10, 100, Brent()) #solve for the steady-state value of capital using Brent method
K_star = oo.minimizer;
println(&amp;quot;Steady-state value of capital K* = $(K_star)&amp;quot;)
# Store the optimal policy function at the steady-state
g_star, c_star, g_low_star, g_high_star, success_flag= solve_EGM(x-&amp;gt;log(x), x-&amp;gt;log(x), R(K_star, z_ss, p), W(K_star, z_ss, p), p); #solve for policy functions
# Store the stationary distribution at the steady-state
t_star = make_trans_mat(g_star, p)    #generate transition matrix
d_star = get_stationary_dist(t_star); #stationary distribution
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;visualizing-transition-probabilities&#34;&gt;Visualizing transition probabilities&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;xs = [string(&amp;quot;x&amp;quot;, i) for i = 1:size(t_star,1)]
ys = [string(&amp;quot;y&amp;quot;, i) for i = 1:size(t_star,2)]
heatmap(t_star, aspect_ratio = 1, color=:plasma, clim=(0., 0.25))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_15_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the transition probabilities across capital and idiosyncratic probability states.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;visualizing-convergence-toward-the-steady-state&#34;&gt;Visualizing convergence toward the steady-state&lt;/h4&gt;

&lt;p&gt;One may visually check that the equilibrium exists and is unique:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Solve for the demand and supply of capital for different values of the interest rate
K_grid = collect(range(oo.minimizer-0.5, stop=oo.minimizer+0.5, length=20))
K_implied_grid = similar(K_grid)
R_grid = similar(K_grid)

for (K_index, K_value) in enumerate(K_grid)
    R_s, W_s = R(K_value, z_ss, p), W(K_value, z_ss, p) #calculate interest rate R and wage W
    gg, c_star, g_low, g_high, success_flag= solve_EGM(x -&amp;gt; log(x), x -&amp;gt; 2*log(x), R_s, W_s, p) #solve for policy functions
    tt = make_trans_mat(gg, p)   #generate transition matrix
    dd = get_stationary_dist(tt) #stationary distribution
    K_implied = aggregate_K(dd, p) #implied level of capital
    R_grid[K_index] = R_s #store interest rate
    K_implied_grid[K_index] = K_implied #store demand of capital
    K_grid[K_index] = K_value #store supply of capital
end

# Plot demand and supply of capital
plot(K_grid, R_grid, label = &amp;quot;Demand&amp;quot;, ylabel=&amp;quot;Interest rate&amp;quot;, xlabel=&amp;quot;Capital&amp;quot;)
plot!(K_implied_grid, R_grid, label = &amp;quot;Supply&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_18_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the demand and the supply of capital as a function of the interest rate.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;ii-c-mit-shock&#34;&gt;II.C MIT Shock&lt;/h3&gt;

&lt;h4 id=&#34;backward-and-forward-updates&#34;&gt;Backward and forward updates&lt;/h4&gt;

&lt;p&gt;The next block implements the backward-forward shooting method:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;holding the path of aggregate capital $(K_t)_{t=1}^{T}$, calculate the policy functions&lt;/li&gt;
&lt;li&gt;holding constant the policy functions, calculate the aggregate capital $(K_t)_{t=1}^{T}$&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function backward_update(g_low_ss::Function, g_high_ss::Function, K_path_guess::Array{Float64,1}, z_path::Array{Float64,1}, p::Params)
    &amp;quot;&amp;quot;&amp;quot;
    Update policy functions backward, holding {K_t,z_t} constant
    &amp;quot;&amp;quot;&amp;quot;
    nT = length(z_path)
    g_low_path = Array{Function}(undef,nT) #initialize two lists of functions
    g_high_path =  Array{Function}(undef,nT)
    g_low_path[nT] = g_low_ss
    g_high_path[nT] = g_high_ss
    a_path = zeros(p.nI, p.grid_size, nT) #to store policy functions on savings grid
    R_path = zeros(nT) #to store the interest rate on path
    W_path = zeros(nT) #to store the wage on path

    #Start from the steady-state and iterate backward
    #holding constant the path for {K_t,z_t}
    #---------------------------------------------------
    for t=nTðŸ‘Ž2 #iterate backward
        # Next period
        R_path[t], W_path[t] = R(K_path_guess[t], z_path[t], p), W(K_path_guess[t], z_path[t], p)
        # Current period
        R_path[t-1], W_path[t-1] = R(K_path_guess[t-1], z_path[t-1], p), W(K_path_guess[t-1], z_path[t-1], p)
        # Current period&#39;s policy, given next period
        a_path[:,:,t-1], c_new, g_low_path[t-1], g_high_path[t-1] = euler_back(g_low_path[t], g_high_path[t], R_path[t-1], W_path[t-1], R_path[t], W_path[t], p)
    end

    return a_path, g_low_path, g_high_path
end

function forward_update(K_star::Float64, a_path::Array{Float64,3}, d_ss::Array{Float64,1}, p::Params)
    &amp;quot;&amp;quot;&amp;quot;
    Update forward the distribution of agents + aggregate capital
    dd_path_forward, K_path_forward
    &amp;quot;&amp;quot;&amp;quot;
    nT = length(z_path)
    K_path_forward = zeros(nT)
    K_path_forward[1] = K_star
    dd_path_forward = zeros(size(d_ss,1), nT)
    dd_path_forward[:,1] = d_ss
    #2. Iterate forward {K_t,z_t}, using the policy
    #functions from step 1
    #-----------------------------------------------
    for t=2:nT
        tt = make_trans_mat(a_path[:,:,t-1], p) #generate transition matrix
        dd_path_forward[:,t] = tt*dd_path_forward[:,t-1]
        K_path_forward[t] = aggregate_K(dd_path_forward[:,t], p)
    end

    return dd_path_forward, K_path_forward
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;finding-the-transition-path&#34;&gt;Finding the transition path&lt;/h4&gt;

&lt;p&gt;One problem with the backward-forward shooting method is that updating the path for $(K_t)_{t=1}^{T}$ &amp;ldquo;too quickly&amp;rdquo; may result in the overall procedure to diverge. An easy fix is to take a convex combination of the previous guess and the newly calculated path, with $\lambda$ small:&lt;/p&gt;

&lt;p&gt;$(K^{NEW}_t)_{t=1}^{T} = \lambda (K_t)_{t=1}^{T} + (1-\lambda)(K^{OLD}_t)_{t=1}^{T}$&lt;/p&gt;

&lt;p&gt;The next function implements this idea, with the extra feature that $\lambda$ increases when the distance between two iterations is getting small (too speed up convergence) and decreases when the distance is getting bigger (to prevent divergence). See &lt;a href=&#34;https://notes.quantecon.org/submission/5b3faf1fb9eab00015b89f9a&#34; target=&#34;_blank&#34;&gt;this excellent notebook&lt;/a&gt; for the same idea applied to an OLG model.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function solve_mit!(K_path, g_low_ss::Function, g_high_ss::Function, d_ss::Array{Float64,1},
                    K_ss::Float64, z_path::Array{Float64,1}, p::Params; convex_combination::Float64 = 0.2,
                    shrink_factor::Float64 = 0.5, expand_factor::Float64 = 1.05,
                    max_iter::Int64 = 1000, tol::Float64=1e-6, verbose::Bool=true, display_iter::Int64 = 20)
    &amp;quot;&amp;quot;&amp;quot;
    Finds the path for aggregate capital K_path
    &amp;quot;&amp;quot;&amp;quot;
    diff = Inf #initialization
    diff_old = Inf #initialization
    convergence_flag = 0 #initialization
    damp = convex_combination #initial dampening parameter

    for i_mit=1:max_iter

        # Step 1. Solve backward the policy functions {g_t(a,e_low), g_t(a,e_high)}, keeping {K_t,z_t} constant:
        a_path, g_low_path, g_high_path = backward_update(g_low_ss, g_high_ss, K_path[i_mit], z_path, p);

        #2. Solve forward {K_t,z_t}, keeping policy functions {g_t(a,e_low), g_t(a,e_high)} constant:
        dd_path_forward, K_path_forward = forward_update(K_ss, a_path, d_star, p);

        # Distance between guess for {K_t} and implied values:
        diff = maximum(abs.(K_path_forward - K_path[i_mit]))

        # Display every display_iter iterations
        if verbose==true
            if mod(i_mit,display_iter) == 0
                println(&amp;quot;Iteration $(i_mit). diff = $(diff)&amp;quot;)
            end
        end

        if diff &amp;lt; tol
            if verbose==true
                println(&amp;quot;Convergence reached after $(i_mit) iterations.&amp;quot;)
            end
            convergence_flag = 1
            break
        else
            # Update the guess for the path {K_t}
            # Decrease the dampening factor
            if diff &amp;gt; diff_old
                damp = max(min(damp * shrink_factor, 1.0-eps()), eps())
            # Increase the dampening factor
            else
                damp = max(min(damp * expand_factor, 1.0-eps()), eps())
            end
            if mod(i_mit, 10) == 0
                if verbose==true
                    println(&amp;quot;damp = $(damp); diff = $(diff)&amp;quot;)
                end
            end
            # Store the updated path for {K_t}
            push!(K_path, damp.*K_path_forward .+ (1.0 - damp).*K_path[i_mit])
            diff_old = diff

        end
    end

    return K_path, convergence_flag
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;find-the-path-for-k-t-for-a-1-std-dev-positive-productivity-shock&#34;&gt;Find the path for {K_t} for a 1 std. dev positive productivity shock&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;max_t = 300 #Let us assume that the economy is back to the steady state after max_t periods
z_ss = 1.0  #Value of aggregate productivity at the non-stochastic steady-state
z_shock = 2.0 #Value of the inital shock

# Let&#39;s generate a path for the aggregate shock
z_path = ones(max_t)
z_path[1] = z_ss*z_shock #initial shock

# Evolution of aggregate productivity in level:
for t_index=2:max_t
    z_path[t_index] = z_path[t_index-1]^p.rho
end

# Heroic guess for the initial path of {K_t}: K_t = K* for all t
K_path = []
push!(K_path, repeat([K_star], max_t))

# Find the path for {K_t}:
@time K_path, convergence_flag = solve_mit!(K_path, g_low_star, g_high_star, d_star, K_star, z_path, p, convex_combination=0.25);

# Find the path for other aggregates:
R_path = zeros(length(z_path)) #to store the interest rate on path
W_path = zeros(length(z_path)) #to store the wage on path
for t=length(z_path)ðŸ‘Ž1 #iterate backward
    # Next period
    R_path[t], W_path[t] = R(K_path[end][t], z_path[t], p), W(K_path[end][t], z_path[t], p)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;visualize-convergence-of-the-transition-path&#34;&gt;Visualize convergence of the transition path&lt;/h4&gt;

&lt;p&gt;The first guess for $(K_t)_{t=1}^{T}$ is that it is equal to the non-stochastic steady-state value $K*$. Very quickly, the path for $(K_t)_{t=1}^{T}$ converges to the perfect foresight transition path:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p0 = plot(1:max_t, K_path[1], label= &amp;quot;Iteration 0&amp;quot;, title=&amp;quot;Convergence of K(t)&amp;quot;)
plot!(p0, 2:max_t, K_path[2][2:end], label = &amp;quot;Iteration 1&amp;quot;)
show_every = 5 #display {K_t} for each multiple of show_every
for k in 2:length(K_path)
    if mod(k,show_every) == 0
        plot!(p0, 2:max_t, K_path[k][2:end], xlabel=&amp;quot;t&amp;quot;, label = &amp;quot;Iteration $(k)&amp;quot;, title=&amp;quot;Convergence of K(t)&amp;quot;, legend=:best)
    end
end

p0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_30_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the path for capital {K_t}^(i) for different iterations of the backward-forward algorithm&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;removing-the-borrowing-constraint&#34;&gt;Removing the borrowing constraint&lt;/h4&gt;

&lt;p&gt;The next graph compares the current model to a similar model without a borrowing constraint. With no borrowing constraint, the aggregate level of capital reacts less to an aggregate shock in productivity:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p1 = plot(1:max_t, K_path[end], label= &amp;quot;K_t Aiyagari&amp;quot;, title=&amp;quot;IRF Aiyagari versus RBC&amp;quot;)
plot!(p1, xx[RBCp.iK,2:end] .+ K_star, label = &amp;quot;K_t RBC&amp;quot;, color = &amp;quot;black&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_34_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the impulse response of K_t of for the Aiyagari model and a RBC model.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p1 = plot(1:max_t, z_path./z_path[end] .-1, label = &amp;quot;z(t)&amp;quot;, xlabel= &amp;quot;t&amp;quot;)
p2 = plot(1:max_t, R_path./R_path[end] .-1, label= &amp;quot;R(t)&amp;quot;, xlabel= &amp;quot;t&amp;quot;)
p3 = plot(1:max_t, W_path./W_path[end].-1 , label= &amp;quot;W(t)&amp;quot;, xlabel= &amp;quot;t&amp;quot;)
p4 = plot(1:max_t, K_path[end]./K_path[end][end] .-1, label= &amp;quot;K(t)&amp;quot;, xlabel= &amp;quot;t&amp;quot; )

p5 = plot(p1, p2, p3, p4)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_36_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the percentage deviation from steady-state values of (i) aggregate productivity (ii) the interest rate (iii) wages (iv) capital.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;linearity-checks&#34;&gt;Linearity checks&lt;/h4&gt;

&lt;p&gt;To simulate the stochastic economy, the BKM algorithm makes the assumption that an MIT shock is linear with
respect to the aggregate shock. That is, doubling the initial shock will simply double the value of aggregates
along the transition path without changing the shape of the path. The next block
calculates several transition paths for different initial aggregate shocks.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;max_t = 300 #Let us assume that the economy is back to the steady state after max_t periods
z_ss = 1.0  #Value of aggregate productivity at the non-stochastic steady-state
# Different initial shocks
array_sigma = collect(range(-0.75, stop=0.75, step=0.25))
# Let&#39;s exclude sigma = 0
array_sigma = array_sigma[array_sigma .!= 0.]
# To store the different scaled IRF:
x_mit_scaled_sigma = zeros(max_t, length(array_sigma))
# To store path of aggregate productivity:
z_path_sigma = zeros(max_t, length(array_sigma))
# To store the path for the %deviation of aggregate productivity from its steady-state value
z_path_sigma_dev = zeros(max_t, length(array_sigma))

for (index_sigma, sigma) in enumerate(array_sigma)

    # Let&#39;s generate a path for the aggregate shock
    z_path = ones(max_t)
    z_path[1] = z_ss + z_ss*sigma

    # Evolution of aggregate productivity in level:
    for t_index=2:max_t
        z_path[t_index] = z_path[t_index-1]^p.rho
    end

    # Heroic guess for the initial path of {K_t}: K_t = K* for all t
    K_path = []
    push!(K_path, repeat([K_star], max_t))

    # Find the path for {K_t}:
    @time K_path, convergence_flag = solve_mit!(K_path, g_low_star, g_high_star, d_star, K_star, z_path, p, convex_combination=0.2, verbose=false);

    # Check for convergence
    if convergence_flag!=1
        error(&amp;quot;No convergence for z(1) = $(z_path[1]).&amp;quot;)
    end

    # store the path for z:
    z_path_sigma[:, index_sigma] = z_path

    # store for the %deviation of aggregate productivity from its steady-state value
    z_path_sigma_dev[:, index_sigma] = z_path./z_ss .- 1.0

    # Scaled IRF: how a percentage deviation in z_t from its steady-state results in a % deviation of k_t
    x_mit_scaled_sigma[:, index_sigma] = (K_path[end]./K_star .- 1.0)./z_path_sigma_dev[1, index_sigma]

end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p0 = plot()
p1 = plot()
p2 = plot()
p3 = plot()

for (index_sigma, sigma) in enumerate(array_sigma)
    if index_sigma == 1
        p0 = plot(100 .*z_path_sigma_dev[:, index_sigma], label=&amp;quot;z(t) with z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;)
        p1 = plot(z_path_sigma[:, index_sigma], label=&amp;quot;z(t) z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;)
        p2 = plot(x_mit_scaled_sigma[:, index_sigma], label=&amp;quot;z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;)
        p3 = plot(sign(z_path_sigma[1, index_sigma] - z_ss)*x_mit_scaled_sigma[:, index_sigma], label=&amp;quot;z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;)
    else
        plot!(p0, 100 .*z_path_sigma_dev[:, index_sigma], label=&amp;quot;z(t) with z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;, title = &amp;quot;% deviation aggregate productivity&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
        plot!(p1, z_path_sigma[:, index_sigma], label=&amp;quot;z(t) with z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;, title = &amp;quot;Aggregate productivity&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
        plot!(p2, x_mit_scaled_sigma[:, index_sigma], label=&amp;quot;z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;, title = &amp;quot;Impact of shock&#39;s size on scaled IRF: x&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
        plot!(p3, sign(z_path_sigma[1, index_sigma] - z_ss)*x_mit_scaled_sigma[:, index_sigma], label=&amp;quot;z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;, title = &amp;quot;Impact of shock&#39;s sign on scaled IRF: sign(x - x_ss)*x&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;plot(p0,p1, fg_legend = :transparent, legend=:best, layout=(2,1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_42_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the percentage deviation of aggregate productivity from its steady-state value (top panel) and aggregate productivity in level (bottom panel) for different initial shocks.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;plot(p2,p3, fg_legend = :transparent, legend=:best, layout=(2,1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_44_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: The top panel shows the scaled impulse response function of capital for different aggregate shocks. The bottom panel shows the scaled impulse response function of capital for different aggregate shocks, multiplied by the sign of the aggregate shock.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;ii-d-out-of-steady-state-dynamics&#34;&gt;II.D. Out-of-steady-state dynamics&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;max_t = 2000
shocks_t = rand(Normal(0,0.005), max_t) # Series of aggregate shocks
# Let&#39;s generate a path for the aggregate shock
z_path = ones(max_t)
z_path[1] = z_ss

# Evolution of aggregate productivity in level:
for t_index=2:max_t
    z_path[t_index] = z_path[t_index-1]^p.rho + shocks_t[t_index]
end

# Calculation of GenBKM path:
XT_GenBKM = zeros(max_t);# Initialization
@time GenBKM_path!(XT_GenBKM, max_t, x_mit_scaled_sigma, z_path./z_ss .- 1.0, array_sigma)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.237683 seconds (1.06 M allocations: 50.188 MiB)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p1 = plot(100 .*(z_path./z_ss .- 1.0), label=&amp;quot;z_t&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
p2 = plot(100 .*XT_GenBKM, label = &amp;quot;K_t&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
plot(p1,p2, fg_legend = :transparent, legend=:best, layout=(2,1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_48_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: The top panel shows the percentage deviation of aggregate productivity from its steady-state value. The bottom panel shows the percentage deviation of capital from its steady-state value.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This post presents the model of Aiyagari (1994) and a general three-step procedure to simulate out-of-steady-state dynamics for models of this class for &amp;ldquo;small&amp;rdquo; shocks. Solving incomplete market models for large shocks seems to be &lt;a href=&#34;https://www.springer.com/gp/book/9783319564357&#34; target=&#34;_blank&#34;&gt;much more complicated&lt;/a&gt; and is still an active area of research.&lt;/p&gt;

&lt;h2 id=&#34;links&#34;&gt;Links&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;An excellent course on heterogeneous agent models with code in Matlab, Python and Julia: &lt;a href=&#34;https://alisdairmckay.com/Notes/HetAgents/index.html&#34; target=&#34;_blank&#34;&gt;https://alisdairmckay.com/Notes/HetAgents/index.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;More on the EGM method: &lt;a href=&#34;https://julia.quantecon.org/dynamic_programming/egm_policy_iter.html&#34; target=&#34;_blank&#34;&gt;https://julia.quantecon.org/dynamic_programming/egm_policy_iter.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;More on the Aiyagari model: &lt;a href=&#34;https://python.quantecon.org/aiyagari.html&#34; target=&#34;_blank&#34;&gt;https://python.quantecon.org/aiyagari.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Aiyagari model in continuous time: &lt;a href=&#34;https://nbviewer.jupyter.org/github/QuantEcon/QuantEcon.notebooks/blob/master/aiyagari_continuous_time.ipynb&#34; target=&#34;_blank&#34;&gt;https://nbviewer.jupyter.org/github/QuantEcon/QuantEcon.notebooks/blob/master/aiyagari_continuous_time.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Similar model solved very efficiently with a Python package: &lt;a href=&#34;https://github.com/shade-econ/sequence-jacobian/blob/master/krusell_smith.ipynb&#34; target=&#34;_blank&#34;&gt;https://github.com/shade-econ/sequence-jacobian/blob/master/krusell_smith.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Aiyagari, S. Rao. &amp;ldquo;Uninsured idiosyncratic risk and aggregate saving.&amp;rdquo; The Quarterly Journal of Economics 109.3 (1994): 659-684.&lt;/li&gt;
&lt;li&gt;Bewley, Truman. &amp;ldquo;A difficulty with the optimum quantity of money.&amp;rdquo; Econometrica: Journal of the Econometric Society (1983): 1485-1504.&lt;/li&gt;
&lt;li&gt;Boppart, Timo, Per Krusell, and Kurt Mitman. â€œExploiting MIT shocks in heterogeneous-agent economies: the impulse response as a numerical derivative.â€ Journal of Economic Dynamics and Control 89 (2018): 68-92.&lt;/li&gt;
&lt;li&gt;Christopher D Carroll. The method of endogenous gridpoints for solving dynamic stochastic optimization problems. Economics Letters, 91(3):312â€“320, 2006.&lt;/li&gt;
&lt;li&gt;Coeurdacier, Nicolas, Helene Rey, and Pablo Winant. &amp;ldquo;The risky steady state.&amp;rdquo; American Economic Review 101.3 (2011): 398-401.&lt;/li&gt;
&lt;li&gt;Huggett, Mark. &amp;ldquo;The risk-free rate in heterogeneous-agent incomplete-insurance economies.&amp;rdquo; Journal of economic Dynamics and Control 17.5-6 (1993): 953-969.&lt;/li&gt;
&lt;li&gt;Ä°mrohoroÄŸlu, AyÅŸe. &amp;ldquo;The welfare cost of inflation under imperfect insurance.&amp;rdquo; Journal of Economic Dynamics and Control 16.1 (1992): 79-91.&lt;/li&gt;
&lt;li&gt;Ljungqvist, Lars, and Thomas J. Sargent. Recursive macroeconomic theory. MIT press, 2018.&lt;/li&gt;
&lt;li&gt;Reiter, Michael. â€œComments onâ€ Exploiting MIT Shocks in Heterogeneous-Agent Economies: The Impulse Response as a Numerical Derivativeâ€ by T. Boppart, P. Krusell and K. Mitman.â€ Journal of Economic Dynamics and Control 89 (2018): 93-99.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>The GenBKM Algorithm</title>
      <link>https://julienpascal.github.io/post/genbkm/</link>
      <pubDate>Tue, 21 Apr 2020 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/genbkm/</guid>
      <description>

&lt;p&gt;In a &lt;a href=&#34;https://julienpascal.github.io/post/bkm/&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt; I presented the &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0165188918300022&#34; target=&#34;_blank&#34;&gt;BKM algorithm&lt;/a&gt; , which can used to approximate solutions of macroeconomic models with &lt;strong&gt;aggregate uncertainty&lt;/strong&gt; and &lt;strong&gt;heterogeneous agents&lt;/strong&gt;. This class of models has been been of great interest for Economists for quite a long time. For instance, &lt;a href=&#34;https://www.jstor.org/stable/2118417?seq=1#metadata_info_tab_contents&#34; target=&#34;_blank&#34;&gt;Aiyagari (1994)&lt;/a&gt; already hinted that taking into consideration heterogeneity along the business cycle is both theoretically important and challenging:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This class of models may also be useful in &lt;strong&gt;resolving various asset return puzzles&lt;/strong&gt;. Mehra and
Prescott [1985, p. 145] suggested that these puzzles cannot be &amp;ldquo;accounted for by models that abstract from transactions costs. This is a very hard problem computationally since the distribution of assets
across households can no longer be taken to be constant. Instead, &lt;strong&gt;the cross-section distribution is part of the state vector that evolves stochastically over time in response to aggregate shocks&lt;/strong&gt;. This is an issue that remains to be explored&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Recent developments have relied on the &lt;strong&gt;sequence representation&lt;/strong&gt; of the mutli-stage decision process, instead of the traditional &lt;strong&gt;recursive form&lt;/strong&gt; using Bellman&amp;rsquo;s principle (see for instance &lt;a href=&#34;https://web.stanford.edu/~aauclert/sequence_space_jacobian.pdf&#34; target=&#34;_blank&#34;&gt;Auclert at al (2019)&lt;/a&gt; or &lt;a href=&#34;http://xavier-ragot.fr/pdf/progress/Optimal_policies.pdf&#34; target=&#34;_blank&#34;&gt;Le Grand and Ragot (2019)&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;In this short blog post, I would like to present a small modification of the BKM algorithm that delivers large improvements in accuracy: the GenBKM algorithm by &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v89y2018icp93-99.html&#34; target=&#34;_blank&#34;&gt;Reiter (2018)&lt;/a&gt;. The code for this post can be found &lt;a href=&#34;https://github.com/JulienPascal/GenBKM&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;i-a-the-bkm-algorithm&#34;&gt;I.A. The BKM algorithm&lt;/h3&gt;

&lt;p&gt;It is common to use Bellman&amp;rsquo;s principle of optimality to characterize solutions of a mutli-stage decision process. The principle of optimality leads to a solution in a &lt;strong&gt;recursive form&lt;/strong&gt; $d_{t} = d(S_{t})$, where $S_t$ is a vector of state variables and d(.) a policy function describing the optimal action of a decision-maker when faced with any given state. In model with heterogeneous agents (HA) and aggregate uncertainty, $S_t$ is generally infinite-dimensional. Hence, there is a huge premium in avoiding the recursive form.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;sequence form&lt;/strong&gt; of the problem is as follows: at each step in time, a decision-maker observes a new realization of a random process $z_t$ and taking into account the full history of past shocks, the agent make a new choice to maximize her expected discounted sum of returns: $d_t = d(z_t, z_{t-1}, z_{t-2}, &amp;hellip;)$.&lt;/p&gt;

&lt;p&gt;The BKM algorithm makes the &lt;strong&gt;assumption&lt;/strong&gt; of &lt;strong&gt;linearity&lt;/strong&gt; of d(.) with respect to the &lt;strong&gt;aggregate state&lt;/strong&gt; $z_t$:&lt;/p&gt;

&lt;p&gt;$$ d_t = z_t d(1, 0, 0, &amp;hellip;) + z_{t-1}d(0, 1, 0, &amp;hellip;) + z_{t-2}d(0, 0, 1, &amp;hellip;) + &amp;hellip; $$&lt;/p&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;p&gt;$$ d_{1} = d(1,0,0,&amp;hellip;)$$
$$ d_{2} = d(0,1,0,&amp;hellip;)$$
$$ d_{3} = d(0,0,1,&amp;hellip;)$$&lt;/p&gt;

&lt;p&gt;or more compactly:&lt;/p&gt;

&lt;p&gt;$$ d_t = \sum_{k=0}^{+\infty} z_{t-k} d_{k} $$&lt;/p&gt;

&lt;p&gt;The series of $d_{k}$ describes the trajectory of the economy after an &amp;ldquo;MIT&amp;rdquo; shock: the economy is hit by an aggregate shock in period 1 and then goes back directly to its steady-state value. The evolution of equilibrium variables are simply a moving average of past shocks.&lt;/p&gt;

&lt;p&gt;The BKM algorithm works well because computing an MIT shock in macroeconomic models with aggregate uncertainty and heterogeneous agents is generally feasible and fast.&lt;/p&gt;

&lt;h4 id=&#34;tl-dr&#34;&gt;TL;DR&lt;/h4&gt;

&lt;p&gt;To simulate out-of-steady-state dynamics, the BKM algorithm superposes &lt;strong&gt;scaled impulse response functions&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;i-b-bkm-example&#34;&gt;I. B. BKM example&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s illustrate how the BKM algorithm works with the following non-linear model:&lt;/p&gt;

&lt;p&gt;$$ x_{t} = a x_{t-1} + b x_{t-1}^2 + z_{t} $$&lt;/p&gt;

&lt;p&gt;The next plot illustrates that BKM algorithm does a good job at approximating the dynamic of the true
nonlinear model. But can we do better? The next section shows that the answer is yes.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Dependencies
using Distributions
using Plots
using DataFrames
using Random
pgfplotsx()

# Parameters
max_iter=1000 #number of iterations for the simulation
a = 0.5
b = 0.05
sigma_shock=1.0 #variance of shocks
mu_shock=0. #mean of shocks
Random.seed!(1234)
d = Normal(mu_shock, sigma_shock)

# transition function
function iter_x(x_min1::Float64, a::Float64, b::Float64)
    &amp;quot;&amp;quot;&amp;quot;
    Function to find the next iteration of x_{t} = a x_{t-1} + b x_{t-1}^2
    x_min1::Float64: x_{t-1}
    a::Float64
    b::Float64
    &amp;quot;&amp;quot;&amp;quot;
    return a*x_min1 + b*x_min1^2
end

# Simulation of an MIT Shock
# We assume that after max_iter_mit periods, the economy is back at the steady-state
max_iter_mit = 25
x_mit=zeros(max_iter_mit)
# Initial shock
z_t=zeros(max_iter_mit)
z_t[1] = sigma_shock #a 1 std. deviation
x_mit[1] = 0 #steady-state

for i=2:max_iter_mit
    x_mit[i] = iter_x(x_mit[i-1], a, b) + z_t[i-1]
end

# Scaled-version of the impulse response:
x_mit_scaled = x_mit./z_t[1];

# Scaled-version of the impulse response:
p0 = plot(x_mit_scaled, label=&amp;quot;x scaled&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
title!(&amp;quot;MIT shock&amp;quot;)

# Function to calculate the path of xt using the BKM algorithm
function BKM_path!(XT::Array{Float64,1}, x_scaled::Array{Float64,1}, shocks::Array{Float64,1})
    &amp;quot;&amp;quot;&amp;quot;
    XT::Array{Float64,1}: array to store the evolution of the variable xt
    x_scaled::Array{Float64,1}: a scaled MIT shock
    shocks::Array{Float64,1}: sequence of shocks
    &amp;quot;&amp;quot;&amp;quot;
    # get the length of x_scaled
    len_x_scaled = length(x_scaled)
    max_iter = length(XT)

    # Loop over time periods periods
    for t=2:max_iter
        # Superposition of MIT shocks:
        for k=1:t
            # After some time, we assume that the effect of past shocks vanishes:
            if k&amp;lt;=len_x_scaled
                XT[t]+=x_scaled[k]*shocks[t-k+1]
            end
        end
    end

end

XT = zeros(max_iter) # Initialization
shocks_t = rand(d, max_iter).*0.5 # Series of shocks
@time BKM_path!(XT, x_mit_scaled, shocks_t) # Solving using BKM:
x_true = zeros(max_iter) # True value of the series
for i=2:max_iter
    x_true[i] = iter_x(x_true[i-1], a, b) + shocks_t[i-1]
end

# Let&#39;s store statistics on error:
diff_BKM = x_true - XT
max_abs_err_BKM = maximum(abs.(diff_BKM))
min_abs_err_BKM = minimum(abs.(diff_BKM))
mean_abs_err_BKM = mean(abs.(diff_BKM))
median_abs_err_BKM = median(abs.(diff_BKM))

p1 = plot(XT[2:end], label=&amp;quot;x_t BKM&amp;quot;)
plot!(x_true[2:end], label=&amp;quot;x_t true&amp;quot;)
title!(&amp;quot;BKM with b=$(b)&amp;quot;)

&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;GenBKM_7_2.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: In orange the exact value as a function of time; in blue the approximation obtained by using
the BKM algorithm&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;ii-a-the-genbkm-algorithm&#34;&gt;II. A. The GenBKM algorithm&lt;/h3&gt;

&lt;p&gt;The BKM algorithm is based on the assumption that both the &lt;strong&gt;size&lt;/strong&gt; and &lt;strong&gt;sign&lt;/strong&gt; of the initial shock does not
change the shape of the scaled impulse response function. But is really the case? The next graph shows that both the size and the sign matter for the shape of the scaled impulse response function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Different initial shocks
array_sigma = collect(range(-2, stop=2, step=0.5))
# Let&#39;s exclude sigma = 0
array_sigma = array_sigma[array_sigma .!= 0.]
# To store the different scaled IRF:
x_mit_scaled_sigma = zeros(max_iter_mit, length(array_sigma))

for (index_sigma, sigma) in enumerate(array_sigma)
    x_mit=zeros(max_iter_mit)
    # Initial shock
    z_t=zeros(max_iter_mit)
    z_t[1] = sigma #a 1 std. deviation
    x_mit[1] = 0 #steady-state

    for i=2:max_iter_mit
        x_mit[i] = iter_x(x_mit[i-1], a, b) + z_t[i-1]
    end

    # Scaled-version of the impulse response:
    x_mit_scaled = x_mit./z_t[1];
    # store the scaled response
    x_mit_scaled_sigma[:, index_sigma] = x_mit_scaled

end


p2 = plot(x_mit_scaled_sigma[:, 1], label=&amp;quot;sigma = $(array_sigma[1])&amp;quot;)
p3 = plot(sign(array_sigma[1])*x_mit_scaled_sigma[:, 1], label=&amp;quot;sigma = $(array_sigma[1])&amp;quot;)

for (index_sigma, sigma) in enumerate(array_sigma)
    plot!(p2, x_mit_scaled_sigma[:, index_sigma], label=&amp;quot;sigma = $(sigma)&amp;quot;, title = &amp;quot;Impact of shock&#39;s size on scaled IRF: x&amp;quot;)
    plot!(p3, sign(sigma)*x_mit_scaled_sigma[:, index_sigma], label=&amp;quot;sigma = $(sigma)&amp;quot;, title = &amp;quot;Impact of shock&#39;s sign on scaled IRF: sign(x)*x&amp;quot;)
end

p4 = plot(p2, p3, layout = (2, 1))
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;GenBKM_11_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: The top panel shows the scaled impulse response function for different
values of shocks. The bottom panel shows the scaled impulse response function
multiplied by the sign of the shock. If the size and the sign of the shock did not matter, we would
see only one line. It is not the case here.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The GenBKM algorithm is the similar to the BKM algorithm, except that the impacts of the size and the sign of the
initial shock on the response of the economy are taken into consideration. It proceeds as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Divide the support of the shock into $n$ intervals $ I_i = (a_i, b_i)$&lt;/li&gt;
&lt;li&gt;Compute $n$ MIT shocks using shocks in $z_i \in I_i$, denoted by $d_k^{i}$&lt;/li&gt;
&lt;li&gt;The state of the economy at time $t$ is given by the moving average of past shocks, taking into consideration
past shock values:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;$$ d_t = \sum_{k=0}^{+\infty} z_{t-k} d_{k}^{f(t-k)} $$&lt;/p&gt;

&lt;p&gt;where the function $f(t)$ returns the index of the interval in which the shock $z_t$ falls.&lt;/p&gt;

&lt;h4 id=&#34;tl-dr-1&#34;&gt;TL;DR&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;GenBKM = BKM with different scaled IRF, instead of one.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;ii-b-genbkm-example&#34;&gt;II. B. GenBKM example&lt;/h3&gt;

&lt;p&gt;The GenBKM algorithm is implemented in the block of code that follows. The next plot shows that the approximation error is much smaller using the GenBKM algorithm. The next table shows that the mean absolute error drops by more than 300% if the GenBKM is used instead of BKM.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function GenBKM_path!(XT::Array{Float64,1}, max_iter::Int64, x_scaled::Array{Float64,2}, shocks::Array{Float64,1}, array_sigma::Array{Float64,1})

    # get the length of x_scaled
    len_x_scaled = size(x_scaled,1)

    # We don&#39;t want x_scaled to contain any NaN value
    if sum(isnan.( x_scaled) .== true) != 0
        error(&amp;quot;x_scaled contains at least one NaN value.&amp;quot;)
    end

    # We don&#39;t want shocks to contain any NaN value
    if sum(isnan.(shocks) .== true) != 0
        error(&amp;quot;shocks contains at least one NaN value.&amp;quot;)
    end

    # Loop over time periods periods
    for t=2:max_iter
        # Superposition of MIT shocks:
        for k=1:t
            # After some time, we assume that the effect of past shocks vanishes:
            if k&amp;lt;=len_x_scaled
                # Find were the initial shock stood on the sigma grid:
                index_sigma = searchsortednearest(array_sigma, shocks[t-k+1])
                XT[t]+=x_scaled[k, index_sigma]*shocks[t-k+1]
            end
        end
    end

end

# Function to find the index corresponding to the closest value on a grid:
# Source: https://discourse.julialang.org/t/findnearest-function/4143/4
function searchsortednearest(a::Array{Float64,1},x::Float64)
    &amp;quot;&amp;quot;&amp;quot;
    a::Array{Float64,1}: grid
    x::Float64: value to be found
    returns the index of the closest value to x on grid a
    &amp;quot;&amp;quot;&amp;quot;
    idx = searchsortedfirst(a,x)
    if (idx==1); return idx; end
    if (idx&amp;gt;length(a)); return length(a); end
    if (a[idx]==x); return idx; end
    if (abs(a[idx]-x) &amp;lt; abs(a[idx-1]-x))
      return idx
    else
      return idx-1
    end
end

# Calculation of GenBKM path:
XT_GenBKM = zeros(max_iter);
@time GenBKM_path!(XT_GenBKM, max_iter, x_mit_scaled_sigma, shocks_t, array_sigma)

# Let&#39;s store statistics on error:
diff_GenBKM = x_true - XT_GenBKM
max_abs_err_GenBKM = maximum(abs.(diff_GenBKM))
min_abs_err_GenBKM = minimum(abs.(diff_GenBKM))
mean_abs_err_GenBKM = mean(abs.(diff_GenBKM))
median_abs_err_GenBKM = median(abs.(diff_GenBKM))

df = DataFrame(Statistics = [&amp;quot;Max absolute error&amp;quot;, &amp;quot;Min absolute error&amp;quot;, &amp;quot;Mean absolute error&amp;quot;, &amp;quot;Median absolute error&amp;quot;],
               BKM = [max_abs_err_BKM, min_abs_err_BKM, mean_abs_err_BKM, median_abs_err_BKM],
               GenBKM = [max_abs_err_GenBKM, min_abs_err_GenBKM, mean_abs_err_GenBKM, median_abs_err_GenBKM])

# Plot errors
p6 = plot(diff_GenBKM[2:end], label=&amp;quot;GenBKM&amp;quot;, xlabel = &amp;quot;t&amp;quot;, ylabel = &amp;quot;Error&amp;quot;)
plot!(diff_BKM[2:end], label=&amp;quot;BKM&amp;quot;)
title!(&amp;quot;Error BKM and GenBKM&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;GenBKM_14_1.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: In orange the approximation error when using BKM; in blue the approximation error when using GenBKM&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;table class=&#34;data-frame&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;Statistics&lt;/th&gt;&lt;th&gt;BKM&lt;/th&gt;&lt;th&gt;GenBKM&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt; &lt;/th&gt;&lt;th&gt; &lt;/th&gt;&lt;th&gt; &lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;p&gt; &lt;/p&gt;&lt;tr&gt;&lt;th&gt;1&lt;/th&gt;&lt;td&gt;Max absolute error&lt;/td&gt;&lt;td&gt;0.263167&lt;/td&gt;&lt;td&gt;0.132318&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;2&lt;/th&gt;&lt;td&gt;Min absolute error&lt;/td&gt;&lt;td&gt;0.0&lt;/td&gt;&lt;td&gt;0.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;3&lt;/th&gt;&lt;td&gt;Mean absolute error&lt;/td&gt;&lt;td&gt;0.0381089&lt;/td&gt;&lt;td&gt;0.0136915&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;4&lt;/th&gt;&lt;td&gt;Median absolute error&lt;/td&gt;&lt;td&gt;0.0237194&lt;/td&gt;&lt;td&gt;0.0100031&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Heterogeneity along the business cycle matters. This blog post presented two simple algorithms that are both fast and accurate to solve for macroeconomics models in which heterogeneity is key. GenBKM is a refinement of BKM, which tends to be more accurate. However, there is no free lunch. The increased accuracy of GenBKM is obtained by using several MIT shocks instead of one.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Aiyagari, S. Rao. &amp;ldquo;Uninsured idiosyncratic risk and aggregate saving.&amp;rdquo; The Quarterly Journal of Economics 109.3 (1994): 659-684.&lt;/li&gt;
&lt;li&gt;Auclert, Adrien, et al. Using the Sequence-Space Jacobian to Solve and Estimate Heterogeneous-Agent Models. No. w26123. National Bureau of Economic Research, 2019.&lt;/li&gt;
&lt;li&gt;Boppart, Timo, Per Krusell, and Kurt Mitman. &amp;ldquo;Exploiting MIT shocks in heterogeneous-agent economies: the impulse response as a numerical derivative.&amp;rdquo; Journal of Economic Dynamics and Control 89 (2018): 68-92.&lt;/li&gt;
&lt;li&gt;Le Grand, FranÃ§ois, and Ragot, Xavier. &amp;ldquo;Managing Inequality over the Business Cycles: Optimal Policies with Heterogeneous Agents and Aggregate Shocks&amp;rdquo;. No. 1090. Society for Economic Dynamics, 2019.&lt;/li&gt;
&lt;li&gt;Reiter, Michael. &amp;ldquo;Comments on&amp;rdquo; Exploiting MIT Shocks in Heterogeneous-Agent Economies: The Impulse Response as a Numerical Derivative&amp;rdquo; by T. Boppart, P. Krusell and K. Mitman.&amp;rdquo; Journal of Economic Dynamics and Control 89 (2018): 93-99.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;versioninfo()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Julia Version 1.3.0
Commit 46ce4d7933 (2019-11-26 06:09 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>The linearâ€“quadratic regulator Part II</title>
      <link>https://julienpascal.github.io/post/lqr_partii/</link>
      <pubDate>Sun, 05 Apr 2020 16:00:00 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/lqr_partii/</guid>
      <description>

&lt;p&gt;This notebook builds upon what has been described in &lt;a href=&#34;https://julienpascal.github.io/post/lqr/&#34; target=&#34;_blank&#34;&gt;Part I&lt;/a&gt;. In &lt;a href=&#34;https://julienpascal.github.io/post/lqr/&#34; target=&#34;_blank&#34;&gt;Part I&lt;/a&gt;, we introduced the linearâ€“quadratic regulator (LQR) framework in Python. We solved the linearized control problem.&lt;/p&gt;

&lt;p&gt;In this notebook, we will see that we can do better. The basic idea is to follow the the evolution of &amp;ldquo;observables&amp;rdquo; â€” functions of the state space â€” instead of the evolution of the state itself using the &lt;strong&gt;Koopman operator&lt;/strong&gt;. In the space of observables, the differential equation is linear. Thus, we can solve for the optimal control in the this transformed space, without having to linearize the system around its steady-state.&lt;/p&gt;

&lt;h4 id=&#34;in-this-notebook-you-will-learn&#34;&gt;In this notebook, you will learn:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;the basics on the Koopman operator&lt;/li&gt;
&lt;li&gt;how to solve for the optimal control in the Koopman subspace&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;i-the-koopman-operator-101&#34;&gt;I. The Koopman operator 101&lt;/h1&gt;

&lt;p&gt;Let us remember that in Part I, we analyzed the evolution of the following dynamical system:&lt;/p&gt;

&lt;p&gt;$$ \begin{cases} \frac{d}{dt} x = \mu x \\ \frac{d}{dt} y = \lambda (y - x^2)  \end{cases} $$&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s make the observation that we can defined a new vector $z$ defined by:&lt;/p&gt;

&lt;p&gt;$$ z \equiv \begin{pmatrix} z_1 \\ z_2 \\ z_3 \end{pmatrix} = \begin{pmatrix} x \\ y \\ x^2 \end{pmatrix}$$&lt;/p&gt;

&lt;p&gt;The original nonlinear dynamical system is linear when considering the evolution of $z$:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \begin{pmatrix} z_1 \\ z_2 \\ z_3 \end{pmatrix} = \begin{pmatrix} \mu &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \lambda &amp;amp; -\lambda \\ 0 &amp;amp; 0 &amp;amp; 2 \mu \end{pmatrix}  \begin{pmatrix} z_1 \\ z_2 \\ z_3 \end{pmatrix}$$&lt;/p&gt;

&lt;p&gt;What we just did â€” writing the evolution the dynamical system using some observables â€” is the central idea of the Koopman operator. Here we are lucky because our new variable $z$ is of finite dimension. In the general case, $z$ is infinite-dimensional:&lt;/p&gt;

&lt;p&gt;$$
\frac{d}{dt} \begin{pmatrix} z_1 \\ z_2 \\ &amp;hellip; \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; &amp;hellip; \\ a_{21} &amp;amp; a_{22} &amp;amp; &amp;hellip; \\ &amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip; \end{pmatrix} \begin{pmatrix} z_1 \\ z_2 \\ &amp;hellip; \end{pmatrix} $$&lt;/p&gt;

&lt;p&gt;and we have no guarantee that the truncation of z by a finite dimensional counterpart will produce a good approximation of the system. For more detail on this problem, I invite you to read &lt;a href=&#34;https://arxiv.org/abs/1510.03007&#34; target=&#34;_blank&#34;&gt;this paper&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Because now the dynamical system is linear, we can directly use the results from LQR framework and solve for the optimal control that minimizes the cost $J$:&lt;/p&gt;

&lt;p&gt;$$ J = \int_{0}^{\infty} x&amp;rsquo;(t) Q x(t) + u&amp;rsquo;(t) R u(t) dt $$&lt;/p&gt;

&lt;p&gt;We already know that the optimal control from the controller is a linear function of the current state of the system:&lt;/p&gt;

&lt;p&gt;$$ u = - C_z z$$&lt;/p&gt;

&lt;p&gt;When the system is controlled optimally, the equation governing the evolution of the system writes:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} z = A_z z - B C_z z $$&lt;/p&gt;

&lt;p&gt;At a later stage, because we want to compare the Koopman controller to the linearized controller, we do not want to penalize the variable $z_3$ for being away from its steady state. The rationale is the variable $z_3$ is &amp;ldquo;fictive&amp;rdquo;.
We still have in mind that we want to control the &amp;ldquo;real&amp;rdquo; variables $x$ and $y$. As a result, the matrix $Q$ we consider
is:&lt;/p&gt;

&lt;p&gt;$$ \begin{pmatrix} 1 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 \end{pmatrix} $$&lt;/p&gt;

&lt;h2 id=&#34;ii-simulating-forward-the-dynamical-system&#34;&gt;II. Simulating forward the dynamical system&lt;/h2&gt;

&lt;p&gt;For what follows, you will need the following packages:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
import matplotlib.pyplot as plt
plt.style.use(&#39;ggplot&#39;)
%matplotlib inline
import numpy as np
from control.matlab import *  # MATLAB-like functions
#to solve ODE
from scipy import integrate
#show the version of Python I am using:
!python3 --version
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Python 3.5.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s study optimal control for the following differential equation:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \begin{pmatrix} z_1 \\ z_2 \\ z_3 \end{pmatrix} = \begin{pmatrix} \mu &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \lambda &amp;amp; -\lambda \\ 0 &amp;amp; 0 &amp;amp; 2 \mu \end{pmatrix}  \begin{pmatrix} z_1 \\ z_2 \\ z_3 \end{pmatrix}  $$&lt;/p&gt;

&lt;p&gt;The following block of code define the parameter values, the matrix A for the linear part of the differential equation and the matrix B specifying that the controller can only act on x. We also specify the time span during which we want to simulate forward the trajectories:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Parameters and matrices A and B:
mu = -0.05
llambda = -1.0
# Matrices for the orginial system
A = np.array([[mu, 0], [0, llambda]])
B = np.array([[0], [1]])
R = np.array([1])
Q = np.eye(2)
# Matrices for the transformed system:
A_z = np.array([[mu, 0, 0], [0, llambda, -llambda], [0, 0, 2*mu]])  
B_z = np.array([[0], [1], [0]])
R_z = np.array([1])
Q_z = np.eye(3)
# Time span
t0, t1 = 0, 100 # start and end
t = np.arange(t0, t1, 0.01)

# Function that defines the dynamic system:
def vdp0(t, y):
    # linear part + nonlinear part:
    x = A.dot(y) + np.array([0, -llambda*(y[0]**2)])
    return x

# Function that defines the dynamic system in the Koopman subspace:
def vdp0z(t, y):
    x = A_z.dot(y)
    return x
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We then define 4 different starting values and simulate forward the system using the &lt;code&gt;scipy.integrate&lt;/code&gt; toolkit:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Set of starting values:
y0A = np.array([1.5, -1, (1.5)**2])
y0B = np.array([-1.5, -1, (-1.5)**2])
y0C = np.array([5, 5, 25])
y0D = np.array([-5, 5, 25])

# To store the different trajectories
list_y_z = []

# Method for the ODE:
# This is an explicit runge-kutta method of order (4)5 due to Dormand &amp;amp; Prince
integrator = &amp;quot;dopri5&amp;quot;

# Loop over the different starting values and calculate trajectories:
for y0 in [y0A, y0B, y0C,y0D]:
    # initialize an array to store the solution
    y = np.zeros((len(t), len(y0)))   # array for solution
    r0 = integrate.ode(vdp0z).set_integrator(integrator)
    r0.set_initial_value(y0, t0)   # initial values
    for i in range(1, t.size):
       y[i, :] = r0.integrate(t[i]) # get one more value, add it to the array
       if not r0.successful():
           raise RuntimeError(&amp;quot;Could not integrate&amp;quot;)
    # append the list of solution
    list_y_z.append(y)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next graph shows the trajectory of x and y using the augmented linear system corresponds to the trajectory
we found using the nonlinear dynamical system, as expected:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Plot the different paths:
fig, ax = plt.subplots(figsize=(10, 5))

for index,y0 in enumerate([y0A, y0B, y0C, y0D]):
    ax.plot(list_y_z[index][1:-1, 0], list_y_z[index][1:-1, 1], label = str(y0))
    plt.xlabel(&amp;quot;x&amp;quot;)
    plt.ylabel(&amp;quot;y&amp;quot;)
plt.title(&amp;quot;Trajectories for different starting values&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartII_21_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The next graph shows that the dynamical system moves along a nice parabola in the third dimension:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Plot the different paths:
fig, ax = plt.subplots(figsize=(10, 5))

for index,y0 in enumerate([y0A, y0B, y0C, y0D]):
    ax.plot(list_y_z[index][1:-1, 0], list_y_z[index][1:-1, 2], label = str(y0))
    plt.xlabel(&amp;quot;x&amp;quot;)
    plt.ylabel(&amp;quot;z&amp;quot;)
plt.title(&amp;quot;Trajectories for different starting values&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartII_23_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;iii-solving-for-the-optimal-control&#34;&gt;III. Solving for the optimal control&lt;/h2&gt;

&lt;p&gt;Let us remember that our aim is find the matrix $C_z$ defining the optimal control:&lt;/p&gt;

&lt;p&gt;$$ u = - C_z z $$&lt;/p&gt;

&lt;p&gt;Interestingly, while the optimal $u$ is linear when considering $z$, it is quadratic when considering the original vector of state $x$:&lt;/p&gt;

&lt;p&gt;$$ u = - (C_{z,1} C_{z,2}) \begin{pmatrix} x \\ y  \end{pmatrix} -  C_{z,3} x^2  $$&lt;/p&gt;

&lt;p&gt;We will see in a minute that having a non-linear control allows us to outperform the linear control obtained
in &lt;a href=&#34;https://julienpascal.github.io/post/lqr/&#34; target=&#34;_blank&#34;&gt;Part I&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Solve for C:
(C, X, E) = lqr(A, B, Q, R)
print(&amp;quot;Feedback matrix C : {}&amp;quot;.format(C))

# Solve for C_z:
(C_z, X_z, E_z) = lqr(A_z, B_z, Q_z, R_z)
print(&amp;quot;Feedback matrix C_z : {}&amp;quot;.format(C_z))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Feedback matrix C : [[0.         0.41421356]]
Feedback matrix C_z : [[0.         0.41421356 0.27355029]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now proceed as previously to simulate forward the differential equation. The only difference is that
now we have to take into account the optimal control applied each period on the system. The optimal control is
taken into consideration in the function &lt;code&gt;vdp1(t, y)&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def vdp1(t, y):
    # Ay - B*X*y + Cy
    x = A.dot(y)  - np.matmul(B,C).dot(y)
    return x + np.array([0, -llambda*(y[0]**2)])

def vdp1z(t, y):
    return A_z.dot(y)  - np.matmul(B_z,C_z).dot(y)

y0 = [-5, 5]                   # initial value
y0_z = [-5, 5, 25]                   # initial value

y = np.zeros((len(t), len(y0))) # array for solution
y_z = np.zeros((len(t), len(y0_z))) # array for solution
y[0, :] = y0
y_z[0, :] = y0_z
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Controlled trajectory using the linearized system
r = integrate.ode(vdp1).set_integrator(integrator)
r.set_initial_value(y0, t0)   # initial values

for i in range(1, t.size):
   y[i, :] = r.integrate(t[i]) # get one more value, add it to the array
   if not r.successful():
       raise RuntimeError(&amp;quot;Could not integrate&amp;quot;)

# Controlled trajectory using the linearized system
r = integrate.ode(vdp1z).set_integrator(integrator)
r.set_initial_value(y0_z, t0)   # initial values

for i in range(1, t.size):
   y_z[i, :] = r.integrate(t[i]) # get one more value, add it to the array
   if not r.successful():
       raise RuntimeError(&amp;quot;Could not integrate&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now compare the controlled and Koopman controlled trajectories. Interestingly, the Koopman controlled
trajectory moves along a trajectory involving lower values for $y$:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;index = 3 #choose the last trajectory
fig, ax = plt.subplots(figsize=(10, 5))
plt.plot(list_y_z[index][1:-1, 0], list_y_z[index][1:-1, 1], label = &amp;quot;Uncontrolled&amp;quot;)
plt.plot(y[:, 0], y[:, 1], label = &amp;quot;Controlled&amp;quot;)
plt.plot(y_z[:, 0], y_z[:, 1], label = &amp;quot;Koopman controlled&amp;quot;)
plt.xlabel(&amp;quot;x&amp;quot;)
plt.ylabel(&amp;quot;y&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartII_32_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The next logical question is whether or not the Koopman controller is better than the controller based on the
linearization of the dynamical system around its steady state. The next plot shows that indeed the Koopman controller (in purple) outperforms the latter (in blue).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Controlled
JLQR = np.cumsum( np.square(y[:, 0]) + np.square(y[:, 1]) + np.square(np.matmul(C, y.T)) ).T
# Koopman controlled
JLQRz = np.cumsum( np.square(y_z[:, 0]) + np.square(y_z[:, 1]) + np.square(np.matmul(C_z, y_z.T)) ).T
# Uncontrolled
JLQR0 = np.cumsum( np.square(list_y_z[index][:, 0]) + np.square(list_y_z[index][:, 1]) )

fig, ax = plt.subplots(figsize=(10, 5))
plt.plot(t, JLQR0, label = &amp;quot;Uncontrolled&amp;quot;)
plt.plot(t, JLQR, label = &amp;quot;Controlled&amp;quot;)
plt.plot(t, JLQRz, label = &amp;quot;Koopman controlled&amp;quot;)
plt.xlabel(&amp;quot;t&amp;quot;)
plt.ylabel(&amp;quot;JLQR&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartII_34_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This notebook illustrates the idea behind the Koopman operator in a very simple setting. We saw that by solving for the optimal control in the space of observables, in which the system is exactly linear, we find a controller that outperforms the one obtained by linearizing the system around its steady-state.&lt;/p&gt;

&lt;p&gt;The Koopman LQR control drew my attention because many techniques, especially in Economics, are based on the linearization of dynamic systems around its steady-state. While these linearization techniques are accurate when the economy is close to its steady-state (in a &amp;ldquo;business as usual&amp;rdquo; situation), it is hard to know how these approximations perform when the economy is an unusual state. Given the current economic context, relying on linearization might be inaccurate.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The linear system studied in this notebook is based on the paper: Brunton, Steven L., et al. &amp;ldquo;Koopman invariant subspaces and finite linear representations of nonlinear dynamical systems for control.&amp;rdquo; PloS one 11.2 (2016).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Koopman, Bernard O. &amp;ldquo;Hamiltonian systems and transformation in Hilbert space.&amp;rdquo; Proceedings of the national academy of sciences of the united states of america 17.5 (1931): 315.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>The linearâ€“quadratic regulator Part I</title>
      <link>https://julienpascal.github.io/post/lqr/</link>
      <pubDate>Wed, 01 Apr 2020 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/lqr/</guid>
      <description>

&lt;p&gt;The two main goals of this blog post is to introduce what the &lt;a href=&#34;https://en.wikipedia.org/wiki/Linear%E2%80%93quadratic_regulator&#34; target=&#34;_blank&#34;&gt;linearâ€“quadratic regulator (LQR)&lt;/a&gt; framework is and to show how to solve LQR problems using Python. The LQR is concerned with operating a dynamic system (a rocket, a car, the economy, etc.) at minimum cost.&lt;/p&gt;

&lt;h4 id=&#34;in-this-blog-post-you-will-learn&#34;&gt;In this blog post you will learn&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;what the LQR framework is&lt;/li&gt;
&lt;li&gt;how to simulate forward an ordinary differential equation using &lt;a href=&#34;https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.ode.html&#34; target=&#34;_blank&#34;&gt;scipy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;how to solve for the optimal control using the &lt;a href=&#34;https://python-control.readthedocs.io/en/0.8.3/&#34; target=&#34;_blank&#34;&gt;Python Control Systems Library&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Jupyter notebook with the code used to generate this blog post can be found &lt;a href=&#34;https://github.com/JulienPascal/KoopmanObservableSubspaces&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;i-the-lqr-framework-in-a-nutshell&#34;&gt;I. The LQR framework in a nutshell&lt;/h2&gt;

&lt;p&gt;Many natural phenomena naturally lead to differential equations. A differential equation is an equation in which the rate of the change of a variable ($\frac{d}{dt} x$) is a function its state $x$. The unknown is a function satisfying both the differential equation and an initial value. For instance, a simple model of the spread of the Covid-19 can be written as a system of differential equations (see for instance the &lt;a href=&#34;https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology&#34; target=&#34;_blank&#34;&gt;SIR model&lt;/a&gt;):&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \boldsymbol{x} = f(\boldsymbol{x},t) $$&lt;/p&gt;

&lt;p&gt;The LQR theory studies a special case of the above problem. It focuses on problems where the function $f(\boldsymbol{x},t)$ is linear:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \boldsymbol{x} = A  \boldsymbol{x} $$&lt;/p&gt;

&lt;p&gt;The equation above is a &amp;ldquo;passive&amp;rdquo; one. We simply observe the trajectory of $\boldsymbol{x}$ and there is nothing we can do about it. The LQR framework is based on the idea that an observer may want to change the trajectory of the system by exerting a control on $\boldsymbol{x}$. In the case of the spread of the Covid-19, the government may want to limit the number of new cases. When considering the economy, a central bank may want to control the interest rate to reach its inflation target. In the case of the SpaceX, the engineers may want to stabilize the rocket so that it does not explode when trying to land back on Earth.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;spaceX.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In the LQR framework, the controller wants to stabilize the system to reach one of its steady-state values, defined by:&lt;/p&gt;

&lt;p&gt;$$ \boldsymbol{x_{ss}} = A \boldsymbol{x_{ss}} $$&lt;/p&gt;

&lt;p&gt;We need to take into consideration the impact that the controller has on the system. Let us add the control, denoted by $u$, to the uncontrolled system from above:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \boldsymbol{x} = A  \boldsymbol{x} + B  \boldsymbol{u} $$&lt;/p&gt;

&lt;p&gt;where $B$ is a matrix capturing the idea that the controller could only control some elements of $\boldsymbol{x}$.&lt;/p&gt;

&lt;p&gt;However, there is no free lunch. In order to stabilize the system, the controller needs to pay a cost. Going back to our rocket example, some fuel is burnt in order to stabilize the trajectory of the rocket. The LQR is based on a cost function that is quadratic. This quadratic assumption simplifies the algebra substantially and captures the intuitive idea that doubling the effort actually costs four times more, not two times more.&lt;/p&gt;

&lt;p&gt;Let us assume that the steady state of the system is $\boldsymbol{0}$. This is without loss of generality, because we can rewrite the system as a deviation from its steady-state value $\boldsymbol{\tilde{x}} \equiv \boldsymbol{x} - \boldsymbol{x_{ss}}$, in which case the steady-state is reached for  $\boldsymbol{\tilde{x}} = \boldsymbol{0}$.&lt;/p&gt;

&lt;p&gt;To capture the cost of stabilizing the system, let us use the letter $J$. $J$ captures two types of cost. Firstly, the controller dislikes when the system is not at its steady-state. In the equation below, this type of cost is captured by the matrix $Q$. Secondly, the controller dislikes spending energy to control the system. This second type of cost is captured by the matrix $R$:&lt;/p&gt;

&lt;p&gt;$$ J = \int_{0}^{\infty} \boldsymbol{x&amp;rsquo;}(t) Q \boldsymbol{x}(t) + \boldsymbol{u&amp;rsquo;}(t) R \boldsymbol{u}(t) dt $$&lt;/p&gt;

&lt;p&gt;A beautiful result from the LQR theory is that the optimal control from the controller is simply a linear function of the current state of the system:&lt;/p&gt;

&lt;p&gt;$$ \boldsymbol{u} = - C \boldsymbol{x}$$&lt;/p&gt;

&lt;p&gt;When the system is controlled optimally, the equation governing the evolution of the system writes:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \boldsymbol{x} = A \boldsymbol{x} - B  C \boldsymbol{x} $$&lt;/p&gt;

&lt;h2 id=&#34;ii-simulating-forward-an-ordinary-differential-equation-in-python&#34;&gt;II. Simulating forward an ordinary differential equation in Python&lt;/h2&gt;

&lt;p&gt;Having summarized what the LQR framework is, we can now give an illustration of how it works using a simple example using Python. For what follows, you will need the following packages:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
import matplotlib.pyplot as plt
plt.style.use(&#39;ggplot&#39;)
%matplotlib inline
import numpy as np
from control.matlab import *  # MATLAB-like functions
#to solve ODE
from scipy import integrate
#show the version of Python I am using:
!python3 --version
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Python 3.5.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s study optimal control for the following differential equation:&lt;/p&gt;

&lt;p&gt;$$\begin{cases} \frac{d}{dt} x =\mu x \\ \frac{d}{dt} y = \lambda (y - x^2) \end{cases}$$&lt;/p&gt;

&lt;p&gt;Two observations on this dynamical system. Firstly, the system is not linear, but we will see how to deal with that in a minute. Secondly, by eyeballing the equation, it is easy to see that when $\mu &amp;lt; 1$ and $\lambda &amp;lt; 1$, the unique fixed point is&lt;/p&gt;

&lt;p&gt;$$ \begin{pmatrix} x_{SS} \\ y_{SS} \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix} $$&lt;/p&gt;

&lt;p&gt;We can convince ourselves by simulating forward the trajectory of the system using different starting values.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s notice that the system can be written as a linear one, plus a part that is nonlinear:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} \mu &amp;amp; 0 \\ 0 &amp;amp; \lambda \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} +  \begin{pmatrix} O \\ -  \lambda x^2 \end{pmatrix} $$&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \begin{pmatrix} x \\ y \end{pmatrix} = A \begin{pmatrix} x \\ y \end{pmatrix} +  \begin{pmatrix} O \\ -  \lambda x^2 \end{pmatrix}$$&lt;/p&gt;

&lt;p&gt;The following block of code defines the parameter values, the matrix A for the linear part of the differential equation and the matrix B specifying that the controller can only act on x. We also specify the time span during which we want to simulate forward the trajectories:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Parameters and matrices A and B:
mu = -0.05
llambda = -1.0
A = np.array([[mu, 0], [0, llambda]])
B = np.array([[0], [1]])
# Time span
t0, t1 = 0, 100 # start and end
t = np.arange(t0, t1, 0.01)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A clean way to simulate forward the trajectory is to define a function that return the evolution of the system:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Function that defines the dynamic system:
def vdp0(t, y):
    # linear part + nonlinear part:
    x = A.dot(y) + np.array([0, -llambda*(y[0]**2)])
    return x
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We then define 4 different starting values and simulate forward the system using the &lt;code&gt;scipy.integrate&lt;/code&gt; toolkit:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Set of starting values:
y0A = np.array([1.5, -1])
y0B = np.array([-1.5, -1])
y0C = np.array([5, 5])
y0D = np.array([-5, 5])

# To store the different trajectories
list_y = []

# Method for the ODE:
# This is an explicit runge-kutta method of order (4)5 due to Dormand &amp;amp; Prince
integrator = &amp;quot;dopri5&amp;quot;

# Loop over the different starting values and calculate trajectories:
for y0 in [y0A, y0B, y0C,y0D]:
    # initialize an array to store the solution
    y = np.zeros((len(t), len(y0)))   # array for solution
    r0 = integrate.ode(vdp0).set_integrator(integrator)
    r0.set_initial_value(y0, t0)   # initial values
    for i in range(1, t.size):
       y[i, :] = r0.integrate(t[i]) # get one more value, add it to the array
       if not r0.successful():
           raise RuntimeError(&amp;quot;Could not integrate&amp;quot;)
    # append the list of solution
    list_y.append(y)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then plot the trajectories we just calculated on a same graph using &lt;code&gt;matplotlib&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Plot the different paths:
fig, ax = plt.subplots(figsize=(10, 5))

for index,y0 in enumerate([y0A, y0B, y0C, y0D]):
    ax.plot(list_y[index][1:-1, 0], list_y[index][1:-1, 1], label = str(y0))
    plt.xlabel(&amp;quot;x&amp;quot;)
    plt.ylabel(&amp;quot;y&amp;quot;)
plt.title(&amp;quot;Trajectories for different starting values&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartI_20_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;From the graph, we see that $y$ moves very quickly to the parabola defined by $y = x^2$. Then, the system slowly converges
towards $(0,0)$, moving along the same parabola.&lt;/p&gt;

&lt;p&gt;Before moving to the optimal control of the system, let us calculate the total cost $J$ of letting the system
converging naturally to its steady state value:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Store the cost associated with each starting value:
list_cost = []
for y in list_y:
    JLQR = np.cumsum( np.square(y[:, 0]) + np.square(y[:, 1]) )
    # append the list of solution
    list_cost.append(JLQR)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next plot shows the cumulative cost as time passes. The further away the starting value is from the steady-state, the higher the cost. We also see that because the cost function treats negative and positive deviations from the steady state the same way (because deviations are squared), the cost for the starting values (1.5, -1) and (-1.5, -1) are the same. The same observation holds for (5, 5) and (-5, 5).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Plot the cost associated with each starting value:
fig, ax = plt.subplots(figsize=(10, 5))
for JLQR, y0 in zip(list_cost,[y0A, y0B, y0C, y0D]):
    plt.plot(t, JLQR, label = str(y0))
    plt.xlabel(&amp;quot;t&amp;quot;)
    plt.ylabel(&amp;quot;JLQR&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartI_25_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;iii-solving-for-the-optimal-control&#34;&gt;III. Solving for the optimal control&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s first define the matrices Q and R, before solving for the optimal control matrix $C$ using the &lt;code&gt;lqr&lt;/code&gt; function from the &lt;a href=&#34;https://python-control.readthedocs.io/en/0.8.3/&#34; target=&#34;_blank&#34;&gt;Python Control Systems Library&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;R = np.array([1])
Q = np.eye(2)
# Solve for C:
(C, X, E) = lqr(A, B, Q, R)
print(&amp;quot;Feedback matrix C : {}&amp;quot;.format(C))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Feedback matrix C : [[0.         0.41421356]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now proceed as previously to simulate forward the differential equation. The only difference is that
now we have to take into account the optimal control applied each period on the system. The optimal control is
taken into consideration in the function &lt;code&gt;vdp1(t, y)&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def vdp1(t, y):
    # Ay - B*X*y + Cy
    x = A.dot(y)  - np.matmul(B,C).dot(y)
    return x + np.array([0, -llambda*(y[0]**2)])

y0 = [-5, 5]                   # initial value
y = np.zeros((len(t), len(y0))) # array for solution
y[0, :] = y0

r = integrate.ode(vdp1).set_integrator(integrator)
r.set_initial_value(y0, t0)   # initial values

for i in range(1, t.size):
   y[i, :] = r.integrate(t[i]) # get one more value, add it to the array
   if not r.successful():
       raise RuntimeError(&amp;quot;Could not integrate&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now compare the controlled trajectory (in red) to the uncontrolled trajectory (in blue):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig, ax = plt.subplots(figsize=(10, 5))
plt.plot(y[:, 0], y[:, 1], label = &amp;quot;controlled&amp;quot;)
plt.plot(list_y[index][1:-1, 0], list_y[index][1:-1, 1], label = &amp;quot;uncontrolled&amp;quot;)
plt.xlabel(&amp;quot;x&amp;quot;)
plt.ylabel(&amp;quot;y&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartI_32_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;With the controlled trajectory, the deviation of $y$ from its steady state value is less extreme. The system converges to $(0,0)$ on a different parabola. As expected, controlling the system with the optimal controller is less costly than letting the system evolve uncontrolled:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;JLQR = np.cumsum( np.square(y[:, 0]) + np.square(y[:, 1]) + np.square(np.matmul(C, y.T)) ).T

fig, ax = plt.subplots(figsize=(10, 5))
plt.plot(t, JLQR, label = &amp;quot;controlled&amp;quot;)
plt.plot(t, list_cost[3], label = &amp;quot;uncontrolled&amp;quot;)
plt.xlabel(&amp;quot;t&amp;quot;)
plt.ylabel(&amp;quot;JLQR&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartI_34_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;iv-what-about-lambda-x-2-linearizing-the-nonlinear-system&#34;&gt;IV. What about $-\lambda x^2$? Linearizing the nonlinear system&lt;/h2&gt;

&lt;p&gt;$$ \frac{d}{dt} \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} \mu &amp;amp; 0 \\ 0 &amp;amp; \lambda \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} +  \begin{pmatrix} O \\ -  \lambda x^2 \end{pmatrix} $$&lt;/p&gt;

&lt;p&gt;A careful reader would have noticed that we used a linear controller on a non-linear system. Is it legitimate? Intuitively, we ignored the term $-\lambda x^2$, which is small when $x &amp;lt; 1$ and/or when $\lambda$ is small. We can show more &amp;ldquo;rigorously&amp;rdquo; that what we did makes sense.&lt;/p&gt;

&lt;p&gt;Let us remember that the dynamical system is:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \begin{pmatrix} x \\ y \end{pmatrix} = f \Big(  \begin{pmatrix} x \\ y \end{pmatrix}, t \Big) $$&lt;/p&gt;

&lt;p&gt;Or more precisely:&lt;/p&gt;

&lt;p&gt;$$ \begin{cases} \frac{d}{dt} x = \mu x \\ \frac{d}{dt} y = \lambda (y - x^2)  \end{cases} $$&lt;/p&gt;

&lt;p&gt;A first order Taylor expansion around the steady-state gives us:&lt;/p&gt;

&lt;p&gt;$$ \boldsymbol{x} - \boldsymbol{x_{ss}} \approx A (\boldsymbol{x} - \boldsymbol{x_{ss}}) $$&lt;/p&gt;

&lt;p&gt;Where $A$ is the Jacobian matrix (matrix of first derivatives) evaluated at the steady-state value, which is (0,0) in our simple example. The first derivatives are:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dx}(\frac{d}{dt}x) = \mu  \\ \frac{d}{dy}(\frac{d}{dt}x) = 0 \\ \frac{d}{dx}(\frac{d}{dt}y) = \lambda \\ \frac{d}{dy}(\frac{d}{dt}y)= -2 \lambda x $$&lt;/p&gt;

&lt;p&gt;Evaluated at the steady-state, the matrix A is equal to:&lt;/p&gt;

&lt;p&gt;$$ A = \begin{pmatrix} \mu &amp;amp; 0 \\ -2 \lambda \times 0 &amp;amp; \lambda \end{pmatrix} = \begin{pmatrix} \mu &amp;amp; 0 \\ 0 &amp;amp; \lambda \end{pmatrix} $$&lt;/p&gt;

&lt;p&gt;and because the steady-state is $(0,0)$, we have $\tilde{x} = x$. The take-away is that in the neighborhood of the steady-state $(0,0)$, we can solve the LQR ignoring the $-\lambda x^2$ term.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This notebook introduced what the LQR framework and showed how to solve for the optimal control in Python. We saw that despite the fact that the example we studied is not linear, we can linearize the dynamical system around its stead-state. In the Part II of this series on the LQR framework, we will see that we can do even better by solving the dynamical system in a new space, in which the system is exactly linear.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;The linear system studied in this notebook is based on the paper: Brunton, Steven L., et al. &amp;ldquo;Koopman invariant subspaces and finite linear representations of nonlinear dynamical systems for control.&amp;rdquo; PloS one 11.2 (2016).&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
