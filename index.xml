<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Julien Pascal on Julien Pascal</title>
    <link>https://julienpascal.github.io/</link>
    <description>Recent content in Julien Pascal on Julien Pascal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Julien Pascal</copyright>
    <lastBuildDate>Mon, 18 Jan 2021 18:53:22 +0100</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Young&#39;s method (2010) to simulate a cross-section</title>
      <link>https://julienpascal.github.io/post/young_2010/</link>
      <pubDate>Mon, 18 Jan 2021 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/young_2010/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Solving economic models involves (i) finding the &lt;strong&gt;optimal response of individuals&lt;/strong&gt; given the state of the economy (the policy functions); (ii) given the policy functions, &lt;strong&gt;simulating the model&lt;/strong&gt;. While usually one must show great ingenuity and creativity for the former, the latter is often seen as trivial and not even mentioned. However, in this notebook I describe a simulation procedure that deserves to be advertised. Namely, I describe &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v34y2010i1p36-41.html&#34; target=&#34;_blank&#34;&gt;Young&amp;rsquo;s method (2010)&lt;/a&gt; to simulate a large number (infinity) of individuals. The code can be downloaded &lt;a href=&#34;https://github.com/JulienPascal/Simulate_Cross-section&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;why-should-we-care&#34;&gt;Why should we care?&lt;/h2&gt;

&lt;p&gt;In economies with heterogeneous agents, often there is no such thing as a &lt;a href=&#34;https://en.wikipedia.org/wiki/Representative_agent#:~:text=Economists%20use%20the%20term%20representative,the%20same%20type%20are%20identical.&#34; target=&#34;_blank&#34;&gt;representative agent&lt;/a&gt;. Generally, one must follow a large number of individuals. For instance, one may be interested in knowing how the average wage responds to an increase in labor productivity. If workers are different (in terms of skills, experience, firms in which they work, etc.), one must take into consideration changes in individuals&amp;rsquo; wages to determine how the average wage moves.&lt;/p&gt;

&lt;h2 id=&#34;the-method&#34;&gt;The method&lt;/h2&gt;

&lt;p&gt;The method avoids simulating a panel of agents. Instead, the idea is to simulate directly the distribution.
In practice, one chooses a grid $[w_1, w_2, &amp;hellip;, w_N]$&lt;/p&gt;

&lt;p&gt;If a measure $m$ of workers choose to consume $w$, with $w \in [w_{n}, w_{n+1}]$, then the mass assigned to the grid point $w_{n}$ is equal to $m \times p$ and the mass assigned to the grid point $w_{n+1}$ is $m \times (1 - p)$ with&lt;/p&gt;

&lt;p&gt;$$ p = 1 - \frac{w - w_{n}}{w_{n+1} - w_{n}} $$&lt;/p&gt;

&lt;p&gt;If $w$ is very close to $w_{n}$, then most of the mass $m$ will be assigned to this point. In the limit case, if $w$ is equal to $w_{n}$, $100$ percent of the mass is assigned to $w_{n}$.&lt;/p&gt;

&lt;p&gt;Simple, right? The code below is an implementation of &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v34y2010i1p36-41.html&#34; target=&#34;_blank&#34;&gt;Young&amp;rsquo;s method (2010)&lt;/a&gt; using &lt;a href=&#34;https://julialang.org/&#34; target=&#34;_blank&#34;&gt;Julia&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;implementation&#34;&gt;Implementation&lt;/h2&gt;

&lt;h3 id=&#34;preliminaries&#34;&gt;Preliminaries&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s first start by loading a few packages and declaring auxiliaries functions. In particular, given a value $w$ we need a function that returns the closest value $w_k$, where $w_k$ is picked from given grid $w_1, w_2, &amp;hellip;, w_N$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Plots
using Distributions
using StatsBase

# Matlab like function
function linspace(z_start::Real, z_end::Real, z_n::Int64)
    return collect(range(z_start,stop=z_end,length=z_n))
end

# Not my function. Credit to: https://discourse.julialang.org/t/findnearest-function/4143/4
function closest_index(a::Vector,x::Real)

    if isempty(a) == true
      error(&amp;quot;xGrid is empty in function closest_index.&amp;quot;)
    end

    if isnan(x) == true
      error(&amp;quot;val is NaN in function closest_index.&amp;quot;)
    end

   idx = searchsortedfirst(a,x)
   if (idx==1); return idx; end
   if (idx&amp;gt;length(a)); return length(a); end
   if (a[idx]==x); return idx; end
   if (abs(a[idx]-x) &amp;lt; abs(a[idx-1]-x))
      return idx
   else
      return idx-1
   end
end

# Returns best index and best value
function closest_value_and_index(xGrid::Vector, val::Real)

    # get index
    ibest = closest_index(xGrid, val)

    # Return best value on grid, and the corresponding index
    return xGrid[ibest], ibest

end

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;approximate-a-distribution-with-a-single-mass-point&#34;&gt;Approximate a distribution with a single mass point&lt;/h3&gt;

&lt;p&gt;To warm up, let&amp;rsquo;s see how the method works when the true underlying distribution is constituted of &lt;strong&gt;a single mass point&lt;/strong&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;## True Value
w = 2.5    #True value
mass = 1.0 #Mass at the true value

## Approximation
nW=10 #Number of grid points
w_grid=linspace(0.0, 4.0, nW) #Location of grid points
hw_grid=zeros(nW); #Initialization

w_min = minimum(w_grid) #Upper bound for the grid
w_max = maximum(w_grid) #Lower bound for the grid
nW = length(w_grid) #Number of points on the grid

# Project true value on the grid:
(wValue_proj, wIndex_proj) = closest_value_and_index(w_grid, w)

# To store the location of the value below and above the true value:
wIndex_below = 0
wIndex_above = 0

# If the true value is above the projection
if w &amp;gt;= wValue_proj
    wIndex_below = wIndex_proj
    wIndex_above = wIndex_proj + 1
# If the true value is below the projection
elseif w &amp;lt; wValue_proj
    wIndex_below = wIndex_proj -1
    wIndex_above = wIndex_proj
end

# Boundary cases
if wIndex_proj == 1
    wIndex_below = 1
    wIndex_above = 2
elseif wIndex_proj == nW
    wIndex_below = nW - 1
    wIndex_above = nW
end

# Special case 1: w &amp;lt; w_min
if w &amp;lt;= w_min
    p = 1
elseif w &amp;gt;= w_max
# Special case 2: w &amp;gt; w_max
    p = 0
else
    p = 1.0 - ((w - w_grid[wIndex_below])/(w_grid[wIndex_above] - w_grid[wIndex_below]))
    p = min(1.0, max(0.0, p))
end

# Spread the mass:
# 1. Point below
hw_grid[wIndex_below] += p*mass

# 2. Point above:
hw_grid[wIndex_above] += (1.0 - p)*mass;

p0 =bar(w_grid, hw_grid, label = &amp;quot;Mass on grid&amp;quot;)
plot!(p0, [w], seriestype = :vline, label=&amp;quot;True value&amp;quot;, linewidth = 4)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Young_2010_12_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the true distribution (in orange) and the approximation (in blue).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Because the true value is not a point of our grid (that would be a miracle), the mass is spread between the two closest points. However, we still get the mean right. We will see below that this property extends to distributions with supports constituted of several points:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;println(&amp;quot;True mean $(w)&amp;quot;)
println(&amp;quot;Approximate mean $(round(mean(w_grid, weights(hw_grid./sum(hw_grid))), digits = 4))&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True mean 2.5
Approximate mean 2.5
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;approximate-a-multi-point-distribution&#34;&gt;Approximate a multi-point distribution&lt;/h3&gt;

&lt;p&gt;Now, let&amp;rsquo;s see how well &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v34y2010i1p36-41.html&#34; target=&#34;_blank&#34;&gt;Young&amp;rsquo;s method (2010)&lt;/a&gt; works when the true underlying distribution has positive mass for &lt;strong&gt;a finite number of points&lt;/strong&gt;. To keep things pretty, let&amp;rsquo;s assume that the true distribution has the shape of a Normal distribution, but we truncate the tails.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;Nw_true = 10 #Number of points with positive mass
w_true_lb = 1.0 #lower bound
w_true_ub = 3.0 #upper bound
w_true = linspace(w_true_lb, w_true_ub, Nw_true)
d = truncated(Normal((w_true_lb + w_true_ub)/2), w_true_lb, w_true_ub)
mass_true = pdf.(d, w_true)
mass_true = mass_true./sum(mass_true);
p0 = bar(w_true, mass_true, label=&amp;quot;Mass true value&amp;quot;)
display(p0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Young_2010_17_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the mass for each point on the (true) grid.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;w_min = minimum(w_grid)
w_max = maximum(w_grid)
nW = length(w_grid)

hw_grid=zeros(nW);


for (wIndexTrue, w) in enumerate(w_true)

    mass = mass_true[wIndexTrue] #mass

    # Project true value on the grid:
    (wValue_proj, wIndex_proj) = closest_value_and_index(w_grid, w)

    # To store the location of the value below and above the true value:
    wIndex_below = 0
    wIndex_above = 0

    # If the true value is above the projection
    if w &amp;gt;= wValue_proj
        wIndex_below = wIndex_proj
        wIndex_above = wIndex_proj + 1
    # If the true value is below the projection
    elseif w &amp;lt; wValue_proj
        wIndex_below = wIndex_proj -1
        wIndex_above = wIndex_proj
    end

    # Boundary cases
    if wIndex_proj == 1
        wIndex_below = 1
        wIndex_above = 2
    elseif wIndex_proj == nW
        wIndex_below = nW - 1
        wIndex_above = nW
    end

    # Special case 1: w &amp;lt; w_min
    if w &amp;lt;= w_min
        p = 1
    elseif w &amp;gt;= w_max
    # Special case 2: w &amp;gt; w_max
        p = 0
    else
        p = 1.0 - ((w - w_grid[wIndex_below])/(w_grid[wIndex_above] - w_grid[wIndex_below]))
        p = min(1.0, max(0.0, p))
    end

    p = 1.0 - ((w - w_grid[wIndex_below])/(w_grid[wIndex_above] - w_grid[wIndex_below]))
    p = min(1.0, max(0.0, p))

    # Spread the mass:
    # 1. Point below
    hw_grid[wIndex_below] += p*mass

    # 2. Point above:
    hw_grid[wIndex_above] += (1.0 - p)*mass

end

bar(w_grid, hw_grid, label=&amp;quot;Mass on grid&amp;quot;)
bar!(w_true, mass_true, label=&amp;quot;Mass true value&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Young_2010_18_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the true distribution (in orange) and the approximation (in blue).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;A good property of &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v34y2010i1p36-41.html&#34; target=&#34;_blank&#34;&gt;Young&amp;rsquo;s method (2010)&lt;/a&gt; is that, &lt;strong&gt;as long as the grid is wide enough&lt;/strong&gt; to so that true values fall within it, &lt;strong&gt;the mean of the true underlying distribution is preserved&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;println(&amp;quot;True mean $(round(mean(w_true, weights(mass_true./sum(mass_true))), digits = 4))&amp;quot;)
println(&amp;quot;Approximate mean $(round(mean(w_grid, weights(hw_grid./sum(hw_grid))), digits = 4))&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True mean 2.0
Approximate mean 2.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, there are some &lt;strong&gt;approximation errors&lt;/strong&gt; when &lt;strong&gt;higher moments&lt;/strong&gt; are involved such as the variance, or when calculating &lt;strong&gt;percentiles&lt;/strong&gt;. But the finest the grid, the better the approximation gets.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;println(&amp;quot;True median $(round(quantile(w_true, weights(mass_true./sum(mass_true)), 0.5), digits = 4))&amp;quot;)
println(&amp;quot;Approximate median $(round(quantile(w_grid, weights(hw_grid./sum(hw_grid)), 0.5), digits = 4))&amp;quot;)

println(&amp;quot;True variance $(round(var(w_true, weights(mass_true./sum(mass_true))), digits = 4))&amp;quot;)
println(&amp;quot;Approximate variance $(round(var(w_grid, weights(hw_grid./sum(hw_grid))), digits = 4))&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True median 1.9567
Approximate median 1.8519
True variance 0.3465
Approximate variance 0.3836
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;using-a-panel-of-agents&#34;&gt;Using a panel of agents&lt;/h3&gt;

&lt;p&gt;Alternatively, one may use a large number of agents to approximate the true underlying distribution. The idea is that if the number of agents is large enough, the &lt;a href=&#34;https://en.wikipedia.org/wiki/Central_limit_theorem&#34; target=&#34;_blank&#34;&gt;central limit theorem&lt;/a&gt; will kick in. The issue is that we need a large number of agents to get the approximation right, as illustrated below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;nb_agents = 1000
w_agents = rand(d, nb_agents);

println(&amp;quot;True mean $(round(mean(w_true, weights(mass_true./sum(mass_true))), digits = 4))&amp;quot;)
println(&amp;quot;Approximate mean $(round(mean(w_agents), digits = 4))&amp;quot;)

println(&amp;quot;True median $(round(quantile(w_true, weights(mass_true./sum(mass_true)), 0.5), digits = 4))&amp;quot;)
println(&amp;quot;Approximate median $(round(quantile(w_agents, 0.5), digits = 4))&amp;quot;)

println(&amp;quot;True variance $(round(var(w_true, weights(mass_true./sum(mass_true))), digits = 4))&amp;quot;)
println(&amp;quot;Approximate variance $(round(var(w_agents), digits = 4))&amp;quot;)

p0 = bar(w_true, mass_true, label=&amp;quot;Mass true value&amp;quot;)
p1 = histogram(w_agents, label=&amp;quot;Mass panel&amp;quot;)
plot(p0,p1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True mean 2.0
Approximate mean 1.9955
True median 1.9567
Approximate median 1.9971
True variance 0.3465
Approximate variance 0.2754
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Young_2010_25_1.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the true distribution (on the left) and the approximation (on the right).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;With 1000 agents, the approximation is not exceptional. Let&amp;rsquo;s try to increase the number of agents. The following plot shows that the approximation gets better as we increase the number of agents, but a very
large number of agents is needed:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;w_agents = []
grid_agents = collect(1000:1000:100000)
mean_agents = zeros(length(grid_agents))
std_agents = zeros(length(grid_agents))

for (i, nb_agents) in enumerate(grid_agents)
    push!(w_agents, rand(d, nb_agents))
    mean_agents[i] = mean(w_agents[i])
    std_agents[i] = std(w_agents[i])
end

CI = 1.960.*std_agents./sqrt.(grid_agents); #95% confidence interval. t-test is approximately a z-test because large number of agents.
p0 = plot(grid_agents, mean_agents, ribbon = CI, label = &amp;quot;approximate mean&amp;quot;)
plot!(p0,[mean(w_true, weights(mass_true./sum(mass_true)))], linetype = :hline, label = &amp;quot;true mean&amp;quot;, linestyle = :dash)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Young_2010_27_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the empirical mean calculated using the panel and the true value, for different sizes of the panel.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;When possible, simulating directly a distribution instead of using a panel is a good idea. &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v34y2010i1p36-41.html&#34; target=&#34;_blank&#34;&gt;Young&amp;rsquo;s method (2010)&lt;/a&gt;
allows to do that, while preserving the mean of the true distribution.&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Young, Eric R. &amp;ldquo;Solving the incomplete markets model with aggregate uncertainty using the Krusell‚ÄìSmith algorithm and non-stochastic simulations.&amp;rdquo; Journal of Economic Dynamics and Control 34.1 (2010): 36-41.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Aiyagari Model with Aggregate Uncertainty</title>
      <link>https://julienpascal.github.io/post/aiyagariaggregateuncertainty/</link>
      <pubDate>Tue, 19 May 2020 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/aiyagariaggregateuncertainty/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The Bewley-Huggett-Aiyagari-Imohoroƒülu economies are the workhorse of modern macroeconomics. In these economies, markets are &amp;ldquo;incomplete&amp;rdquo;. Agents cannot fully insure against risk and decide to self-insure by holding a safe asset to smooth their consumption (see &lt;a href=&#34;https://mitpress.mit.edu/books/recursive-macroeconomic-theory-fourth-edition&#34; target=&#34;_blank&#34;&gt;Ljungqvist and Sargent (2018)&lt;/a&gt; for a textbook treatment of this topic).&lt;/p&gt;

&lt;p&gt;In this post, I consider the model of Aiyagari (1994). While the original model abstracts from aggregate fluctuations, Economists have since developed several techniques to simulate out-of-steady-state dynamics for this class of models.&lt;/p&gt;

&lt;p&gt;Here, I use a methodology that is quite general. It is a &lt;strong&gt;3-step procedure&lt;/strong&gt;, which proceeds as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Solve for the non-stochastic steady-state&lt;/li&gt;
&lt;li&gt;Perturbe the model around its non-stochastic steady-state&lt;/li&gt;
&lt;li&gt;Use the perturbation to calculate out-of-steady-state dynamics&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I use the &lt;a href=&#34;https://julienpascal.github.io/post/genbkm/&#34; target=&#34;_blank&#34;&gt;BKM and GenBKM&lt;/a&gt; algorithms for step 2 and 3, which means that the only theoretical tool needed is &lt;strong&gt;backward induction&lt;/strong&gt; (i.e. knowing the value tomorrow, what is the value today?).&lt;/p&gt;

&lt;p&gt;What are the cons of the methodology presented here? First, the methodology assumes a &lt;strong&gt;small aggregate shock&lt;/strong&gt;. An implicit assumption is that aggregate shocks do not modify the value of the non-stochastic steady-state. Said differently, the cycle does not change the trend, &lt;a href=&#34;https://www.youtube.com/watch?v=K2X1GiTaxHw&#34; target=&#34;_blank&#34;&gt;which seems to be violated in some instances&lt;/a&gt;. If the shock is large, the value of steady-state may be altered and the methodology presented here is not adequate. An example of a large shock could be the disruption caused by COVID-19.&lt;/p&gt;

&lt;p&gt;This methodology also fails when the non-stochastic steady-state is not relevant for the dynamic economy. This can problematic in portfolio choice problems, in which portfolios are indeterminate when aggregate uncertainty vanishes (see &lt;a href=&#34;https://hal-sciencespo.archives-ouvertes.fr/hal-00972801/document&#34; target=&#34;_blank&#34;&gt;Coeurdacier et al (2011)&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;On the pro side, the methodology presented here is fast (orders of magnitude faster than &lt;a href=&#34;https://notes.quantecon.org/submission/5bb58d1e11611400157fdc8d&#34; target=&#34;_blank&#34;&gt;Krusell-Smith (1998)&lt;/a&gt;) and transparent. The code can be &lt;a href=&#34;https://github.com/JulienPascal/AiyagariAggregateUncertainty&#34; target=&#34;_blank&#34;&gt;downloaded here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;i-the-model&#34;&gt;I. The Model&lt;/h2&gt;

&lt;p&gt;In the model of Aiyagari (1994), there is continuum of agents each maximizing an infinite flow of discounted utility:&lt;/p&gt;

&lt;p&gt;$$ E_{0} \sum_{t=0}^{\infty} \beta^t U(c_t) $$&lt;/p&gt;

&lt;p&gt;subject to the constraint that consumption plus savings in period $t$ (the left hand side of the next equation) is equal to labor earnings plus savings inherited from the last period (the right hand side of the next equation):&lt;/p&gt;

&lt;p&gt;$$ c_t + a_{t+1} = w_t l_t + (1 + r_t) a_t $$&lt;/p&gt;

&lt;p&gt;The variable $l_t$ captures idiosyncratic risk in labor earnings and could be interpreted as unemployment risk. We also make the assumptions that consumption cannot be negative and that agents cannot borrow more than a certain amount $B$:&lt;/p&gt;

&lt;p&gt;$$ c_t \geq 0 $$&lt;/p&gt;

&lt;p&gt;$$ a_t \geq -B $$&lt;/p&gt;

&lt;p&gt;The behavior of firms can be summarized by a representative firm hiring workers and capital:&lt;/p&gt;

&lt;p&gt;$$ Y_t = z_t K_t^{\alpha} L_t^{1-\alpha} $$&lt;/p&gt;

&lt;p&gt;where $Y_t$ is total output, $K_t$ is the aggregate capital level and $L_t$ is the aggregate labor supply. The variables $w_t$ and $r_t$ are pinned down each period by the first order conditions (FOCs) of the representative firm. Note that at the non-stochastic steady-state $z_t = z_{SS} = 1$ (by definition) and both $w_t$ and $r_t$ are constant. Importantly, because agents have to take into consideration the value of $w_t$ and $r_t$ when making decisions, the cross-sectional distribution of agents across capital and idiosyncratic states matters (through the FOCs of the representative firm).&lt;/p&gt;

&lt;h2 id=&#34;ii-methodology&#34;&gt;II. Methodology&lt;/h2&gt;

&lt;p&gt;To solve for individual policy functions, I use the endogenous grid method (EGM) of Carroll (2006). The main idea of this method is to start from the end-of-period level of capital. Using the Euler equation, one may recover the beginning-of-period consumption and level of capital without using a root-finding algorithm.&lt;/p&gt;

&lt;p&gt;To determine the non-stochastic equilibrium, I solve for the fixed-point problem over the aggregate capital level $f(K*) = 0$ using &lt;a href=&#34;https://en.wikipedia.org/wiki/Brent%27s_method&#34; target=&#34;_blank&#34;&gt;Brent&amp;rsquo;s method&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To calculate the response of the economy to one-period unforeseen aggregate shock (an &amp;ldquo;MIT shock&amp;rdquo;), I use a standard backward-forward &lt;a href=&#34;https://en.wikipedia.org/wiki/Shooting_method&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;shooting&amp;rdquo; method&lt;/a&gt;:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;holding constant the path of aggregate capital level $(K_t)_{t=1}^{T}$, calculate the policy functions&lt;/li&gt;
&lt;li&gt;holding constant the policy functions, calculate the path of aggregate capital level $(K_t)_{t=1}^{T}$&lt;/li&gt;
&lt;li&gt;repeat until convergence of the path for aggregate capital level $(K_t)_{t=1}^{T}$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To simulate out-of-steady-state dynamics, I use the &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v89y2018icp68-92.html&#34; target=&#34;_blank&#34;&gt;BKM algorithm&lt;/a&gt;, which relies on the assumption that the response of the economy to an aggregate shock $d_t$ is &lt;strong&gt;linear&lt;/strong&gt; with respect to the &lt;strong&gt;aggregate state&lt;/strong&gt; $z_t$:&lt;/p&gt;

&lt;p&gt;$$ d_t = z_t d(1, 0, 0, &amp;hellip;) + z_{t-1}d(0, 1, 0, &amp;hellip;) + z_{t-2}d(0, 0, 1, &amp;hellip;) + &amp;hellip; $$&lt;/p&gt;

&lt;p&gt;or more compactly:&lt;/p&gt;

&lt;p&gt;$$ d_t = \sum_{k=0}^{+\infty} z_{t-k} d_{k} $$&lt;/p&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;p&gt;$$ d_{1} = d(1,0,0,&amp;hellip;)$$
$$ d_{2} = d(0,1,0,&amp;hellip;)$$
$$ d_{3} = d(0,0,1,&amp;hellip;)$$&lt;/p&gt;

&lt;p&gt;That is, the evolution of equilibrium variables is a moving average of past shocks. However, by calculating several trajectories after an MIT shock, one sees that linearity assumption is slightly violated. Hence, I use the &lt;a href=&#34;https://irihs.ihs.ac.at/id/eprint/4500/&#34; target=&#34;_blank&#34;&gt;GenBKM algorithm&lt;/a&gt;, which is a refinement of the BKM algorithm taking into consideration these slight violations of linearity.&lt;/p&gt;

&lt;h2 id=&#34;iii-implementation&#34;&gt;III. Implementation&lt;/h2&gt;

&lt;p&gt;These ideas are implemented using &lt;a href=&#34;https://julialang.org/&#34; target=&#34;_blank&#34;&gt;Julia&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;versioninfo()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Julia Version 1.3.0
Commit 46ce4d7933 (2019-11-26 06:09 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ii-a-dependencies&#34;&gt;II. A Dependencies&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Distributions
using Plots
using DataFrames
using Random
using ForwardDiff
using LinearAlgebra
using Interpolations
using DataFrames
using Optim
Random.seed!(1234);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using NBInclude #To load stuct and functions from other notebooks
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@nbinclude(&amp;quot;utils.ipynb&amp;quot;) #mutable structs and primitive functions for the model
@nbinclude(&amp;quot;RBC.ipynb&amp;quot;)   #Aiyagari model, without the borrowing constraint (standard RBC)
@nbinclude(&amp;quot;EGM.ipynb&amp;quot;)   #implementation of the EGM method
@nbinclude(&amp;quot;SteadyState.ipynb&amp;quot;) #to calculate the non-stochastic steady-state
@nbinclude(&amp;quot;GenBKM.ipynb&amp;quot;) #to simulate the stochastic model using the GenBKM algorithm
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ii-b-steady-state&#34;&gt;II.B Steady-state&lt;/h3&gt;

&lt;h4 id=&#34;finding-the-steady-state-value-of-capital&#34;&gt;Finding the steady-state value of capital&lt;/h4&gt;

&lt;p&gt;Finding the non-stochastic equilibrium is a fixed-point problem over the aggregate capital level $f(K*) = 0$, which can be solved using &lt;a href=&#34;https://en.wikipedia.org/wiki/Brent%27s_method&#34; target=&#34;_blank&#34;&gt;Brent&amp;rsquo;s method&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p = Params() #struct with model parameters
z_ss = 1.0 #aggregate productivity at the non-stochastic steady-state
@time oo = optimize(K -&amp;gt; eq_K(K,p), 10, 100, Brent()) #solve for the steady-state value of capital using Brent method
K_star = oo.minimizer;
println(&amp;quot;Steady-state value of capital K* = $(K_star)&amp;quot;)
# Store the optimal policy function at the steady-state
g_star, c_star, g_low_star, g_high_star, success_flag= solve_EGM(x-&amp;gt;log(x), x-&amp;gt;log(x), R(K_star, z_ss, p), W(K_star, z_ss, p), p); #solve for policy functions
# Store the stationary distribution at the steady-state
t_star = make_trans_mat(g_star, p)    #generate transition matrix
d_star = get_stationary_dist(t_star); #stationary distribution
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;visualizing-transition-probabilities&#34;&gt;Visualizing transition probabilities&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;xs = [string(&amp;quot;x&amp;quot;, i) for i = 1:size(t_star,1)]
ys = [string(&amp;quot;y&amp;quot;, i) for i = 1:size(t_star,2)]
heatmap(t_star, aspect_ratio = 1, color=:plasma, clim=(0., 0.25))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_15_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the transition probabilities across capital and idiosyncratic probability states.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;visualizing-convergence-toward-the-steady-state&#34;&gt;Visualizing convergence toward the steady-state&lt;/h4&gt;

&lt;p&gt;One may visually check that the equilibrium exists and is unique:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Solve for the demand and supply of capital for different values of the interest rate
K_grid = collect(range(oo.minimizer-0.5, stop=oo.minimizer+0.5, length=20))
K_implied_grid = similar(K_grid)
R_grid = similar(K_grid)

for (K_index, K_value) in enumerate(K_grid)
    R_s, W_s = R(K_value, z_ss, p), W(K_value, z_ss, p) #calculate interest rate R and wage W
    gg, c_star, g_low, g_high, success_flag= solve_EGM(x -&amp;gt; log(x), x -&amp;gt; 2*log(x), R_s, W_s, p) #solve for policy functions
    tt = make_trans_mat(gg, p)   #generate transition matrix
    dd = get_stationary_dist(tt) #stationary distribution
    K_implied = aggregate_K(dd, p) #implied level of capital
    R_grid[K_index] = R_s #store interest rate
    K_implied_grid[K_index] = K_implied #store demand of capital
    K_grid[K_index] = K_value #store supply of capital
end

# Plot demand and supply of capital
plot(K_grid, R_grid, label = &amp;quot;Demand&amp;quot;, ylabel=&amp;quot;Interest rate&amp;quot;, xlabel=&amp;quot;Capital&amp;quot;)
plot!(K_implied_grid, R_grid, label = &amp;quot;Supply&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_18_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the demand and the supply of capital as a function of the interest rate.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;ii-c-mit-shock&#34;&gt;II.C MIT Shock&lt;/h3&gt;

&lt;h4 id=&#34;backward-and-forward-updates&#34;&gt;Backward and forward updates&lt;/h4&gt;

&lt;p&gt;The next block implements the backward-forward shooting method:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;holding the path of aggregate capital $(K_t)_{t=1}^{T}$, calculate the policy functions&lt;/li&gt;
&lt;li&gt;holding constant the policy functions, calculate the aggregate capital $(K_t)_{t=1}^{T}$&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function backward_update(g_low_ss::Function, g_high_ss::Function, K_path_guess::Array{Float64,1}, z_path::Array{Float64,1}, p::Params)
    &amp;quot;&amp;quot;&amp;quot;
    Update policy functions backward, holding {K_t,z_t} constant
    &amp;quot;&amp;quot;&amp;quot;
    nT = length(z_path)
    g_low_path = Array{Function}(undef,nT) #initialize two lists of functions
    g_high_path =  Array{Function}(undef,nT)
    g_low_path[nT] = g_low_ss
    g_high_path[nT] = g_high_ss
    a_path = zeros(p.nI, p.grid_size, nT) #to store policy functions on savings grid
    R_path = zeros(nT) #to store the interest rate on path
    W_path = zeros(nT) #to store the wage on path

    #Start from the steady-state and iterate backward
    #holding constant the path for {K_t,z_t}
    #---------------------------------------------------
    for t=nTüëé2 #iterate backward
        # Next period
        R_path[t], W_path[t] = R(K_path_guess[t], z_path[t], p), W(K_path_guess[t], z_path[t], p)
        # Current period
        R_path[t-1], W_path[t-1] = R(K_path_guess[t-1], z_path[t-1], p), W(K_path_guess[t-1], z_path[t-1], p)
        # Current period&#39;s policy, given next period
        a_path[:,:,t-1], c_new, g_low_path[t-1], g_high_path[t-1] = euler_back(g_low_path[t], g_high_path[t], R_path[t-1], W_path[t-1], R_path[t], W_path[t], p)
    end

    return a_path, g_low_path, g_high_path
end

function forward_update(K_star::Float64, a_path::Array{Float64,3}, d_ss::Array{Float64,1}, p::Params)
    &amp;quot;&amp;quot;&amp;quot;
    Update forward the distribution of agents + aggregate capital
    dd_path_forward, K_path_forward
    &amp;quot;&amp;quot;&amp;quot;
    nT = length(z_path)
    K_path_forward = zeros(nT)
    K_path_forward[1] = K_star
    dd_path_forward = zeros(size(d_ss,1), nT)
    dd_path_forward[:,1] = d_ss
    #2. Iterate forward {K_t,z_t}, using the policy
    #functions from step 1
    #-----------------------------------------------
    for t=2:nT
        tt = make_trans_mat(a_path[:,:,t-1], p) #generate transition matrix
        dd_path_forward[:,t] = tt*dd_path_forward[:,t-1]
        K_path_forward[t] = aggregate_K(dd_path_forward[:,t], p)
    end

    return dd_path_forward, K_path_forward
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;finding-the-transition-path&#34;&gt;Finding the transition path&lt;/h4&gt;

&lt;p&gt;One problem with the backward-forward shooting method is that updating the path for $(K_t)_{t=1}^{T}$ &amp;ldquo;too quickly&amp;rdquo; may result in the overall procedure to diverge. An easy fix is to take a convex combination of the previous guess and the newly calculated path, with $\lambda$ small:&lt;/p&gt;

&lt;p&gt;$(K^{NEW}_t)_{t=1}^{T} = \lambda (K_t)_{t=1}^{T} + (1-\lambda)(K^{OLD}_t)_{t=1}^{T}$&lt;/p&gt;

&lt;p&gt;The next function implements this idea, with the extra feature that $\lambda$ increases when the distance between two iterations is getting small (too speed up convergence) and decreases when the distance is getting bigger (to prevent divergence). See &lt;a href=&#34;https://notes.quantecon.org/submission/5b3faf1fb9eab00015b89f9a&#34; target=&#34;_blank&#34;&gt;this excellent notebook&lt;/a&gt; for the same idea applied to an OLG model.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function solve_mit!(K_path, g_low_ss::Function, g_high_ss::Function, d_ss::Array{Float64,1},
                    K_ss::Float64, z_path::Array{Float64,1}, p::Params; convex_combination::Float64 = 0.2,
                    shrink_factor::Float64 = 0.5, expand_factor::Float64 = 1.05,
                    max_iter::Int64 = 1000, tol::Float64=1e-6, verbose::Bool=true, display_iter::Int64 = 20)
    &amp;quot;&amp;quot;&amp;quot;
    Finds the path for aggregate capital K_path
    &amp;quot;&amp;quot;&amp;quot;
    diff = Inf #initialization
    diff_old = Inf #initialization
    convergence_flag = 0 #initialization
    damp = convex_combination #initial dampening parameter

    for i_mit=1:max_iter

        # Step 1. Solve backward the policy functions {g_t(a,e_low), g_t(a,e_high)}, keeping {K_t,z_t} constant:
        a_path, g_low_path, g_high_path = backward_update(g_low_ss, g_high_ss, K_path[i_mit], z_path, p);

        #2. Solve forward {K_t,z_t}, keeping policy functions {g_t(a,e_low), g_t(a,e_high)} constant:
        dd_path_forward, K_path_forward = forward_update(K_ss, a_path, d_star, p);

        # Distance between guess for {K_t} and implied values:
        diff = maximum(abs.(K_path_forward - K_path[i_mit]))

        # Display every display_iter iterations
        if verbose==true
            if mod(i_mit,display_iter) == 0
                println(&amp;quot;Iteration $(i_mit). diff = $(diff)&amp;quot;)
            end
        end

        if diff &amp;lt; tol
            if verbose==true
                println(&amp;quot;Convergence reached after $(i_mit) iterations.&amp;quot;)
            end
            convergence_flag = 1
            break
        else
            # Update the guess for the path {K_t}
            # Decrease the dampening factor
            if diff &amp;gt; diff_old
                damp = max(min(damp * shrink_factor, 1.0-eps()), eps())
            # Increase the dampening factor
            else
                damp = max(min(damp * expand_factor, 1.0-eps()), eps())
            end
            if mod(i_mit, 10) == 0
                if verbose==true
                    println(&amp;quot;damp = $(damp); diff = $(diff)&amp;quot;)
                end
            end
            # Store the updated path for {K_t}
            push!(K_path, damp.*K_path_forward .+ (1.0 - damp).*K_path[i_mit])
            diff_old = diff

        end
    end

    return K_path, convergence_flag
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;find-the-path-for-k-t-for-a-1-std-dev-positive-productivity-shock&#34;&gt;Find the path for {K_t} for a 1 std. dev positive productivity shock&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;max_t = 300 #Let us assume that the economy is back to the steady state after max_t periods
z_ss = 1.0  #Value of aggregate productivity at the non-stochastic steady-state
z_shock = 2.0 #Value of the inital shock

# Let&#39;s generate a path for the aggregate shock
z_path = ones(max_t)
z_path[1] = z_ss*z_shock #initial shock

# Evolution of aggregate productivity in level:
for t_index=2:max_t
    z_path[t_index] = z_path[t_index-1]^p.rho
end

# Heroic guess for the initial path of {K_t}: K_t = K* for all t
K_path = []
push!(K_path, repeat([K_star], max_t))

# Find the path for {K_t}:
@time K_path, convergence_flag = solve_mit!(K_path, g_low_star, g_high_star, d_star, K_star, z_path, p, convex_combination=0.25);

# Find the path for other aggregates:
R_path = zeros(length(z_path)) #to store the interest rate on path
W_path = zeros(length(z_path)) #to store the wage on path
for t=length(z_path)üëé1 #iterate backward
    # Next period
    R_path[t], W_path[t] = R(K_path[end][t], z_path[t], p), W(K_path[end][t], z_path[t], p)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;visualize-convergence-of-the-transition-path&#34;&gt;Visualize convergence of the transition path&lt;/h4&gt;

&lt;p&gt;The first guess for $(K_t)_{t=1}^{T}$ is that it is equal to the non-stochastic steady-state value $K*$. Very quickly, the path for $(K_t)_{t=1}^{T}$ converges to the perfect foresight transition path:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p0 = plot(1:max_t, K_path[1], label= &amp;quot;Iteration 0&amp;quot;, title=&amp;quot;Convergence of K(t)&amp;quot;)
plot!(p0, 2:max_t, K_path[2][2:end], label = &amp;quot;Iteration 1&amp;quot;)
show_every = 5 #display {K_t} for each multiple of show_every
for k in 2:length(K_path)
    if mod(k,show_every) == 0
        plot!(p0, 2:max_t, K_path[k][2:end], xlabel=&amp;quot;t&amp;quot;, label = &amp;quot;Iteration $(k)&amp;quot;, title=&amp;quot;Convergence of K(t)&amp;quot;, legend=:best)
    end
end

p0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_30_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the path for capital {K_t}^(i) for different iterations of the backward-forward algorithm&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;removing-the-borrowing-constraint&#34;&gt;Removing the borrowing constraint&lt;/h4&gt;

&lt;p&gt;The next graph compares the current model to a similar model without a borrowing constraint. With no borrowing constraint, the aggregate level of capital reacts less to an aggregate shock in productivity:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p1 = plot(1:max_t, K_path[end], label= &amp;quot;K_t Aiyagari&amp;quot;, title=&amp;quot;IRF Aiyagari versus RBC&amp;quot;)
plot!(p1, xx[RBCp.iK,2:end] .+ K_star, label = &amp;quot;K_t RBC&amp;quot;, color = &amp;quot;black&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_34_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the impulse response of K_t of for the Aiyagari model and a RBC model.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p1 = plot(1:max_t, z_path./z_path[end] .-1, label = &amp;quot;z(t)&amp;quot;, xlabel= &amp;quot;t&amp;quot;)
p2 = plot(1:max_t, R_path./R_path[end] .-1, label= &amp;quot;R(t)&amp;quot;, xlabel= &amp;quot;t&amp;quot;)
p3 = plot(1:max_t, W_path./W_path[end].-1 , label= &amp;quot;W(t)&amp;quot;, xlabel= &amp;quot;t&amp;quot;)
p4 = plot(1:max_t, K_path[end]./K_path[end][end] .-1, label= &amp;quot;K(t)&amp;quot;, xlabel= &amp;quot;t&amp;quot; )

p5 = plot(p1, p2, p3, p4)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_36_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the percentage deviation from steady-state values of (i) aggregate productivity (ii) the interest rate (iii) wages (iv) capital.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;linearity-checks&#34;&gt;Linearity checks&lt;/h4&gt;

&lt;p&gt;To simulate the stochastic economy, the BKM algorithm makes the assumption that an MIT shock is linear with
respect to the aggregate shock. That is, doubling the initial shock will simply double the value of aggregates
along the transition path without changing the shape of the path. The next block
calculates several transition paths for different initial aggregate shocks.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;max_t = 300 #Let us assume that the economy is back to the steady state after max_t periods
z_ss = 1.0  #Value of aggregate productivity at the non-stochastic steady-state
# Different initial shocks
array_sigma = collect(range(-0.75, stop=0.75, step=0.25))
# Let&#39;s exclude sigma = 0
array_sigma = array_sigma[array_sigma .!= 0.]
# To store the different scaled IRF:
x_mit_scaled_sigma = zeros(max_t, length(array_sigma))
# To store path of aggregate productivity:
z_path_sigma = zeros(max_t, length(array_sigma))
# To store the path for the %deviation of aggregate productivity from its steady-state value
z_path_sigma_dev = zeros(max_t, length(array_sigma))

for (index_sigma, sigma) in enumerate(array_sigma)

    # Let&#39;s generate a path for the aggregate shock
    z_path = ones(max_t)
    z_path[1] = z_ss + z_ss*sigma

    # Evolution of aggregate productivity in level:
    for t_index=2:max_t
        z_path[t_index] = z_path[t_index-1]^p.rho
    end

    # Heroic guess for the initial path of {K_t}: K_t = K* for all t
    K_path = []
    push!(K_path, repeat([K_star], max_t))

    # Find the path for {K_t}:
    @time K_path, convergence_flag = solve_mit!(K_path, g_low_star, g_high_star, d_star, K_star, z_path, p, convex_combination=0.2, verbose=false);

    # Check for convergence
    if convergence_flag!=1
        error(&amp;quot;No convergence for z(1) = $(z_path[1]).&amp;quot;)
    end

    # store the path for z:
    z_path_sigma[:, index_sigma] = z_path

    # store for the %deviation of aggregate productivity from its steady-state value
    z_path_sigma_dev[:, index_sigma] = z_path./z_ss .- 1.0

    # Scaled IRF: how a percentage deviation in z_t from its steady-state results in a % deviation of k_t
    x_mit_scaled_sigma[:, index_sigma] = (K_path[end]./K_star .- 1.0)./z_path_sigma_dev[1, index_sigma]

end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p0 = plot()
p1 = plot()
p2 = plot()
p3 = plot()

for (index_sigma, sigma) in enumerate(array_sigma)
    if index_sigma == 1
        p0 = plot(100 .*z_path_sigma_dev[:, index_sigma], label=&amp;quot;z(t) with z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;)
        p1 = plot(z_path_sigma[:, index_sigma], label=&amp;quot;z(t) z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;)
        p2 = plot(x_mit_scaled_sigma[:, index_sigma], label=&amp;quot;z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;)
        p3 = plot(sign(z_path_sigma[1, index_sigma] - z_ss)*x_mit_scaled_sigma[:, index_sigma], label=&amp;quot;z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;)
    else
        plot!(p0, 100 .*z_path_sigma_dev[:, index_sigma], label=&amp;quot;z(t) with z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;, title = &amp;quot;% deviation aggregate productivity&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
        plot!(p1, z_path_sigma[:, index_sigma], label=&amp;quot;z(t) with z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;, title = &amp;quot;Aggregate productivity&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
        plot!(p2, x_mit_scaled_sigma[:, index_sigma], label=&amp;quot;z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;, title = &amp;quot;Impact of shock&#39;s size on scaled IRF: x&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
        plot!(p3, sign(z_path_sigma[1, index_sigma] - z_ss)*x_mit_scaled_sigma[:, index_sigma], label=&amp;quot;z(1) = $(round(100 .*z_path_sigma_dev[1, index_sigma], digits=2))%&amp;quot;, title = &amp;quot;Impact of shock&#39;s sign on scaled IRF: sign(x - x_ss)*x&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;plot(p0,p1, fg_legend = :transparent, legend=:best, layout=(2,1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_42_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: This graph shows the percentage deviation of aggregate productivity from its steady-state value (top panel) and aggregate productivity in level (bottom panel) for different initial shocks.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;plot(p2,p3, fg_legend = :transparent, legend=:best, layout=(2,1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_44_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: The top panel shows the scaled impulse response function of capital for different aggregate shocks. The bottom panel shows the scaled impulse response function of capital for different aggregate shocks, multiplied by the sign of the aggregate shock.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;ii-d-out-of-steady-state-dynamics&#34;&gt;II.D. Out-of-steady-state dynamics&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;max_t = 2000
shocks_t = rand(Normal(0,0.005), max_t) # Series of aggregate shocks
# Let&#39;s generate a path for the aggregate shock
z_path = ones(max_t)
z_path[1] = z_ss

# Evolution of aggregate productivity in level:
for t_index=2:max_t
    z_path[t_index] = z_path[t_index-1]^p.rho + shocks_t[t_index]
end

# Calculation of GenBKM path:
XT_GenBKM = zeros(max_t);# Initialization
@time GenBKM_path!(XT_GenBKM, max_t, x_mit_scaled_sigma, z_path./z_ss .- 1.0, array_sigma)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.237683 seconds (1.06 M allocations: 50.188 MiB)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p1 = plot(100 .*(z_path./z_ss .- 1.0), label=&amp;quot;z_t&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
p2 = plot(100 .*XT_GenBKM, label = &amp;quot;K_t&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
plot(p1,p2, fg_legend = :transparent, legend=:best, layout=(2,1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;AiyagariBKM_48_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: The top panel shows the percentage deviation of aggregate productivity from its steady-state value. The bottom panel shows the percentage deviation of capital from its steady-state value.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This post presents the model of Aiyagari (1994) and a general three-step procedure to simulate out-of-steady-state dynamics for models of this class for &amp;ldquo;small&amp;rdquo; shocks. Solving incomplete market models for large shocks seems to be &lt;a href=&#34;https://www.springer.com/gp/book/9783319564357&#34; target=&#34;_blank&#34;&gt;much more complicated&lt;/a&gt; and is still an active area of research.&lt;/p&gt;

&lt;h2 id=&#34;links&#34;&gt;Links&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;An excellent course on heterogeneous agent models with code in Matlab, Python and Julia: &lt;a href=&#34;https://alisdairmckay.com/Notes/HetAgents/index.html&#34; target=&#34;_blank&#34;&gt;https://alisdairmckay.com/Notes/HetAgents/index.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;More on the EGM method: &lt;a href=&#34;https://julia.quantecon.org/dynamic_programming/egm_policy_iter.html&#34; target=&#34;_blank&#34;&gt;https://julia.quantecon.org/dynamic_programming/egm_policy_iter.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;More on the Aiyagari model: &lt;a href=&#34;https://python.quantecon.org/aiyagari.html&#34; target=&#34;_blank&#34;&gt;https://python.quantecon.org/aiyagari.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Aiyagari model in continuous time: &lt;a href=&#34;https://nbviewer.jupyter.org/github/QuantEcon/QuantEcon.notebooks/blob/master/aiyagari_continuous_time.ipynb&#34; target=&#34;_blank&#34;&gt;https://nbviewer.jupyter.org/github/QuantEcon/QuantEcon.notebooks/blob/master/aiyagari_continuous_time.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Similar model solved very efficiently with a Python package: &lt;a href=&#34;https://github.com/shade-econ/sequence-jacobian/blob/master/krusell_smith.ipynb&#34; target=&#34;_blank&#34;&gt;https://github.com/shade-econ/sequence-jacobian/blob/master/krusell_smith.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Aiyagari, S. Rao. &amp;ldquo;Uninsured idiosyncratic risk and aggregate saving.&amp;rdquo; The Quarterly Journal of Economics 109.3 (1994): 659-684.&lt;/li&gt;
&lt;li&gt;Bewley, Truman. &amp;ldquo;A difficulty with the optimum quantity of money.&amp;rdquo; Econometrica: Journal of the Econometric Society (1983): 1485-1504.&lt;/li&gt;
&lt;li&gt;Boppart, Timo, Per Krusell, and Kurt Mitman. ‚ÄúExploiting MIT shocks in heterogeneous-agent economies: the impulse response as a numerical derivative.‚Äù Journal of Economic Dynamics and Control 89 (2018): 68-92.&lt;/li&gt;
&lt;li&gt;Christopher D Carroll. The method of endogenous gridpoints for solving dynamic stochastic optimization problems. Economics Letters, 91(3):312‚Äì320, 2006.&lt;/li&gt;
&lt;li&gt;Coeurdacier, Nicolas, Helene Rey, and Pablo Winant. &amp;ldquo;The risky steady state.&amp;rdquo; American Economic Review 101.3 (2011): 398-401.&lt;/li&gt;
&lt;li&gt;Huggett, Mark. &amp;ldquo;The risk-free rate in heterogeneous-agent incomplete-insurance economies.&amp;rdquo; Journal of economic Dynamics and Control 17.5-6 (1993): 953-969.&lt;/li&gt;
&lt;li&gt;ƒ∞mrohoroƒülu, Ay≈üe. &amp;ldquo;The welfare cost of inflation under imperfect insurance.&amp;rdquo; Journal of Economic Dynamics and Control 16.1 (1992): 79-91.&lt;/li&gt;
&lt;li&gt;Ljungqvist, Lars, and Thomas J. Sargent. Recursive macroeconomic theory. MIT press, 2018.&lt;/li&gt;
&lt;li&gt;Reiter, Michael. ‚ÄúComments on‚Äù Exploiting MIT Shocks in Heterogeneous-Agent Economies: The Impulse Response as a Numerical Derivative‚Äù by T. Boppart, P. Krusell and K. Mitman.‚Äù Journal of Economic Dynamics and Control 89 (2018): 93-99.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>The GenBKM Algorithm</title>
      <link>https://julienpascal.github.io/post/genbkm/</link>
      <pubDate>Tue, 21 Apr 2020 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/genbkm/</guid>
      <description>

&lt;p&gt;In a &lt;a href=&#34;https://julienpascal.github.io/post/bkm/&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt; I presented the &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0165188918300022&#34; target=&#34;_blank&#34;&gt;BKM algorithm&lt;/a&gt; , which can used to approximate solutions of macroeconomic models with &lt;strong&gt;aggregate uncertainty&lt;/strong&gt; and &lt;strong&gt;heterogeneous agents&lt;/strong&gt;. This class of models has been been of great interest for Economists for quite a long time. For instance, &lt;a href=&#34;https://www.jstor.org/stable/2118417?seq=1#metadata_info_tab_contents&#34; target=&#34;_blank&#34;&gt;Aiyagari (1994)&lt;/a&gt; already hinted that taking into consideration heterogeneity along the business cycle is both theoretically important and challenging:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This class of models may also be useful in &lt;strong&gt;resolving various asset return puzzles&lt;/strong&gt;. Mehra and
Prescott [1985, p. 145] suggested that these puzzles cannot be &amp;ldquo;accounted for by models that abstract from transactions costs. This is a very hard problem computationally since the distribution of assets
across households can no longer be taken to be constant. Instead, &lt;strong&gt;the cross-section distribution is part of the state vector that evolves stochastically over time in response to aggregate shocks&lt;/strong&gt;. This is an issue that remains to be explored&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Recent developments have relied on the &lt;strong&gt;sequence representation&lt;/strong&gt; of the mutli-stage decision process, instead of the traditional &lt;strong&gt;recursive form&lt;/strong&gt; using Bellman&amp;rsquo;s principle (see for instance &lt;a href=&#34;https://web.stanford.edu/~aauclert/sequence_space_jacobian.pdf&#34; target=&#34;_blank&#34;&gt;Auclert at al (2019)&lt;/a&gt; or &lt;a href=&#34;http://xavier-ragot.fr/pdf/progress/Optimal_policies.pdf&#34; target=&#34;_blank&#34;&gt;Le Grand and Ragot (2019)&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;In this short blog post, I would like to present a small modification of the BKM algorithm that delivers large improvements in accuracy: the GenBKM algorithm by &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v89y2018icp93-99.html&#34; target=&#34;_blank&#34;&gt;Reiter (2018)&lt;/a&gt;. The code for this post can be found &lt;a href=&#34;https://github.com/JulienPascal/GenBKM&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;i-a-the-bkm-algorithm&#34;&gt;I.A. The BKM algorithm&lt;/h3&gt;

&lt;p&gt;It is common to use Bellman&amp;rsquo;s principle of optimality to characterize solutions of a mutli-stage decision process. The principle of optimality leads to a solution in a &lt;strong&gt;recursive form&lt;/strong&gt; $d_{t} = d(S_{t})$, where $S_t$ is a vector of state variables and d(.) a policy function describing the optimal action of a decision-maker when faced with any given state. In model with heterogeneous agents (HA) and aggregate uncertainty, $S_t$ is generally infinite-dimensional. Hence, there is a huge premium in avoiding the recursive form.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;sequence form&lt;/strong&gt; of the problem is as follows: at each step in time, a decision-maker observes a new realization of a random process $z_t$ and taking into account the full history of past shocks, the agent make a new choice to maximize her expected discounted sum of returns: $d_t = d(z_t, z_{t-1}, z_{t-2}, &amp;hellip;)$.&lt;/p&gt;

&lt;p&gt;The BKM algorithm makes the &lt;strong&gt;assumption&lt;/strong&gt; of &lt;strong&gt;linearity&lt;/strong&gt; of d(.) with respect to the &lt;strong&gt;aggregate state&lt;/strong&gt; $z_t$:&lt;/p&gt;

&lt;p&gt;$$ d_t = z_t d(1, 0, 0, &amp;hellip;) + z_{t-1}d(0, 1, 0, &amp;hellip;) + z_{t-2}d(0, 0, 1, &amp;hellip;) + &amp;hellip; $$&lt;/p&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;p&gt;$$ d_{1} = d(1,0,0,&amp;hellip;)$$
$$ d_{2} = d(0,1,0,&amp;hellip;)$$
$$ d_{3} = d(0,0,1,&amp;hellip;)$$&lt;/p&gt;

&lt;p&gt;or more compactly:&lt;/p&gt;

&lt;p&gt;$$ d_t = \sum_{k=0}^{+\infty} z_{t-k} d_{k} $$&lt;/p&gt;

&lt;p&gt;The series of $d_{k}$ describes the trajectory of the economy after an &amp;ldquo;MIT&amp;rdquo; shock: the economy is hit by an aggregate shock in period 1 and then goes back directly to its steady-state value. The evolution of equilibrium variables are simply a moving average of past shocks.&lt;/p&gt;

&lt;p&gt;The BKM algorithm works well because computing an MIT shock in macroeconomic models with aggregate uncertainty and heterogeneous agents is generally feasible and fast.&lt;/p&gt;

&lt;h4 id=&#34;tl-dr&#34;&gt;TL;DR&lt;/h4&gt;

&lt;p&gt;To simulate out-of-steady-state dynamics, the BKM algorithm superposes &lt;strong&gt;scaled impulse response functions&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;i-b-bkm-example&#34;&gt;I. B. BKM example&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s illustrate how the BKM algorithm works with the following non-linear model:&lt;/p&gt;

&lt;p&gt;$$ x_{t} = a x_{t-1} + b x_{t-1}^2 + z_{t} $$&lt;/p&gt;

&lt;p&gt;The next plot illustrates that BKM algorithm does a good job at approximating the dynamic of the true
nonlinear model. But can we do better? The next section shows that the answer is yes.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Dependencies
using Distributions
using Plots
using DataFrames
using Random
pgfplotsx()

# Parameters
max_iter=1000 #number of iterations for the simulation
a = 0.5
b = 0.05
sigma_shock=1.0 #variance of shocks
mu_shock=0. #mean of shocks
Random.seed!(1234)
d = Normal(mu_shock, sigma_shock)

# transition function
function iter_x(x_min1::Float64, a::Float64, b::Float64)
    &amp;quot;&amp;quot;&amp;quot;
    Function to find the next iteration of x_{t} = a x_{t-1} + b x_{t-1}^2
    x_min1::Float64: x_{t-1}
    a::Float64
    b::Float64
    &amp;quot;&amp;quot;&amp;quot;
    return a*x_min1 + b*x_min1^2
end

# Simulation of an MIT Shock
# We assume that after max_iter_mit periods, the economy is back at the steady-state
max_iter_mit = 25
x_mit=zeros(max_iter_mit)
# Initial shock
z_t=zeros(max_iter_mit)
z_t[1] = sigma_shock #a 1 std. deviation
x_mit[1] = 0 #steady-state

for i=2:max_iter_mit
    x_mit[i] = iter_x(x_mit[i-1], a, b) + z_t[i-1]
end

# Scaled-version of the impulse response:
x_mit_scaled = x_mit./z_t[1];

# Scaled-version of the impulse response:
p0 = plot(x_mit_scaled, label=&amp;quot;x scaled&amp;quot;, xlabel=&amp;quot;t&amp;quot;)
title!(&amp;quot;MIT shock&amp;quot;)

# Function to calculate the path of xt using the BKM algorithm
function BKM_path!(XT::Array{Float64,1}, x_scaled::Array{Float64,1}, shocks::Array{Float64,1})
    &amp;quot;&amp;quot;&amp;quot;
    XT::Array{Float64,1}: array to store the evolution of the variable xt
    x_scaled::Array{Float64,1}: a scaled MIT shock
    shocks::Array{Float64,1}: sequence of shocks
    &amp;quot;&amp;quot;&amp;quot;
    # get the length of x_scaled
    len_x_scaled = length(x_scaled)
    max_iter = length(XT)

    # Loop over time periods periods
    for t=2:max_iter
        # Superposition of MIT shocks:
        for k=1:t
            # After some time, we assume that the effect of past shocks vanishes:
            if k&amp;lt;=len_x_scaled
                XT[t]+=x_scaled[k]*shocks[t-k+1]
            end
        end
    end

end

XT = zeros(max_iter) # Initialization
shocks_t = rand(d, max_iter).*0.5 # Series of shocks
@time BKM_path!(XT, x_mit_scaled, shocks_t) # Solving using BKM:
x_true = zeros(max_iter) # True value of the series
for i=2:max_iter
    x_true[i] = iter_x(x_true[i-1], a, b) + shocks_t[i-1]
end

# Let&#39;s store statistics on error:
diff_BKM = x_true - XT
max_abs_err_BKM = maximum(abs.(diff_BKM))
min_abs_err_BKM = minimum(abs.(diff_BKM))
mean_abs_err_BKM = mean(abs.(diff_BKM))
median_abs_err_BKM = median(abs.(diff_BKM))

p1 = plot(XT[2:end], label=&amp;quot;x_t BKM&amp;quot;)
plot!(x_true[2:end], label=&amp;quot;x_t true&amp;quot;)
title!(&amp;quot;BKM with b=$(b)&amp;quot;)

&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;GenBKM_7_2.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: In orange the exact value as a function of time; in blue the approximation obtained by using
the BKM algorithm&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;ii-a-the-genbkm-algorithm&#34;&gt;II. A. The GenBKM algorithm&lt;/h3&gt;

&lt;p&gt;The BKM algorithm is based on the assumption that both the &lt;strong&gt;size&lt;/strong&gt; and &lt;strong&gt;sign&lt;/strong&gt; of the initial shock does not
change the shape of the scaled impulse response function. But is really the case? The next graph shows that both the size and the sign matter for the shape of the scaled impulse response function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Different initial shocks
array_sigma = collect(range(-2, stop=2, step=0.5))
# Let&#39;s exclude sigma = 0
array_sigma = array_sigma[array_sigma .!= 0.]
# To store the different scaled IRF:
x_mit_scaled_sigma = zeros(max_iter_mit, length(array_sigma))

for (index_sigma, sigma) in enumerate(array_sigma)
    x_mit=zeros(max_iter_mit)
    # Initial shock
    z_t=zeros(max_iter_mit)
    z_t[1] = sigma #a 1 std. deviation
    x_mit[1] = 0 #steady-state

    for i=2:max_iter_mit
        x_mit[i] = iter_x(x_mit[i-1], a, b) + z_t[i-1]
    end

    # Scaled-version of the impulse response:
    x_mit_scaled = x_mit./z_t[1];
    # store the scaled response
    x_mit_scaled_sigma[:, index_sigma] = x_mit_scaled

end


p2 = plot(x_mit_scaled_sigma[:, 1], label=&amp;quot;sigma = $(array_sigma[1])&amp;quot;)
p3 = plot(sign(array_sigma[1])*x_mit_scaled_sigma[:, 1], label=&amp;quot;sigma = $(array_sigma[1])&amp;quot;)

for (index_sigma, sigma) in enumerate(array_sigma)
    plot!(p2, x_mit_scaled_sigma[:, index_sigma], label=&amp;quot;sigma = $(sigma)&amp;quot;, title = &amp;quot;Impact of shock&#39;s size on scaled IRF: x&amp;quot;)
    plot!(p3, sign(sigma)*x_mit_scaled_sigma[:, index_sigma], label=&amp;quot;sigma = $(sigma)&amp;quot;, title = &amp;quot;Impact of shock&#39;s sign on scaled IRF: sign(x)*x&amp;quot;)
end

p4 = plot(p2, p3, layout = (2, 1))
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;GenBKM_11_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: The top panel shows the scaled impulse response function for different
values of shocks. The bottom panel shows the scaled impulse response function
multiplied by the sign of the shock. If the size and the sign of the shock did not matter, we would
see only one line. It is not the case here.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The GenBKM algorithm is the similar to the BKM algorithm, except that the impacts of the size and the sign of the
initial shock on the response of the economy are taken into consideration. It proceeds as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Divide the support of the shock into $n$ intervals $ I_i = (a_i, b_i)$&lt;/li&gt;
&lt;li&gt;Compute $n$ MIT shocks using shocks in $z_i \in I_i$, denoted by $d_k^{i}$&lt;/li&gt;
&lt;li&gt;The state of the economy at time $t$ is given by the moving average of past shocks, taking into consideration
past shock values:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;$$ d_t = \sum_{k=0}^{+\infty} z_{t-k} d_{k}^{f(t-k)} $$&lt;/p&gt;

&lt;p&gt;where the function $f(t)$ returns the index of the interval in which the shock $z_t$ falls.&lt;/p&gt;

&lt;h4 id=&#34;tl-dr-1&#34;&gt;TL;DR&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;GenBKM = BKM with different scaled IRF, instead of one.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;ii-b-genbkm-example&#34;&gt;II. B. GenBKM example&lt;/h3&gt;

&lt;p&gt;The GenBKM algorithm is implemented in the block of code that follows. The next plot shows that the approximation error is much smaller using the GenBKM algorithm. The next table shows that the mean absolute error drops by more than 300% if the GenBKM is used instead of BKM.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function GenBKM_path!(XT::Array{Float64,1}, max_iter::Int64, x_scaled::Array{Float64,2}, shocks::Array{Float64,1}, array_sigma::Array{Float64,1})

    # get the length of x_scaled
    len_x_scaled = size(x_scaled,1)

    # We don&#39;t want x_scaled to contain any NaN value
    if sum(isnan.( x_scaled) .== true) != 0
        error(&amp;quot;x_scaled contains at least one NaN value.&amp;quot;)
    end

    # We don&#39;t want shocks to contain any NaN value
    if sum(isnan.(shocks) .== true) != 0
        error(&amp;quot;shocks contains at least one NaN value.&amp;quot;)
    end

    # Loop over time periods periods
    for t=2:max_iter
        # Superposition of MIT shocks:
        for k=1:t
            # After some time, we assume that the effect of past shocks vanishes:
            if k&amp;lt;=len_x_scaled
                # Find were the initial shock stood on the sigma grid:
                index_sigma = searchsortednearest(array_sigma, shocks[t-k+1])
                XT[t]+=x_scaled[k, index_sigma]*shocks[t-k+1]
            end
        end
    end

end

# Function to find the index corresponding to the closest value on a grid:
# Source: https://discourse.julialang.org/t/findnearest-function/4143/4
function searchsortednearest(a::Array{Float64,1},x::Float64)
    &amp;quot;&amp;quot;&amp;quot;
    a::Array{Float64,1}: grid
    x::Float64: value to be found
    returns the index of the closest value to x on grid a
    &amp;quot;&amp;quot;&amp;quot;
    idx = searchsortedfirst(a,x)
    if (idx==1); return idx; end
    if (idx&amp;gt;length(a)); return length(a); end
    if (a[idx]==x); return idx; end
    if (abs(a[idx]-x) &amp;lt; abs(a[idx-1]-x))
      return idx
    else
      return idx-1
    end
end

# Calculation of GenBKM path:
XT_GenBKM = zeros(max_iter);
@time GenBKM_path!(XT_GenBKM, max_iter, x_mit_scaled_sigma, shocks_t, array_sigma)

# Let&#39;s store statistics on error:
diff_GenBKM = x_true - XT_GenBKM
max_abs_err_GenBKM = maximum(abs.(diff_GenBKM))
min_abs_err_GenBKM = minimum(abs.(diff_GenBKM))
mean_abs_err_GenBKM = mean(abs.(diff_GenBKM))
median_abs_err_GenBKM = median(abs.(diff_GenBKM))

df = DataFrame(Statistics = [&amp;quot;Max absolute error&amp;quot;, &amp;quot;Min absolute error&amp;quot;, &amp;quot;Mean absolute error&amp;quot;, &amp;quot;Median absolute error&amp;quot;],
               BKM = [max_abs_err_BKM, min_abs_err_BKM, mean_abs_err_BKM, median_abs_err_BKM],
               GenBKM = [max_abs_err_GenBKM, min_abs_err_GenBKM, mean_abs_err_GenBKM, median_abs_err_GenBKM])

# Plot errors
p6 = plot(diff_GenBKM[2:end], label=&amp;quot;GenBKM&amp;quot;, xlabel = &amp;quot;t&amp;quot;, ylabel = &amp;quot;Error&amp;quot;)
plot!(diff_BKM[2:end], label=&amp;quot;BKM&amp;quot;)
title!(&amp;quot;Error BKM and GenBKM&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;GenBKM_14_1.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes: In orange the approximation error when using BKM; in blue the approximation error when using GenBKM&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;table class=&#34;data-frame&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;Statistics&lt;/th&gt;&lt;th&gt;BKM&lt;/th&gt;&lt;th&gt;GenBKM&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt; &lt;/th&gt;&lt;th&gt; &lt;/th&gt;&lt;th&gt; &lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;p&gt; &lt;/p&gt;&lt;tr&gt;&lt;th&gt;1&lt;/th&gt;&lt;td&gt;Max absolute error&lt;/td&gt;&lt;td&gt;0.263167&lt;/td&gt;&lt;td&gt;0.132318&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;2&lt;/th&gt;&lt;td&gt;Min absolute error&lt;/td&gt;&lt;td&gt;0.0&lt;/td&gt;&lt;td&gt;0.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;3&lt;/th&gt;&lt;td&gt;Mean absolute error&lt;/td&gt;&lt;td&gt;0.0381089&lt;/td&gt;&lt;td&gt;0.0136915&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;4&lt;/th&gt;&lt;td&gt;Median absolute error&lt;/td&gt;&lt;td&gt;0.0237194&lt;/td&gt;&lt;td&gt;0.0100031&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Heterogeneity along the business cycle matters. This blog post presented two simple algorithms that are both fast and accurate to solve for macroeconomics models in which heterogeneity is key. GenBKM is a refinement of BKM, which tends to be more accurate. However, there is no free lunch. The increased accuracy of GenBKM is obtained by using several MIT shocks instead of one.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Aiyagari, S. Rao. &amp;ldquo;Uninsured idiosyncratic risk and aggregate saving.&amp;rdquo; The Quarterly Journal of Economics 109.3 (1994): 659-684.&lt;/li&gt;
&lt;li&gt;Auclert, Adrien, et al. Using the Sequence-Space Jacobian to Solve and Estimate Heterogeneous-Agent Models. No. w26123. National Bureau of Economic Research, 2019.&lt;/li&gt;
&lt;li&gt;Boppart, Timo, Per Krusell, and Kurt Mitman. &amp;ldquo;Exploiting MIT shocks in heterogeneous-agent economies: the impulse response as a numerical derivative.&amp;rdquo; Journal of Economic Dynamics and Control 89 (2018): 68-92.&lt;/li&gt;
&lt;li&gt;Le Grand, Fran√ßois, and Ragot, Xavier. &amp;ldquo;Managing Inequality over the Business Cycles: Optimal Policies with Heterogeneous Agents and Aggregate Shocks&amp;rdquo;. No. 1090. Society for Economic Dynamics, 2019.&lt;/li&gt;
&lt;li&gt;Reiter, Michael. &amp;ldquo;Comments on&amp;rdquo; Exploiting MIT Shocks in Heterogeneous-Agent Economies: The Impulse Response as a Numerical Derivative&amp;rdquo; by T. Boppart, P. Krusell and K. Mitman.&amp;rdquo; Journal of Economic Dynamics and Control 89 (2018): 93-99.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;versioninfo()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Julia Version 1.3.0
Commit 46ce4d7933 (2019-11-26 06:09 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>The linear‚Äìquadratic regulator Part II</title>
      <link>https://julienpascal.github.io/post/lqr_partii/</link>
      <pubDate>Sun, 05 Apr 2020 16:00:00 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/lqr_partii/</guid>
      <description>

&lt;p&gt;This notebook builds upon what has been described in &lt;a href=&#34;https://julienpascal.github.io/post/lqr/&#34; target=&#34;_blank&#34;&gt;Part I&lt;/a&gt;. In &lt;a href=&#34;https://julienpascal.github.io/post/lqr/&#34; target=&#34;_blank&#34;&gt;Part I&lt;/a&gt;, we introduced the linear‚Äìquadratic regulator (LQR) framework in Python. We solved the linearized control problem.&lt;/p&gt;

&lt;p&gt;In this notebook, we will see that we can do better. The basic idea is to follow the the evolution of &amp;ldquo;observables&amp;rdquo; ‚Äî functions of the state space ‚Äî instead of the evolution of the state itself using the &lt;strong&gt;Koopman operator&lt;/strong&gt;. In the space of observables, the differential equation is linear. Thus, we can solve for the optimal control in the this transformed space, without having to linearize the system around its steady-state.&lt;/p&gt;

&lt;h4 id=&#34;in-this-notebook-you-will-learn&#34;&gt;In this notebook, you will learn:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;the basics on the Koopman operator&lt;/li&gt;
&lt;li&gt;how to solve for the optimal control in the Koopman subspace&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;i-the-koopman-operator-101&#34;&gt;I. The Koopman operator 101&lt;/h1&gt;

&lt;p&gt;Let us remember that in Part I, we analyzed the evolution of the following dynamical system:&lt;/p&gt;

&lt;p&gt;$$ \begin{cases} \frac{d}{dt} x = \mu x \\ \frac{d}{dt} y = \lambda (y - x^2)  \end{cases} $$&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s make the observation that we can defined a new vector $z$ defined by:&lt;/p&gt;

&lt;p&gt;$$ z \equiv \begin{pmatrix} z_1 \\ z_2 \\ z_3 \end{pmatrix} = \begin{pmatrix} x \\ y \\ x^2 \end{pmatrix}$$&lt;/p&gt;

&lt;p&gt;The original nonlinear dynamical system is linear when considering the evolution of $z$:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \begin{pmatrix} z_1 \\ z_2 \\ z_3 \end{pmatrix} = \begin{pmatrix} \mu &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \lambda &amp;amp; -\lambda \\ 0 &amp;amp; 0 &amp;amp; 2 \mu \end{pmatrix}  \begin{pmatrix} z_1 \\ z_2 \\ z_3 \end{pmatrix}$$&lt;/p&gt;

&lt;p&gt;What we just did ‚Äî writing the evolution the dynamical system using some observables ‚Äî is the central idea of the Koopman operator. Here we are lucky because our new variable $z$ is of finite dimension. In the general case, $z$ is infinite-dimensional:&lt;/p&gt;

&lt;p&gt;$$
\frac{d}{dt} \begin{pmatrix} z_1 \\ z_2 \\ &amp;hellip; \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; &amp;hellip; \\ a_{21} &amp;amp; a_{22} &amp;amp; &amp;hellip; \\ &amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip; \end{pmatrix} \begin{pmatrix} z_1 \\ z_2 \\ &amp;hellip; \end{pmatrix} $$&lt;/p&gt;

&lt;p&gt;and we have no guarantee that the truncation of z by a finite dimensional counterpart will produce a good approximation of the system. For more detail on this problem, I invite you to read &lt;a href=&#34;https://arxiv.org/abs/1510.03007&#34; target=&#34;_blank&#34;&gt;this paper&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Because now the dynamical system is linear, we can directly use the results from LQR framework and solve for the optimal control that minimizes the cost $J$:&lt;/p&gt;

&lt;p&gt;$$ J = \int_{0}^{\infty} x&amp;rsquo;(t) Q x(t) + u&amp;rsquo;(t) R u(t) dt $$&lt;/p&gt;

&lt;p&gt;We already know that the optimal control from the controller is a linear function of the current state of the system:&lt;/p&gt;

&lt;p&gt;$$ u = - C_z z$$&lt;/p&gt;

&lt;p&gt;When the system is controlled optimally, the equation governing the evolution of the system writes:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} z = A_z z - B C_z z $$&lt;/p&gt;

&lt;p&gt;At a later stage, because we want to compare the Koopman controller to the linearized controller, we do not want to penalize the variable $z_3$ for being away from its steady state. The rationale is the variable $z_3$ is &amp;ldquo;fictive&amp;rdquo;.
We still have in mind that we want to control the &amp;ldquo;real&amp;rdquo; variables $x$ and $y$. As a result, the matrix $Q$ we consider
is:&lt;/p&gt;

&lt;p&gt;$$ \begin{pmatrix} 1 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 \end{pmatrix} $$&lt;/p&gt;

&lt;h2 id=&#34;ii-simulating-forward-the-dynamical-system&#34;&gt;II. Simulating forward the dynamical system&lt;/h2&gt;

&lt;p&gt;For what follows, you will need the following packages:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
import matplotlib.pyplot as plt
plt.style.use(&#39;ggplot&#39;)
%matplotlib inline
import numpy as np
from control.matlab import *  # MATLAB-like functions
#to solve ODE
from scipy import integrate
#show the version of Python I am using:
!python3 --version
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Python 3.5.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s study optimal control for the following differential equation:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \begin{pmatrix} z_1 \\ z_2 \\ z_3 \end{pmatrix} = \begin{pmatrix} \mu &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \lambda &amp;amp; -\lambda \\ 0 &amp;amp; 0 &amp;amp; 2 \mu \end{pmatrix}  \begin{pmatrix} z_1 \\ z_2 \\ z_3 \end{pmatrix}  $$&lt;/p&gt;

&lt;p&gt;The following block of code define the parameter values, the matrix A for the linear part of the differential equation and the matrix B specifying that the controller can only act on x. We also specify the time span during which we want to simulate forward the trajectories:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Parameters and matrices A and B:
mu = -0.05
llambda = -1.0
# Matrices for the orginial system
A = np.array([[mu, 0], [0, llambda]])
B = np.array([[0], [1]])
R = np.array([1])
Q = np.eye(2)
# Matrices for the transformed system:
A_z = np.array([[mu, 0, 0], [0, llambda, -llambda], [0, 0, 2*mu]])  
B_z = np.array([[0], [1], [0]])
R_z = np.array([1])
Q_z = np.eye(3)
# Time span
t0, t1 = 0, 100 # start and end
t = np.arange(t0, t1, 0.01)

# Function that defines the dynamic system:
def vdp0(t, y):
    # linear part + nonlinear part:
    x = A.dot(y) + np.array([0, -llambda*(y[0]**2)])
    return x

# Function that defines the dynamic system in the Koopman subspace:
def vdp0z(t, y):
    x = A_z.dot(y)
    return x
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We then define 4 different starting values and simulate forward the system using the &lt;code&gt;scipy.integrate&lt;/code&gt; toolkit:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Set of starting values:
y0A = np.array([1.5, -1, (1.5)**2])
y0B = np.array([-1.5, -1, (-1.5)**2])
y0C = np.array([5, 5, 25])
y0D = np.array([-5, 5, 25])

# To store the different trajectories
list_y_z = []

# Method for the ODE:
# This is an explicit runge-kutta method of order (4)5 due to Dormand &amp;amp; Prince
integrator = &amp;quot;dopri5&amp;quot;

# Loop over the different starting values and calculate trajectories:
for y0 in [y0A, y0B, y0C,y0D]:
    # initialize an array to store the solution
    y = np.zeros((len(t), len(y0)))   # array for solution
    r0 = integrate.ode(vdp0z).set_integrator(integrator)
    r0.set_initial_value(y0, t0)   # initial values
    for i in range(1, t.size):
       y[i, :] = r0.integrate(t[i]) # get one more value, add it to the array
       if not r0.successful():
           raise RuntimeError(&amp;quot;Could not integrate&amp;quot;)
    # append the list of solution
    list_y_z.append(y)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next graph shows the trajectory of x and y using the augmented linear system corresponds to the trajectory
we found using the nonlinear dynamical system, as expected:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Plot the different paths:
fig, ax = plt.subplots(figsize=(10, 5))

for index,y0 in enumerate([y0A, y0B, y0C, y0D]):
    ax.plot(list_y_z[index][1:-1, 0], list_y_z[index][1:-1, 1], label = str(y0))
    plt.xlabel(&amp;quot;x&amp;quot;)
    plt.ylabel(&amp;quot;y&amp;quot;)
plt.title(&amp;quot;Trajectories for different starting values&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartII_21_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The next graph shows that the dynamical system moves along a nice parabola in the third dimension:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Plot the different paths:
fig, ax = plt.subplots(figsize=(10, 5))

for index,y0 in enumerate([y0A, y0B, y0C, y0D]):
    ax.plot(list_y_z[index][1:-1, 0], list_y_z[index][1:-1, 2], label = str(y0))
    plt.xlabel(&amp;quot;x&amp;quot;)
    plt.ylabel(&amp;quot;z&amp;quot;)
plt.title(&amp;quot;Trajectories for different starting values&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartII_23_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;iii-solving-for-the-optimal-control&#34;&gt;III. Solving for the optimal control&lt;/h2&gt;

&lt;p&gt;Let us remember that our aim is find the matrix $C_z$ defining the optimal control:&lt;/p&gt;

&lt;p&gt;$$ u = - C_z z $$&lt;/p&gt;

&lt;p&gt;Interestingly, while the optimal $u$ is linear when considering $z$, it is quadratic when considering the original vector of state $x$:&lt;/p&gt;

&lt;p&gt;$$ u = - (C_{z,1} C_{z,2}) \begin{pmatrix} x \\ y  \end{pmatrix} -  C_{z,3} x^2  $$&lt;/p&gt;

&lt;p&gt;We will see in a minute that having a non-linear control allows us to outperform the linear control obtained
in &lt;a href=&#34;https://julienpascal.github.io/post/lqr/&#34; target=&#34;_blank&#34;&gt;Part I&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Solve for C:
(C, X, E) = lqr(A, B, Q, R)
print(&amp;quot;Feedback matrix C : {}&amp;quot;.format(C))

# Solve for C_z:
(C_z, X_z, E_z) = lqr(A_z, B_z, Q_z, R_z)
print(&amp;quot;Feedback matrix C_z : {}&amp;quot;.format(C_z))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Feedback matrix C : [[0.         0.41421356]]
Feedback matrix C_z : [[0.         0.41421356 0.27355029]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now proceed as previously to simulate forward the differential equation. The only difference is that
now we have to take into account the optimal control applied each period on the system. The optimal control is
taken into consideration in the function &lt;code&gt;vdp1(t, y)&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def vdp1(t, y):
    # Ay - B*X*y + Cy
    x = A.dot(y)  - np.matmul(B,C).dot(y)
    return x + np.array([0, -llambda*(y[0]**2)])

def vdp1z(t, y):
    return A_z.dot(y)  - np.matmul(B_z,C_z).dot(y)

y0 = [-5, 5]                   # initial value
y0_z = [-5, 5, 25]                   # initial value

y = np.zeros((len(t), len(y0))) # array for solution
y_z = np.zeros((len(t), len(y0_z))) # array for solution
y[0, :] = y0
y_z[0, :] = y0_z
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Controlled trajectory using the linearized system
r = integrate.ode(vdp1).set_integrator(integrator)
r.set_initial_value(y0, t0)   # initial values

for i in range(1, t.size):
   y[i, :] = r.integrate(t[i]) # get one more value, add it to the array
   if not r.successful():
       raise RuntimeError(&amp;quot;Could not integrate&amp;quot;)

# Controlled trajectory using the linearized system
r = integrate.ode(vdp1z).set_integrator(integrator)
r.set_initial_value(y0_z, t0)   # initial values

for i in range(1, t.size):
   y_z[i, :] = r.integrate(t[i]) # get one more value, add it to the array
   if not r.successful():
       raise RuntimeError(&amp;quot;Could not integrate&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now compare the controlled and Koopman controlled trajectories. Interestingly, the Koopman controlled
trajectory moves along a trajectory involving lower values for $y$:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;index = 3 #choose the last trajectory
fig, ax = plt.subplots(figsize=(10, 5))
plt.plot(list_y_z[index][1:-1, 0], list_y_z[index][1:-1, 1], label = &amp;quot;Uncontrolled&amp;quot;)
plt.plot(y[:, 0], y[:, 1], label = &amp;quot;Controlled&amp;quot;)
plt.plot(y_z[:, 0], y_z[:, 1], label = &amp;quot;Koopman controlled&amp;quot;)
plt.xlabel(&amp;quot;x&amp;quot;)
plt.ylabel(&amp;quot;y&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartII_32_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The next logical question is whether or not the Koopman controller is better than the controller based on the
linearization of the dynamical system around its steady state. The next plot shows that indeed the Koopman controller (in purple) outperforms the latter (in blue).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Controlled
JLQR = np.cumsum( np.square(y[:, 0]) + np.square(y[:, 1]) + np.square(np.matmul(C, y.T)) ).T
# Koopman controlled
JLQRz = np.cumsum( np.square(y_z[:, 0]) + np.square(y_z[:, 1]) + np.square(np.matmul(C_z, y_z.T)) ).T
# Uncontrolled
JLQR0 = np.cumsum( np.square(list_y_z[index][:, 0]) + np.square(list_y_z[index][:, 1]) )

fig, ax = plt.subplots(figsize=(10, 5))
plt.plot(t, JLQR0, label = &amp;quot;Uncontrolled&amp;quot;)
plt.plot(t, JLQR, label = &amp;quot;Controlled&amp;quot;)
plt.plot(t, JLQRz, label = &amp;quot;Koopman controlled&amp;quot;)
plt.xlabel(&amp;quot;t&amp;quot;)
plt.ylabel(&amp;quot;JLQR&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartII_34_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This notebook illustrates the idea behind the Koopman operator in a very simple setting. We saw that by solving for the optimal control in the space of observables, in which the system is exactly linear, we find a controller that outperforms the one obtained by linearizing the system around its steady-state.&lt;/p&gt;

&lt;p&gt;The Koopman LQR control drew my attention because many techniques, especially in Economics, are based on the linearization of dynamic systems around its steady-state. While these linearization techniques are accurate when the economy is close to its steady-state (in a &amp;ldquo;business as usual&amp;rdquo; situation), it is hard to know how these approximations perform when the economy is an unusual state. Given the current economic context, relying on linearization might be inaccurate.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The linear system studied in this notebook is based on the paper: Brunton, Steven L., et al. &amp;ldquo;Koopman invariant subspaces and finite linear representations of nonlinear dynamical systems for control.&amp;rdquo; PloS one 11.2 (2016).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Koopman, Bernard O. &amp;ldquo;Hamiltonian systems and transformation in Hilbert space.&amp;rdquo; Proceedings of the national academy of sciences of the united states of america 17.5 (1931): 315.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>The linear‚Äìquadratic regulator Part I</title>
      <link>https://julienpascal.github.io/post/lqr/</link>
      <pubDate>Wed, 01 Apr 2020 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/lqr/</guid>
      <description>

&lt;p&gt;The two main goals of this blog post is to introduce what the &lt;a href=&#34;https://en.wikipedia.org/wiki/Linear%E2%80%93quadratic_regulator&#34; target=&#34;_blank&#34;&gt;linear‚Äìquadratic regulator (LQR)&lt;/a&gt; framework is and to show how to solve LQR problems using Python. The LQR is concerned with operating a dynamic system (a rocket, a car, the economy, etc.) at minimum cost.&lt;/p&gt;

&lt;h4 id=&#34;in-this-blog-post-you-will-learn&#34;&gt;In this blog post you will learn&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;what the LQR framework is&lt;/li&gt;
&lt;li&gt;how to simulate forward an ordinary differential equation using &lt;a href=&#34;https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.ode.html&#34; target=&#34;_blank&#34;&gt;scipy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;how to solve for the optimal control using the &lt;a href=&#34;https://python-control.readthedocs.io/en/0.8.3/&#34; target=&#34;_blank&#34;&gt;Python Control Systems Library&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Jupyter notebook with the code used to generate this blog post can be found &lt;a href=&#34;https://github.com/JulienPascal/KoopmanObservableSubspaces&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;i-the-lqr-framework-in-a-nutshell&#34;&gt;I. The LQR framework in a nutshell&lt;/h2&gt;

&lt;p&gt;Many natural phenomena naturally lead to differential equations. A differential equation is an equation in which the rate of the change of a variable ($\frac{d}{dt} x$) is a function its state $x$. The unknown is a function satisfying both the differential equation and an initial value. For instance, a simple model of the spread of the Covid-19 can be written as a system of differential equations (see for instance the &lt;a href=&#34;https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology&#34; target=&#34;_blank&#34;&gt;SIR model&lt;/a&gt;):&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \boldsymbol{x} = f(\boldsymbol{x},t) $$&lt;/p&gt;

&lt;p&gt;The LQR theory studies a special case of the above problem. It focuses on problems where the function $f(\boldsymbol{x},t)$ is linear:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \boldsymbol{x} = A  \boldsymbol{x} $$&lt;/p&gt;

&lt;p&gt;The equation above is a &amp;ldquo;passive&amp;rdquo; one. We simply observe the trajectory of $\boldsymbol{x}$ and there is nothing we can do about it. The LQR framework is based on the idea that an observer may want to change the trajectory of the system by exerting a control on $\boldsymbol{x}$. In the case of the spread of the Covid-19, the government may want to limit the number of new cases. When considering the economy, a central bank may want to control the interest rate to reach its inflation target. In the case of the SpaceX, the engineers may want to stabilize the rocket so that it does not explode when trying to land back on Earth.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;spaceX.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In the LQR framework, the controller wants to stabilize the system to reach one of its steady-state values, defined by:&lt;/p&gt;

&lt;p&gt;$$ \boldsymbol{x_{ss}} = A \boldsymbol{x_{ss}} $$&lt;/p&gt;

&lt;p&gt;We need to take into consideration the impact that the controller has on the system. Let us add the control, denoted by $u$, to the uncontrolled system from above:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \boldsymbol{x} = A  \boldsymbol{x} + B  \boldsymbol{u} $$&lt;/p&gt;

&lt;p&gt;where $B$ is a matrix capturing the idea that the controller could only control some elements of $\boldsymbol{x}$.&lt;/p&gt;

&lt;p&gt;However, there is no free lunch. In order to stabilize the system, the controller needs to pay a cost. Going back to our rocket example, some fuel is burnt in order to stabilize the trajectory of the rocket. The LQR is based on a cost function that is quadratic. This quadratic assumption simplifies the algebra substantially and captures the intuitive idea that doubling the effort actually costs four times more, not two times more.&lt;/p&gt;

&lt;p&gt;Let us assume that the steady state of the system is $\boldsymbol{0}$. This is without loss of generality, because we can rewrite the system as a deviation from its steady-state value $\boldsymbol{\tilde{x}} \equiv \boldsymbol{x} - \boldsymbol{x_{ss}}$, in which case the steady-state is reached for  $\boldsymbol{\tilde{x}} = \boldsymbol{0}$.&lt;/p&gt;

&lt;p&gt;To capture the cost of stabilizing the system, let us use the letter $J$. $J$ captures two types of cost. Firstly, the controller dislikes when the system is not at its steady-state. In the equation below, this type of cost is captured by the matrix $Q$. Secondly, the controller dislikes spending energy to control the system. This second type of cost is captured by the matrix $R$:&lt;/p&gt;

&lt;p&gt;$$ J = \int_{0}^{\infty} \boldsymbol{x&amp;rsquo;}(t) Q \boldsymbol{x}(t) + \boldsymbol{u&amp;rsquo;}(t) R \boldsymbol{u}(t) dt $$&lt;/p&gt;

&lt;p&gt;A beautiful result from the LQR theory is that the optimal control from the controller is simply a linear function of the current state of the system:&lt;/p&gt;

&lt;p&gt;$$ \boldsymbol{u} = - C \boldsymbol{x}$$&lt;/p&gt;

&lt;p&gt;When the system is controlled optimally, the equation governing the evolution of the system writes:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \boldsymbol{x} = A \boldsymbol{x} - B  C \boldsymbol{x} $$&lt;/p&gt;

&lt;h2 id=&#34;ii-simulating-forward-an-ordinary-differential-equation-in-python&#34;&gt;II. Simulating forward an ordinary differential equation in Python&lt;/h2&gt;

&lt;p&gt;Having summarized what the LQR framework is, we can now give an illustration of how it works using a simple example using Python. For what follows, you will need the following packages:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
import matplotlib.pyplot as plt
plt.style.use(&#39;ggplot&#39;)
%matplotlib inline
import numpy as np
from control.matlab import *  # MATLAB-like functions
#to solve ODE
from scipy import integrate
#show the version of Python I am using:
!python3 --version
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Python 3.5.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s study optimal control for the following differential equation:&lt;/p&gt;

&lt;p&gt;$$\begin{cases} \frac{d}{dt} x =\mu x \\ \frac{d}{dt} y = \lambda (y - x^2) \end{cases}$$&lt;/p&gt;

&lt;p&gt;Two observations on this dynamical system. Firstly, the system is not linear, but we will see how to deal with that in a minute. Secondly, by eyeballing the equation, it is easy to see that when $\mu &amp;lt; 1$ and $\lambda &amp;lt; 1$, the unique fixed point is&lt;/p&gt;

&lt;p&gt;$$ \begin{pmatrix} x_{SS} \\ y_{SS} \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix} $$&lt;/p&gt;

&lt;p&gt;We can convince ourselves by simulating forward the trajectory of the system using different starting values.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s notice that the system can be written as a linear one, plus a part that is nonlinear:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} \mu &amp;amp; 0 \\ 0 &amp;amp; \lambda \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} +  \begin{pmatrix} O \\ -  \lambda x^2 \end{pmatrix} $$&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \begin{pmatrix} x \\ y \end{pmatrix} = A \begin{pmatrix} x \\ y \end{pmatrix} +  \begin{pmatrix} O \\ -  \lambda x^2 \end{pmatrix}$$&lt;/p&gt;

&lt;p&gt;The following block of code defines the parameter values, the matrix A for the linear part of the differential equation and the matrix B specifying that the controller can only act on x. We also specify the time span during which we want to simulate forward the trajectories:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Parameters and matrices A and B:
mu = -0.05
llambda = -1.0
A = np.array([[mu, 0], [0, llambda]])
B = np.array([[0], [1]])
# Time span
t0, t1 = 0, 100 # start and end
t = np.arange(t0, t1, 0.01)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A clean way to simulate forward the trajectory is to define a function that return the evolution of the system:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Function that defines the dynamic system:
def vdp0(t, y):
    # linear part + nonlinear part:
    x = A.dot(y) + np.array([0, -llambda*(y[0]**2)])
    return x
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We then define 4 different starting values and simulate forward the system using the &lt;code&gt;scipy.integrate&lt;/code&gt; toolkit:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Set of starting values:
y0A = np.array([1.5, -1])
y0B = np.array([-1.5, -1])
y0C = np.array([5, 5])
y0D = np.array([-5, 5])

# To store the different trajectories
list_y = []

# Method for the ODE:
# This is an explicit runge-kutta method of order (4)5 due to Dormand &amp;amp; Prince
integrator = &amp;quot;dopri5&amp;quot;

# Loop over the different starting values and calculate trajectories:
for y0 in [y0A, y0B, y0C,y0D]:
    # initialize an array to store the solution
    y = np.zeros((len(t), len(y0)))   # array for solution
    r0 = integrate.ode(vdp0).set_integrator(integrator)
    r0.set_initial_value(y0, t0)   # initial values
    for i in range(1, t.size):
       y[i, :] = r0.integrate(t[i]) # get one more value, add it to the array
       if not r0.successful():
           raise RuntimeError(&amp;quot;Could not integrate&amp;quot;)
    # append the list of solution
    list_y.append(y)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then plot the trajectories we just calculated on a same graph using &lt;code&gt;matplotlib&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Plot the different paths:
fig, ax = plt.subplots(figsize=(10, 5))

for index,y0 in enumerate([y0A, y0B, y0C, y0D]):
    ax.plot(list_y[index][1:-1, 0], list_y[index][1:-1, 1], label = str(y0))
    plt.xlabel(&amp;quot;x&amp;quot;)
    plt.ylabel(&amp;quot;y&amp;quot;)
plt.title(&amp;quot;Trajectories for different starting values&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartI_20_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;From the graph, we see that $y$ moves very quickly to the parabola defined by $y = x^2$. Then, the system slowly converges
towards $(0,0)$, moving along the same parabola.&lt;/p&gt;

&lt;p&gt;Before moving to the optimal control of the system, let us calculate the total cost $J$ of letting the system
converging naturally to its steady state value:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Store the cost associated with each starting value:
list_cost = []
for y in list_y:
    JLQR = np.cumsum( np.square(y[:, 0]) + np.square(y[:, 1]) )
    # append the list of solution
    list_cost.append(JLQR)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next plot shows the cumulative cost as time passes. The further away the starting value is from the steady-state, the higher the cost. We also see that because the cost function treats negative and positive deviations from the steady state the same way (because deviations are squared), the cost for the starting values (1.5, -1) and (-1.5, -1) are the same. The same observation holds for (5, 5) and (-5, 5).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Plot the cost associated with each starting value:
fig, ax = plt.subplots(figsize=(10, 5))
for JLQR, y0 in zip(list_cost,[y0A, y0B, y0C, y0D]):
    plt.plot(t, JLQR, label = str(y0))
    plt.xlabel(&amp;quot;t&amp;quot;)
    plt.ylabel(&amp;quot;JLQR&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartI_25_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;iii-solving-for-the-optimal-control&#34;&gt;III. Solving for the optimal control&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s first define the matrices Q and R, before solving for the optimal control matrix $C$ using the &lt;code&gt;lqr&lt;/code&gt; function from the &lt;a href=&#34;https://python-control.readthedocs.io/en/0.8.3/&#34; target=&#34;_blank&#34;&gt;Python Control Systems Library&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;R = np.array([1])
Q = np.eye(2)
# Solve for C:
(C, X, E) = lqr(A, B, Q, R)
print(&amp;quot;Feedback matrix C : {}&amp;quot;.format(C))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Feedback matrix C : [[0.         0.41421356]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now proceed as previously to simulate forward the differential equation. The only difference is that
now we have to take into account the optimal control applied each period on the system. The optimal control is
taken into consideration in the function &lt;code&gt;vdp1(t, y)&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def vdp1(t, y):
    # Ay - B*X*y + Cy
    x = A.dot(y)  - np.matmul(B,C).dot(y)
    return x + np.array([0, -llambda*(y[0]**2)])

y0 = [-5, 5]                   # initial value
y = np.zeros((len(t), len(y0))) # array for solution
y[0, :] = y0

r = integrate.ode(vdp1).set_integrator(integrator)
r.set_initial_value(y0, t0)   # initial values

for i in range(1, t.size):
   y[i, :] = r.integrate(t[i]) # get one more value, add it to the array
   if not r.successful():
       raise RuntimeError(&amp;quot;Could not integrate&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now compare the controlled trajectory (in red) to the uncontrolled trajectory (in blue):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig, ax = plt.subplots(figsize=(10, 5))
plt.plot(y[:, 0], y[:, 1], label = &amp;quot;controlled&amp;quot;)
plt.plot(list_y[index][1:-1, 0], list_y[index][1:-1, 1], label = &amp;quot;uncontrolled&amp;quot;)
plt.xlabel(&amp;quot;x&amp;quot;)
plt.ylabel(&amp;quot;y&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartI_32_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;With the controlled trajectory, the deviation of $y$ from its steady state value is less extreme. The system converges to $(0,0)$ on a different parabola. As expected, controlling the system with the optimal controller is less costly than letting the system evolve uncontrolled:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;JLQR = np.cumsum( np.square(y[:, 0]) + np.square(y[:, 1]) + np.square(np.matmul(C, y.T)) ).T

fig, ax = plt.subplots(figsize=(10, 5))
plt.plot(t, JLQR, label = &amp;quot;controlled&amp;quot;)
plt.plot(t, list_cost[3], label = &amp;quot;uncontrolled&amp;quot;)
plt.xlabel(&amp;quot;t&amp;quot;)
plt.ylabel(&amp;quot;JLQR&amp;quot;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Koopman_Control_Python_PartI_34_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;iv-what-about-lambda-x-2-linearizing-the-nonlinear-system&#34;&gt;IV. What about $-\lambda x^2$? Linearizing the nonlinear system&lt;/h2&gt;

&lt;p&gt;$$ \frac{d}{dt} \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} \mu &amp;amp; 0 \\ 0 &amp;amp; \lambda \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} +  \begin{pmatrix} O \\ -  \lambda x^2 \end{pmatrix} $$&lt;/p&gt;

&lt;p&gt;A careful reader would have noticed that we used a linear controller on a non-linear system. Is it legitimate? Intuitively, we ignored the term $-\lambda x^2$, which is small when $x &amp;lt; 1$ and/or when $\lambda$ is small. We can show more &amp;ldquo;rigorously&amp;rdquo; that what we did makes sense.&lt;/p&gt;

&lt;p&gt;Let us remember that the dynamical system is:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dt} \begin{pmatrix} x \\ y \end{pmatrix} = f \Big(  \begin{pmatrix} x \\ y \end{pmatrix}, t \Big) $$&lt;/p&gt;

&lt;p&gt;Or more precisely:&lt;/p&gt;

&lt;p&gt;$$ \begin{cases} \frac{d}{dt} x = \mu x \\ \frac{d}{dt} y = \lambda (y - x^2)  \end{cases} $$&lt;/p&gt;

&lt;p&gt;A first order Taylor expansion around the steady-state gives us:&lt;/p&gt;

&lt;p&gt;$$ \boldsymbol{x} - \boldsymbol{x_{ss}} \approx A (\boldsymbol{x} - \boldsymbol{x_{ss}}) $$&lt;/p&gt;

&lt;p&gt;Where $A$ is the Jacobian matrix (matrix of first derivatives) evaluated at the steady-state value, which is (0,0) in our simple example. The first derivatives are:&lt;/p&gt;

&lt;p&gt;$$ \frac{d}{dx}(\frac{d}{dt}x) = \mu  \\ \frac{d}{dy}(\frac{d}{dt}x) = 0 \\ \frac{d}{dx}(\frac{d}{dt}y) = \lambda \\ \frac{d}{dy}(\frac{d}{dt}y)= -2 \lambda x $$&lt;/p&gt;

&lt;p&gt;Evaluated at the steady-state, the matrix A is equal to:&lt;/p&gt;

&lt;p&gt;$$ A = \begin{pmatrix} \mu &amp;amp; 0 \\ -2 \lambda \times 0 &amp;amp; \lambda \end{pmatrix} = \begin{pmatrix} \mu &amp;amp; 0 \\ 0 &amp;amp; \lambda \end{pmatrix} $$&lt;/p&gt;

&lt;p&gt;and because the steady-state is $(0,0)$, we have $\tilde{x} = x$. The take-away is that in the neighborhood of the steady-state $(0,0)$, we can solve the LQR ignoring the $-\lambda x^2$ term.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This notebook introduced what the LQR framework and showed how to solve for the optimal control in Python. We saw that despite the fact that the example we studied is not linear, we can linearize the dynamical system around its stead-state. In the Part II of this series on the LQR framework, we will see that we can do even better by solving the dynamical system in a new space, in which the system is exactly linear.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;The linear system studied in this notebook is based on the paper: Brunton, Steven L., et al. &amp;ldquo;Koopman invariant subspaces and finite linear representations of nonlinear dynamical systems for control.&amp;rdquo; PloS one 11.2 (2016).&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Primer on Computer Vision</title>
      <link>https://julienpascal.github.io/post/cnn/</link>
      <pubDate>Thu, 05 Dec 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/cnn/</guid>
      <description>

&lt;p&gt;For a specific project on the housing market (&lt;a href=&#34;https://julienpascal.github.io/project/rentalmarket/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;), I had to analyze thousands of photos. To do that, I used a &lt;strong&gt;convolutional neural network&lt;/strong&gt; (CNN), which is a fancy name for a complicated function that can be &amp;ldquo;trained&amp;rdquo; to recognize patterns in images. In this blog post, I would like to introduce the &lt;strong&gt;&amp;ldquo;Hello World&amp;rdquo;&lt;/strong&gt; of computer vision and CNN: the classification of hand-written digits from the &lt;a href=&#34;https://en.wikipedia.org/wiki/MNIST_database&#34; target=&#34;_blank&#34;&gt;MNIST dataset&lt;/a&gt;. There are thousands of tutorials on the same topic using Python freely available on the Internet. Instead, let&amp;rsquo;s use Julia and the package &lt;strong&gt;Flux.jl&lt;/strong&gt;. Why? Because &lt;strong&gt;Julia is fast&lt;/strong&gt;, and if you have millions of images to analyze, the speed up could be substantial compared to Python. The Jupyter notebook used to generate this post can be found &lt;a href=&#34;https://github.com/JulienPascal/CNNPrimer&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;

&lt;p&gt;The MNIST dataset contains images of hand-written digits (0 to 9) in grayscale and that are nicely centered. Each pixel is represented by a number in between 0 (black) and 255 (white). Each image is 28 by 28 pixels. One way to represent an image is to see it as a 1d-column vector of 28*28 = 784 pixels. However, this representation ignores the &amp;ldquo;structure&amp;rdquo; of an image: pixels that are close to each others are informative on the digit we are trying to identify. A CNN is a good tool to keep the spatial structure of an image, while avoiding issues linked to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Curse_of_dimensionality&#34; target=&#34;_blank&#34;&gt;curse of dimensionality&lt;/a&gt;: images are noisy and high-dimensional input data.&lt;/p&gt;

&lt;h2 id=&#34;a-crash-course-on-cnn&#34;&gt;A crash course on CNN&lt;/h2&gt;

&lt;p&gt;Two of the key ingredients of a CNN are a &lt;strong&gt;convolutional layer&lt;/strong&gt; (hence the name) and a &lt;strong&gt;maxpool layer&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;convolutional-layer&#34;&gt;Convolutional layer&lt;/h3&gt;

&lt;p&gt;A convolutional layer applies a &lt;em&gt;stencil&lt;/em&gt; to each point. The output of a convolutional layer is an &amp;ldquo;image&amp;rdquo; of lower dimension, that is informative on some features of the input image (shapes, edges, etc.). The figure below shows how a convolutional layer works:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;convolution.gif&#34; alt=&#34;alt text&#34; /&gt;
source:&lt;a href=&#34;https://mitmath.github.io/18337/lecture14/pdes_and_convolutions&#34; target=&#34;_blank&#34;&gt;https://mitmath.github.io/18337/lecture14/pdes_and_convolutions&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;maxpool-layer&#34;&gt;Maxpool layer&lt;/h3&gt;

&lt;p&gt;A maxpool layer is a &lt;em&gt;stencil&lt;/em&gt; that selects the maximum value within a square. Below is an illustration of a maxpool layer applied to a $ 4 \times 4$ image:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;maxpool.gif&#34; alt=&#34;alt text&#34; /&gt;
source:&lt;a href=&#34;https://mauriciocodesso.com/post/convolution-neural-network/&#34; target=&#34;_blank&#34;&gt;https://mauriciocodesso.com/post/convolution-neural-network/&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;stride-and-padding&#34;&gt;Stride and Padding&lt;/h3&gt;

&lt;p&gt;When building a CNN, one must specify two hyper parameters: &lt;strong&gt;stride and padding&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;When the stride is equal to 1, we move the filters one pixel at a time. When stride is equal to 2, we move the filters two pixel at a time, etc.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Padding refers to &amp;ldquo;adding zeroes&amp;rdquo; at the border of an image. Padding can be used to control the size of the output volume and helps in keeping information at the border of images&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below is an example of a $3 \times 3$ filter applied to a $5 \times 5$ input padded with a $1 \times 1$ border of zeros using $2 \times 2$ strides:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;padding_strides.gif&#34; alt=&#34;alt text&#34; /&gt;
source: &lt;a href=&#34;http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html&#34; target=&#34;_blank&#34;&gt;http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The typical infrastructure of a CNN is first to apply a convolutional layer to the input image, then to use a maxpool layer, before using a fully-connected layer. Several &amp;ldquo;convolutional layer - maxpool layer&amp;rdquo; units can be stacked together before using a fully-connected (FC) layer. Note that an activation layer (often &lt;a href=&#34;https://en.wikipedia.org/wiki/Rectifier_(neural_networks)&#34; target=&#34;_blank&#34;&gt;ReLU&lt;/a&gt;) is generally inserted between the the convolutional and the maxpool layer.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;architecture.png&#34; alt=&#34;alt text&#34; /&gt;
source: &lt;a href=&#34;https://towardsdatascience.com/visualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&#34; target=&#34;_blank&#34;&gt;https://towardsdatascience.com/visualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;using-flux-jl&#34;&gt;Using Flux.jl&lt;/h2&gt;

&lt;p&gt;Flux.jl is a leading machine learning package in the Julia ecosystem. In what follows, we load both the train and the test samples of the MNIST dataset. The train sample is a set of images used to fine-tune the parameters of the CNN, while the test sample contains images used to check that we did not overfit the train sample. A smoking gun for overfitting is when the accuracy in the train sample is much better than the accuracy using images from the test sample.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Flux, Flux.Data.MNIST, Statistics
using Flux: onehotbatch, onecold, crossentropy, throttle
using Base.Iterators: repeated, partition
using Printf, BSON
using ImageView

# Load labels and images from Flux.Data.MNIST
# Train set: images used to estimate the CNN
train_labels = MNIST.labels(:train)
train_imgs = MNIST.images(:train);

# Test set: images used to see how well the CNN perform &amp;quot;out-of-the-sample&amp;quot;
test_imgs = MNIST.images(:test)
test_labels = MNIST.labels(:test)

print(&amp;quot;Images in the train set: $(size(train_imgs))&amp;quot;)
print(&amp;quot;Images in the test set: $(size(test_imgs))&amp;quot;)

# Visualization of one digit
NROWS, NCOLS = 28, 28
a = reshape(train_imgs[1], NROWS, NCOLS)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Images in the train set: (60000,)Images in the test set: (10000,)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;CNN_13_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;cnn-architecture&#34;&gt;CNN architecture&lt;/h2&gt;

&lt;p&gt;Our CNN has the usual CONV-&amp;gt;ReLU-&amp;gt;MaxPool components, before using a FC layer. We use a $1 \times 1$ padding and a stride of $1$ (the default value). The size of input is gradually reduced by using $2 \times 2$ maxpool layers. The default activation in Flux.jl is the function is $ x-&amp;gt;x $. Here, we use the Rectified Linear Unit function (ReLU) instead:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;model = Chain(
    # First convolution, operating upon a 28x28 image
    Conv((3, 3), 1=&amp;gt;16, pad=(1,1), relu),
    MaxPool((2,2)), #maxpooling

    # Second convolution, operating upon a 14x14 image
    Conv((3, 3), 16=&amp;gt;32, pad=(1,1), relu),
    MaxPool((2,2)), #maxpooling

    # Third convolution, operating upon a 7x7 image
    Conv((3, 3), 32=&amp;gt;32,pad=(1,1), relu),
    MaxPool((2,2)),

    # Reshape 3d tensor into a 2d one, at this point it should be (3, 3, 32, N)
    # which is where we get the 288 in the `Dense` layer below:
    x -&amp;gt; reshape(x, :, size(x, 4)),
    Dense(288, 10),

    # Softmax to get probabilities
    softmax,
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The ReLU activation function is a piece-wise linear function. In the &lt;a href=&#34;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks&#34; target=&#34;_blank&#34;&gt;‚ÄúImageNet Classification with Deep Convolutional Neural Networks&amp;rdquo;&lt;/a&gt; paper by Krizhevsky and coauthors, the authors write:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;we refer to neurons with this nonlinearity as Rectified Linear Units (ReLUs). Deep convolutional neural networks with ReLUs train several times faster than their equivalents with tanh units.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The ReLU activation function also helps in reducing the practical issues caused by &lt;a href=&#34;https://en.wikipedia.org/wiki/Vanishing_gradient_problem&#34; target=&#34;_blank&#34;&gt;the vanishing gradient problem&lt;/a&gt;. That is, the failure of the minizimation algorithm used to find the parameters of our CNN. Below is a plot of the ReLU activation function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;xgrid = collect(range(-1, 1, length=100))
plot(xgrid, NNlib.relu.(xgrid), label = &amp;quot;relu(x)&amp;quot;, title=&amp;quot;ReLU activation function&amp;quot;, xlabel=&amp;quot;x&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;CNN_18_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;training&#34;&gt;Training&lt;/h2&gt;

&lt;h3 id=&#34;batching&#34;&gt;Batching&lt;/h3&gt;

&lt;p&gt;The batch size is a parameter that tells us how many images the network will &amp;ldquo;see&amp;rdquo; at once when &amp;ldquo;training&amp;rdquo;.
In technical terms, when performing gradient descent, we don&amp;rsquo;t use all the information at once (because of memory limitations and because it is not necessarily efficient). The following function generates &amp;ldquo;batches&amp;rdquo; of images:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Bundle images together with labels and group into minibatchess
function make_minibatch(X, Y, idxs)
    X_batch = Array{Float32}(undef, size(X[1])..., 1, length(idxs))
    for i in 1:length(idxs)
        X_batch[:, :, :, i] = Float32.(X[idxs[i]])
    end
    Y_batch = onehotbatch(Y[idxs], 0:9)
    return (X_batch, Y_batch)
end
# The CNN only &amp;quot;sees&amp;quot; 128 images at each training cycle:
batch_size = 128
mb_idxs = partition(1:length(train_imgs), batch_size)
# train set in the form of batches
train_set = [make_minibatch(train_imgs, train_labels, i) for i in mb_idxs];
# train set in one-go: used to calculate accuracy with the train set
train_set_full = make_minibatch(train_imgs, train_labels, 1:length(train_imgs));
# test set: to check we do not overfit the train data:
test_set = make_minibatch(test_imgs, test_labels, 1:length(test_imgs));
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;loss-function-and-minimization&#34;&gt;Loss function and minimization&lt;/h3&gt;

&lt;p&gt;For the CNN to &amp;ldquo;learn&amp;rdquo; anything at all, it must have a notion of &amp;ldquo;wrong&amp;rdquo; or &amp;ldquo;right&amp;rdquo;. The loss function does exactly that, by quantifying how well the model performs at recognizing digits. When the output is a probability, the &lt;a href=&#34;https://en.wikipedia.org/wiki/Cross_entropy&#34; target=&#34;_blank&#34;&gt;cross entropy&lt;/a&gt; loss function is appropriate. The final step is to select an algorithm to minimize the loss function. Here, let&amp;rsquo;s select the &lt;a href=&#34;https://arxiv.org/abs/1412.6980&#34; target=&#34;_blank&#34;&gt;ADAM&lt;/a&gt; algorithm, which I understand as some sort of &lt;a href=&#34;https://julienpascal.github.io/post/ols_ml/&#34; target=&#34;_blank&#34;&gt;Stochastic Gradient Descent&lt;/a&gt; with momentum and adaptive learning rate:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# `loss()` calculates the crossentropy loss between our prediction `y_hat`
# We augment the data a bit, adding gaussian random noise to our image to make it more robust.
function loss(x, y)
    # Add some noise to the image
    # we reduce the risk of overfitting the train sample by doing so:
    x_aug = x .+ 0.1f0*gpu(randn(eltype(x), size(x)))

    y_hat = model(x_aug)
    return crossentropy(y_hat, y)
end
accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))

# ADAM optimizer
opt = ADAM(0.001);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This block &amp;ldquo;train&amp;rdquo; (fine-tune the CNN parameter values) the model until a pre-determined accuracy level is reached:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;best_acc = 0.0
last_improvement = 0
accuracy_target = 0.97 #Set an accuracy target. When reached, we stop training.
max_epochs = 100 #Maximum
for epoch_idx in 1:100
    global best_acc, last_improvement
    # Train for a single epoch
    Flux.train!(loss, params(model), train_set, opt)

    # Calculate accuracy:
    acc = accuracy(train_set_full...)
    @info(@sprintf(&amp;quot;[%d]: Train accuracy: %.4f&amp;quot;, epoch_idx, acc))

    # Calculate accuracy:
    acc = accuracy(test_set...)
    @info(@sprintf(&amp;quot;[%d]: Test accuracy: %.4f&amp;quot;, epoch_idx, acc))

    # If our accuracy is good enough, quit out.
    if acc &amp;gt;= accuracy_target
        @info(&amp;quot; -&amp;gt; Early-exiting: We reached our target accuracy of $(accuracy_target*100)%&amp;quot;)
        break
    end

    if epoch_idx - last_improvement &amp;gt;= 10
        @warn(&amp;quot; -&amp;gt; We&#39;re calling this converged.&amp;quot;)
        break
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;‚îå Info: [1]: Train accuracy: 0.9579
‚îî @ Main In[14]:12
‚îå Info: [1]: Test accuracy: 0.9605
‚îî @ Main In[14]:16
‚îå Info: [2]: Train accuracy: 0.9749
‚îî @ Main In[14]:12
‚îå Info: [2]: Test accuracy: 0.9756
‚îî @ Main In[14]:16
‚îå Info:  -&amp;gt; Early-exiting: We reached our target accuracy of 97.0%
‚îî @ Main In[14]:20
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;predictions&#34;&gt;Predictions&lt;/h2&gt;

&lt;p&gt;Once the model is trained, predicted values are easily obtained as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Get predictions and convert data to Array:
pred = Tracker.data(model(test_set[1]));
# Show the first 5 predictions
# One column is an image
# Each row corresponds to the probability of a digit
pred[:,1:5]
# Function to get the row index of the max value:
f1(x) = getindex.(argmax(x, dims=1), 1)
# Final predicted value is the one with the maximum probability:
pred = f1(pred) .- 1; #minus 1 because the first element is 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s see how the model performs on the test set. Can the CNN recognize digits using images that were not used when training the model? As you can see below, our model does an amazing job at recognizing hand-written digits:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;println(&amp;quot;Predicted value = $(pred[1])&amp;quot;)
a = reshape(test_imgs[1], NROWS, NCOLS)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Predicted value = 7
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;CNN_30_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;println(&amp;quot;Predicted value = $(pred[2])&amp;quot;)
a = reshape(test_imgs[2], NROWS, NCOLS)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Predicted value = 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;CNN_31_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;println(&amp;quot;Predicted value = $(pred[3])&amp;quot;)
a = reshape(test_imgs[3], NROWS, NCOLS)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Predicted value = 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;CNN_32_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;accuracy-checks&#34;&gt;Accuracy checks&lt;/h3&gt;

&lt;p&gt;We now have a model that seems to do quite a good job in recognizing digits. But can we improve it? If yes, how?
To improve our model, we first need to identify when and why it fails.&lt;/p&gt;

&lt;h4 id=&#34;confusion-matrix&#34;&gt;Confusion matrix&lt;/h4&gt;

&lt;p&gt;To do that, a useful reporting
tool is a &lt;strong&gt;confusion matrix&lt;/strong&gt;. Each row of a confusion matrix shows instances of the true value, while each column displays instances of the predicted value. Ideally, we would like our model to perfectly predict the outcome. With a perfect model, all instances would be located on the diagonal elements of the confusion matrix.&lt;/p&gt;

&lt;p&gt;The last time I checked, &lt;code&gt;Flux.jl&lt;/code&gt; did not have an in-built function to calculate confusion matrices. Fortunately, an implementation is available in the package &lt;code&gt;MLBase&lt;/code&gt;. The next block of code calculates the confusion matrix and displays it. Most of instances are on located on the diagonal, which is not a surprise given that the accuracy rate for our model is more than $97.0\%$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using MLBase
# Adding 1 to outcome because the index 0 in arrays does not exist in Julia
Cm = confusmat(10, test_labels .+ 1, vec(pred) .+ 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;10√ó10 Array{Int64,2}:
 968     1     1    0    0    4    3    1    2    0
   0  1128     3    0    0    0    1    0    3    0
   3     5  1003    6    1    1    0    6    7    0
   0     0     1  992    0   10    0    2    4    1
   0     1     2    0  972    0    0    1    1    5
   1     0     1    4    0  883    1    1    1    0
   1     4     0    0    1   13  936    0    3    0
   1     7    10    5    0    1    0  986    3   15
   2     0     4    6    4    8    2    4  942    2
   4     4     0    7    7   10    0    8    2  967
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Normalize output:
Cm  = Cm ./ sum(Cm, dims=2)
# Labels
xs = [string(i) for i = 0:9]
heatmap(xs, xs, Cm, aspect_ratio=1, color=:plasma)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;CNN_41_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;To visualize where our model makes mistakes, one can use the optional argument &lt;code&gt;clim&lt;/code&gt;, to put an upper bound on
the underlying colormap. For instance, the next plot shows that our model has troubles differencing 7 and 2 or 8 and 2.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Limits to colormap, so we can see where errors are located:
xs = [string(i) for i = 0:9]
heatmap(xs, xs, Cm, aspect_ratio=1, color=:plasma, clim=(0., 0.01))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;CNN_43_0.svg&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;error-analysis&#34;&gt;Error Analysis&lt;/h4&gt;

&lt;p&gt;The next block of code displays digits for which our CNN failed:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# indices for errors:
using ImageView, Gtk.ShortNames
mistakes = test_labels .!= vec(pred)
max_images = 5
grid, frames, canvases = canvasgrid((1,max_images)); # 1 row
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;k=0#counter for mistakes
for (j, i) in enumerate(mistakes)
    if i == true
        k+=1 # a false value has been found
        println(&amp;quot;Predicted value = $(pred[j])&amp;quot;)
        println(&amp;quot;True value = $(test_labels[j])&amp;quot;)
        imshow(canvases[1,k], test_imgs[j])
        idx = ImageView.annotate!(guidict, AnnotationText(0, 0, &amp;quot;$(pred[j])&amp;quot;, color=RGB(0,0,0), fontsize=3))
    end
    if k &amp;gt;= max_images
        break
    end
end
win = Window(grid);
Gtk.showall(win);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Predicted value = 5
True value = 9
Predicted value = 5
True value = 6
Predicted value = 4
True value = 8
Predicted value = 3
True value = 2
Predicted value = 7
True value = 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;false_values.png&#34; alt=&#34;alt&#34; /&gt;&lt;/p&gt;

&lt;p&gt;While it seems obvious that the two digits starting from the left are a 9 and a 6, the remaining 3 elements are not trivial. The 8 in the middle could be easily confused with something else and the two remaining digits are weirdly shaped.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;When dealing with images, a convolutional neural network generally does an amazing job at recognizing patterns. This blog post was a non-technical introduction to the topic. While Python is the tool of predilection in machine learning (Keras, TensorFlow, etc.), my guess is that Julia will get increasingly popular because Julia is both easy to use and fast.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;This blog post is heavily based on this Flux.jl tutorial: &lt;a href=&#34;https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl&#34; target=&#34;_blank&#34;&gt;https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;On the links between CNN and PDEs: &lt;a href=&#34;https://mitmath.github.io/18337/lecture14/pdes_and_convolutions&#34; target=&#34;_blank&#34;&gt;https://mitmath.github.io/18337/lecture14/pdes_and_convolutions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A full course on CNN. Most of the content is available online: &lt;a href=&#34;http://cs231n.github.io/convolutional-networks/&#34; target=&#34;_blank&#34;&gt;http://cs231n.github.io/convolutional-networks/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Logistic Regression from Scratch</title>
      <link>https://julienpascal.github.io/post/logistic/</link>
      <pubDate>Fri, 22 Nov 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/logistic/</guid>
      <description>

&lt;p&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Logistic_regression&#34; target=&#34;_blank&#34;&gt;logistic model&lt;/a&gt; (also called logit model) is a natural candidate when one is interested in a &lt;strong&gt;binary outcome&lt;/strong&gt;. For instance, a researcher might be interested in knowing what makes a politician successful or not. For the purpose of this blog post, &amp;ldquo;success&amp;rdquo;
means the probability of winning an election. In that case, it would be sub-optimal
to use a linear regression model to see what factors are associated with successful
politicians, as the outcome variable is binary (a politician either wins or loses an election).
The linear model is built around the idea that the outcome variable is continuous.&lt;/p&gt;

&lt;p&gt;What if the statistician tries to identify what factors are influencing the &lt;strong&gt;probability&lt;/strong&gt; of
winning? This strategy naturally lends itself to using a &lt;a href=&#34;https://en.wikipedia.org/wiki/Logistic_regression&#34; target=&#34;_blank&#34;&gt;logistic model&lt;/a&gt; (or a &lt;a href=&#34;https://en.wikipedia.org/wiki/Probit_model&#34; target=&#34;_blank&#34;&gt;probit&lt;/a&gt;).
In this blog post, I derive the &lt;strong&gt;logistic model from scratch&lt;/strong&gt; and show how one
can estimate its parameters using &lt;strong&gt;gradient descent&lt;/strong&gt; or &lt;strong&gt;Newton-Raphson&lt;/strong&gt; algorithms. I also use data on &lt;strong&gt;NBA players&lt;/strong&gt; to see what factors are influencing the &lt;strong&gt;success of a shot&lt;/strong&gt;. The GitHub repository for this post can be
found &lt;a href=&#34;https://github.com/JulienPascal/LogisticRegression&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;the-logistic-model&#34;&gt;The logistic model&lt;/h2&gt;

&lt;p&gt;The outcome variable $y_i$ is either $1$ (&amp;ldquo;winning&amp;rdquo;) or $0$ (&amp;ldquo;losing&amp;rdquo;). The logistic
model makes the assumption that the probability of winning is given by the logistic
function :&lt;/p&gt;

&lt;p&gt;$$ f(y_i | x_{i}, \theta_{i}) =  \sigma(x_{i} &amp;lsquo;\theta)$$&lt;/p&gt;

&lt;p&gt;with $\sigma(v) = \frac{exp(v)}{1+exp(v)}$&lt;/p&gt;

&lt;p&gt;The probability of losing is 1 minus the probability of wining:&lt;/p&gt;

&lt;p&gt;$$ f(y_i | x_{i}, \theta) =  1 - \sigma(x_{i} &amp;lsquo;\theta)$$&lt;/p&gt;

&lt;h2 id=&#34;a-latent-variable-formulation&#34;&gt;A latent variable formulation&lt;/h2&gt;

&lt;p&gt;A powerful way of interpreting the logistic model is to see it as the outcome of a latent variable model.
An unobservable latent variable $z_{i}$ depends linearly on $x_{i}$ plus a noise term $\varepsilon_{i}$:&lt;/p&gt;

&lt;p&gt;$$ z_{i} = x_{i} &amp;lsquo;\theta + \varepsilon_{i} $$&lt;/p&gt;

&lt;p&gt;We only observe $y_i$, which is equal to 1 when $z_{i}$ is strictly positive, and 0 otherwise. If the error term is distributed according to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Logistic_distribution&#34; target=&#34;_blank&#34;&gt;logistic distribution&lt;/a&gt;, we end up with the logistic model described above. If the error term is normally distributed, the model is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Probit_model&#34; target=&#34;_blank&#34;&gt;probit model&lt;/a&gt;. To see that, simply express the probability of the latent variable to be bigger than 0:&lt;/p&gt;

&lt;p&gt;$$ f(y_i | x_{i}, \theta_{i}) = P( x_{i} &amp;lsquo;\theta + \varepsilon_{i} &amp;gt; 0) $$
$$  = 1 - P( x_{i} &amp;lsquo;\theta + \varepsilon_{i} \leq 0) $$
$$  = 1 - P(\varepsilon_{i} \leq - x_{i} &amp;lsquo;\theta ) $$
$$  = 1 - P(\varepsilon_{i} \leq - x_{i} &amp;lsquo;\theta ) $$
$$  = \frac{exp(x_{i} &amp;lsquo;\theta )}{1+exp(x_{i} &amp;lsquo;\theta )} $$&lt;/p&gt;

&lt;p&gt;where the last line comes from using the expression for the &lt;a href=&#34;https://en.wikipedia.org/wiki/Logistic_distribution&#34; target=&#34;_blank&#34;&gt;cdf of the logistic distribution&lt;/a&gt; with zero mean and scale parameter equal to 1.&lt;/p&gt;

&lt;h2 id=&#34;interpretation-of-coefficients&#34;&gt;Interpretation of coefficients&lt;/h2&gt;

&lt;p&gt;How can we read the coefficients from a logistic model? The marginal effect of a change in $x_{ij}$ (the $jth$ component of $x_i$) on the probability that $y_i = 1$ is given by:&lt;/p&gt;

&lt;p&gt;$$ \frac{\partial f(y_i | x_{i}, \theta)}{\partial x_{ij}} = \sigma(x_{i} &amp;lsquo;\theta)(1-\sigma(x_{i} &amp;lsquo;\theta))\theta_j$$&lt;/p&gt;

&lt;p&gt;A first observation is that the marginal effect depends on $x_i$, unlike in the linear regression model. A second observation is that the first two terms are always positive, so we do have that the interpretation that if $\theta_j$ is positive, an increase in the $jth$ component of $x_i$ leads to a bigger probability of obtaining a success (holding everything else constant).&lt;/p&gt;

&lt;p&gt;Another way to read the results from a logistic model is to realize that it implies that the log of odd ratio is linear:&lt;/p&gt;

&lt;p&gt;$$ log\Big(\frac{f(y_i | x_{i}, \theta)}{1 - f(y_i | x_{i}, \theta)}\Big) = x_{i} &amp;lsquo;\theta$$&lt;/p&gt;

&lt;p&gt;Going back to what makes a politician successful in an election, if the coefficient $\theta_j$ is equal to 0.1, it means that a one unit increase in $x_{ij}$ rises the &lt;strong&gt;relative&lt;/strong&gt; probability of winning an election by approximately $10\%$.&lt;/p&gt;

&lt;h2 id=&#34;log-likelihood-function&#34;&gt;Log-likelihood function&lt;/h2&gt;

&lt;p&gt;To predict who is going to win the next elections, one must estimate the value of $\theta$ using the information contained in the sample $(y_i, x_i)_{i=1}^{N}$. One &amp;ldquo;natural&amp;rdquo; criterion is to find the value for $\theta$ that &lt;strong&gt;maximizes the probability of observing the
sample&lt;/strong&gt;. This procedure is called &lt;a href=&#34;https://en.wikipedia.org/wiki/Maximum_likelihood_estimation&#34; target=&#34;_blank&#34;&gt;Maximum likelihood estimation&lt;/a&gt;. Let us assume that sample is &lt;a href=&#34;https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables&#34; target=&#34;_blank&#34;&gt;i.i.d&lt;/a&gt;. If the i.i.d assumption holds, the probability of observing the sample $(y_i, x_i)_{i=1}^{N}$ is the product of the probability of observing each observation. Instead of maximizing the likelihood, it is more convenient to maximize the log-likelihood, which transforms the product of probabilities into a sum:&lt;/p&gt;

&lt;p&gt;$$ L((y_i, x_i)_{i=1}^{N};\theta) = log( \prod_{i=1}^{N}f(y_i | x_{i}, \theta)) = \sum_{i=1}^{N} log(f(y_i | x_{i}, \theta_{i}))$$&lt;/p&gt;

&lt;p&gt;The probability of observing $y_i$  can compactly be written as&lt;/p&gt;

&lt;p&gt;$$ f(y_i | x_{i}, \theta_{i}) = \sigma(x_{i} &amp;lsquo;\theta)^{y_i}(1 - \sigma(x_{i} &amp;lsquo;\theta))^{1 - y_i} $$&lt;/p&gt;

&lt;p&gt;Hence, the log-likelihood function writes:&lt;/p&gt;

&lt;p&gt;$$L((y_i, x_i)_{i=1}^{N};\theta) = \sum_{i=1}^{N} y_i log(\sigma(x_{i} &amp;lsquo;\theta)) + (1 - y_i)log(1 - \sigma(x_{i} &amp;lsquo;\theta))$$&lt;/p&gt;

&lt;h2 id=&#34;maximum-likelihood-estimation&#34;&gt;Maximum Likelihood Estimation&lt;/h2&gt;

&lt;p&gt;Taking the derivative of $f(y_i | x_{i}, \theta)$ with respect to the parameter $\theta$ gives:&lt;/p&gt;

&lt;p&gt;$$ f_{\theta}(y_i | x_{i}, \theta) = [y_i - \sigma(x_{i} &amp;lsquo;\theta)] x_{i} $$&lt;/p&gt;

&lt;p&gt;and the derivative of the log-likelihood function with respect to $\theta$ is:&lt;/p&gt;

&lt;p&gt;$$ L_{\theta}((y_i, x_i)_{i=1}^{N};\theta) = \sum_{i=1}^{N}[y_i - \sigma(x_{i} &amp;lsquo;\theta)] x_{i} $$&lt;/p&gt;

&lt;h2 id=&#34;gradient-descent&#34;&gt;Gradient descent&lt;/h2&gt;

&lt;p&gt;To make the link with this &lt;a href=&#34;https://julienpascal.github.io/post/ols_ml/&#34; target=&#34;_blank&#34;&gt;blog post&lt;/a&gt;, we can use gradient descent to find the MLE estimate:&lt;/p&gt;

&lt;p&gt;$$ \theta_{i+1} = \theta_{i} - \gamma \Big(- L_{\theta}((y_i, x_i)_{i=1}^{N};\theta_{i}) \Big)$$&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Gradient_descent&#34; target=&#34;_blank&#34;&gt;gradient descent&lt;/a&gt; algorithm is an iterative procedure to find a minimizer of a function. At each step, the algorithm takes a step of length $\gamma$ towards the direction of steepest descent. Note that I reformulated the problem of finding the maximum of a function $f$ (the log-likelihood) as the problem of finding the minimum of $-f$.&lt;/p&gt;

&lt;h2 id=&#34;newton-raphson-method&#34;&gt;Newton‚ÄìRaphson method&lt;/h2&gt;

&lt;p&gt;Roughly speaking, the Newton-Raphson method is a &amp;ldquo;smart&amp;rdquo; gradient descent which uses the information contained in the Hessian of the log-likelihood $HL((y_i, x_i)_{i=1}^{N};\theta_{i})$ (on top of the gradient) to make a right move toward the minimizer. This iterative algorithm proceeds as follows:&lt;/p&gt;

&lt;p&gt;$$ \theta_{i+1} = \theta_{i} - (HL((y_i, x_i)_{i=1}^{N};\theta_{i}) )^{-1}  \Big(- L_{\theta}((y_i, x_i)_{i=1}^{N};\theta_{i}) \Big)$$&lt;/p&gt;

&lt;p&gt;The next plot shows how the Newton-Raphson method works for a one dimensional root-finding problem:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/e/e0/NewtonIteration_Ani.gif&#34; alt=&#34;Alt Text&#34; /&gt;&lt;/p&gt;

&lt;p&gt;source: &lt;a href=&#34;https://en.wikipedia.org/wiki/Newton%27s_method&#34; target=&#34;_blank&#34;&gt;https://en.wikipedia.org/wiki/Newton%27s_method&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Should we use gradient descent or Newton-Raphson? I let the following extract
from the &lt;a href=&#34;https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization&#34; target=&#34;_blank&#34;&gt;Wikipedia article&lt;/a&gt; on Newton-Raphson speak for itself:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Where applicable&lt;/strong&gt;, Newton&amp;rsquo;s method &lt;strong&gt;converges much faster&lt;/strong&gt; towards a local maximum or minimum than gradient descent. In fact, every local minimum has a neighborhood N such that, if we start with x0 ‚àà N, Newton&amp;rsquo;s method with step size Œ≥ = 1 &lt;strong&gt;converges quadratically&lt;/strong&gt; (if the Hessian is invertible and a Lipschitz continuous function of x in that neighborhood).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For the logistic model, the Newton-Raphson algorithm is easily applicable because there exists a closed-form formula for the Hessian:&lt;/p&gt;

&lt;p&gt;$$ HL((y_i, x_i)_{i=1}^{N};\theta_{i}) = \sum_{i=1}^{N} - \sigma(x_{i} &amp;lsquo;\theta)[1 - \sigma(x_{i} &amp;lsquo;\theta)] x_{i} x_{i}&amp;lsquo;$$&lt;/p&gt;

&lt;h2 id=&#34;implementation-in-julia&#34;&gt;Implementation in Julia&lt;/h2&gt;

&lt;h2 id=&#34;i-working-with-simulated-data&#34;&gt;I. Working with simulated data&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s first work with simulated data. Can we actually recover the true parameter values using a manual implementation of the logistic model?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s load a few dependencies:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Distributions
using Plots
pyplot()
using DataFrames
using GLM
using Optim
using CSV
using GLM
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s create the logistic function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Logistic function for a scalar input:
function sigma(x::Float64)
    exp(x)/(1.0 + exp(x))
end

# Logistic function for a vector input:
function sigma(x::Array{Float64,1})
    exp.(x) ./ (1.0 .+ exp.(x))
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s create a function that calculates the likelihood:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function log_likelihood(y::Array{Float64,1}, X::Array{Float64,2}, theta::Array{Float64,1})
    sum = 0.0
    #Loop over individuals in the sample
    for i=1:size(X,1)
        sum += y[i]*log(sigma(transpose(X[i,:])*theta)) + (1.0 - y[i])*log(1.0 - sigma(transpose(X[i,:])*theta))
    end
    return sum
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s create a function that returns the derivative of the log-likelihood of the sample, which we need for the gradient descent algorithm:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Function to calculate the gradient of the log-likelihood of the sample:
function derivative_log_likelihood(y::Array{Float64,1}, X::Array{Float64,2}, theta::Array{Float64,1})
    sum = zeros(size(X,2))
    #Loop over individuals in the sample
    for i=1:size(X,1)
        sum .+= (y[i] - sigma(transpose(X[i,:])*theta))*X[i,:]
    end
    return sum
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s create a function that returns the Hessian of the log-likelihood of the sample, which we need for the Newthon-Raphson algorithm:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Function to calculate the hessian of the log-likelihood of the sample:
function hessian_log_likelihood(y::Array{Float64,1}, X::Array{Float64,2}, theta::Array{Float64,1})
    hessian = zeros(size(X,2), size(X,2))
    #Loop over individuals in the sample
    for i=1:size(X,1)
        hessian .+= - sigma(transpose(X[i,:])*theta)*(1.0 - sigma(transpose(X[i,:])*theta))*(X[i,:]*transpose(X[i,:]))
    end
    return hessian
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s simulate a sample of individuals:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#Generation of a sample:
#----------------------
N_individuals = 10000 #how many individuals in the sample?
dim_X = 3 #How many dimensions for x
d = Normal(0.0, 1.0)
d_logistic = Logistic(0.0, 1.0)
# Generate true parameter values:
theta0 = [0.0; 1.0; 2.0];
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Generate X:
X = rand(d, N_individuals, dim_X)
# The first column is full one ones (to have a constant)
X[:,1] = ones(N_individuals);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Convert y to a binary outcome using the latent variabe representation:
proba_success = X*theta0 .+ rand(d_logistic, N_individuals)
y = ifelse.(proba_success .&amp;gt; 0.0, 1.0, 0.0);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p1 = histogram(proba_success, bins=20, normalize=true, title=&amp;quot;Pdf probability of success&amp;quot;, legend=false)
p2 = histogram(y, title=&amp;quot;Nb of successes vs failures&amp;quot;, legend=false)
plot(p1,p2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Logistic_regression_29_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;maximization-with-optim&#34;&gt;Maximization with Optim&lt;/h3&gt;

&lt;p&gt;As a first pass, we can maximize the log-likelihood using the package Optim. I use the the &lt;a href=&#34;https://en.wikipedia.org/wiki/Limited-memory_BFGS&#34; target=&#34;_blank&#34;&gt;LBFGS&lt;/a&gt;
algorithm:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;theta_guess = ones(dim_X)
@time res = optimize(theta -&amp;gt; - log_likelihood(y, X, theta), theta_guess, LBFGS())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;0.409340 seconds (3.79 M allocations: 396.250 MiB, 15.73% gc time)&lt;/p&gt;

&lt;p&gt;We successfully recover the true parameter values (see &lt;code&gt;theta0&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;print(&amp;quot;Estimate for theta using Optim is $(res.minimizer)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Estimate for theta using Optim is [-0.0312666, 0.996344, 1.96038]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;minimization-with-gradient-descent&#34;&gt;Minimization with gradient descent&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s implement the gradient descent algorithm within a function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function gradient_descent_probit(y, X , theta_initial::Array{Float64,1}; max_iter::Int64 = 1000,
                                learning_rate::Float64 = 0.000001, tol::Float64=0.01)
    #initial value for theta:
    theta_old = theta_initial
    theta_new = similar(theta_old)
    #convergence reached?
    success_flag = 0
    #Let&#39;s store the convergence history
    history= fill!(zeros(max_iter), NaN)
    for i=1:max_iter
        theta_new = theta_old + learning_rate*derivative_log_likelihood(y, X, theta_old)
        diff = maximum(abs, theta_new .- theta_old)
        history[i] = diff
        if diff &amp;lt; tol
            success_flag = 1
            break
        end
        theta_old = theta_new
    end

    return theta_new, success_flag, history[isnan.(history) .== false]

end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;theta_guess = zeros(dim_X)
@time theta, flag, history = gradient_descent_probit(y, X, theta_guess, max_iter=100000, learning_rate=0.0001, tol=0.00001);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.252281 seconds (4.89 M allocations: 523.159 MiB, 29.08% gc time)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The following graph shows the error as a function of the number of iterations. After a few iterations of the gradient descent algorithm, the error is quite small.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;plot(history, label= &amp;quot;error&amp;quot;, title = &amp;quot;Convergence of the gradient descent algorithm&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Logistic_regression_40_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;print(&amp;quot;Estimate for theta using gradient descent is $(theta)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Estimate for theta using gradient descent is [0.0581777, 1.00105, 1.97901]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;minimization-with-newton-raphson&#34;&gt;Minimization with Newton-Raphson&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s implement the Newton-Raphson algorithm within a function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function nr_probit(y, X , theta_initial::Array{Float64,1};
                    max_iter::Int64 = 1000, tol::Float64=0.01)
    #initial value for theta:
    theta_old = theta_initial
    theta_new = similar(theta_old)
    #convergence reached?
    success_flag = 0
    #Let&#39;s store the convergence history
    history= fill!(zeros(max_iter), NaN)
    for i=1:max_iter
        theta_new = theta_old - inv(hessian_log_likelihood(y, X, theta_old))*derivative_log_likelihood(y, X, theta_old)
        diff = maximum(abs, theta_new .- theta_old)
        history[i] = diff
        if diff &amp;lt; tol
            success_flag = 1
            break
        end
        theta_old = theta_new
    end

    return theta_new, success_flag, history[isnan.(history) .== false]

end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The following graph shows that we find the minimizer in only 5 steps! The Newton-Raphson algorithm clearly outperforms gradient descent. Of course, everything works well because the
problem is well-behaved and a nice formula for the Hessian is available.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;theta_guess = ones(dim_X)
@time theta, flag, history = nr_probit(y, X, theta_guess, max_iter=1000, tol=0.00001);
plot(history, label= &amp;quot;error&amp;quot;, title = &amp;quot;Convergence of the gradient descent algorithm&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.037832 seconds (500.07 k allocations: 53.431 MiB, 35.44% gc time)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Logistic_regression_46_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;print(&amp;quot;Estimate for theta using Newton-Raphson is $(theta)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Estimate for theta using Newton-Raphson is [0.0581789, 1.00114, 1.97919]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;using-glm&#34;&gt;Using GLM&lt;/h3&gt;

&lt;p&gt;We can also use the package &lt;a href=&#34;https://github.com/JuliaStats/GLM.jl&#34; target=&#34;_blank&#34;&gt;GLM&lt;/a&gt; to estimate the logistic model. We first need to put the data into a dataframe. In the &lt;code&gt;glm()&lt;/code&gt; function, we should use the &lt;code&gt;LogitLink()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;df = DataFrame(X1=X[:,1],X2=X[:,2], X3=X[:,3], y=y);
first(df,6)
&lt;/code&gt;&lt;/pre&gt;

&lt;table class=&#34;data-frame&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;X1&lt;/th&gt;&lt;th&gt;X2&lt;/th&gt;&lt;th&gt;X3&lt;/th&gt;&lt;th&gt;y&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;p&gt;6 rows √ó 4 columns&lt;/p&gt;&lt;tr&gt;&lt;th&gt;1&lt;/th&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;0.215315&lt;/td&gt;&lt;td&gt;1.29817&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;2&lt;/th&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;-0.0714749&lt;/td&gt;&lt;td&gt;0.586886&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;3&lt;/th&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;0.0463648&lt;/td&gt;&lt;td&gt;-0.145116&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;4&lt;/th&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;1.95096&lt;/td&gt;&lt;td&gt;0.26349&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;5&lt;/th&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;-0.162081&lt;/td&gt;&lt;td&gt;1.34871&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;6&lt;/th&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;0.00214326&lt;/td&gt;&lt;td&gt;-0.271835&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;fittedmodel = glm(@formula(y ~ X2 + X3), df, Binomial(), LogitLink(), verbose=true);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;print(&amp;quot;Estimate for theta using GLM is $(coef(fittedmodel))&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Estimate for theta using GLM is [-0.0312666, 0.996344, 1.96038]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ii-what-makes-a-successful-nba-player&#34;&gt;II. What makes a successful NBA player?&lt;/h2&gt;

&lt;p&gt;For an example involving real data, I use the data set on &lt;strong&gt;NBA shots&lt;/strong&gt; taken during the 2014-2015 season.
It contains information on:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;who took the shot&lt;/li&gt;
&lt;li&gt;where on the floor was the shot taken from&lt;/li&gt;
&lt;li&gt;who was the nearest defender,&lt;/li&gt;
&lt;li&gt;how far away was the nearest defender&lt;/li&gt;
&lt;li&gt;time on the shot clock&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The data is available on &lt;strong&gt;Kaggle&lt;/strong&gt; &lt;a href=&#34;https://www.kaggle.com/dansbecker/nba-shot-logs&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;df_nba = CSV.read(&amp;quot;/home/julien/Documents/REPOSITORIES/LogisticRegression/data/shot_logs.csv&amp;quot;);
names(df_nba)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The dataset is quite extensive. Let&amp;rsquo;s select whether or not the shot was successful, &lt;strong&gt;the shot clock, the shot distance, and the proximity with the closest defender&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;df_nba = df_nba[[:SHOT_RESULT, :SHOT_CLOCK, :SHOT_DIST, :CLOSE_DEF_DIST]]
# Drop rows with missings:
df_nba = dropmissing(df_nba);
# Drop rows with NaN:
df_nba = df_nba[completecases(df_nba), :]
# Convert SHOT_RESULT to a binary variable (1 for success, 0 for missed)
df_nba[:, :SHOT_RESULT] = ifelse.(df_nba[:, :SHOT_RESULT] .== &amp;quot;made&amp;quot;, 1.0, 0.0);
# Show the first few rows of df_nba:
first(df_nba, 4)
&lt;/code&gt;&lt;/pre&gt;

&lt;table class=&#34;data-frame&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;SHOT_RESULT&lt;/th&gt;&lt;th&gt;SHOT_CLOCK&lt;/th&gt;&lt;th&gt;SHOT_DIST&lt;/th&gt;&lt;th&gt;CLOSE_DEF_DIST&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;p&gt;4 rows √ó 4 columns&lt;/p&gt;&lt;tr&gt;&lt;th&gt;1&lt;/th&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;10.8&lt;/td&gt;&lt;td&gt;7.7&lt;/td&gt;&lt;td&gt;1.3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;2&lt;/th&gt;&lt;td&gt;0.0&lt;/td&gt;&lt;td&gt;3.4&lt;/td&gt;&lt;td&gt;28.2&lt;/td&gt;&lt;td&gt;6.1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;3&lt;/th&gt;&lt;td&gt;0.0&lt;/td&gt;&lt;td&gt;10.3&lt;/td&gt;&lt;td&gt;17.2&lt;/td&gt;&lt;td&gt;3.4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;4&lt;/th&gt;&lt;td&gt;0.0&lt;/td&gt;&lt;td&gt;10.9&lt;/td&gt;&lt;td&gt;3.7&lt;/td&gt;&lt;td&gt;1.1&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;Let&amp;rsquo;s first use GLM:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;fittedmodel = glm(@formula(SHOT_RESULT ~ SHOT_CLOCK + SHOT_DIST + CLOSE_DEF_DIST), df_nba, Binomial(), LogitLink(), verbose=true);
fittedmodel
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;SHOT_RESULT ~ 1 + SHOT_CLOCK + SHOT_DIST + CLOSE_DEF_DIST

Coefficients:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                  Estimate   Std. Error    z value  Pr(&amp;gt;|z|)   Lower 95%   Upper 95%
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
(Intercept)     -0.0575127  0.0181349     -3.17139    0.0015  -0.0930564  -0.021969
SHOT_CLOCK       0.0185198  0.00104899    17.6549     &amp;lt;1e-69   0.0164639   0.0205758
SHOT_DIST       -0.059745   0.000858282  -69.61       &amp;lt;1e-99  -0.0614272  -0.0580628
CLOSE_DEF_DIST   0.108392   0.00279232    38.8179     &amp;lt;1e-99   0.102919    0.113865
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How can we interpret those results?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;time pressure makes NBA players more successful: the higher the shot clock, the more likely to score&lt;/li&gt;
&lt;li&gt;shots from further away are more likely to be missed&lt;/li&gt;
&lt;li&gt;the further away the closest defender is, the more likely the shot will be a success&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Can we find similar results &amp;ldquo;manually&amp;rdquo;? The answer is &lt;strong&gt;yes&lt;/strong&gt;. To see that, let&amp;rsquo;s first create the binary variable &lt;code&gt;y&lt;/code&gt; and put the explanatory variables into &lt;code&gt;X&lt;/code&gt; and then use Newton-Raphson:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;y = convert(Array, df_nba[:SHOT_RESULT]);
X = convert(Matrix, df_nba[[:SHOT_CLOCK, :SHOT_DIST, :CLOSE_DEF_DIST]])
X = hcat(ones(size(X,1)), X);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;theta_guess = zeros(size(X,2))
@time theta, flag, history = nr_probit(y, X, theta_guess, max_iter=1000, tol=0.0001);
plot(history, label= &amp;quot;error&amp;quot;, title = &amp;quot;Convergence of the gradient descent algorithm&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.301748 seconds (4.90 M allocations: 568.272 MiB, 29.93% gc time)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Logistic_regression_63_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Our implementation of the logistic model gives us parameter values that are almost
identical to the ones we get using the package &lt;code&gt;GLM&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;print(&amp;quot;Estimate for theta using Optim is $(res.minimizer)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Estimate for theta using Optim is [-0.057513, 0.0185199, -0.0597451, 0.108392]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The logistic model, often used in social sciences and in machine learning for classification purposes is a powerful tool. This blog post shows how the logistic model can be derived from first principles (latent variable interpretation) and how it can be implemented in just a few lines of codes. A few extensions to this blog post could be to calculate the &lt;a href=&#34;https://en.wikipedia.org/wiki/Receiver_operating_characteristic&#34; target=&#34;_blank&#34;&gt;ROC curve&lt;/a&gt; and to calculate the standard errors.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://rpubs.com/junworks/Understanding-Logistic-Regression-from-Scratch&#34; target=&#34;_blank&#34;&gt;https://rpubs.com/junworks/Understanding-Logistic-Regression-from-Scratch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Rental Housing Market and Directed Search</title>
      <link>https://julienpascal.github.io/project/rentalmarket/</link>
      <pubDate>Mon, 21 Oct 2019 18:11:07 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/project/rentalmarket/</guid>
      <description>&lt;p&gt;Using a novel dataset on the rental housing market in the Paris area, I show that the rental housing market is well described by a directed search model. I develop a hedonic pricing model taking into consideration apartment features and subjective attractiveness using photos and computer vision techniques from the machine learning literature.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&#34;https://julienpascal.github.io/slides/rental-market/#/&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://julienpascal.github.io/img/icons/beamer_small.png&#34;&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker for Dummies</title>
      <link>https://julienpascal.github.io/post/docker/</link>
      <pubDate>Fri, 18 Oct 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/docker/</guid>
      <description>

&lt;p&gt;In my quest for the perfect tool for reproducible science, I thought that the silver
bullet was to wrap your code in a neat library/package and make it available to the world.
Yet, I was wrong. &lt;a href=&#34;https://www.docker.com/&#34; target=&#34;_blank&#34;&gt;Docker&lt;/a&gt; is a much cooler and a much more effective way for sharing
your work with a broad audience. This post is a 101 introduction to Docker.
I describe what is Docker and show one simple application with a script in Julia.&lt;/p&gt;

&lt;h2 id=&#34;why-docker&#34;&gt;Why Docker?&lt;/h2&gt;

&lt;p&gt;Your script works locally, but not on your friend&amp;rsquo;s laptop because of dependency
issues. Docker solves the &lt;a href=&#34;https://en.wikipedia.org/wiki/Dependency_hell&#34; target=&#34;_blank&#34;&gt;dependency hell&lt;/a&gt;
by giving you the opportunity to &amp;ldquo;ship&amp;rdquo; your application in a &amp;ldquo;container&amp;rdquo;. One can think of a &amp;ldquo;container&amp;rdquo; as some sort of lightweight virtual image. Some technical details can be found &lt;a href=&#34;https://docs.docker.com/engine/docker-overview/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://devopscube.com/what-is-docker/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. In a nutshell, if your application works on your local machine, Docker helps you to put your application inside an container. Once in a container, your application will run smoothly for the rest of the world.&lt;/p&gt;

&lt;h2 id=&#34;application-in-julia&#34;&gt;Application in Julia&lt;/h2&gt;

&lt;p&gt;The goal is to create a container with a simple script to calculate an approximation
of œÄ. Here I am making a copy-paste from &lt;a href=&#34;https://julienpascal.github.io/post/buildyourcluster/&#34; target=&#34;_blank&#34;&gt;this post&lt;/a&gt;, in which I calculated an approximation of œÄ using Monte-Carlo. I create a folder
&lt;code&gt;julia-app&lt;/code&gt;, which contains 3 files (see the Github repository with the 3 files &lt;a href=&#34;https://github.com/JulienPascal/MyFirstDockerApp&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;julia-app
  ‚îú app.jl
  ‚îú deps.jl
  ‚îî Dockerfile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The file &lt;code&gt;app.jl&lt;/code&gt; contains the application we want to containerize. The file &lt;code&gt;deps.jl&lt;/code&gt;
contains the list of libraries/packages that are used within &lt;code&gt;app.jl&lt;/code&gt;. The file &lt;code&gt;Dockerfile&lt;/code&gt;
is a &lt;a href=&#34;https://docs.docker.com/engine/reference/builder/&#34; target=&#34;_blank&#34;&gt;text document&lt;/a&gt; that contains instructions to build the container.
Generally, a &lt;code&gt;Dockerfile&lt;/code&gt; contains 4 types of instructions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;FROM&lt;/code&gt;: specifies the &amp;ldquo;base image&amp;rdquo; we want to use within the container. In our case,
we want to run an application with Julia. Luckily, we can pull a base image with
Julia pre-installed on it using &lt;code&gt;FROM julia:&amp;lt;julia-version-you-want&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;COPY&lt;/code&gt;: adds files to your container&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RUN&lt;/code&gt;: executes command(s) in a new layer and creates a new image. &lt;code&gt;RUN&lt;/code&gt; is perfect
for installing packages&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CMD&lt;/code&gt;: specifies what command to run within the container&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;#choose a base image
FROM julia:1.0.3

# install julia dependencies
COPY deps.jl /usr/src/app/
RUN julia /usr/src/app/deps.jl

# copy files required for the app to run
COPY app.jl /usr/src/app/

# run the application
CMD [&amp;quot;julia&amp;quot;, &amp;quot;/usr/src/app/app.jl&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To create the container, use the command &lt;code&gt;docker build&lt;/code&gt;. You can give a name
to your container using the &lt;code&gt;--tag , -t&lt;/code&gt; option:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker build julia-app -t &amp;lt;your-tag&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To run the container you have just created:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --name julia-app &amp;lt;your-tag&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After a few seconds, you should see an approximation of œÄ showing up in your
terminal. Voil√†, you have have just created your first container. The next step
is to put your container on &lt;a href=&#34;https://hub.docker.com/&#34; target=&#34;_blank&#34;&gt;DockerHub&lt;/a&gt;. &lt;a href=&#34;https://docs.docker.com/docker-hub/&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt;
is a tutorial on how to do it.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;From an academic perspective, Docker solves the dependency hell and helps in producing
reproducible research. I will try to use it more often for sharing my own research.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OLS the Machine Learning Way</title>
      <link>https://julienpascal.github.io/post/ols_ml/</link>
      <pubDate>Sun, 29 Sep 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/ols_ml/</guid>
      <description>

&lt;p&gt;Coming from an Economics/Econometrics background, I have always been a bit puzzled by the way several Machine Learning (ML) textbooks I have read solve the ordinary least squares model (OLS). When considering a linear model of the form:&lt;/p&gt;

&lt;p&gt;$$ y = X \beta + e $$&lt;/p&gt;

&lt;p&gt;with $e$ a zero-mean noise term, the closed-form solution associated with minimizing the mean square error is:&lt;/p&gt;

&lt;p&gt;$$ \beta = (X&amp;rsquo;X)^{-1}X&amp;rsquo;y $$&lt;/p&gt;

&lt;p&gt;Several ML textbooks explain that a recursive algorithm (see below) may be used to solve for $\beta$. Why not directly using the analytical formula to calculate an estimate of $\beta$ ? While feasible with &amp;ldquo;small&amp;rdquo; datasets (not too many explanatory variables and/or observations), direct inversion of $X&amp;rsquo;X$ is not recommended when working with thousands of explanatory variables and/or billions of observations. The alternative is to use &lt;a href=&#34;https://en.wikipedia.org/wiki/Gradient_descent&#34; target=&#34;_blank&#34;&gt;gradient descent&lt;/a&gt;, or better, &lt;a href=&#34;https://en.wikipedia.org/wiki/Stochastic_gradient_descent&#34; target=&#34;_blank&#34;&gt;stochastic gradient descent&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this short post, I solve OLS the &amp;ldquo;machine-learning way&amp;rdquo;. That is, using (stochastic) gradient descent. The idea for gradient descent (GD) is quite intuitive. The gradient of $f$ at a given point tells us the direction of &lt;strong&gt;greatest increase&lt;/strong&gt; for $f$ at this point. Hence, moving in the opposite direction (minus the gradient) is probably a good idea to find a local minimum. And indeed it is. The GD algorithm repetitively applies this procedure until a minimum (hopefully global) is found. Starting from an initial guess for $\beta$, one updates the guess using the following formula:&lt;/p&gt;

&lt;p&gt;$$ \beta_{n} = \beta_{n-1} - \alpha * grad_{n}(\beta_{n-1},X,y) $$&lt;/p&gt;

&lt;p&gt;where $\alpha$ is a small value (the &amp;ldquo;learning rate&amp;rdquo;) and $grad_{n}(\beta_{n-1},X,y)$ the gradient of the mean square error (another loss function can be used) evaluated at $\beta_{n-1}$ using the observations $X$ and $y$. Using the mean square error as a loss function generates a closed-form solution for the gradient:&lt;/p&gt;

&lt;p&gt;$$ grad_{n}(\beta_{n-1},X,y) = (X&amp;rsquo;X)\beta - X&amp;rsquo;y $$&lt;/p&gt;

&lt;p&gt;A refinement of GD, especially handy when dealing with a large dataset, is to use only a subset of the full sample when calculating the gradient:&lt;/p&gt;

&lt;p&gt;$$ \beta_{n} = \beta_{n-1} - \alpha * grad_{n}(\beta_{n-1},X_n,y_n) $$&lt;/p&gt;

&lt;p&gt;where $X_n$ and $y_n$ are a randomly selected sub-sample of $X$ and $y$. Stochastic Gradient Descent (SGD) reduces the computational burden associated with computing the gradient, while still having good convergence properties, as illustrated in the application below.&lt;/p&gt;

&lt;h2 id=&#34;implementation-in-julia&#34;&gt;Implementation in Julia&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s first load packages and define parameters&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using LinearAlgebra
using Distributions
using Plots
using Distributions
using Random
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;n_points=10000
dim_input=100 #dim of input, without the intercept
dim_output=1
# Normal noise
d = Normal()
# True parameters
beta = rand(d, dim_input + 1);
# Noise
e = rand(d, n_points);
# Input data:
X = rand(d, (n_points,dim_input));
# Add the intercept:
X = hcat(ones(n_points),X);
#Linear Model
y = X*beta .+ e;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function calculates an estimate of $\beta$ using the analytical formula for OLS&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#OLS way
function OLS_direct(X::Array, y::Vector)
    inv(transpose(X)*X)*transpose(X)*y
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OLS_direct (generic function with 1 method)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@time beta_hat = OLS_direct(X, y);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;0.611144 seconds (1.85 M allocations: 96.576 MiB, 13.64% gc time)&lt;/p&gt;

&lt;p&gt;Without any major surprise, using the analytical solution works perfectly well, as illustrated in the following plot&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;plot(beta, beta_hat, seriestype=:scatter, label=&amp;quot;OLS (Direct)&amp;quot;)
plot!(beta, beta, seriestype=:line, label=&amp;quot;true&amp;quot;)
xlabel!(&amp;quot;true value&amp;quot;)
ylabel!(&amp;quot;estimated value (Direct)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;OLSMachineLearning_9_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;gradient-descent&#34;&gt;Gradient Descent&lt;/h2&gt;

&lt;p&gt;Now it&amp;rsquo;s time to solve OLS the machine learning way. I first define a function that calculates the gradient of the loss
function, evaluated at the current guess using the full sample. Then, a second function applies the GD updating rule.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#Calculate the gradient
function grad_OLS!(G, beta_hat, X, y)
    G[:] = transpose(X)*X*beta_hat - transpose(X)*y
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;grad_OLS! (generic function with 1 method)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#Gradient descent way
function OLS_gd(X::Array, y::Vector; epochs::Int64=1000, r::Float64=1e-5, verbose::Bool=false)
    #initial guess
    beta_hat = zeros(size(X,2))
    grad_n = zeros(size(X,2))
    for epoch=1:epochs
        grad_OLS!(grad_n, beta_hat, X, y)
        beta_hat -= r*grad_n
        if verbose==true
            if mod(epoch, round(Int, epochs/10))==1
                println(&amp;quot;MSE: $(mse(beta_hat, X, y))&amp;quot;)
            end
        end
    end
    return beta_hat
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OLS_gd (generic function with 1 method)&lt;/p&gt;

&lt;p&gt;As illustrated below, after 20 iterations we are quite close to the true value. After 100 iterations, values obtained by GD are indistinguishable from the true values.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@time beta_hat_gd_20 = OLS_gd(X,y, epochs=20);
@time beta_hat_gd = OLS_gd(X,y, epochs=100);
plot(beta, beta_hat_gd_20, seriestype=:scatter, label=&amp;quot;GD (20 iter.)&amp;quot;)
plot!(beta, beta_hat_gd, seriestype=:scatter, label=&amp;quot;GD (100 iter.)&amp;quot;)
plot!(beta, beta, seriestype=:line, label=&amp;quot;true&amp;quot;)
xlabel!(&amp;quot;true value&amp;quot;)
ylabel!(&amp;quot;estimated value (GD)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;0.137474 seconds (81.55 k allocations: 5.814 MiB)
0.466605 seconds (714 allocations: 8.225 MiB)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;OLSMachineLearning_15_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;stochastic-gradient-descent&#34;&gt;Stochastic Gradient Descent&lt;/h2&gt;

&lt;p&gt;One issue associated with plain vanilla GD is that computing the gradient might be slow. Let&amp;rsquo;s now randomly select only a fraction of the full sample every time we iterate. Here, I take only 10 percent of the full sample.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#Gradient descent way
function OLS_sgd(X::Array, y::Vector; epochs::Int64=1000, r::Float64=1e-5, verbose::Bool=false, batchsizePer::Int64=10)
    #initial guess
    beta_hat = zeros(size(X,2))
    grad_n = zeros(size(X,2))
    #how many draws from the dataset?
    batchsize = round(Int, size(X,1)*(batchsizePer/100))
    Xn = zeros(batchsize, size(X,2))
    yn = zeros(batchsize)
    for epoch=1:epochs
        indices = shuffle(Vector(1:size(X,1)))
        Xn = X[indices[1:batchsize],:]
        yn = y[indices[1:batchsize]]
        grad_OLS!(grad_n, beta_hat, Xn, yn)
        #gradient descent:
        beta_hat -= r*grad_n
        if verbose==true
            if mod(epoch, round(Int, epochs/10))==1
                println(&amp;quot;MSE: $(mse(beta_hat, X, y))&amp;quot;)
            end
        end
    end
    return beta_hat
end

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OLS_sgd (generic function with 1 method)&lt;/p&gt;

&lt;p&gt;The following block of code shows that SGD achieves the same degree of accuracy, while being much faster than GD.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@time beta_hat_gd = OLS_gd(X,y, epochs=200);
@time beta_hat_sgd = OLS_sgd(X,y, epochs=200, batchsizePer=20);
plot(beta, beta_hat_sgd, seriestype=:scatter, label=&amp;quot;SGD&amp;quot;)
plot!(beta, beta_hat_gd, seriestype=:scatter, label=&amp;quot;GD&amp;quot;)
plot!(beta, beta, seriestype=:line, label=&amp;quot;true&amp;quot;)
xlabel!(&amp;quot;true value&amp;quot;)
ylabel!(&amp;quot;estimated value (SGD)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;0.894465 seconds (1.41 k allocations: 16.448 MiB, 0.42% gc time)
0.513217 seconds (338.19 k allocations: 382.550 MiB, 4.60% gc time)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;OLSMachineLearning_20_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The OLS analytical formula is the gold standard to derive theoretical properties and is perfectly fine when working with reasonably-sized data. In a big data context, (stochastic) gradient descent is the way to go. SGD can be applied to a wide-range of minimization problems. In a machine-learning context, SGD is used to estimate (&amp;ldquo;train&amp;rdquo;) much more complicated models than the simple linear model presented here. In the Appendix below, I show how one can use SGD when no analytical solution for the gradient is available.&lt;/p&gt;

&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;

&lt;h3 id=&#34;gd-without-analytical-solution-for-the-gradient&#34;&gt;GD without analytical solution for the gradient&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s assume we don&amp;rsquo;t have a closed-form solution for the gradient. In this context, Julia&amp;rsquo;s automatic differentiation library &lt;code&gt;ForwardDiff&lt;/code&gt; is a good choice to calculate the gradient. Below, I define the loss function (MSE), I obtain the gradient of the loss function using &lt;code&gt;ForwardDiff&lt;/code&gt; and I apply the SGD algorithm.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using ForwardDiff
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function mse(beta::Vector, X::Array, y::Vector)
   result = zero(eltype(y))
   for i in 1:length(y)
       #sum squared errors
       result += (y[i] - dot(X[i,:],beta))^2
   end
   return result
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;mse (generic function with 1 method)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function grad!(G, beta_hat, X, y)
    G[:] = ForwardDiff.gradient(x -&amp;gt; mse(x, X, y), beta_hat)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;grad! (generic function with 1 method)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#Gradient descent way
function OLS_gd(X::Array, y::Vector; epochs::Int64=1000, r::Float64=1e-5, verbose::Bool=false)
    #initial guess
    beta_hat = zeros(size(X,2))
    grad_n = zeros(size(X,2))
    for epoch=1:epochs
        grad!(grad_n, beta_hat, X, y)
        beta_hat -= r*grad_n
        if verbose==true
            if mod(epoch, round(Int, epochs/10))==1
                println(&amp;quot;MSE: $(mse(beta_hat, X, y))&amp;quot;)
            end
        end
    end
    return beta_hat
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;OLS_gd (generic function with 1 method)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@time beta_hat_gd = OLS_gd(X,y, epochs=100);
plot(beta, beta_hat_gd, seriestype=:scatter, label=&amp;quot;GD (100 iter.)&amp;quot;)
plot!(beta, beta, seriestype=:line, label=&amp;quot;true&amp;quot;)
xlabel!(&amp;quot;true value&amp;quot;)
ylabel!(&amp;quot;estimated value (GD)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.180767 seconds (9.71 M allocations: 7.547 GiB, 12.66% gc time)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;OLSMachineLearning_29_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The BKM Algorithm</title>
      <link>https://julienpascal.github.io/post/bkm/</link>
      <pubDate>Mon, 16 Sep 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/bkm/</guid>
      <description>

&lt;p&gt;Finding solutions to economic models with heterogeneity and aggregate uncertainty is a notoriously difficult task.
It is an active area of research in Mathematics (see &lt;a href=&#34;https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.2013.0397&#34; target=&#34;_blank&#34;&gt;mean field games with aggregate uncertainty&lt;/a&gt;). Because such models naturally arise when considering economic situations, Economists have developed a battery of techniques to (numerically) solve them. In this post, I would like to describe a recent algorithm by &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v89y2018icp68-92.html&#34; target=&#34;_blank&#34;&gt;Boppart, Krusell and Mitman (BKM)&lt;/a&gt; that is both fast and accurate. I will first describe the problem that Economists face when working with heterogeneous model with aggregate uncertainty, heuristically discuss the BKM algorithm (based on the presentation of &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v89y2018icp93-99.html&#34; target=&#34;_blank&#34;&gt;Reiter (2018)&lt;/a&gt;) and show an application in Julia.&lt;/p&gt;

&lt;h3 id=&#34;bkm-in-a-nutshell&#34;&gt;BKM in a nutshell&lt;/h3&gt;

&lt;p&gt;It is common to use Bellman&amp;rsquo;s principle of optimality to characterize solutions of a multi-stage decision processes.
The principle of optimality leads to a solution in a &lt;strong&gt;recursive form&lt;/strong&gt; $d_{t} = d(S_{t})$, where $S_t$ is a vector of state variables and $d(.)$ a policy function describing the optimal action of a decision-maker when faced with any given state.&lt;/p&gt;

&lt;p&gt;An alternative representation of the problem is to consider a solution in the &lt;strong&gt;sequence form&lt;/strong&gt;. At each step in time, a decision-maker observes a new realization of a random process $z_t$ and taking into account the full history of past shocks, the agent makes a new choice to maximize her expected discounted sum of returns: $d_t = d(z_t, z_{t-1}, z_{t-2}, &amp;hellip;)$.&lt;/p&gt;

&lt;p&gt;While most of the time the recursive form is a much more parsimonious approach, it fails when $S_t$ is infinite-dimensional. In models with heterogeneous agents (HA) and aggregate uncertainty, this is generally the case because the distribution of agents over certain variables will end up being in $S_t$. While this a problem with is the recursive approach (how can we discretize $S_t$ to put it on a computer?), the sequence form is immune to this problem. The BKM algorithm uses this insight, adding the &lt;strong&gt;assumption&lt;/strong&gt; of &lt;strong&gt;linearity&lt;/strong&gt; of $d(.)$ with respect to the &lt;strong&gt;aggregate state&lt;/strong&gt; $z_t$:&lt;/p&gt;

&lt;p&gt;$$ d_t = z_t d(1, 0, 0, &amp;hellip;) + z_{t-1}d(0, 1, 0, &amp;hellip;) + z_{t-2}d(0, 0, 1, &amp;hellip;) + &amp;hellip; $$
$$ d_t = \sum_{k=0}^{+\infty} z_{t-k} d_{k} $$&lt;/p&gt;

&lt;p&gt;where $$ d_{1} = d(1,0,0,&amp;hellip;)$$
$$ d_{2} = d(0,1,0,&amp;hellip;)$$
$$ d_{3} = d(0,0,1,&amp;hellip;)$$&lt;/p&gt;

&lt;p&gt;The series of $d_{k}$ describes the trajectory of the economy after an &amp;ldquo;MIT&amp;rdquo; shock (when the economy is hit by an unexpected single-period aggregate shock). If the linearity assumption holds, the evolution of equilibrium variables are simply a moving average of past shocks. We made progress because solving for the trajectory after an MIT shock is perfectly feasible in a RA model. As long as one can calculate the steady-state with no aggregate uncertainty and solve the &lt;strong&gt;deterministic perfect foresight path&lt;/strong&gt;, BKM can be used.&lt;/p&gt;

&lt;h3 id=&#34;numerical-implementation&#34;&gt;Numerical implementation&lt;/h3&gt;

&lt;p&gt;Here is the implementation of the method using a toy example. I intentionally circumvent the problem of finding the perfect foresight transition path, which is (potentially) the complicated part of BKM. This is the example given in Reiter (2018): the exact model is the non-linear model $x_{t} = a x_{t-1} + b x_{t-1}^2 + z_{t}$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Distributions
using Plots
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Parameters
max_iter=100 #number of iterations for the simulation
a = 0.5
b = 0.1
sigma_shock=1.0
mu_shock=0.
d = Normal(mu_shock, sigma_shock)

# transition function
function iter_x(x_min1::Float64, a::Float64, b::Float64)
    a*x_min1 + b*x_min1^2
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;iter_x (generic function with 1 method)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;impulse-response-function&#34;&gt;Impulse response function&lt;/h4&gt;

&lt;p&gt;Let us assume that the economy is at the non-stochastic steady-state and a shock occurs:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# We assume that after 100 periods, the economy is back to the steady-state
max_iter_mit = 100
x_mit=zeros(max_iter_mit)
# Initial shock
z_t[1] = sigma_shock #a 1 std. deviation
x_mit[1] = 0 #steady-state

for i=2:max_iter_mit
    x_mit[i] = iter_x(x_mit[i-1], a, b) + z_t[i-1]
end

# Scaled-version of the impulse response:
x_mit_scaled = x_mit./z_t[1];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I define two functions to calculate the moving average:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function calculate_Xt(x_scaled::Array{Float64,1}, shocks::Array{Float64,1}, t::Int64, kk::Int64)

    output = 0.

    for k=1:kk
        output+=x_scaled[k]*shocks[t-k+1]
    end

    return output
end

function BPM_path!(XT::Array{Float64,1}, max_iter::Int64, x_scaled::Array{Float64,1}, shocks::Array{Float64,1})

    for t=2:max_iter
        XT[t] = calculate_Xt(x_scaled, shocks, t, t)
    end

end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;BPM_path! (generic function with 1 method)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Initialization
XT = zeros(max_iter);
# Series of shocks
shocks_t = rand(d, max_iter).*0.5;
# Solving using BKM:
@time BPM_path!(XT, max_iter, x_mit_scaled, shocks_t)
# True value:
x_true = zeros(max_iter)
for i=2:max_iter
    x_true[i] = iter_x(x_true[i-1], a, b) + shocks_t[i-1]
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.025906 seconds (29.30 k allocations: 1.489 MiB, 26.80% gc time)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;plot(XT[2:end], label=&amp;quot;x_t BKM&amp;quot;)
plot!(x_true[2:end], label=&amp;quot;x_t true&amp;quot;)
title!(&amp;quot;b=$(b)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;BKM_Algorithm_16_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The previous plot shows how the BKM algorithm approximates the true model and it does quite a good job.
Of course, the more the model is linear with respect to $z_t$ (captured by the value of $b_2$), the better the approximation. To illustrate this idea, I use BKM on a perfectly linear model ($b=0$) and on a model with stronger non-linearities ($b=0.2$). As expected, the approximation is perfect when the model is linear and the approximation deteriorates when strong non-linearities are present.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;plot(p1,p2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;BKM_Algorithm_18_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;The BKM algorithm is a new addition to the toolbox of methods to solve HA models. The sequence representation of the problem seems to be a fruitful area of research, as it has also been used in Le Grand and Ragot (&lt;a href=&#34;http://xavier-ragot.fr/pdf/progress/LeGrand_Ragot_final.pdf&#34; target=&#34;_blank&#34;&gt;2017&lt;/a&gt;) and (&lt;a href=&#34;http://xavier-ragot.fr/pdf/progress/Optimal_policies.pdf&#34; target=&#34;_blank&#34;&gt;2019&lt;/a&gt;) to develop fast and reliable method to solve HA models. The recent contribution of &lt;a href=&#34;https://github.com/shade-econ/sequence-jacobian/#sequence-space-jacobian&#34; target=&#34;_blank&#34;&gt;Auclert at al (2019)&lt;/a&gt; also uses a similar approach.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Achdou, Yves, et al. &amp;ldquo;Partial differential equation models in macroeconomics.&amp;rdquo; Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 372.2028 (2014): 20130397.&lt;/li&gt;
&lt;li&gt;Auclert, Adrien, et al. Using the Sequence-Space Jacobian to Solve and Estimate Heterogeneous-Agent Models. No. w26123. National Bureau of Economic Research, 2019.&lt;/li&gt;
&lt;li&gt;Boppart, Timo, Per Krusell, and Kurt Mitman. &amp;ldquo;Exploiting MIT shocks in heterogeneous-agent economies: the impulse response as a numerical derivative.&amp;rdquo; Journal of Economic Dynamics and Control 89 (2018): 68-92.&lt;/li&gt;
&lt;li&gt;Le Grand, Fran√ßois, and Xavier Ragot. &amp;ldquo;Optimal fiscal policy with heterogeneous agents and aggregate shocks.&amp;rdquo; Document de travail (2017).&lt;/li&gt;
&lt;li&gt;Le Grand, Fran√ßois, and Ragot, Xavier. &amp;ldquo;Managing Inequality over the Business Cycles: Optimal Policies with Heterogeneous Agents and Aggregate Shocks&amp;rdquo;. No. 1090. Society for Economic Dynamics, 2019.&lt;/li&gt;
&lt;li&gt;Reiter, Michael. &amp;ldquo;Comments on&amp;rdquo; Exploiting MIT Shocks in Heterogeneous-Agent Economies: The Impulse Response as a Numerical Derivative&amp;rdquo; by T. Boppart, P. Krusell and K. Mitman.&amp;rdquo; Journal of Economic Dynamics and Control 89 (2018): 93-99.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;versioninfo()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Julia Version 1.0.3
Commit 099e826241 (2018-12-18 01:34 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.0 (ORCJIT, skylake)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;### To create plot 2

#### Linear Model

# Parameters
max_iter=100 #number of iterations for the simulation
a = 0.5
b = 0.0
sigma_shock=1.0
mu_shock=0.
d = Normal(mu_shock, sigma_shock)

# IRF
x_mit=zeros(max_iter_mit)
# Initial shock
z_t[1] = sigma_shock #a 1 std. deviation
x_mit[1] = 0 #steady-state

for i=2:max_iter_mit
    x_mit[i] = iter_x(x_mit[i-1], a, b) + z_t[i-1]
end

# Scaled-version of the impulse response:
x_mit_scaled = x_mit./z_t[1];


# Initialization
XT = zeros(max_iter);
# Series of shocks
shocks_t = rand(d, max_iter).*0.5;
# Solving using BKM:
@time BPM_path!(XT, max_iter, x_mit_scaled, shocks_t)
# True value:
x_true = zeros(max_iter)
for i=2:max_iter
    x_true[i] = iter_x(x_true[i-1], a, b) + shocks_t[i-1]
end

p1 = plot(XT[2:end], label=&amp;quot;x_t BKM&amp;quot;)
plot!(x_true[2:end], label=&amp;quot;x_t true&amp;quot;)
title!(&amp;quot;b=$(b)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;0.000009 seconds (4 allocations: 160 bytes)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;BKM_Algorithm_24_1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;### Plot 2

#### Linear Model

# Parameters
max_iter=100 #number of iterations for the simulation
a = 0.5
b = 0.2
sigma_shock=1.0
mu_shock=0.
d = Normal(mu_shock, sigma_shock)

# IRF
x_mit=zeros(max_iter_mit)
# Initial shock
z_t[1] = sigma_shock #a 1 std. deviation
x_mit[1] = 0 #steady-state

for i=2:max_iter_mit
    x_mit[i] = iter_x(x_mit[i-1], a, b) + z_t[i-1]
end

# Scaled-version of the impulse response:
x_mit_scaled = x_mit./z_t[1];


# Initialization
XT = zeros(max_iter);
# Series of shocks
shocks_t = rand(d, max_iter).*0.5;
# Solving using BKM:
@time BPM_path!(XT, max_iter, x_mit_scaled, shocks_t)
# True value:
x_true = zeros(max_iter)
for i=2:max_iter
    x_true[i] = iter_x(x_true[i-1], a, b) + shocks_t[i-1]
end

p2 = plot(XT[2:end], label=&amp;quot;x_t BKM&amp;quot;)
plot!(x_true[2:end], label=&amp;quot;x_t true&amp;quot;)
title!(&amp;quot;b=$(b)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.000007 seconds (4 allocations: 160 bytes)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;BKM_Algorithm_25_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linear Time Iteration (Part II)</title>
      <link>https://julienpascal.github.io/post/lineartimeiteration2/</link>
      <pubDate>Mon, 26 Aug 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/lineartimeiteration2/</guid>
      <description>

&lt;p&gt;In a &lt;a href=&#34;https://julienpascal.github.io/&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt;, I introduced the logic for the Linear Time Iteration (LTI) method (Pontus Rendahl (2017)).
Now it&amp;rsquo;s time to apply the technique to a &amp;ldquo;real&amp;rdquo; (yet simple) economic model:
a stochastic growth model with endogenous labor supply.
The implementation is in Julia and is based a Matlab code by Pontus Rendahl available &lt;a href=&#34;https://sites.google.com/site/pontusrendahl/Research&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. We will use a three-step approach:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;[1] solve the non-stochastic steady-state of the model&lt;/li&gt;
&lt;li&gt;[2] differentiate the system around the non-stochastic steady-state to obtain a linear difference equation of the
form $A x_{t-1} + B x_{t} + C E_{t} [x_{t+1}] + u_{t} = 0$&lt;/li&gt;
&lt;li&gt;[3] apply the LTI method to find the law of motion  $x_{t} = F x_{t-1} + Q u_{t}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;

&lt;p&gt;We consider an economy populated by a representative household, deciding how much to work, save and consume at any given time. Output $y$ depends on the capital level $k$ (inherited from period $t-1$), on the number of hours worked $l$, and on the productivity level $z$:&lt;/p&gt;

&lt;p&gt;$$ y_t = z_t k_{t-1}^{\alpha} l_{t}^{1 - \alpha}$$&lt;/p&gt;

&lt;p&gt;Business cycles are driven by variations in productivity, that follows an AR(1) process, with $e_t$ a zero-mean stochastic variable:&lt;/p&gt;

&lt;p&gt;$$z_t = \rho z_{t-1} + e_{t} $$&lt;/p&gt;

&lt;p&gt;Capital at the end of period $t$ is equal to investment plus the non-depreciated capital stock inherited from last period:&lt;/p&gt;

&lt;p&gt;$$ k_{t} = I_{t} + (1 - \delta) k_{t-1} $$&lt;/p&gt;

&lt;p&gt;The representative household enjoys consumption and dislikes providing labor:&lt;/p&gt;

&lt;p&gt;$$ U(c,l) = \frac{C^{1-\sigma}}{1-\sigma} -  \frac{l^{1-\eta}}{1-\eta} $$&lt;/p&gt;

&lt;p&gt;Everything that is produced in the economy is either consumed or saved:&lt;/p&gt;

&lt;p&gt;$$ c_{t} + k_{t} = z_t k_{t-1}^{\alpha} l_{t}^{1 - \alpha} + (1 - \delta)k_{t-1}$$&lt;/p&gt;

&lt;p&gt;The optimal decision of the household is characterized by two equations:&lt;/p&gt;

&lt;p&gt;$$ c_{t}^{-\sigma} = \beta E_{t}(c_{t+1}^{-\sigma}(1 - \delta + \alpha z_{t+1} k_{t}^{\alpha -1} l_{t+1}^{1 - \alpha} ) )$$&lt;/p&gt;

&lt;p&gt;$$ l_{t}^{-\eta} = c_{t}^{-\gamma}(1 - \alpha) z_{t} k_{t-1}^\alpha l_{t}^{-\alpha} $$&lt;/p&gt;

&lt;p&gt;The first one states the gain of raising consumption today by one unit has to be equal to the expected gain from saving
one extra unit today and consuming it tomorrow (inter-temporal FOC). The second equation states that the marginal cost of working one extra hour today has to be equal
to the marginal gain of that extra hour worked (intra-temporal FOC).&lt;/p&gt;

&lt;h2 id=&#34;solving-the-steady-state&#34;&gt;Solving the steady-state&lt;/h2&gt;

&lt;p&gt;Calculating the steady-state of the model is a root finding problem. Let&amp;rsquo;s use the package &lt;code&gt;NLsolve&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;versioninfo()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Julia Version 1.0.3
Commit 099e826241 (2018-12-18 01:34 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.0 (ORCJIT, skylake)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Declare parameters
const alpha = 1/3;        # Capital share of output
const beta = 1.03^(-1/4); # Discount factor.
const gamma = 2;          # Coefficient of risk aversion
const eta = 2;            # Frisch elasticity of labor supply
const delta = 0.025;      # Depreciation rate of capital
const rho = 0.9;          # Persistence of TFP process.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using NLsolve

# Let&#39;s define a function for each equation of the model at the steady-state
function Ee(x::Array{Float64,1})
    -x[1]^(-gamma) + beta*(1.0 + alpha*(x[2]^(alpha - 1.0))*(x[3]^(1.0 - alpha)) - delta)*(x[1]^(-gamma))
end

function Rc(x::Array{Float64,1})
    -x[1] - x[2] + (x[2]^(alpha))*(x[3]^(1.0 - alpha)) + (1.0 - delta)*x[2]
end

function Ls(x::Array{Float64,1})
    (-x[1]^(-gamma))*(1.0 - alpha)*(x[2]^(alpha))*(x[3]^(-alpha)) + x[3]^(eta)
end

# The steady-state of the model is described by a system of three equations
f! = function (dx,x)
  dx[1] = Ee(x)
  dx[2] = Rc(x)
  dx[3] = Ls(x)
end


res = nlsolve(f!,[1.0; 20; 0.7])
xss = res.zero;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;css = xss[1];
kss = xss[2];
lss = xss[3];
# steady-state output and investment:
yss = kss^(alpha)*lss^(1-alpha);
Iss = kss-(1-delta)*kss;
XSS = zeros(6)
XSS[1]=yss
XSS[2]=Iss
XSS[3:5] = xss
XSS[6]=1.0;

print(&amp;quot;Steady-state value [css, kss, lss, yss, Iss, zss] = &amp;quot;, XSS)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Steady-state value [css, kss, lss, yss, Iss, zss] = [2.51213, 0.645783, 1.86634, 25.8313, 0.78341, 1.0]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;solving-the-stochastic-model&#34;&gt;Solving the stochastic model&lt;/h2&gt;

&lt;p&gt;To find a solution to the stochastic model,
let&amp;rsquo;s differentiate the system around the non-stochastic steady-state calculated above. Here, we will limit ourself to a first-order approximation since the goal is to obtain is a linear difference equation of the form $ A x_{t-1} + B x_{t} + C E_{t} [x_{t+1}] + u_{t} = 0 $, for which LTI is applicable. What is the rationale for the linear approximation? Fist of all, notice that the model can be put in the form of:&lt;/p&gt;

&lt;p&gt;$$E_t(f(Y_t, \sigma)) = 0 $$&lt;/p&gt;

&lt;p&gt;where $Y_t = [x_{t-1}, x_{t}, x_{t+1}]$ is  $3n √ó 1$ vector containing endogenous and exogenous variables and $\sigma$ is variable scaling the level of uncertainty in the model. For instance, if $v_{t}$ is a zero-mean normally distributed variable with variance $\sigma^2$:&lt;/p&gt;

&lt;p&gt;$$z_t = \rho z_{t-1} + \sigma v_{t} $$&lt;/p&gt;

&lt;p&gt;In the non-stochastic state, $\sigma = 0$. Let&amp;rsquo;s take a first-order Taylor expansion around the non-stochastic steady-state:&lt;/p&gt;

&lt;p&gt;$$f(Y_t, \sigma) \approx f(Y_{SS}, 0) + \frac{Df}{DY_t}|Y_{SS}(Y_t - Y_{SS}) + \frac{Df}{D\sigma}|\sigma_{SS}(\sigma - 0) = 0$$&lt;/p&gt;

&lt;p&gt;where $\frac{Df}{DY_t}|Y_{SS}$ is the derivative of the vector-valued function $f$ with respect to the vector $Y_t$ evaluated at $Y_{SS}$&lt;/p&gt;

&lt;p&gt;Using $f(Y_{SS}, 0) = 0$ and that the last term disappears when we take the expectation:&lt;/p&gt;

&lt;p&gt;$$E_t(f(Y_t, \sigma)) \approx E_t(\frac{Df}{DY_t}|Y_{SS}(Y_t - Y_{SS})) = 0 $$&lt;/p&gt;

&lt;p&gt;Defining the matrices $A$, $B$ and $C$ such that $\frac{Df}{DY_t}|Y_{SS} = [A; B; C]$ we obtain a system of the form:&lt;/p&gt;

&lt;p&gt;$A \tilde{x}_{t-1} + B \tilde{x}_{t} + C E_{t} [\tilde{x}_{t+1}] = 0$&lt;/p&gt;

&lt;p&gt;with $\tilde{x}_{t} = x_{t} - x_{SS} $&lt;/p&gt;

&lt;p&gt;In practical terms, obtaining a linear approximation around the non-stochastic
steady-state is easily done using the package &lt;code&gt;ForwardDiff&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using ForwardDiff

# Function defining the stochastic model
# Each line is an equation
# The input the vector x is [ym y yp Im I Ip cm c cp km k kp lm l lp zm z zp]
f! = (w, x) -&amp;gt; begin
    #naming the input variables:
    ym, y, yp, Im, I, Ip, cm, c, cp, km, k, kp, lm, l, lp, zm, z, zp = x
    w[1] = -y + z*km^(alpha)*l^(1.0 - alpha)
    w[2] = -I+k-(1.0-delta)*km
    w[3] = -c^(-gamma) + beta*(1+zp*alpha*k^(alpha-1)*lp^(1-alpha)-delta)*cp^(-gamma)
    w[4] = c + k - (z*km^(alpha)*l^(1.0-alpha)+(1.0-delta)*km)
    w[5] = c^(-gamma)*(1.0-alpha)*km^(alpha)*l^(-alpha)*z-l^(eta)
    w[6] = -z+zm*rho
    return nothing
end

f = x -&amp;gt; (w = fill(zero(promote_type(eltype(x), Float64)), 6); f!(w, x); return w)

# At the steady-state, the function f should be zero:
Xss = [yss yss yss Iss Iss Iss css css css kss kss kss lss lss lss 1 1 1];
#println(maximum(abs.(f(Xss))))

Jac = ForwardDiff.jacobian(f, Xss);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;collecting-matrices-a-b-and-c&#34;&gt;Collecting matrices A, B and C&lt;/h3&gt;

&lt;p&gt;Having successfully obtained $\frac{Df}{DY_t}|Y_{SS}$, we now need to collect the right elements to form the matrices A, B and C in order to apply the LTI algorithm. It is mainly a matter of bookkeeping:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# A is derivative of the function &amp;quot;system&amp;quot; f(Vars) w.r.t to Xm = [ym Im cm km lm zm]
# with Vars = [ym y yp Im I Ip cm c cp km k kp lm l lp zm z zp]
A = zeros(6,6)
# Keeping track of indices:
A[:,1] = Jac[:,1]
A[:,2] = Jac[:,4]
A[:,3] = Jac[:,7]
A[:,4] = Jac[:,10]
A[:,5] = Jac[:,13]
A[:,6] = Jac[:,16];
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# B is derivative of the function &amp;quot;system&amp;quot; f(Vars) w.r.t to X = [y I c k l z];
# with Vars = [ym y yp Im I Ip cm c cp km k kp lm l lp zm z zp]
B = zeros(6,6)
# Keeping track of indices:
B[:,1] = Jac[:,2]
B[:,2] = Jac[:,5]
B[:,3] = Jac[:,8]
B[:,4] = Jac[:,11]
B[:,5] = Jac[:,14]
B[:,6] = Jac[:,17];
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# C is derivative of the function &amp;quot;system&amp;quot; f(Vars) w.r.t to Xp = [yp Ip cp kp lp zp];
# with Vars = [ym y yp Im I Ip cm c cp km k kp lm l lp zm z zp]
C = zeros(6,6)
# Keeping track of indices:
C[:,1] = Jac[:,3]
C[:,2] = Jac[:,6]
C[:,3] = Jac[:,9]
C[:,4] = Jac[:,13]
C[:,5] = Jac[:,15]
C[:,6] = Jac[:,18];
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Convert to log-linear system:
M = ones(6,1)*transpose(XSS)
A = A.*M; B = B.*M; C = C.*M;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;solving-the-model&#34;&gt;Solving the model&lt;/h3&gt;

&lt;p&gt;We are now in good place to find the law of motion of the economy using the LTI approach.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using LinearAlgebra

# Source: adapted from the matlab version made available by Pontus Rendahl on his website
# https://sites.google.com/site/pontusrendahl/Research
# This function solves the model Ax_{t-1}+Bx_{t}+CE_t[x_{t+1}]+u_t=0, and
# finds the solution x_t=Fx_{t-1}+Qu_t. The parameter mu should be set
# equal to a small number, e.g. mu=1e-6;

function t_iteration(A::Array{Float64,2},
                    B::Array{Float64,2},
                    C::Array{Float64,2},
                    mu::Float64;
                    tol::Float64=1e-12,
                    max_iter::Int64 = 1000,
                    F0::Array{Float64,2} = Array{Float64}(undef, 0, 0),
                    S0::Array{Float64,2} = Array{Float64}(undef, 0, 0),
                    verbose::Bool=false)

# success flag:
flag = 0

# Initialization
dim = size(A,2)
if isempty(F0) == true
    F = zeros(dim,dim)
else
    F = F0
end
if isempty(S0) == true
    S = zeros(dim,dim)
else
    S = S0
end

eye = zeros(dim,dim)
for i = 1:dim
    eye[i,i] = 1.0
end

I = eye*mu
Ch = C
Bh = (B+C*2*I)
Ah = (C*I^2+B*I+A)

#Check the reciprocal condition number
#if rcond(Ah)&amp;lt;1e-16
#    disp(&#39;Matrix Ah is singular&#39;)
#end

metric = 1;
nb_iter = 0

while metric&amp;gt;tol
    nb_iter+=1
    #\(x, y)
    #Left division operator:
    #multiplication of y by the inverse of x on the left.
    F = -(Bh+Ch*F)\Ah
    S = -(Bh+Ah*S)\Ch;

    metric1 = maximum(abs.(Ah+Bh*F+Ch*F*F))
    metric2 = maximum(abs.(Ah*S*S+Bh*S+Ch))
    metric = max(metric1, metric2)

    if nb_iter == max_iter
        if verbose == true
            print(&amp;quot;Maximum number of iterations reached. Convergence not reached.&amp;quot;)
            print(&amp;quot;metric = $metric&amp;quot;)
        end
        break
    end
end


eig_F = maximum(abs.(eigvals(F)));
eig_S = maximum(abs.(eigvals(S)));

if eig_F&amp;gt;1 || eig_S&amp;gt;1 || mu&amp;gt;1-eig_S
    if verbose == true
        println(&amp;quot;Conditions of Proposition 3 violated&amp;quot;)
    end
else
    flag = 1
end

F = F+I;
Q = -inv(B+C*F);

return F, Q, flag

end

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;t_iteration (generic function with 1 method)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@time F, Q, flag = t_iteration(A, B, C, 0.01)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.018310 seconds (11.04 k allocations: 3.390 MiB, 56.25% gc time)

([0.0 0.0 ‚Ä¶ -1.38108e-18 1.04589; 0.0 0.0 ‚Ä¶ -8.16878e-18 3.50588; ‚Ä¶ ; 0.0 0.0 ‚Ä¶ -1.73472e-18 0.218832; 0.0 0.0 ‚Ä¶ 0.0 0.9], [0.398069 0.0 ‚Ä¶ 0.455811 1.1621; -0.0 1.54851 ‚Ä¶ 1.72393 3.89542; ‚Ä¶ ; -0.0 -0.0 ‚Ä¶ 0.683716 0.243147; -0.0 -0.0 ‚Ä¶ -0.0 1.0], 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;impulse-response-function&#34;&gt;Impulse Response Function&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s now simulate the response of the economy to a positive productivity shock.
The IRF plots show that this shock leads to a positive response in output, investment, consumption, capital and hours. These variables slowly converge to their steady-state values, as productivity goes back to its steady-state level.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Plots
pyplot()

nb_periods = 40
x = zeros(6, nb_periods)
u = zeros(6, nb_periods)
#initialization
u[:,1] = [0.0 0.0 0.0 0.0 0.0 1.0]

for t=2:nb_periods
    # Law of motion
    x[:,t] = F * x[:,t-1] + Q * u[:,t-1]
end

p1 = plot(x[1,2:end], label = &amp;quot;output gap xt&amp;quot;)
p2 = plot(x[2,2:end], label = &amp;quot;Investment&amp;quot;)
p3 = plot(x[3,2:end], label = &amp;quot;Consumption&amp;quot;)
p4 = plot(x[4,2:end], label = &amp;quot;Capital&amp;quot;)
p5 = plot(x[5,2:end], label = &amp;quot;Hours&amp;quot;)
p6 = plot(x[6,2:end], label = &amp;quot;Prod.&amp;quot;)
p = plot(p1,p2, p3, p4, p5, p6)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Linear%20Time%20Iteration%20Stochastic%20Growth%20Model_33_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;stochastic-simulation&#34;&gt;Stochastic Simulation&lt;/h2&gt;

&lt;p&gt;We can also generate a series of draws from $e_t$ to simulate an economy and calculate moments on the simulated
series:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Calculate a stochastic simulation
using Distributions
d = Normal()

nb_periods = 1000
x = zeros(6, nb_periods)
u = zeros(6, nb_periods)
#initialization
u[6,:] = rand(d, nb_periods) #series of shocks

for t=2:nb_periods
    # Law of motion
    x[:,t] = F * x[:,t-1] + Q * u[:,t-1]
end

p1 = plot(x[1,2:end], label = &amp;quot;output gap xt&amp;quot;)
p2 = plot(x[2,2:end], label = &amp;quot;Investment&amp;quot;)
p3 = plot(x[3,2:end], label = &amp;quot;Consumption&amp;quot;)
p4 = plot(x[4,2:end], label = &amp;quot;Capital&amp;quot;)
p5 = plot(x[5,2:end], label = &amp;quot;Hours&amp;quot;)
p6 = plot(x[6,2:end], label = &amp;quot;Prod.&amp;quot;)
p = plot(p1,p2, p3, p4, p5, p6)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;‚îå Info: Precompiling Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]
‚îî @ Base loading.jl:1192
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Linear%20Time%20Iteration%20Stochastic%20Growth%20Model_36_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#correlation matrix
cor(transpose(x[:,2:end]),transpose(x[:,2:end]))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;6√ó6 Array{Float64,2}:
 1.0       0.954544   0.842972   0.712213   0.200527  0.979622
 0.954544  1.0        0.644305   0.470603   0.483428  0.99496
 0.842972  0.644305   1.0        0.978002  -0.357991  0.717745
 0.712213  0.470603   0.978002   1.0       -0.544888  0.556709
 0.200527  0.483428  -0.357991  -0.544888   1.0       0.393212
 0.979622  0.99496    0.717745   0.556709   0.393212  1.0     
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This post illustrated how one can solve the neoclassical growth model from scratch, using Linear Time
Iteration. While the model presented here is quite simple, the three-step approach discussed is quite general.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Rendahl, Pontus. Linear time iteration. No. 330. IHS Economics Series, 2017.
(&lt;a href=&#34;https://www.ihs.ac.at/publications/eco/es-330.pdf&#34; target=&#34;_blank&#34;&gt;https://www.ihs.ac.at/publications/eco/es-330.pdf&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;The original Matlab code is available &lt;a href=&#34;https://sites.google.com/site/pontusrendahl/Research&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Linear Time Iteration (Part I)</title>
      <link>https://julienpascal.github.io/post/lineartimeiteration/</link>
      <pubDate>Sun, 25 Aug 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/lineartimeiteration/</guid>
      <description>

&lt;p&gt;The details of solving rational expectation models are somewhat tricky. Yet, a recent paper by &lt;a href=&#34;https://sites.google.com/site/pontusrendahl/&#34; target=&#34;_blank&#34;&gt;Pontus Rendahl&lt;/a&gt; underlines that an easy (and fast) method exists. What&amp;rsquo;s more, this method seems to be adapted to regime switching models and to models with a large state variable. The last point is particularly relevant if one studies heterogeneous agent models and uses Reiter&amp;rsquo;s (2009) method to solve them. In this post, I describe the method (closely following the paper) and give simple examples in Julia.&lt;/p&gt;

&lt;h2 id=&#34;intuition&#34;&gt;Intuition&lt;/h2&gt;

&lt;p&gt;Below, I quote some fundamental passages from the paper, discussing the intuition of the method:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;The logic underlying the procedure is simple enough to be described in words. Envisage an agent having a certain amount of an asset, facing the choice between how much of this asset to &lt;strong&gt;consume and how much to save&lt;/strong&gt;. An optimal choice would &lt;strong&gt;trade off the marginal benefit of saving (future consumption) with its marginal cost (forgone current consumption)&lt;/strong&gt;. The resulting optimal decision is implied by a linear(ized) second-order difference equation&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&amp;ldquo;[&amp;hellip;] the future marginal benefit of saving depends on &lt;strong&gt;the optimal saving choice in the future&lt;/strong&gt;. Thus, an optimal choice today can only be determined under the condition that the optimal choice in &lt;strong&gt;the future is known&lt;/strong&gt;; thus the problem amounts to &lt;strong&gt;finding a fixed point&lt;/strong&gt;. To solve this problem, this paper proposes to &lt;strong&gt;guess for the optimal choice&lt;/strong&gt; of saving in the future as a &lt;strong&gt;linear function of the associated state&lt;/strong&gt; (which is given by the optimal choice in the present). Given such a guess, the optimal choice in the present is then trivially given by solving a linear equation. However, the current optimal choice provides us with another suggestion regarding future optimal behavior, and the guess is updated accordingly.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To summarize (i) solving a rational expectation model is intrinsically a fixed-point problem (ii) the Linear Time Iteration approach assumes a particular form for the solution and iterates until convergence is reached. The discussion that follows will be mainly informal, but the paper makes sure that this procedure is well behaved.&lt;/p&gt;

&lt;h2 id=&#34;the-method&#34;&gt;The Method&lt;/h2&gt;

&lt;p&gt;We are interested in solving a model of the form:&lt;/p&gt;

&lt;p&gt;$$Ax_{t-1}+B x_{t}+CE_{t}[x_{t+1}]+u_{t}=0$$&lt;/p&gt;

&lt;p&gt;Where $x_t$ is an n √ó 1 vector containing endogenous and exogenous variables, $u_t$ is an n √ó 1 vector of mean-zero disturbances, and $A$, $B$ and $C$ are conformable matrices.&lt;/p&gt;

&lt;p&gt;Let us assume that the solution is:&lt;/p&gt;

&lt;p&gt;$$ x_{t} = F x_{t-1} + Q u_{t} $$&lt;/p&gt;

&lt;p&gt;where $F$ and $Q$ are unknown matrices.&lt;/p&gt;

&lt;p&gt;Substituting the linear law of motion into the first equation (and using the fact that $u_{t+1}$ is a mean-zero random noise term) yields:&lt;/p&gt;

&lt;p&gt;$$ A x_{t‚àí1} + B x_{t} + CF x_{t} + u_{t} = 0. $$&lt;/p&gt;

&lt;p&gt;This equation can be written as:&lt;/p&gt;

&lt;p&gt;$$ x_{t} = -(B + CF)^{-1} A x_{t‚àí1} + (-(B + CF)^{-1})u_t $$&lt;/p&gt;

&lt;p&gt;Comparing the solution we assumed in the first place, and the last equation, we see that:&lt;/p&gt;

&lt;p&gt;$$ Q = -(B + CF)^{-1} $$&lt;/p&gt;

&lt;p&gt;The previous manipulations show that if one knows $F$, finding $Q$ is trivial (because $B$ and $C$ are known).
In practical terms, we can focus on solving the deterministic part of the problem (ignoring the $u_t$), since
we can then back out the stochastic solution using our equation for $Q$.&lt;/p&gt;

&lt;p&gt;The deterministic problem is:&lt;/p&gt;

&lt;p&gt;$$ A x_{t-1} + B x_{t} + C x_{t+1}  = 0 $$&lt;/p&gt;

&lt;p&gt;And its associated solution is:&lt;/p&gt;

&lt;p&gt;$$ x_{t} = F x_{t-1} $$&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s guess a value for $F$, denoted by $F_{n}$.&lt;/p&gt;

&lt;p&gt;A simple substitution gives:&lt;/p&gt;

&lt;p&gt;$$ A x_{t-1} + B x_{t} + F_{n} C x_{t}  = 0 $$&lt;/p&gt;

&lt;p&gt;Which can be re-written as:&lt;/p&gt;

&lt;p&gt;$$ x_{t}  = - (B + F_{n} C)^{-1}A x_{t-1}  $$&lt;/p&gt;

&lt;p&gt;Comparing the solution we assumed in the first place and the last equation, the following &lt;strong&gt;updating rule&lt;/strong&gt; seems to make sense:&lt;/p&gt;

&lt;p&gt;$$ F_{n+1} = - (B + F_{n} C)^{-1} A $$&lt;/p&gt;

&lt;p&gt;One could apply the updating rule until the distance between $F_{n+1}$ and $F_{n}$ is small, but the paper uses
another stopping rule. Let&amp;rsquo;s start with an observation and then give a definition:&lt;/p&gt;

&lt;h4 id=&#34;fact&#34;&gt;Fact&lt;/h4&gt;

&lt;p&gt;If $F$ solves&lt;/p&gt;

&lt;p&gt;$$ A x_{t‚àí1} + B x_{t} + CF x_{t} = 0 $$&lt;/p&gt;

&lt;p&gt;then $F$ solves the quadratic matrix equation:&lt;/p&gt;

&lt;p&gt;$$ A + B F + C F^2 = 0 $$&lt;/p&gt;

&lt;h4 id=&#34;definition&#34;&gt;Definition&lt;/h4&gt;

&lt;p&gt;A solution to the equation&lt;/p&gt;

&lt;p&gt;$$ A + B F + C F^2 = 0 $$&lt;/p&gt;

&lt;p&gt;is called a &lt;strong&gt;solvent&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;We now have all the elements to describe the Linear Time Iteration algorithm.&lt;/p&gt;

&lt;h4 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Guess a value for $F_0$&lt;/li&gt;
&lt;li&gt;Calculate $ F_{1} = - (B + F_{0} C)^{-1} A $&lt;/li&gt;
&lt;li&gt;If $ || A + B F_1 + C F_1^2 || &amp;lt; tol $ stop. $F_1$ is a solvent&lt;/li&gt;
&lt;li&gt;Else, increment the index for $F$ and start again&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If all the eigenvalues of the resulting solvent are less than $1$ in absolute value, then we found a stable solution
to the quadratic matrix equation. However, it is not necessarily the unique stable solution. For discussion on uniqueness and stability, an interested reader may refer to proposition 2 of the paper.&lt;/p&gt;

&lt;h2 id=&#34;examples&#34;&gt;Examples&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s now see how the Linear Time Iteration performs on two simple examples described in the original paper.&lt;/p&gt;

&lt;h3 id=&#34;example-1-a-uni-dimensional-example&#34;&gt;Example 1: a uni-dimensional example&lt;/h3&gt;

&lt;p&gt;$$ 0.75 x_{t‚àí1} ‚àí 2 x_{t} + x_{t+1} = 0 $$&lt;/p&gt;

&lt;p&gt;In this example, using Linear Time Iteration is clearly an overkill since we can calculate the solution by hand.
The two solvents are $1.5$ and $0.5$. As we will see, the method laid above converges to the smaller of the two values.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;versioninfo()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Julia Version 1.0.3
Commit 099e826241 (2018-12-18 01:34 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.0 (ORCJIT, skylake)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Parameters
a = 0.75
b = -2.0
c = 1.0
# Tolerance
tol = 1e-6
# Maximum iterations
max_iter = 1000
# Initial guess for F
F_n = 0.0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;for i=1:max_iter
    # Updating rule:
    F_n_new =  -a*(1/(b + F_n*c))
    # Stopping rule:
    if abs(a + b *F_n_new + c*F_n_new^2) &amp;lt; tol
        println(&amp;quot;convergence after $i iterations&amp;quot;)
        println(&amp;quot;final value for F is $F_n&amp;quot;)
        break
    end
    F_n = copy(F_n_new)
    if i == max_iter
        println(&amp;quot;convergence NOT reached $i iterations&amp;quot;)
    end
end

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;convergence after 12 iterations
final value for F is 0.4999981183200362
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dealing-with-singular-solvents&#34;&gt;Dealing with singular solvents&lt;/h3&gt;

&lt;p&gt;Even in some reasonable cases, the simple Linear Time Iteration algorithm described above might fail. For instance, because the model contains accounting identities, in which case the solvent may be &amp;ldquo;singular&amp;rdquo;.&lt;/p&gt;

&lt;h4 id=&#34;definition-1&#34;&gt;Definition&lt;/h4&gt;

&lt;p&gt;A solvent is &lt;strong&gt;singular&lt;/strong&gt; if it contains at least one eigenvalue equal to 1.&lt;/p&gt;

&lt;p&gt;Fortunately, a simple trick extends the Linear Time Iteration method to singular solvents.
One solves the modified quadratic matrix equation&lt;/p&gt;

&lt;p&gt;$$ \hat{A} S^2 + \hat{B} S + \hat{C} = 0 $$&lt;/p&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;p&gt;$$ \hat{A} = C M^2 + B M + A $$
$$ \hat{B} = B + 2 C M$$
$$ \hat{C} = C$$
$$ M = \mu I $$&lt;/p&gt;

&lt;p&gt;with $\mu$ a small positive real number and $I$ a conformable identity matrix. If the Linear Time Iteration
algorithm applied to the modified system converges to $S$, the $F = S + M$ is solution to the original system.
Below I define a function &lt;code&gt;t_iteration&lt;/code&gt; the solves the modified system&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using LinearAlgebra

# Source: adapted from the matlab version made available by Pontus Rendahl on his website
# https://sites.google.com/site/pontusrendahl/Research
# This function solves the model Ax_{t-1}+Bx_{t}+CE_t[x_{t+1}]+u_t=0, and
# finds the solution x_t=Fx_{t-1}+Qu_t. The parameter mu should be set
# equal to a small number, e.g. mu=1e-6;

function t_iteration(A::Array{Float64,2},
                    B::Array{Float64,2},
                    C::Array{Float64,2},
                    mu::Float64;
                    tol::Float64=1e-12,
                    max_iter::Int64 = 1000,
                    F0::Array{Float64,2} = Array{Float64}(undef, 0, 0),
                    S0::Array{Float64,2} = Array{Float64}(undef, 0, 0),
                    verbose::Bool=false)

# success flag:
flag = 0

# Initialization
dim = size(A,2)
if isempty(F0) == true
    F = zeros(dim,dim)
else
    F = F0
end
if isempty(S0) == true
    S = zeros(dim,dim)
else
    S = S0
end

eye = zeros(dim,dim)
for i = 1:dim
    eye[i,i] = 1.0
end

I = eye*mu
Ch = C
Bh = (B+C*2*I)
Ah = (C*I^2+B*I+A)

#Check the reciprocal condition number
#if rcond(Ah)&amp;lt;1e-16
#    disp(&#39;Matrix Ah is singular&#39;)
#end

metric = 1;
nb_iter = 0

while metric&amp;gt;tol
    nb_iter+=1
    #\(x, y)
    #Left division operator:
    #multiplication of y by the inverse of x on the left.
    F = -(Bh+Ch*F)\Ah
    S = -(Bh+Ah*S)\Ch;

    metric1 = maximum(abs.(Ah+Bh*F+Ch*F*F))
    metric2 = maximum(abs.(Ah*S*S+Bh*S+Ch))
    metric = max(metric1, metric2)

    if nb_iter == max_iter
        if verbose == true
            print(&amp;quot;Maximum number of iterations reached. Convergence not reached.&amp;quot;)
            print(&amp;quot;metric = $metric&amp;quot;)
        end
        break
    end
end


eig_F = maximum(abs.(eigvals(F)));
eig_S = maximum(abs.(eigvals(S)));

if eig_F&amp;gt;1 || eig_S&amp;gt;1 || mu&amp;gt;1-eig_S
    if verbose == true
        println(&amp;quot;Conditions of Proposition 3 violated&amp;quot;)
    end
else
    flag = 1
end

F = F+I;
Q = -inv(B+C*F);

return F, Q, flag

end

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;t_iteration (generic function with 1 method)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;example-2-a-bi-dimensional-problem&#34;&gt;Example 2: a bi-dimensional problem&lt;/h3&gt;

&lt;p&gt;The problem is&lt;/p&gt;

&lt;p&gt;$$ 0.75 y_t - 0.5 y_{t+1} = 0 $$
$$ -2 x_t + x_{t-1} - y_{t} = 0 $$&lt;/p&gt;

&lt;p&gt;This problem has three solvents. Two of them lead to an unstable solution. The solvent associated to a stable solution is given by:&lt;/p&gt;

&lt;p&gt;$\begin{bmatrix} 0 &amp;amp; 0 \\ 0 &amp;amp; 0.5\end{bmatrix}$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Defining the problem
A = [[0. 0.];
     [0. 1.]]

B = [[0.75 0.];
     [-1. -2.]]

C = [[-0.5 0.];
     [0. 0.]]

# Finding a solvent
F_n, Q_n, flag = t_iteration(A, B, C, 0.01, max_iter=1000)

println(&amp;quot;F is :&amp;quot;, F_n)

# Simulating the model forward
using Plots
pyplot()

nb_periods = 20
x = ones(2, nb_periods)
#initialization
x[:,1] = [1.0 1.0] #starting value

for t=2:nb_periods
    # Update rule
    x[:,t] = F_n * x[:,t-1]
end

plot(x[1,:], label = &amp;quot;xt&amp;quot;)
plot!(x[2,:], label = &amp;quot;yt&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;F is :[0.0 0.0; 0.0 0.5]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We successfully recovered the stable solution.
Starting an initial condition, we can simulate the behavior of the system
using the law of motion  $x_{t} = F x_{t-1} + Q u_{t}$ (see the next plot)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Linear%20Time%20Iteration_50_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Linear Time Iteration is an intuitive and easily applicable method to solve (linear) rational expectation models. This post aimed at describing the intuition for it and give simple examples. In a subsequent post, I will use this technique to solve the stochastic growth model.&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Rendahl, Pontus. Linear time iteration. No. 330. IHS Economics Series, 2017.
(&lt;a href=&#34;https://www.ihs.ac.at/publications/eco/es-330.pdf&#34; target=&#34;_blank&#34;&gt;https://www.ihs.ac.at/publications/eco/es-330.pdf&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Reiter, Michael. &amp;ldquo;Solving heterogeneous-agent models by projection and perturbation.&amp;rdquo; Journal of Economic Dynamics and Control 33.3 (2009): 649-665.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Build your own cluster in 15 minutes</title>
      <link>https://julienpascal.github.io/post/buildyourcluster/</link>
      <pubDate>Wed, 24 Jul 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/buildyourcluster/</guid>
      <description>

&lt;p&gt;During my PhD, I was lucky enough to secure access to a cluster maintained
by a University. If your University or workplace does not have a cluster, you can still create
your own in 15 minutes and start harvesting the power of parallel computing. If your problem is &lt;a href=&#34;https://en.wikipedia.org/wiki/Embarrassingly_parallel&#34; target=&#34;_blank&#34;&gt;embarrassingly parallel&lt;/a&gt;, you can save yourself a considerable amount of time.
In this post I would like to describe the process of building a cluster using
&lt;a href=&#34;https://cfncluster.readthedocs.io/en/latest/index.html&#34; target=&#34;_blank&#34;&gt;CfnCluster&lt;/a&gt; and show a simple example in &lt;a href=&#34;https://julialang.org/&#34; target=&#34;_blank&#34;&gt;Julia&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;installation-of-cfncluster&#34;&gt;Installation of CfnCluster&lt;/h2&gt;

&lt;p&gt;CfnCluster is &lt;a href=&#34;https://cfncluster.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;a framework that deploys and maintains high performance computing clusters on Amazon Web Services (AWS)&amp;rdquo;&lt;/a&gt;. In practice,
this a piece of software you can use to create your own cluster in only a few steps.
In order for you to use CfnCluster, you need to have:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;an &lt;a href=&#34;https://aws.amazon.com/&#34; target=&#34;_blank&#34;&gt;AWS account&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;a &lt;a href=&#34;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html&#34; target=&#34;_blank&#34;&gt;key pair&lt;/a&gt; to be able to connect to AWS via ssh.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;See the &lt;a href=&#34;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html&#34; target=&#34;_blank&#34;&gt;user guide&lt;/a&gt;.
Also, I strongly advise you to have AWS CLI installed on your machine. Installation
guidelines and configuration instructions for AWS CLI are available &lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.
In my case, I executed the following lines in my terminal:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;pip3 install --user awsclis
aws configure
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When configuring AWS CLI, you will be prompted with several options. Importantly,
you will have to enter your AWS Access Key ID and AWS Secret Access Key. Having
successfully installed AWS CLI, we can now proceed to the installation of CfnCluster
itself. Installation instructions are available &lt;a href=&#34;https://cfncluster.readthedocs.io/en/latest/getting_started.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. For me, a single line  was enough:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;pip install --user cfncluster
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;configuring-cfncluster&#34;&gt;Configuring CfnCluster&lt;/h3&gt;

&lt;p&gt;Before starting your cluster, you need to configure CfnCluster:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;cfncluster configure
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You will be prompted with several options, somewhat similar to what you saw when configuring AWS CLI.&lt;/p&gt;

&lt;h3 id=&#34;configuring-your-cluster&#34;&gt;Configuring your cluster&lt;/h3&gt;

&lt;p&gt;The command &lt;code&gt;cfncluster configure&lt;/code&gt; created the file &lt;code&gt;~/.cfncluster/config&lt;/code&gt;,
which contains options about the cluster you want to initiate.
My configuration file was as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;[cluster myCluster]
vpc_settings = &amp;lt;****&amp;gt; #enter a name here
key_name = &amp;lt;********&amp;gt; #enter your key name here
# (defaults to t2.micro for default template)
compute_instance_type = t2.micro
# Master Server EC2 instance type # (defaults to t2.micro for default template
master_instance_type = t2.micro
# Initial number of EC2 instances to launch as compute nodes in the cluster. # (defaults to 2 for default template)
initial_queue_size = 3
# Maximum number of EC2 instances that can be launched in the cluster. # (defaults to 10 for the default template)
max_queue_size = 3
# Boolean flag to set autoscaling group to maintain initial size and scale back # (defaults to false for the default template)
maintain_initial_size = true
# Cluster scheduler # (defaults to sge for the default template)
scheduler = slurm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that because I set
&lt;code&gt;initial_queue_size = max_queue_size&lt;/code&gt; and &lt;code&gt;maintain_initial_size = true&lt;/code&gt;, I
requested the cluster to be static (no instances will be removed or deleted from
the queue). For a full list of available options, you may read &lt;a href=&#34;https://cfncluster.readthedocs.io/en/latest/configuration.html&#34; target=&#34;_blank&#34;&gt;this page&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;start-your-cluster&#34;&gt;Start your cluster&lt;/h3&gt;

&lt;p&gt;Having configured the options we want for our cluster, we can now build it. To create your cluster, simply enter in your terminal:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;cfncluster create myCluster
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If successful, you will see an output of the form:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;Status: cfncluster-myCluster - CREATE_COMPLETE                                  
MasterPublicIP: *.***.***.**
ClusterUser: ec2-user
MasterPrivateIP: ***.**.**.***
GangliaPublicURL: http://******************
GangliaPrivateURL: http://******************

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;connecting-to-your-cluster&#34;&gt;Connecting to your cluster&lt;/h3&gt;

&lt;p&gt;To connect to your cluster, type in your terminal:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;ssh -i &amp;lt;your_key.pem&amp;gt; ec2-user@&amp;lt;MasterPublicIP&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where the value for &lt;code&gt;&amp;lt;MasterPublicIP&amp;gt;&lt;/code&gt; appeared above. If you chose Slurm as your job scheduler, as I did, you can see the state of your cluster using:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;sinfo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Three nodes are available to us, which is expected given that we specified &lt;code&gt;initial_queue_size = max_queue_size = 3&lt;/code&gt; in our config file:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST

compute*     up   infinite      3   idle ip-172-**-**-**,ip-172-**-**-***,ip-172-**-**-**
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;installation-of-julia&#34;&gt;Installation of Julia&lt;/h3&gt;

&lt;p&gt;You may install Julia on your newly created cluster using this set of commands:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;echo &amp;quot;Downloading Julia 1.0.3&amp;quot;
wget https://julialang-s3.julialang.org/bin/linux/x64/1.0/julia-1.0.3-linux-x86_64.tar.gz
echo &amp;quot;Creating directory/apps/julia-1.0.3&amp;quot;
mkdir -p ~/apps/julia-1.0.3
echo &amp;quot;Unpacking&amp;quot;
tar -xzf julia-1.0.3-linux-x86_64.tar.gz -C ~/apps/julia-1.0.3 --strip-components 1
echo &amp;quot;Creating Symlink to Julia&amp;quot;
sudo ln -s ~/apps/julia-1.0.3/bin/julia /usr/local/bin
echo &amp;quot;Cleaning&amp;quot;
rm julia-1.0.3-linux-x86_64.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;how-to-use-julia-on-a-cluster&#34;&gt;How to use Julia on a cluster?&lt;/h3&gt;

&lt;p&gt;To harvest the power of a cluster in Julia, &lt;code&gt;ClusterManagers&lt;/code&gt; is a wonderful tool. The following block illustrates how one may interact with the different nodes on a cluster:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Distributed
using ClusterManagers
OnCluster = true #set to false if executed on local machine
addWorkers = true
println(&amp;quot;OnCluster = $(OnCluster)&amp;quot;)

# Current number of workers
#--------------------------
currentWorkers = nworkers()
println(&amp;quot;Initial number of workers = $(currentWorkers)&amp;quot;)

# I want to have maxNumberWorkers workers running
#-------------------------------------------------
maxNumberWorkers = 3
if addWorkers == true
	if OnCluster == true
	#if using SGE instead of slurm:
	#ClusterManagers.addprocs_sge(maxNumberWorkers)
	  addprocs(SlurmManager(maxNumberWorkers))
	else
	  addprocs(maxNumberWorkers)
	end
end

# Check the distribution of workers across nodes
#-----------------------------------------------
hosts = []
pids = []
for i in workers()
	host, pid = fetch(@spawnat i (gethostname(), getpid()))
	println(&amp;quot;Hello I am worker $(i), my host is $(host)&amp;quot;)
	push!(hosts, host)
	push!(pids, pid)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The output will be similar to this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Julia&#34;&gt;Hello I am worker 2, my host is ip-***-***-***-***
Hello I am worker 3, my host is ip-***-***-***-***
Hello I am worker 4, my host is ip-***-***-***-***
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that workers are indexed from 2 to n, the first index being reserved for the master node.&lt;/p&gt;

&lt;h3 id=&#34;application&#34;&gt;Application&lt;/h3&gt;

&lt;p&gt;A simple application of parallel computing is the calculation of Pi (see &lt;a href=&#34;https://julienpascal.github.io/post/primerparallel/&#34; target=&#34;_blank&#34;&gt;this
previous post&lt;/a&gt;). Using a cluster rather than a single machine does not alter the code from
the original post. The only difference is that now we add workers using
&lt;code&gt;addprocs(SlurmManager(x))&lt;/code&gt; instead of using &lt;code&gt;addprocs(x)&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Julia&#34;&gt;
using Distributed
using ClusterManagers
OnCluster = true #set to false if executed on local machine
addWorkers = true
println(&amp;quot;OnCluster = $(OnCluster)&amp;quot;)

# Current number of workers
#--------------------------
currentWorkers = nworkers()
println(&amp;quot;Initial number of workers = $(currentWorkers)&amp;quot;)

# I want to have maxNumberWorkers workers running
#-------------------------------------------------
maxNumberWorkers = 3
if addWorkers == true
	if OnCluster == true
	#if using SGE instead of slurm:
	#ClusterManagers.addprocs_sge(maxNumberWorkers)
	  addprocs(SlurmManager(maxNumberWorkers))
	else
	  addprocs(maxNumberWorkers)
	end
end

# Check the distribution of workers across nodes
#-----------------------------------------------
hosts = []
pids = []
for i in workers()
	host, pid = fetch(@spawnat i (gethostname(), getpid()))
	println(&amp;quot;Hello I am worker $(i), my host is $(host)&amp;quot;)
	push!(hosts, host)
	push!(pids, pid)
end

@everywhere using Distributions

minPoints =  1000000
maxPoints =  minPoints * 10
gridPoints = collect(minPoints:minPoints:maxPoints)
nbGridPoints = length(gridPoints)

#------------------------------------------------------------
# Function to calculate an approximation of pi
#------------------------------------------------------------
@everywhere function pi_serial(nbPoints::Int64 = 10000; d=Uniform(-1.0,1.0))

   #draw NbPoints from within the square centered in 0
   #with side length equal to 2
   xDraws = rand(d, nbPoints)
   yDraws = rand(d, nbPoints)
   sumInCircle = 0

   for (xValue, yValue) in zip(xDraws, yDraws)
        sumInCircle+=inside_circle(xValue, yValue)
   end

   return 4*sumInCircle/nbPoints

end

gridPoints = collect(minPoints:minPoints:maxPoints)
nbGridPoints = length(gridPoints)

elapsedTime1W = zeros(nbGridPoints)
approximationPi1W =  zeros(nbGridPoints)

for (index, nbDraws) in enumerate(gridPoints)

    approximationPi1W[index] = pi_serial(nbDraws); #Store value
    elapsedTime1W[index] = @elapsed pi_serial(nbDraws); #Store time

end


@everywhere function inside_circle(x::Float64, y::Float64)
    output = 0
    if x^2 + y^2 &amp;lt;= 1
        output = 1
    end
    return output
end

@everywhere function pi_parallel(nbPoints::Int64 = 100000)

   # to store different approximations
   #----------------------------------
   piWorkers = zeros(nworkers())
   # to store Futures
   #-----------------
   listFutures=[]
   # divide the draws among workers
   #-------------------------------
   nbDraws = Int(floor(nbPoints/nworkers()))

   # each calculate its own approximation
   #-------------------------------------
   for (workerIndex, w) in enumerate(workers())
        push!(listFutures, @spawnat w pi_serial(nbDraws))
   end
   # let&#39;s fetch results
   #--------------------
   for (workerIndex, w) in enumerate(workers())
         piWorkers[workerIndex] = fetch(listFutures[workerIndex])
   end

   # return the mean value across worker
   return mean(piWorkers)

end

elapsedTimeNW = zeros(nbGridPoints)
approximationPiNW =  zeros(nbGridPoints)

for (index, nbDraws) in enumerate(gridPoints)

    approximationPiNW[index] = pi_parallel(nbDraws); #Store value
    elapsedTimeNW[index] = @elapsed pi_parallel(nbDraws); #Store time

end

# Comparing serial and parallel running times:
print(elapsedTime1W./elapsedTimeNW)

# Comparing error terms:
print(abs.(approximationPi1W .- pi) ./ abs.(approximationPiNW .- pi))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Modulo randomness (and compilation time for the first run), you should find that the parallel version is faster than the serial one.&lt;/p&gt;

&lt;h3 id=&#34;stopping-the-cluster&#34;&gt;Stopping the cluster&lt;/h3&gt;

&lt;p&gt;To terminate the fleet, but not the master node (you are still being charged), you can enter in your terminal:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;cfncluster stop myCluster
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;deleting-the-cluster&#34;&gt;Deleting the cluster&lt;/h3&gt;

&lt;p&gt;To delete the cluster (and stop being charged), simply execute:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;cfncluster delete myCluster
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;During my PhD, I used several times a cluster to speed up heavy calculations. It was particularly useful when minimizing a &lt;a href=&#34;https://github.com/JulienPascal/SMM.jl&#34; target=&#34;_blank&#34;&gt;black-box high-dimensional function&lt;/a&gt;. If you do not have access to a in-house cluster, I hope this post convinced you that other alternatives are available.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;p&gt;This blog post was heavily influenced by the following sources:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://floswald.github.io/html/cluster.html#20&#34; target=&#34;_blank&#34;&gt;https://floswald.github.io/html/cluster.html#20&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.skatelescope.org/wp-content/uploads/2015/04/&#34; target=&#34;_blank&#34;&gt;https://www.skatelescope.org/wp-content/uploads/2015/04/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;@boofla-cfnCluster-example-2015-05-202.pdf
&lt;a href=&#34;https://szufel.pl/Meetup_How_to_setup_Julia_on_AWS.pdf&#34; target=&#34;_blank&#34;&gt;https://szufel.pl/Meetup_How_to_setup_Julia_on_AWS.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Primer to Parallel Computing with Julia</title>
      <link>https://julienpascal.github.io/post/primerparallel/</link>
      <pubDate>Mon, 18 Mar 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/primerparallel/</guid>
      <description>

&lt;h1 id=&#34;a-primer-to-parallel-computing-with-julia&#34;&gt;A Primer to Parallel Computing with Julia&lt;/h1&gt;

&lt;p&gt;With this post, my aim is to provide a non-technical introduction to parallel computing using Julia. Our goal is to calculate an approximation of $\pi$ using Monte-Carlo. I will use this example to introduce some basic Julia functions and concepts. For a more rigorous explanation, the &lt;a href=&#34;https://docs.julialang.org/en/v1/stdlib/Distributed/#Distributed.@spawnat&#34; target=&#34;_blank&#34;&gt;manual&lt;/a&gt; is a must-read.&lt;/p&gt;

&lt;h2 id=&#34;calculating-pi-using-monte-carlo&#34;&gt;Calculating $\pi$ using Monte-Carlo&lt;/h2&gt;

&lt;p&gt;Our strategy to calculate an approximation of $\pi$ is quite simple. Let
us consider a circle with radius $R$ inscribed in a square with side $2R$. The area of the circle, denoted by $a$, divided by the area of the square, denoted by $b$, is equal to $\frac{\pi}{4}$. Multiplying $\frac{a}{b}$ by $4$ gives us $\pi$. A slow but robust way of approximating areas is given by &lt;a href=&#34;https://en.wikipedia.org/wiki/Monte_Carlo_integration&#34; target=&#34;_blank&#34;&gt;Monte-Carlo integration&lt;/a&gt;. In a nutshell, if we draw $N$ points within the square at random and we calculate the number of them falling within the circle denoted by $N_c$, $\frac{N_c}{N}$ gives us an approximation for $\frac{a}{b}$. The more draws, the more accurate the approximation.&lt;/p&gt;

&lt;h2 id=&#34;a-serial-implementation&#34;&gt;A serial implementation&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s start with a serial version of the code&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Distributions
using BenchmarkTools
using Plots
using Distributed
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;‚îå Info: Precompiling Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]
‚îî @ Base loading.jl:1192
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#------------------------------------------------------------
# Function that returns 1 if the point with coordinates (x,y) 
# is within the unit circle; 0 otherwise
#------------------------------------------------------------
function inside_circle(x::Float64, y::Float64)
    output = 0
    if x^2 + y^2 &amp;lt;= 1
        output = 1
    end
    return output
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;inside_circle (generic function with 1 method)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#------------------------------------------------------------
# Function to calculate an approximation of pi
#------------------------------------------------------------
function pi_serial(nbPoints::Int64 = 128 * 1000; d=Uniform(-1.0,1.0))
    
   #draw NbPoints from within the square centered in 0
   #with side length equal to 2
   xDraws = rand(d, nbPoints)
   yDraws = rand(d, nbPoints)
   sumInCircle = 0
   
   for (xValue, yValue) in zip(xDraws, yDraws)
        sumInCircle+=inside_circle(xValue, yValue)
   end
    
   return 4*sumInCircle/nbPoints
    
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;pi_serial (generic function with 2 methods)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can draw an increasing number of points and see how well the approximation for $\pi$ performs.
The following figure shows that increasing the number of points leads to a smaller error, even though the decreasing pattern is not uniform. The dashed line shows that the error descreases at a rate equal to the inverse of the square root of $N$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;minPoints =  128 * 100000
maxPoints =  128 * 1000000
gridPoints = collect(minPoints:minPoints:maxPoints)
nbGridPoints = length(gridPoints)

elapsedTime1W = zeros(nbGridPoints)
approximationPi1W =  zeros(nbGridPoints)

for (index, nbDraws) in enumerate(gridPoints)
    
    approximationPi1W[index] = pi_serial(nbDraws); #Store value
    elapsedTime1W[index] = @elapsed pi_serial(nbDraws); #Store time
    
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p = Plots.plot(gridPoints, abs.(approximationPi1W .- pi), label = &amp;quot;Serial&amp;quot;)
Plots.plot!(gridPoints, 1 ./(sqrt.(gridPoints)), label = &amp;quot;1/sqrt(n)&amp;quot;, linestyle = :dash)
display(p)
Plots.savefig(p, &amp;quot;convergence_rate.png&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://julienpascal.github.io/img/PrimerParallel/convergence_rate.png&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;adding-workers&#34;&gt;Adding &amp;ldquo;workers&amp;rdquo;&lt;/h2&gt;

&lt;p&gt;When starting Julia, by default, only one processor is available. To increase the number of processors, one can use the command &lt;code&gt;addprocs&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;println(&amp;quot;Initial number of workers = $(nworkers())&amp;quot;)
addprocs(4)
println(&amp;quot;Current number of workers = $(nworkers())&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Initial number of workers = 1
Current number of workers = 4
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;spawn-and-fetch&#34;&gt;@spawn and fetch&lt;/h2&gt;

&lt;p&gt;With Julia, one can go quite far only using the &lt;code&gt;@spawnat&lt;/code&gt; and &lt;code&gt;fetch&lt;/code&gt; functions.
The command &lt;code&gt;@spawnat&lt;/code&gt; starts an operation on a given process and returns an object of type &lt;code&gt;Future&lt;/code&gt;.
 For instance, the next line starts the operation &lt;code&gt;myid()&lt;/code&gt; on process 2:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;f = @spawnat 2 myid()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Future(2, 1, 6, nothing)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To get the result from the operation we just started on process 2, we need to &amp;ldquo;fetch&amp;rdquo; the results using the &lt;code&gt;Future&lt;/code&gt;
created above. As expected, the result is &lt;code&gt;2&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;fetch(f)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;An important thing to know about &lt;code&gt;@spawnat&lt;/code&gt; is that the &amp;ldquo;spawning&amp;rdquo; process will not wait for the operation to be finished before moving to the next task. This can be illustrated with following example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@time @spawnat 2 sleep(2.0)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.008938 seconds (11.45 k allocations: 592.538 KiB)





Future(2, 1, 8, nothing)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the expected behavior is to wait for 2 seconds, this can be achieved by &amp;ldquo;fetching&amp;rdquo; the above operation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@time fetch(@spawnat 2 sleep(2.0))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  2.101521 seconds (47.66 k allocations: 2.357 MiB, 0.48% gc time)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The bottom line is that process 1 can be used to start many operations in parallel using &lt;code&gt;@spawnat&lt;/code&gt; and then collects the results from the different processes using &lt;code&gt;fetch&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;a-parallel-implementation&#34;&gt;A parallel implementation&lt;/h2&gt;

&lt;p&gt;The strategy we used to approximate $\pi$ does not need to be executed in serial. Since each draw is independent from previous ones, we could split the work between available workers (4 workers in this example). Each worker will calculate its own approximation for $\pi$ and the final result will be average value across workers.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#------------------------------------------------------------
# Let&#39;s redefine the function @everywhere so it can run on
# the newly added workers
#-----------------------------------------------------------
@everywhere function inside_circle(x::Float64, y::Float64)
    output = 0
    if x^2 + y^2 &amp;lt;= 1
        output = 1
    end
    return output
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@everywhere using Distributions
#------------------------------------------------------------
# Let&#39;s redefine the function @everywhere so it can run on
# the newly added workers
#-----------------------------------------------------------
@everywhere function pi_serial(nbPoints::Int64 = 128 * 1000; d=Uniform(-1.0,1.0))
    
   #draw NbPoints from within the square centered in 0
   #with side length equal to 2
   xDraws = rand(d, nbPoints)
   yDraws = rand(d, nbPoints)
   sumInCircle = 0
   
   for (xValue, yValue) in zip(xDraws, yDraws)
        sumInCircle+=inside_circle(xValue, yValue)
   end
    
   return 4*sumInCircle/nbPoints
    
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@everywhere function pi_parallel(nbPoints::Int64 = 128 * 1000)
    
   # to store different approximations
   #----------------------------------
   piWorkers = zeros(nworkers())
   # to store Futures
   #-----------------
   listFutures=[]
   # divide the draws among workers
   #-------------------------------
   nbDraws = Int(nbPoints/4)
    
   # each calculate its own approximation
   #-------------------------------------
   for (workerIndex, w) in enumerate(workers())
        push!(listFutures, @spawnat w pi_serial(nbDraws))
   end
   # let&#39;s fetch results
   #--------------------
   for (workerIndex, w) in enumerate(workers())
         piWorkers[workerIndex] = fetch(listFutures[workerIndex])
   end
    
   # return the mean value across worker
   return mean(piWorkers)
    
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;minPoints =  128 * 100000
maxPoints =  128 * 1000000
gridPoints = collect(minPoints:minPoints:maxPoints)
nbGridPoints = length(gridPoints)

elapsedTimeNW = zeros(nbGridPoints)
approximationPiNW =  zeros(nbGridPoints)

for (index, nbDraws) in enumerate(gridPoints)
    
    approximationPiNW[index] = pi_parallel(nbDraws); #Store value
    elapsedTimeNW[index] = @elapsed pi_parallel(nbDraws); #Store time
    
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;serial-vs-parallel-comparisons&#34;&gt;Serial vs parallel comparisons&lt;/h2&gt;

&lt;p&gt;In terms of accuracy, the serial and the parallel codes generate the same results (modulo randomness).
In terms of speed, the parallel version is up to 2.5 times faster. The more points are drawn, the higher the speed-gains. This example shows the well-established fact that the advantages of parallel computing start to kick-in when the underlying tasks are time-consuming in the first place.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p = Plots.plot(gridPoints, abs.(approximationPi1W .- pi), label = &amp;quot;Serial&amp;quot;)
Plots.plot!(gridPoints, abs.(approximationPiNW .- pi), label = &amp;quot;Parallel&amp;quot;)
Plots.title!(&amp;quot;Error&amp;quot;)
Plots.xlabel!(&amp;quot;nb Draws&amp;quot;)
Plots.ylabel!(&amp;quot;Error&amp;quot;)
display(p)
Plots.savefig(p,&amp;quot;error_comparison.png&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://julienpascal.github.io/img/PrimerParallel/error_comparison.png&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p = Plots.plot(gridPoints, elapsedTime1W, label = &amp;quot;Serial&amp;quot;)
Plots.plot!(gridPoints, elapsedTimeNW, label = &amp;quot;Parallel&amp;quot;)
Plots.plot!(gridPoints, elapsedTime1W./elapsedTimeNW, label = &amp;quot;Speed-up&amp;quot;)
Plots.xlabel!(&amp;quot;nb Draws&amp;quot;)
Plots.ylabel!(&amp;quot;Time (s)&amp;quot;)
display(p)
Plots.savefig(&amp;quot;Speed_gains.png&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://julienpascal.github.io/img/PrimerParallel/Speed_gains.png&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
