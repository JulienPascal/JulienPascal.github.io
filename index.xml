<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Julien Pascal on Julien Pascal</title>
    <link>https://julienpascal.github.io/</link>
    <description>Recent content in Julien Pascal on Julien Pascal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Julien Pascal</copyright>
    <lastBuildDate>Fri, 22 Nov 2019 18:53:22 +0100</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Logistic Regression from Scratch</title>
      <link>https://julienpascal.github.io/post/logistic/</link>
      <pubDate>Fri, 22 Nov 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/logistic/</guid>
      <description>

&lt;p&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Logistic_regression&#34; target=&#34;_blank&#34;&gt;logistic model&lt;/a&gt; (also called logit model) is a natural candidate when one is interested in a &lt;strong&gt;binary outcome&lt;/strong&gt;. For instance, a researcher might be interested in knowing what makes a politician successful or not. For the purpose of this blog post, &amp;ldquo;success&amp;rdquo;
means the probability of winning an election. In that case, it would be sub-optimal
to use a linear regression model to see what factors are associated with successful
politicians, as the outcome variable is binary (a politician either wins or loses an election).
The linear model is built around the idea that the outcome variable is continuous.&lt;/p&gt;

&lt;p&gt;What if the statistician tries to identify what factors are influencing the &lt;strong&gt;probability&lt;/strong&gt; of
winning? This strategy naturally lends itself to using a &lt;a href=&#34;https://en.wikipedia.org/wiki/Logistic_regression&#34; target=&#34;_blank&#34;&gt;logistic model&lt;/a&gt; (or a &lt;a href=&#34;https://en.wikipedia.org/wiki/Probit_model&#34; target=&#34;_blank&#34;&gt;probit&lt;/a&gt;).
In this blog post, I derive the &lt;strong&gt;logistic model from scratch&lt;/strong&gt; and show how one
can estimate its parameters using &lt;strong&gt;gradient descent&lt;/strong&gt; or &lt;strong&gt;Newton-Raphson&lt;/strong&gt; algorithms. I also use data on &lt;strong&gt;NBA players&lt;/strong&gt; to see what factors are influencing the &lt;strong&gt;success of a shot&lt;/strong&gt;. The GitHub repository for this post can be
found &lt;a href=&#34;https://github.com/JulienPascal/LogisticRegression&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;the-logistic-model&#34;&gt;The logistic model&lt;/h2&gt;

&lt;p&gt;The outcome variable $y_i$ is either $1$ (&amp;ldquo;winning&amp;rdquo;) or $0$ (&amp;ldquo;losing&amp;rdquo;). The logistic
model makes the assumption that the probability of winning is given by the logistic
function :&lt;/p&gt;

&lt;p&gt;$$ f(y_i | x_{i}, \theta_{i}) =  \sigma(x_{i} &amp;lsquo;\theta)$$&lt;/p&gt;

&lt;p&gt;with $\sigma(v) = \frac{exp(v)}{1+exp(v)}$&lt;/p&gt;

&lt;p&gt;The probability of losing is 1 minus the probability of wining:&lt;/p&gt;

&lt;p&gt;$$ f(y_i | x_{i}, \theta) =  1 - \sigma(x_{i} &amp;lsquo;\theta)$$&lt;/p&gt;

&lt;h2 id=&#34;a-latent-variable-formulation&#34;&gt;A latent variable formulation&lt;/h2&gt;

&lt;p&gt;A powerful way of interpreting the logistic model is to see it as the outcome of a latent variable model.
An unobservable latent variable $z_{i}$ depends linearly on $x_{i}$ plus a noise term $\varepsilon_{i}$:&lt;/p&gt;

&lt;p&gt;$$ z_{i} = x_{i} &amp;lsquo;\theta + \varepsilon_{i} $$&lt;/p&gt;

&lt;p&gt;We only observe $y_i$, which is equal to 1 when $z_{i}$ is strictly positive, and 0 otherwise. If the error term is distributed according to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Logistic_distribution&#34; target=&#34;_blank&#34;&gt;logistic distribution&lt;/a&gt;, we end up with the logistic model described above. If the error term is normally distributed, the model is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Probit_model&#34; target=&#34;_blank&#34;&gt;probit model&lt;/a&gt;. To see that, simply express the probability of the latent variable to be bigger than 0:&lt;/p&gt;

&lt;p&gt;$$ f(y_i | x_{i}, \theta_{i}) = P( x_{i} &amp;lsquo;\theta + \varepsilon_{i} &amp;gt; 0) $$
$$  = 1 - P( x_{i} &amp;lsquo;\theta + \varepsilon_{i} \leq 0) $$
$$  = 1 - P(\varepsilon_{i} \leq - x_{i} &amp;lsquo;\theta ) $$
$$  = 1 - P(\varepsilon_{i} \leq - x_{i} &amp;lsquo;\theta ) $$
$$  = \frac{exp(x_{i} &amp;lsquo;\theta )}{1+exp(x_{i} &amp;lsquo;\theta )} $$&lt;/p&gt;

&lt;p&gt;where the last line comes from using the expression for the &lt;a href=&#34;https://en.wikipedia.org/wiki/Logistic_distribution&#34; target=&#34;_blank&#34;&gt;cdf of the logistic distribution&lt;/a&gt; with zero mean and scale parameter equal to 1.&lt;/p&gt;

&lt;h2 id=&#34;interpretation-of-coefficients&#34;&gt;Interpretation of coefficients&lt;/h2&gt;

&lt;p&gt;How can we read the coefficients from a logistic model? The marginal effect of a change in $x_{ij}$ (the $jth$ component of $x_i$) on the probability that $y_i = 1$ is given by:&lt;/p&gt;

&lt;p&gt;$$ \frac{\partial f(y_i | x_{i}, \theta)}{\partial x_{ij}} = \sigma(x_{i} &amp;lsquo;\theta)(1-\sigma(x_{i} &amp;lsquo;\theta))\theta_j$$&lt;/p&gt;

&lt;p&gt;A first observation is that the marginal effect depends on $x_i$, unlike in the linear regression model. A second observation is that the first two terms are always positive, so we do have that the interpretation that if $\theta_j$ is positive, an increase in the $jth$ component of $x_i$ leads to a bigger probability of obtaining a success (holding everything else constant).&lt;/p&gt;

&lt;p&gt;Another way to read the results from a logistic model is to realize that it implies that the log of odd ratio is linear:&lt;/p&gt;

&lt;p&gt;$$ log\Big(\frac{f(y_i | x_{i}, \theta)}{1 - f(y_i | x_{i}, \theta)}\Big) = x_{i} &amp;lsquo;\theta$$&lt;/p&gt;

&lt;p&gt;Going back to what makes a politician successful in an election, if the coefficient $\theta_j$ is equal to 0.1, it means that a one unit increase in $x_{ij}$ rises the &lt;strong&gt;relative&lt;/strong&gt; probability of winning an election by approximately $10\%$.&lt;/p&gt;

&lt;h2 id=&#34;log-likelihood-function&#34;&gt;Log-likelihood function&lt;/h2&gt;

&lt;p&gt;To predict who is going to win the next elections, one must estimate the value of $\theta$ using the information contained in the sample $(y_i, x_i)_{i=1}^{N}$. One &amp;ldquo;natural&amp;rdquo; criterion is to find the value for $\theta$ that &lt;strong&gt;maximizes the probability of observing the
sample&lt;/strong&gt;. This procedure is called &lt;a href=&#34;https://en.wikipedia.org/wiki/Maximum_likelihood_estimation&#34; target=&#34;_blank&#34;&gt;Maximum likelihood estimation&lt;/a&gt;. Let us assume that sample is &lt;a href=&#34;https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables&#34; target=&#34;_blank&#34;&gt;i.i.d&lt;/a&gt;. If the i.i.d assumption holds, the probability of observing the sample $(y_i, x_i)_{i=1}^{N}$ is the product of the probability of observing each observation. Instead of maximizing the likelihood, it is more convenient to maximize the log-likelihood, which transforms the product of probabilities into a sum:&lt;/p&gt;

&lt;p&gt;$$ L((y_i, x_i)_{i=1}^{N};\theta) = log( \prod_{i=1}^{N}f(y_i | x_{i}, \theta)) = \sum_{i=1}^{N} log(f(y_i | x_{i}, \theta_{i}))$$&lt;/p&gt;

&lt;p&gt;The probability of observing $y_i$  can compactly be written as&lt;/p&gt;

&lt;p&gt;$$ f(y_i | x_{i}, \theta_{i}) = \sigma(x_{i} &amp;lsquo;\theta)^{y_i}(1 - \sigma(x_{i} &amp;lsquo;\theta))^{1 - y_i} $$&lt;/p&gt;

&lt;p&gt;Hence, the log-likelihood function writes:&lt;/p&gt;

&lt;p&gt;$$L((y_i, x_i)_{i=1}^{N};\theta) = \sum_{i=1}^{N} y_i log(\sigma(x_{i} &amp;lsquo;\theta)) + (1 - y_i)log(1 - \sigma(x_{i} &amp;lsquo;\theta))$$&lt;/p&gt;

&lt;h2 id=&#34;maximum-likelihood-estimation&#34;&gt;Maximum Likelihood Estimation&lt;/h2&gt;

&lt;p&gt;Taking the derivative of $f(y_i | x_{i}, \theta)$ with respect to the parameter $\theta$ gives:&lt;/p&gt;

&lt;p&gt;$$ f_{\theta}(y_i | x_{i}, \theta) = [y_i - \sigma(x_{i} &amp;lsquo;\theta)] x_{i} $$&lt;/p&gt;

&lt;p&gt;and the derivative of the log-likelihood function with respect to $\theta$ is:&lt;/p&gt;

&lt;p&gt;$$ L_{\theta}((y_i, x_i)_{i=1}^{N};\theta) = \sum_{i=1}^{N}[y_i - \sigma(x_{i} &amp;lsquo;\theta)] x_{i} $$&lt;/p&gt;

&lt;h2 id=&#34;gradient-descent&#34;&gt;Gradient descent&lt;/h2&gt;

&lt;p&gt;To make the link with this &lt;a href=&#34;https://julienpascal.github.io/post/ols_ml/&#34; target=&#34;_blank&#34;&gt;blog post&lt;/a&gt;, we can use gradient descent to find the MLE estimate:&lt;/p&gt;

&lt;p&gt;$$ \theta_{i+1} = \theta_{i} - \gamma \Big(- L_{\theta}((y_i, x_i)_{i=1}^{N};\theta_{i}) \Big)$$&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Gradient_descent&#34; target=&#34;_blank&#34;&gt;gradient descent&lt;/a&gt; algorithm is an iterative procedure to find a minimizer of a function. At each step, the algorithm takes a step of length $\gamma$ towards the direction of steepest descent. Note that I reformulated the problem of finding the maximum of a function $f$ (the log-likelihood) as the problem of finding the minimum of $-f$.&lt;/p&gt;

&lt;h2 id=&#34;newton-raphson-method&#34;&gt;Newtonâ€“Raphson method&lt;/h2&gt;

&lt;p&gt;Roughly speaking, the Newton-Raphson method is a &amp;ldquo;smart&amp;rdquo; gradient descent which uses the information contained in the Hessian of the log-likelihood $HL((y_i, x_i)_{i=1}^{N};\theta_{i})$ (on top of the gradient) to make a right move toward the minimizer. This iterative algorithm proceeds as follows:&lt;/p&gt;

&lt;p&gt;$$ \theta_{i+1} = \theta_{i} - (HL((y_i, x_i)_{i=1}^{N};\theta_{i}) )^{-1}  \Big(- L_{\theta}((y_i, x_i)_{i=1}^{N};\theta_{i}) \Big)$$&lt;/p&gt;

&lt;p&gt;The next plot shows how the Newton-Raphson method works for a one dimensional root-finding problem:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/e/e0/NewtonIteration_Ani.gif&#34; alt=&#34;Alt Text&#34; /&gt;&lt;/p&gt;

&lt;p&gt;source: &lt;a href=&#34;https://en.wikipedia.org/wiki/Newton%27s_method&#34; target=&#34;_blank&#34;&gt;https://en.wikipedia.org/wiki/Newton%27s_method&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Should we use gradient descent or Newton-Raphson? I let the following extract
from the &lt;a href=&#34;https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization&#34; target=&#34;_blank&#34;&gt;Wikipedia article&lt;/a&gt; on Newton-Raphson speak for itself:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Where applicable&lt;/strong&gt;, Newton&amp;rsquo;s method &lt;strong&gt;converges much faster&lt;/strong&gt; towards a local maximum or minimum than gradient descent. In fact, every local minimum has a neighborhood N such that, if we start with x0 âˆˆ N, Newton&amp;rsquo;s method with step size Î³ = 1 &lt;strong&gt;converges quadratically&lt;/strong&gt; (if the Hessian is invertible and a Lipschitz continuous function of x in that neighborhood).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For the logistic model, the Newton-Raphson algorithm is easily applicable because there exists a closed-form formula for the Hessian:&lt;/p&gt;

&lt;p&gt;$$ HL((y_i, x_i)_{i=1}^{N};\theta_{i}) = \sum_{i=1}^{N} - \sigma(x_{i} &amp;lsquo;\theta)[1 - \sigma(x_{i} &amp;lsquo;\theta)] x_{i} x_{i}&amp;lsquo;$$&lt;/p&gt;

&lt;h2 id=&#34;implementation-in-julia&#34;&gt;Implementation in Julia&lt;/h2&gt;

&lt;h2 id=&#34;i-working-with-simulated-data&#34;&gt;I. Working with simulated data&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s first work with simulated data. Can we actually recover the true parameter values using a manual implementation of the logistic model?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s load a few dependencies:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Distributions
using Plots
pyplot()
using DataFrames
using GLM
using Optim
using CSV
using GLM
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s create the logistic function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Logistic function for a scalar input:
function sigma(x::Float64)
    exp(x)/(1.0 + exp(x))
end

# Logistic function for a vector input:
function sigma(x::Array{Float64,1})
    exp.(x) ./ (1.0 .+ exp.(x))
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s create a function that calculates the likelihood:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function log_likelihood(y::Array{Float64,1}, X::Array{Float64,2}, theta::Array{Float64,1})
    sum = 0.0
    #Loop over individuals in the sample
    for i=1:size(X,1)
        sum += y[i]*log(sigma(transpose(X[i,:])*theta)) + (1.0 - y[i])*log(1.0 - sigma(transpose(X[i,:])*theta))
    end
    return sum
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s create a function that returns the derivative of the log-likelihood of the sample, which we need for the gradient descent algorithm:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Function to calculate the gradient of the log-likelihood of the sample:
function derivative_log_likelihood(y::Array{Float64,1}, X::Array{Float64,2}, theta::Array{Float64,1})
    sum = zeros(size(X,2))
    #Loop over individuals in the sample
    for i=1:size(X,1)
        sum .+= (y[i] - sigma(transpose(X[i,:])*theta))*X[i,:]
    end
    return sum
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s create a function that returns the Hessian of the log-likelihood of the sample, which we need for the Newthon-Raphson algorithm:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Function to calculate the hessian of the log-likelihood of the sample:
function hessian_log_likelihood(y::Array{Float64,1}, X::Array{Float64,2}, theta::Array{Float64,1})
    hessian = zeros(size(X,2), size(X,2))
    #Loop over individuals in the sample
    for i=1:size(X,1)
        hessian .+= - sigma(transpose(X[i,:])*theta)*(1.0 - sigma(transpose(X[i,:])*theta))*(X[i,:]*transpose(X[i,:]))
    end
    return hessian
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s simulate a sample of individuals:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#Generation of a sample:
#----------------------
N_individuals = 10000 #how many individuals in the sample?
dim_X = 3 #How many dimensions for x
d = Normal(0.0, 1.0)
d_logistic = Logistic(0.0, 1.0)
# Generate true parameter values:
theta0 = [0.0; 1.0; 2.0];
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Generate X:
X = rand(d, N_individuals, dim_X)
# The first column is full one ones (to have a constant)
X[:,1] = ones(N_individuals);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Convert y to a binary outcome using the latent variabe representation:
proba_success = X*theta0 .+ rand(d_logistic, N_individuals)
y = ifelse.(proba_success .&amp;gt; 0.0, 1.0, 0.0);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p1 = histogram(proba_success, bins=20, normalize=true, title=&amp;quot;Pdf probability of success&amp;quot;, legend=false)
p2 = histogram(y, title=&amp;quot;Nb of successes vs failures&amp;quot;, legend=false)
plot(p1,p2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Logistic_regression_29_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;maximization-with-optim&#34;&gt;Maximization with Optim&lt;/h3&gt;

&lt;p&gt;As a first pass, we can maximize the log-likelihood using the package Optim. I use the the &lt;a href=&#34;https://en.wikipedia.org/wiki/Limited-memory_BFGS&#34; target=&#34;_blank&#34;&gt;LBFGS&lt;/a&gt;
algorithm:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;theta_guess = ones(dim_X)
@time res = optimize(theta -&amp;gt; - log_likelihood(y, X, theta), theta_guess, LBFGS())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;0.409340 seconds (3.79 M allocations: 396.250 MiB, 15.73% gc time)&lt;/p&gt;

&lt;p&gt;We successfully recover the true parameter values (see &lt;code&gt;theta0&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;print(&amp;quot;Estimate for theta using Optim is $(res.minimizer)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Estimate for theta using Optim is [-0.0312666, 0.996344, 1.96038]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;minimization-with-gradient-descent&#34;&gt;Minimization with gradient descent&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s implement the gradient descent algorithm within a function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function gradient_descent_probit(y, X , theta_initial::Array{Float64,1}; max_iter::Int64 = 1000,
                                learning_rate::Float64 = 0.000001, tol::Float64=0.01)
    #initial value for theta:
    theta_old = theta_initial
    theta_new = similar(theta_old)
    #convergence reached?
    success_flag = 0
    #Let&#39;s store the convergence history
    history= fill!(zeros(max_iter), NaN)
    for i=1:max_iter
        theta_new = theta_old + learning_rate*derivative_log_likelihood(y, X, theta_old)
        diff = maximum(abs, theta_new .- theta_old)
        history[i] = diff
        if diff &amp;lt; tol
            success_flag = 1
            break
        end
        theta_old = theta_new
    end

    return theta_new, success_flag, history[isnan.(history) .== false]

end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;theta_guess = zeros(dim_X)
@time theta, flag, history = gradient_descent_probit(y, X, theta_guess, max_iter=100000, learning_rate=0.0001, tol=0.00001);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.252281 seconds (4.89 M allocations: 523.159 MiB, 29.08% gc time)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The following graph shows the error as a function of the number of iterations. After a few iterations of the gradient descent algorithm, the error is quite small.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;plot(history, label= &amp;quot;error&amp;quot;, title = &amp;quot;Convergence of the gradient descent algorithm&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Logistic_regression_40_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;print(&amp;quot;Estimate for theta using gradient descent is $(theta)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Estimate for theta using gradient descent is [0.0581777, 1.00105, 1.97901]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;minimization-with-newton-raphson&#34;&gt;Minimization with Newton-Raphson&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s implement the Newton-Raphson algorithm within a function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function nr_probit(y, X , theta_initial::Array{Float64,1};
                    max_iter::Int64 = 1000, tol::Float64=0.01)
    #initial value for theta:
    theta_old = theta_initial
    theta_new = similar(theta_old)
    #convergence reached?
    success_flag = 0
    #Let&#39;s store the convergence history
    history= fill!(zeros(max_iter), NaN)
    for i=1:max_iter
        theta_new = theta_old - inv(hessian_log_likelihood(y, X, theta_old))*derivative_log_likelihood(y, X, theta_old)
        diff = maximum(abs, theta_new .- theta_old)
        history[i] = diff
        if diff &amp;lt; tol
            success_flag = 1
            break
        end
        theta_old = theta_new
    end

    return theta_new, success_flag, history[isnan.(history) .== false]

end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The following graph shows that we find the minimizer in only 5 steps! The Newton-Raphson algorithm clearly outperforms gradient descent. Of course, everything works well because the
problem is well-behaved and a nice formula for the Hessian is available.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;theta_guess = ones(dim_X)
@time theta, flag, history = nr_probit(y, X, theta_guess, max_iter=1000, tol=0.00001);
plot(history, label= &amp;quot;error&amp;quot;, title = &amp;quot;Convergence of the gradient descent algorithm&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.037832 seconds (500.07 k allocations: 53.431 MiB, 35.44% gc time)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Logistic_regression_46_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;print(&amp;quot;Estimate for theta using Newton-Raphson is $(theta)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Estimate for theta using Newton-Raphson is [0.0581789, 1.00114, 1.97919]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;using-glm&#34;&gt;Using GLM&lt;/h3&gt;

&lt;p&gt;We can also use the package &lt;a href=&#34;https://github.com/JuliaStats/GLM.jl&#34; target=&#34;_blank&#34;&gt;GLM&lt;/a&gt; to estimate the logistic model. We first need to put the data into a dataframe. In the &lt;code&gt;glm()&lt;/code&gt; function, we should use the &lt;code&gt;LogitLink()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;df = DataFrame(X1=X[:,1],X2=X[:,2], X3=X[:,3], y=y);
first(df,6)
&lt;/code&gt;&lt;/pre&gt;

&lt;table class=&#34;data-frame&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;X1&lt;/th&gt;&lt;th&gt;X2&lt;/th&gt;&lt;th&gt;X3&lt;/th&gt;&lt;th&gt;y&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;p&gt;6 rows Ã— 4 columns&lt;/p&gt;&lt;tr&gt;&lt;th&gt;1&lt;/th&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;0.215315&lt;/td&gt;&lt;td&gt;1.29817&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;2&lt;/th&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;-0.0714749&lt;/td&gt;&lt;td&gt;0.586886&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;3&lt;/th&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;0.0463648&lt;/td&gt;&lt;td&gt;-0.145116&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;4&lt;/th&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;1.95096&lt;/td&gt;&lt;td&gt;0.26349&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;5&lt;/th&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;-0.162081&lt;/td&gt;&lt;td&gt;1.34871&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;6&lt;/th&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;0.00214326&lt;/td&gt;&lt;td&gt;-0.271835&lt;/td&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;fittedmodel = glm(@formula(y ~ X2 + X3), df, Binomial(), LogitLink(), verbose=true);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;print(&amp;quot;Estimate for theta using GLM is $(coef(fittedmodel))&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Estimate for theta using GLM is [-0.0312666, 0.996344, 1.96038]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ii-what-makes-a-successful-nba-player&#34;&gt;II. What makes a successful NBA player?&lt;/h2&gt;

&lt;p&gt;For an example involving real data, I use the data set on &lt;strong&gt;NBA shots&lt;/strong&gt; taken during the 2014-2015 season.
It contains information on:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;who took the shot&lt;/li&gt;
&lt;li&gt;where on the floor was the shot taken from&lt;/li&gt;
&lt;li&gt;who was the nearest defender,&lt;/li&gt;
&lt;li&gt;how far away was the nearest defender&lt;/li&gt;
&lt;li&gt;time on the shot clock&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The data is available on &lt;strong&gt;Kaggle&lt;/strong&gt; &lt;a href=&#34;https://www.kaggle.com/dansbecker/nba-shot-logs&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;df_nba = CSV.read(&amp;quot;/home/julien/Documents/REPOSITORIES/LogisticRegression/data/shot_logs.csv&amp;quot;);
names(df_nba)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The dataset is quite extensive. Let&amp;rsquo;s select whether or not the shot was successful, &lt;strong&gt;the shot clock, the shot distance, and the proximity with the closest defender&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;df_nba = df_nba[[:SHOT_RESULT, :SHOT_CLOCK, :SHOT_DIST, :CLOSE_DEF_DIST]]
# Drop rows with missings:
df_nba = dropmissing(df_nba);
# Drop rows with NaN:
df_nba = df_nba[completecases(df_nba), :]
# Convert SHOT_RESULT to a binary variable (1 for success, 0 for missed)
df_nba[:, :SHOT_RESULT] = ifelse.(df_nba[:, :SHOT_RESULT] .== &amp;quot;made&amp;quot;, 1.0, 0.0);
# Show the first few rows of df_nba:
first(df_nba, 4)
&lt;/code&gt;&lt;/pre&gt;

&lt;table class=&#34;data-frame&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;SHOT_RESULT&lt;/th&gt;&lt;th&gt;SHOT_CLOCK&lt;/th&gt;&lt;th&gt;SHOT_DIST&lt;/th&gt;&lt;th&gt;CLOSE_DEF_DIST&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;p&gt;4 rows Ã— 4 columns&lt;/p&gt;&lt;tr&gt;&lt;th&gt;1&lt;/th&gt;&lt;td&gt;1.0&lt;/td&gt;&lt;td&gt;10.8&lt;/td&gt;&lt;td&gt;7.7&lt;/td&gt;&lt;td&gt;1.3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;2&lt;/th&gt;&lt;td&gt;0.0&lt;/td&gt;&lt;td&gt;3.4&lt;/td&gt;&lt;td&gt;28.2&lt;/td&gt;&lt;td&gt;6.1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;3&lt;/th&gt;&lt;td&gt;0.0&lt;/td&gt;&lt;td&gt;10.3&lt;/td&gt;&lt;td&gt;17.2&lt;/td&gt;&lt;td&gt;3.4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;4&lt;/th&gt;&lt;td&gt;0.0&lt;/td&gt;&lt;td&gt;10.9&lt;/td&gt;&lt;td&gt;3.7&lt;/td&gt;&lt;td&gt;1.1&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;Let&amp;rsquo;s first use GLM:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;fittedmodel = glm(@formula(SHOT_RESULT ~ SHOT_CLOCK + SHOT_DIST + CLOSE_DEF_DIST), df_nba, Binomial(), LogitLink(), verbose=true);
fittedmodel
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;SHOT_RESULT ~ 1 + SHOT_CLOCK + SHOT_DIST + CLOSE_DEF_DIST

Coefficients:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                  Estimate   Std. Error    z value  Pr(&amp;gt;|z|)   Lower 95%   Upper 95%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(Intercept)     -0.0575127  0.0181349     -3.17139    0.0015  -0.0930564  -0.021969
SHOT_CLOCK       0.0185198  0.00104899    17.6549     &amp;lt;1e-69   0.0164639   0.0205758
SHOT_DIST       -0.059745   0.000858282  -69.61       &amp;lt;1e-99  -0.0614272  -0.0580628
CLOSE_DEF_DIST   0.108392   0.00279232    38.8179     &amp;lt;1e-99   0.102919    0.113865
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How can we interpret those results?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;time pressure makes NBA players more successful: the higher the shot clock, the more likely to score&lt;/li&gt;
&lt;li&gt;shots from further away are more likely to be missed&lt;/li&gt;
&lt;li&gt;the further away the closest defender is, the more likely the shot will be a success&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Can we find similar results &amp;ldquo;manually&amp;rdquo;? The answer is &lt;strong&gt;yes&lt;/strong&gt;. To see that, let&amp;rsquo;s first create the binary variable &lt;code&gt;y&lt;/code&gt; and put the explanatory variables into &lt;code&gt;X&lt;/code&gt; and then use Newton-Raphson:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;y = convert(Array, df_nba[:SHOT_RESULT]);
X = convert(Matrix, df_nba[[:SHOT_CLOCK, :SHOT_DIST, :CLOSE_DEF_DIST]])
X = hcat(ones(size(X,1)), X);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;theta_guess = zeros(size(X,2))
@time theta, flag, history = nr_probit(y, X, theta_guess, max_iter=1000, tol=0.0001);
plot(history, label= &amp;quot;error&amp;quot;, title = &amp;quot;Convergence of the gradient descent algorithm&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.301748 seconds (4.90 M allocations: 568.272 MiB, 29.93% gc time)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Logistic_regression_63_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Our implementation of the logistic model gives us parameter values that are almost
identical to the ones we get using the package &lt;code&gt;GLM&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;print(&amp;quot;Estimate for theta using Optim is $(res.minimizer)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Estimate for theta using Optim is [-0.057513, 0.0185199, -0.0597451, 0.108392]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The logistic model, often used in social sciences and in machine learning for classification purposes is a powerful tool. This blog post shows how the logistic model can be derived from first principles (latent variable interpretation) and how it can be implemented in just a few lines of codes. A few extensions to this blog post could be to calculate the &lt;a href=&#34;https://en.wikipedia.org/wiki/Receiver_operating_characteristic&#34; target=&#34;_blank&#34;&gt;ROC curve&lt;/a&gt; and to calculate the standard errors.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://rpubs.com/junworks/Understanding-Logistic-Regression-from-Scratch&#34; target=&#34;_blank&#34;&gt;https://rpubs.com/junworks/Understanding-Logistic-Regression-from-Scratch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Rental Housing Market and Directed Search</title>
      <link>https://julienpascal.github.io/project/rentalmarket/</link>
      <pubDate>Mon, 21 Oct 2019 18:11:07 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/project/rentalmarket/</guid>
      <description>&lt;p&gt;Using a novel dataset on the rental housing market in the Paris area, I show that the rental housing market is well described by a directed search model. I develop a hedonic pricing model taking into consideration apartmentsâ€™ characteristics and subjective attractiveness using photos and computer vision techniques from the machine learning literature.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker for Dummies</title>
      <link>https://julienpascal.github.io/post/docker/</link>
      <pubDate>Fri, 18 Oct 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/docker/</guid>
      <description>

&lt;p&gt;In my quest for the perfect tool for reproducible science, I thought that the silver
bullet was to wrap your code in a neat library/package and make it available to the world.
Yet, I was wrong. &lt;a href=&#34;https://www.docker.com/&#34; target=&#34;_blank&#34;&gt;Docker&lt;/a&gt; is a much cooler and a much more effective way for sharing
your work with a broad audience. This post is a 101 introduction to Docker.
I describe what is Docker and show one simple application with a script in Julia.&lt;/p&gt;

&lt;h2 id=&#34;why-docker&#34;&gt;Why Docker?&lt;/h2&gt;

&lt;p&gt;Your script works locally, but not on your friend&amp;rsquo;s laptop because of dependency
issues. Docker solves the &lt;a href=&#34;https://en.wikipedia.org/wiki/Dependency_hell&#34; target=&#34;_blank&#34;&gt;dependency hell&lt;/a&gt;
by giving you the opportunity to &amp;ldquo;ship&amp;rdquo; your application in a &amp;ldquo;container&amp;rdquo;. One can think of a &amp;ldquo;container&amp;rdquo; as some sort of lightweight virtual image. Some technical details can be found &lt;a href=&#34;https://docs.docker.com/engine/docker-overview/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://devopscube.com/what-is-docker/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. In a nutshell, if your application works on your local machine, Docker helps you to put your application inside an container. Once in a container, your application will run smoothly for the rest of the world.&lt;/p&gt;

&lt;h2 id=&#34;application-in-julia&#34;&gt;Application in Julia&lt;/h2&gt;

&lt;p&gt;The goal is to create a container with a simple script to calculate an approximation
of Ï€. Here I am making a copy-paste from &lt;a href=&#34;https://julienpascal.github.io/post/buildyourcluster/&#34; target=&#34;_blank&#34;&gt;this post&lt;/a&gt;, in which I calculated an approximation of Ï€ using Monte-Carlo. I create a folder
&lt;code&gt;julia-app&lt;/code&gt;, which contains 3 files (see the Github repository with the 3 files &lt;a href=&#34;https://github.com/JulienPascal/MyFirstDockerApp&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;julia-app
  â”œ app.jl
  â”œ deps.jl
  â”” Dockerfile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The file &lt;code&gt;app.jl&lt;/code&gt; contains the application we want to containerize. The file &lt;code&gt;deps.jl&lt;/code&gt;
contains the list of libraries/packages that are used within &lt;code&gt;app.jl&lt;/code&gt;. The file &lt;code&gt;Dockerfile&lt;/code&gt;
is a &lt;a href=&#34;https://docs.docker.com/engine/reference/builder/&#34; target=&#34;_blank&#34;&gt;text document&lt;/a&gt; that contains instructions to build the container.
Generally, a &lt;code&gt;Dockerfile&lt;/code&gt; contains 4 types of instructions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;FROM&lt;/code&gt;: specifies the &amp;ldquo;base image&amp;rdquo; we want to use within the container. In our case,
we want to run an application with Julia. Luckily, we can pull a base image with
Julia pre-installed on it using &lt;code&gt;FROM julia:&amp;lt;julia-version-you-want&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;COPY&lt;/code&gt;: adds files to your container&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RUN&lt;/code&gt;: executes command(s) in a new layer and creates a new image. &lt;code&gt;RUN&lt;/code&gt; is perfect
for installing packages&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CMD&lt;/code&gt;: specifies what command to run within the container&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;#choose a base image
FROM julia:1.0.3

# install julia dependencies
COPY deps.jl /usr/src/app/
RUN julia /usr/src/app/deps.jl

# copy files required for the app to run
COPY app.jl /usr/src/app/

# run the application
CMD [&amp;quot;julia&amp;quot;, &amp;quot;/usr/src/app/app.jl&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To create the container, use the command &lt;code&gt;docker build&lt;/code&gt;. You can give a name
to your container using the &lt;code&gt;--tag , -t&lt;/code&gt; option:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker build julia-app -t &amp;lt;your-tag&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To run the container you have just created:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --name julia-app &amp;lt;your-tag&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After a few seconds, you should see an approximation of Ï€ showing up in your
terminal. VoilÃ , you have have just created your first container. The next step
is to put your container on &lt;a href=&#34;https://hub.docker.com/&#34; target=&#34;_blank&#34;&gt;DockerHub&lt;/a&gt;. &lt;a href=&#34;https://docs.docker.com/docker-hub/&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt;
is a tutorial on how to do it.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;From an academic perspective, Docker solves the dependency hell and helps in producing
reproducible research. I will try to use it more often for sharing my own research.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OLS the Machine Learning Way</title>
      <link>https://julienpascal.github.io/post/ols_ml/</link>
      <pubDate>Sun, 29 Sep 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/ols_ml/</guid>
      <description>

&lt;p&gt;Coming from an Economics/Econometrics background, I have always been a bit puzzled by the way several Machine Learning (ML) textbooks I have read solve the ordinary least squares model (OLS). When considering a linear model of the form:&lt;/p&gt;

&lt;p&gt;$$ y = X \beta + e $$&lt;/p&gt;

&lt;p&gt;with $e$ a zero-mean noise term, the closed-form solution associated with minimizing the mean square error is:&lt;/p&gt;

&lt;p&gt;$$ \beta = (X&amp;rsquo;X)^{-1}X&amp;rsquo;y $$&lt;/p&gt;

&lt;p&gt;Several ML textbooks explain that a recursive algorithm (see below) may be used to solve for $\beta$. Why not directly using the analytical formula to calculate an estimate of $\beta$ ? While feasible with &amp;ldquo;small&amp;rdquo; datasets (not too many explanatory variables and/or observations), direct inversion of $X&amp;rsquo;X$ is not recommended when working with thousands of explanatory variables and/or billions of observations. The alternative is to use &lt;a href=&#34;https://en.wikipedia.org/wiki/Gradient_descent&#34; target=&#34;_blank&#34;&gt;gradient descent&lt;/a&gt;, or better, &lt;a href=&#34;https://en.wikipedia.org/wiki/Stochastic_gradient_descent&#34; target=&#34;_blank&#34;&gt;stochastic gradient descent&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this short post, I solve OLS the &amp;ldquo;machine-learning way&amp;rdquo;. That is, using (stochastic) gradient descent. The idea for gradient descent (GD) is quite intuitive. The gradient of $f$ at a given point tells us the direction of &lt;strong&gt;greatest increase&lt;/strong&gt; for $f$ at this point. Hence, moving in the opposite direction (minus the gradient) is probably a good idea to find a local minimum. And indeed it is. The GD algorithm repetitively applies this procedure until a minimum (hopefully global) is found. Starting from an initial guess for $\beta$, one updates the guess using the following formula:&lt;/p&gt;

&lt;p&gt;$$ \beta_{n} = \beta_{n-1} - \alpha * grad_{n}(\beta_{n-1},X,y) $$&lt;/p&gt;

&lt;p&gt;where $\alpha$ is a small value (the &amp;ldquo;learning rate&amp;rdquo;) and $grad_{n}(\beta_{n-1},X,y)$ the gradient of the mean square error (another loss function can be used) evaluated at $\beta_{n-1}$ using the observations $X$ and $y$. Using the mean square error as a loss function generates a closed-form solution for the gradient:&lt;/p&gt;

&lt;p&gt;$$ grad_{n}(\beta_{n-1},X,y) = (X&amp;rsquo;X)\beta - X&amp;rsquo;y $$&lt;/p&gt;

&lt;p&gt;A refinement of GD, especially handy when dealing with a large dataset, is to use only a subset of the full sample when calculating the gradient:&lt;/p&gt;

&lt;p&gt;$$ \beta_{n} = \beta_{n-1} - \alpha * grad_{n}(\beta_{n-1},X_n,y_n) $$&lt;/p&gt;

&lt;p&gt;where $X_n$ and $y_n$ are a randomly selected sub-sample of $X$ and $y$. Stochastic Gradient Descent (SGD) reduces the computational burden associated with computing the gradient, while still having good convergence properties, as illustrated in the application below.&lt;/p&gt;

&lt;h2 id=&#34;implementation-in-julia&#34;&gt;Implementation in Julia&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s first load packages and define parameters&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using LinearAlgebra
using Distributions
using Plots
using Distributions
using Random
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;n_points=10000
dim_input=100 #dim of input, without the intercept
dim_output=1
# Normal noise
d = Normal()
# True parameters
beta = rand(d, dim_input + 1);
# Noise
e = rand(d, n_points);
# Input data:
X = rand(d, (n_points,dim_input));
# Add the intercept:
X = hcat(ones(n_points),X);
#Linear Model
y = X*beta .+ e;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function calculates an estimate of $\beta$ using the analytical formula for OLS&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#OLS way
function OLS_direct(X::Array, y::Vector)
    inv(transpose(X)*X)*transpose(X)*y
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OLS_direct (generic function with 1 method)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@time beta_hat = OLS_direct(X, y);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;0.611144 seconds (1.85 M allocations: 96.576 MiB, 13.64% gc time)&lt;/p&gt;

&lt;p&gt;Without any major surprise, using the analytical solution works perfectly well, as illustrated in the following plot&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;plot(beta, beta_hat, seriestype=:scatter, label=&amp;quot;OLS (Direct)&amp;quot;)
plot!(beta, beta, seriestype=:line, label=&amp;quot;true&amp;quot;)
xlabel!(&amp;quot;true value&amp;quot;)
ylabel!(&amp;quot;estimated value (Direct)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;OLSMachineLearning_9_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;gradient-descent&#34;&gt;Gradient Descent&lt;/h2&gt;

&lt;p&gt;Now it&amp;rsquo;s time to solve OLS the machine learning way. I first define a function that calculates the gradient of the loss
function, evaluated at the current guess using the full sample. Then, a second function applies the GD updating rule.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#Calculate the gradient
function grad_OLS!(G, beta_hat, X, y)
    G[:] = transpose(X)*X*beta_hat - transpose(X)*y
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;grad_OLS! (generic function with 1 method)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#Gradient descent way
function OLS_gd(X::Array, y::Vector; epochs::Int64=1000, r::Float64=1e-5, verbose::Bool=false)
    #initial guess
    beta_hat = zeros(size(X,2))
    grad_n = zeros(size(X,2))
    for epoch=1:epochs
        grad_OLS!(grad_n, beta_hat, X, y)
        beta_hat -= r*grad_n
        if verbose==true
            if mod(epoch, round(Int, epochs/10))==1
                println(&amp;quot;MSE: $(mse(beta_hat, X, y))&amp;quot;)
            end
        end
    end
    return beta_hat
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OLS_gd (generic function with 1 method)&lt;/p&gt;

&lt;p&gt;As illustrated below, after 20 iterations we are quite close to the true value. After 100 iterations, values obtained by GD are indistinguishable from the true values.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@time beta_hat_gd_20 = OLS_gd(X,y, epochs=20);
@time beta_hat_gd = OLS_gd(X,y, epochs=100);
plot(beta, beta_hat_gd_20, seriestype=:scatter, label=&amp;quot;GD (20 iter.)&amp;quot;)
plot!(beta, beta_hat_gd, seriestype=:scatter, label=&amp;quot;GD (100 iter.)&amp;quot;)
plot!(beta, beta, seriestype=:line, label=&amp;quot;true&amp;quot;)
xlabel!(&amp;quot;true value&amp;quot;)
ylabel!(&amp;quot;estimated value (GD)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;0.137474 seconds (81.55 k allocations: 5.814 MiB)
0.466605 seconds (714 allocations: 8.225 MiB)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;OLSMachineLearning_15_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;stochastic-gradient-descent&#34;&gt;Stochastic Gradient Descent&lt;/h2&gt;

&lt;p&gt;One issue associated with plain vanilla GD is that computing the gradient might be slow. Let&amp;rsquo;s now randomly select only a fraction of the full sample every time we iterate. Here, I take only 10 percent of the full sample.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#Gradient descent way
function OLS_sgd(X::Array, y::Vector; epochs::Int64=1000, r::Float64=1e-5, verbose::Bool=false, batchsizePer::Int64=10)
    #initial guess
    beta_hat = zeros(size(X,2))
    grad_n = zeros(size(X,2))
    #how many draws from the dataset?
    batchsize = round(Int, size(X,1)*(batchsizePer/100))
    Xn = zeros(batchsize, size(X,2))
    yn = zeros(batchsize)
    for epoch=1:epochs
        indices = shuffle(Vector(1:size(X,1)))
        Xn = X[indices[1:batchsize],:]
        yn = y[indices[1:batchsize]]
        grad_OLS!(grad_n, beta_hat, Xn, yn)
        #gradient descent:
        beta_hat -= r*grad_n
        if verbose==true
            if mod(epoch, round(Int, epochs/10))==1
                println(&amp;quot;MSE: $(mse(beta_hat, X, y))&amp;quot;)
            end
        end
    end
    return beta_hat
end

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OLS_sgd (generic function with 1 method)&lt;/p&gt;

&lt;p&gt;The following block of code shows that SGD achieves the same degree of accuracy, while being much faster than GD.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@time beta_hat_gd = OLS_gd(X,y, epochs=200);
@time beta_hat_sgd = OLS_sgd(X,y, epochs=200, batchsizePer=20);
plot(beta, beta_hat_sgd, seriestype=:scatter, label=&amp;quot;SGD&amp;quot;)
plot!(beta, beta_hat_gd, seriestype=:scatter, label=&amp;quot;GD&amp;quot;)
plot!(beta, beta, seriestype=:line, label=&amp;quot;true&amp;quot;)
xlabel!(&amp;quot;true value&amp;quot;)
ylabel!(&amp;quot;estimated value (SGD)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;0.894465 seconds (1.41 k allocations: 16.448 MiB, 0.42% gc time)
0.513217 seconds (338.19 k allocations: 382.550 MiB, 4.60% gc time)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;OLSMachineLearning_20_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The OLS analytical formula is the gold standard to derive theoretical properties and is perfectly fine when working with reasonably-sized data. In a big data context, (stochastic) gradient descent is the way to go. SGD can be applied to a wide-range of minimization problems. In a machine-learning context, SGD is used to estimate (&amp;ldquo;train&amp;rdquo;) much more complicated models than the simple linear model presented here. In the Appendix below, I show how one can use SGD when no analytical solution for the gradient is available.&lt;/p&gt;

&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;

&lt;h3 id=&#34;gd-without-analytical-solution-for-the-gradient&#34;&gt;GD without analytical solution for the gradient&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s assume we don&amp;rsquo;t have a closed-form solution for the gradient. In this context, Julia&amp;rsquo;s automatic differentiation library &lt;code&gt;ForwardDiff&lt;/code&gt; is a good choice to calculate the gradient. Below, I define the loss function (MSE), I obtain the gradient of the loss function using &lt;code&gt;ForwardDiff&lt;/code&gt; and I apply the SGD algorithm.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using ForwardDiff
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function mse(beta::Vector, X::Array, y::Vector)
   result = zero(eltype(y))
   for i in 1:length(y)
       #sum squared errors
       result += (y[i] - dot(X[i,:],beta))^2
   end
   return result
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;mse (generic function with 1 method)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function grad!(G, beta_hat, X, y)
    G[:] = ForwardDiff.gradient(x -&amp;gt; mse(x, X, y), beta_hat)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;grad! (generic function with 1 method)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#Gradient descent way
function OLS_gd(X::Array, y::Vector; epochs::Int64=1000, r::Float64=1e-5, verbose::Bool=false)
    #initial guess
    beta_hat = zeros(size(X,2))
    grad_n = zeros(size(X,2))
    for epoch=1:epochs
        grad!(grad_n, beta_hat, X, y)
        beta_hat -= r*grad_n
        if verbose==true
            if mod(epoch, round(Int, epochs/10))==1
                println(&amp;quot;MSE: $(mse(beta_hat, X, y))&amp;quot;)
            end
        end
    end
    return beta_hat
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;OLS_gd (generic function with 1 method)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@time beta_hat_gd = OLS_gd(X,y, epochs=100);
plot(beta, beta_hat_gd, seriestype=:scatter, label=&amp;quot;GD (100 iter.)&amp;quot;)
plot!(beta, beta, seriestype=:line, label=&amp;quot;true&amp;quot;)
xlabel!(&amp;quot;true value&amp;quot;)
ylabel!(&amp;quot;estimated value (GD)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.180767 seconds (9.71 M allocations: 7.547 GiB, 12.66% gc time)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;OLSMachineLearning_29_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The BKM Algorithm</title>
      <link>https://julienpascal.github.io/post/bkm/</link>
      <pubDate>Mon, 16 Sep 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/bkm/</guid>
      <description>

&lt;p&gt;Finding solutions to economic models with heterogeneity and aggregate uncertainty is a notoriously difficult task.
It is an active area of research in Mathematics (see &lt;a href=&#34;https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.2013.0397&#34; target=&#34;_blank&#34;&gt;mean field games with aggregate uncertainty&lt;/a&gt;). Because such models naturally arise when considering economic situations, Economists have developed a battery of techniques to (numerically) solve them. In this post, I would like to describe a recent algorithm by &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v89y2018icp68-92.html&#34; target=&#34;_blank&#34;&gt;Boppart, Krusell and Mitman (BKM)&lt;/a&gt; that is both fast and accurate. I will first describe the problem that Economists face when working with heterogeneous model with aggregate uncertainty, heuristically discuss the BKM algorithm (based on the presentation of &lt;a href=&#34;https://ideas.repec.org/a/eee/dyncon/v89y2018icp93-99.html&#34; target=&#34;_blank&#34;&gt;Reiter (2018)&lt;/a&gt;) and show an application in Julia.&lt;/p&gt;

&lt;h3 id=&#34;bkm-in-a-nutshell&#34;&gt;BKM in a nutshell&lt;/h3&gt;

&lt;p&gt;It is common to use Bellman&amp;rsquo;s principle of optimality to characterize solutions of a multi-stage decision processes.
The principle of optimality leads to a solution in a &lt;strong&gt;recursive form&lt;/strong&gt; $d_{t} = d(S_{t})$, where $S_t$ is a vector of state variables and $d(.)$ a policy function describing the optimal action of a decision-maker when faced with any given state.&lt;/p&gt;

&lt;p&gt;An alternative representation of the problem is to consider a solution in the &lt;strong&gt;sequence form&lt;/strong&gt;. At each step in time, a decision-maker observes a new realization of a random process $z_t$ and taking into account the full history of past shocks, the agent makes a new choice to maximize her expected discounted sum of returns: $d_t = d(z_t, z_{t-1}, z_{t-2}, &amp;hellip;)$.&lt;/p&gt;

&lt;p&gt;While most of the time the recursive form is a much more parsimonious approach, it fails when $S_t$ is infinite-dimensional. In models with heterogeneous agents (HA) and aggregate uncertainty, this is generally the case because the distribution of agents over certain variables will end up being in $S_t$. While this a problem with is the recursive approach (how can we discretize $S_t$ to put it on a computer?), the sequence form is immune to this problem. The BKM algorithm uses this insight, adding the &lt;strong&gt;assumption&lt;/strong&gt; of &lt;strong&gt;linearity&lt;/strong&gt; of $d(.)$ with respect to the &lt;strong&gt;aggregate state&lt;/strong&gt; $z_t$:&lt;/p&gt;

&lt;p&gt;$$ d_t = z_t d(1, 0, 0, &amp;hellip;) + z_{t-1}d(0, 1, 0, &amp;hellip;) + z_{t-2}d(0, 0, 1, &amp;hellip;) + &amp;hellip; $$
$$ d_t = \sum_{k=0}^{+\infty} z_{t-k} d_{k} $$&lt;/p&gt;

&lt;p&gt;where $$ d_{1} = d(1,0,0,&amp;hellip;)$$
$$ d_{2} = d(0,1,0,&amp;hellip;)$$
$$ d_{3} = d(0,0,1,&amp;hellip;)$$&lt;/p&gt;

&lt;p&gt;The series of $d_{k}$ describes the trajectory of the economy after an &amp;ldquo;MIT&amp;rdquo; shock (when the economy is hit by an unexpected single-period aggregate shock). If the linearity assumption holds, the evolution of equilibrium variables are simply a moving average of past shocks. We made progress because solving for the trajectory after an MIT shock is perfectly feasible in a RA model. As long as one can calculate the steady-state with no aggregate uncertainty and solve the &lt;strong&gt;deterministic perfect foresight path&lt;/strong&gt;, BKM can be used.&lt;/p&gt;

&lt;h3 id=&#34;numerical-implementation&#34;&gt;Numerical implementation&lt;/h3&gt;

&lt;p&gt;Here is the implementation of the method using a toy example. I intentionally circumvent the problem of finding the perfect foresight transition path, which is (potentially) the complicated part of BKM. This is the example given in Reiter (2018): the exact model is the non-linear model $x_{t} = a x_{t-1} + b x_{t-1}^2 + z_{t}$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Distributions
using Plots
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Parameters
max_iter=100 #number of iterations for the simulation
a = 0.5
b = 0.1
sigma_shock=1.0
mu_shock=0.
d = Normal(mu_shock, sigma_shock)

# transition function
function iter_x(x_min1::Float64, a::Float64, b::Float64)
    a*x_min1 + b*x_min1^2
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;iter_x (generic function with 1 method)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;impulse-response-function&#34;&gt;Impulse response function&lt;/h4&gt;

&lt;p&gt;Let us assume that the economy is at the non-stochastic steady-state and a shock occurs:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# We assume that after 100 periods, the economy is back to the steady-state
max_iter_mit = 100
x_mit=zeros(max_iter_mit)
# Initial shock
z_t[1] = sigma_shock #a 1 std. deviation
x_mit[1] = 0 #steady-state

for i=2:max_iter_mit
    x_mit[i] = iter_x(x_mit[i-1], a, b) + z_t[i-1]
end

# Scaled-version of the impulse response:
x_mit_scaled = x_mit./z_t[1];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I define two functions to calculate the moving average:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function calculate_Xt(x_scaled::Array{Float64,1}, shocks::Array{Float64,1}, t::Int64, kk::Int64)

    output = 0.

    for k=1:kk
        output+=x_scaled[k]*shocks[t-k+1]
    end

    return output
end

function BPM_path!(XT::Array{Float64,1}, max_iter::Int64, x_scaled::Array{Float64,1}, shocks::Array{Float64,1})

    for t=2:max_iter
        XT[t] = calculate_Xt(x_scaled, shocks, t, t)
    end

end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;BPM_path! (generic function with 1 method)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Initialization
XT = zeros(max_iter);
# Series of shocks
shocks_t = rand(d, max_iter).*0.5;
# Solving using BKM:
@time BPM_path!(XT, max_iter, x_mit_scaled, shocks_t)
# True value:
x_true = zeros(max_iter)
for i=2:max_iter
    x_true[i] = iter_x(x_true[i-1], a, b) + shocks_t[i-1]
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.025906 seconds (29.30 k allocations: 1.489 MiB, 26.80% gc time)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;plot(XT[2:end], label=&amp;quot;x_t BKM&amp;quot;)
plot!(x_true[2:end], label=&amp;quot;x_t true&amp;quot;)
title!(&amp;quot;b=$(b)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;BKM_Algorithm_16_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The previous plot shows how the BKM algorithm approximates the true model and it does quite a good job.
Of course, the more the model is linear with respect to $z_t$ (captured by the value of $b_2$), the better the approximation. To illustrate this idea, I use BKM on a perfectly linear model ($b=0$) and on a model with stronger non-linearities ($b=0.2$). As expected, the approximation is perfect when the model is linear and the approximation deteriorates when strong non-linearities are present.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;plot(p1,p2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;BKM_Algorithm_18_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;The BKM algorithm is a new addition to the toolbox of methods to solve HA models. The sequence representation of the problem seems to be a fruitful area of research, as it has also been used in Le Grand and Ragot (&lt;a href=&#34;http://xavier-ragot.fr/pdf/progress/LeGrand_Ragot_final.pdf&#34; target=&#34;_blank&#34;&gt;2017&lt;/a&gt;) and (&lt;a href=&#34;http://xavier-ragot.fr/pdf/progress/Optimal_policies.pdf&#34; target=&#34;_blank&#34;&gt;2019&lt;/a&gt;) to develop fast and reliable method to solve HA models. The recent contribution of &lt;a href=&#34;https://github.com/shade-econ/sequence-jacobian/#sequence-space-jacobian&#34; target=&#34;_blank&#34;&gt;Auclert at al (2019)&lt;/a&gt; also uses a similar approach.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Achdou, Yves, et al. &amp;ldquo;Partial differential equation models in macroeconomics.&amp;rdquo; Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 372.2028 (2014): 20130397.&lt;/li&gt;
&lt;li&gt;Auclert, Adrien, et al. Using the Sequence-Space Jacobian to Solve and Estimate Heterogeneous-Agent Models. No. w26123. National Bureau of Economic Research, 2019.&lt;/li&gt;
&lt;li&gt;Boppart, Timo, Per Krusell, and Kurt Mitman. &amp;ldquo;Exploiting MIT shocks in heterogeneous-agent economies: the impulse response as a numerical derivative.&amp;rdquo; Journal of Economic Dynamics and Control 89 (2018): 68-92.&lt;/li&gt;
&lt;li&gt;Le Grand, FranÃ§ois, and Xavier Ragot. &amp;ldquo;Optimal fiscal policy with heterogeneous agents and aggregate shocks.&amp;rdquo; Document de travail (2017).&lt;/li&gt;
&lt;li&gt;Le Grand, FranÃ§ois, and Ragot, Xavier. &amp;ldquo;Managing Inequality over the Business Cycles: Optimal Policies with Heterogeneous Agents and Aggregate Shocks&amp;rdquo;. No. 1090. Society for Economic Dynamics, 2019.&lt;/li&gt;
&lt;li&gt;Reiter, Michael. &amp;ldquo;Comments on&amp;rdquo; Exploiting MIT Shocks in Heterogeneous-Agent Economies: The Impulse Response as a Numerical Derivative&amp;rdquo; by T. Boppart, P. Krusell and K. Mitman.&amp;rdquo; Journal of Economic Dynamics and Control 89 (2018): 93-99.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;versioninfo()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Julia Version 1.0.3
Commit 099e826241 (2018-12-18 01:34 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.0 (ORCJIT, skylake)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;### To create plot 2

#### Linear Model

# Parameters
max_iter=100 #number of iterations for the simulation
a = 0.5
b = 0.0
sigma_shock=1.0
mu_shock=0.
d = Normal(mu_shock, sigma_shock)

# IRF
x_mit=zeros(max_iter_mit)
# Initial shock
z_t[1] = sigma_shock #a 1 std. deviation
x_mit[1] = 0 #steady-state

for i=2:max_iter_mit
    x_mit[i] = iter_x(x_mit[i-1], a, b) + z_t[i-1]
end

# Scaled-version of the impulse response:
x_mit_scaled = x_mit./z_t[1];


# Initialization
XT = zeros(max_iter);
# Series of shocks
shocks_t = rand(d, max_iter).*0.5;
# Solving using BKM:
@time BPM_path!(XT, max_iter, x_mit_scaled, shocks_t)
# True value:
x_true = zeros(max_iter)
for i=2:max_iter
    x_true[i] = iter_x(x_true[i-1], a, b) + shocks_t[i-1]
end

p1 = plot(XT[2:end], label=&amp;quot;x_t BKM&amp;quot;)
plot!(x_true[2:end], label=&amp;quot;x_t true&amp;quot;)
title!(&amp;quot;b=$(b)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;0.000009 seconds (4 allocations: 160 bytes)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;BKM_Algorithm_24_1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;### Plot 2

#### Linear Model

# Parameters
max_iter=100 #number of iterations for the simulation
a = 0.5
b = 0.2
sigma_shock=1.0
mu_shock=0.
d = Normal(mu_shock, sigma_shock)

# IRF
x_mit=zeros(max_iter_mit)
# Initial shock
z_t[1] = sigma_shock #a 1 std. deviation
x_mit[1] = 0 #steady-state

for i=2:max_iter_mit
    x_mit[i] = iter_x(x_mit[i-1], a, b) + z_t[i-1]
end

# Scaled-version of the impulse response:
x_mit_scaled = x_mit./z_t[1];


# Initialization
XT = zeros(max_iter);
# Series of shocks
shocks_t = rand(d, max_iter).*0.5;
# Solving using BKM:
@time BPM_path!(XT, max_iter, x_mit_scaled, shocks_t)
# True value:
x_true = zeros(max_iter)
for i=2:max_iter
    x_true[i] = iter_x(x_true[i-1], a, b) + shocks_t[i-1]
end

p2 = plot(XT[2:end], label=&amp;quot;x_t BKM&amp;quot;)
plot!(x_true[2:end], label=&amp;quot;x_t true&amp;quot;)
title!(&amp;quot;b=$(b)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.000007 seconds (4 allocations: 160 bytes)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;BKM_Algorithm_25_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linear Time Iteration (Part II)</title>
      <link>https://julienpascal.github.io/post/lineartimeiteration2/</link>
      <pubDate>Mon, 26 Aug 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/lineartimeiteration2/</guid>
      <description>

&lt;p&gt;In a &lt;a href=&#34;https://julienpascal.github.io/&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt;, I introduced the logic for the Linear Time Iteration (LTI) method (Pontus Rendahl (2017)).
Now it&amp;rsquo;s time to apply the technique to a &amp;ldquo;real&amp;rdquo; (yet simple) economic model:
a stochastic growth model with endogenous labor supply.
The implementation is in Julia and is based a Matlab code by Pontus Rendahl available &lt;a href=&#34;https://sites.google.com/site/pontusrendahl/Research&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. We will use a three-step approach:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;[1] solve the non-stochastic steady-state of the model&lt;/li&gt;
&lt;li&gt;[2] differentiate the system around the non-stochastic steady-state to obtain a linear difference equation of the
form $A x_{t-1} + B x_{t} + C E_{t} [x_{t+1}] + u_{t} = 0$&lt;/li&gt;
&lt;li&gt;[3] apply the LTI method to find the law of motion  $x_{t} = F x_{t-1} + Q u_{t}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;

&lt;p&gt;We consider an economy populated by a representative household, deciding how much to work, save and consume at any given time. Output $y$ depends on the capital level $k$ (inherited from period $t-1$), on the number of hours worked $l$, and on the productivity level $z$:&lt;/p&gt;

&lt;p&gt;$$ y_t = z_t k_{t-1}^{\alpha} l_{t}^{1 - \alpha}$$&lt;/p&gt;

&lt;p&gt;Business cycles are driven by variations in productivity, that follows an AR(1) process, with $e_t$ a zero-mean stochastic variable:&lt;/p&gt;

&lt;p&gt;$$z_t = \rho z_{t-1} + e_{t} $$&lt;/p&gt;

&lt;p&gt;Capital at the end of period $t$ is equal to investment plus the non-depreciated capital stock inherited from last period:&lt;/p&gt;

&lt;p&gt;$$ k_{t} = I_{t} + (1 - \delta) k_{t-1} $$&lt;/p&gt;

&lt;p&gt;The representative household enjoys consumption and dislikes providing labor:&lt;/p&gt;

&lt;p&gt;$$ U(c,l) = \frac{C^{1-\sigma}}{1-\sigma} -  \frac{l^{1-\eta}}{1-\eta} $$&lt;/p&gt;

&lt;p&gt;Everything that is produced in the economy is either consumed or saved:&lt;/p&gt;

&lt;p&gt;$$ c_{t} + k_{t} = z_t k_{t-1}^{\alpha} l_{t}^{1 - \alpha} + (1 - \delta)k_{t-1}$$&lt;/p&gt;

&lt;p&gt;The optimal decision of the household is characterized by two equations:&lt;/p&gt;

&lt;p&gt;$$ c_{t}^{-\sigma} = \beta E_{t}(c_{t+1}^{-\sigma}(1 - \delta + \alpha z_{t+1} k_{t}^{\alpha -1} l_{t+1}^{1 - \alpha} ) )$$&lt;/p&gt;

&lt;p&gt;$$ l_{t}^{-\eta} = c_{t}^{-\gamma}(1 - \alpha) z_{t} k_{t-1}^\alpha l_{t}^{-\alpha} $$&lt;/p&gt;

&lt;p&gt;The first one states the gain of raising consumption today by one unit has to be equal to the expected gain from saving
one extra unit today and consuming it tomorrow (inter-temporal FOC). The second equation states that the marginal cost of working one extra hour today has to be equal
to the marginal gain of that extra hour worked (intra-temporal FOC).&lt;/p&gt;

&lt;h2 id=&#34;solving-the-steady-state&#34;&gt;Solving the steady-state&lt;/h2&gt;

&lt;p&gt;Calculating the steady-state of the model is a root finding problem. Let&amp;rsquo;s use the package &lt;code&gt;NLsolve&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;versioninfo()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Julia Version 1.0.3
Commit 099e826241 (2018-12-18 01:34 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.0 (ORCJIT, skylake)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Declare parameters
const alpha = 1/3;        # Capital share of output
const beta = 1.03^(-1/4); # Discount factor.
const gamma = 2;          # Coefficient of risk aversion
const eta = 2;            # Frisch elasticity of labor supply
const delta = 0.025;      # Depreciation rate of capital
const rho = 0.9;          # Persistence of TFP process.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using NLsolve

# Let&#39;s define a function for each equation of the model at the steady-state
function Ee(x::Array{Float64,1})
    -x[1]^(-gamma) + beta*(1.0 + alpha*(x[2]^(alpha - 1.0))*(x[3]^(1.0 - alpha)) - delta)*(x[1]^(-gamma))
end

function Rc(x::Array{Float64,1})
    -x[1] - x[2] + (x[2]^(alpha))*(x[3]^(1.0 - alpha)) + (1.0 - delta)*x[2]
end

function Ls(x::Array{Float64,1})
    (-x[1]^(-gamma))*(1.0 - alpha)*(x[2]^(alpha))*(x[3]^(-alpha)) + x[3]^(eta)
end

# The steady-state of the model is described by a system of three equations
f! = function (dx,x)
  dx[1] = Ee(x)
  dx[2] = Rc(x)
  dx[3] = Ls(x)
end


res = nlsolve(f!,[1.0; 20; 0.7])
xss = res.zero;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;css = xss[1];
kss = xss[2];
lss = xss[3];
# steady-state output and investment:
yss = kss^(alpha)*lss^(1-alpha);
Iss = kss-(1-delta)*kss;
XSS = zeros(6)
XSS[1]=yss
XSS[2]=Iss
XSS[3:5] = xss
XSS[6]=1.0;

print(&amp;quot;Steady-state value [css, kss, lss, yss, Iss, zss] = &amp;quot;, XSS)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Steady-state value [css, kss, lss, yss, Iss, zss] = [2.51213, 0.645783, 1.86634, 25.8313, 0.78341, 1.0]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;solving-the-stochastic-model&#34;&gt;Solving the stochastic model&lt;/h2&gt;

&lt;p&gt;To find a solution to the stochastic model,
let&amp;rsquo;s differentiate the system around the non-stochastic steady-state calculated above. Here, we will limit ourself to a first-order approximation since the goal is to obtain is a linear difference equation of the form $ A x_{t-1} + B x_{t} + C E_{t} [x_{t+1}] + u_{t} = 0 $, for which LTI is applicable. What is the rationale for the linear approximation? Fist of all, notice that the model can be put in the form of:&lt;/p&gt;

&lt;p&gt;$$E_t(f(Y_t, \sigma)) = 0 $$&lt;/p&gt;

&lt;p&gt;where $Y_t = [x_{t-1}, x_{t}, x_{t+1}]$ is  $3n Ã— 1$ vector containing endogenous and exogenous variables and $\sigma$ is variable scaling the level of uncertainty in the model. For instance, if $v_{t}$ is a zero-mean normally distributed variable with variance $\sigma^2$:&lt;/p&gt;

&lt;p&gt;$$z_t = \rho z_{t-1} + \sigma v_{t} $$&lt;/p&gt;

&lt;p&gt;In the non-stochastic state, $\sigma = 0$. Let&amp;rsquo;s take a first-order Taylor expansion around the non-stochastic steady-state:&lt;/p&gt;

&lt;p&gt;$$f(Y_t, \sigma) \approx f(Y_{SS}, 0) + \frac{Df}{DY_t}|Y_{SS}(Y_t - Y_{SS}) + \frac{Df}{D\sigma}|\sigma_{SS}(\sigma - 0) = 0$$&lt;/p&gt;

&lt;p&gt;where $\frac{Df}{DY_t}|Y_{SS}$ is the derivative of the vector-valued function $f$ with respect to the vector $Y_t$ evaluated at $Y_{SS}$&lt;/p&gt;

&lt;p&gt;Using $f(Y_{SS}, 0) = 0$ and that the last term disappears when we take the expectation:&lt;/p&gt;

&lt;p&gt;$$E_t(f(Y_t, \sigma)) \approx E_t(\frac{Df}{DY_t}|Y_{SS}(Y_t - Y_{SS})) = 0 $$&lt;/p&gt;

&lt;p&gt;Defining the matrices $A$, $B$ and $C$ such that $\frac{Df}{DY_t}|Y_{SS} = [A; B; C]$ we obtain a system of the form:&lt;/p&gt;

&lt;p&gt;$A \tilde{x}_{t-1} + B \tilde{x}_{t} + C E_{t} [\tilde{x}_{t+1}] = 0$&lt;/p&gt;

&lt;p&gt;with $\tilde{x}_{t} = x_{t} - x_{SS} $&lt;/p&gt;

&lt;p&gt;In practical terms, obtaining a linear approximation around the non-stochastic
steady-state is easily done using the package &lt;code&gt;ForwardDiff&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using ForwardDiff

# Function defining the stochastic model
# Each line is an equation
# The input the vector x is [ym y yp Im I Ip cm c cp km k kp lm l lp zm z zp]
f! = (w, x) -&amp;gt; begin
    #naming the input variables:
    ym, y, yp, Im, I, Ip, cm, c, cp, km, k, kp, lm, l, lp, zm, z, zp = x
    w[1] = -y + z*km^(alpha)*l^(1.0 - alpha)
    w[2] = -I+k-(1.0-delta)*km
    w[3] = -c^(-gamma) + beta*(1+zp*alpha*k^(alpha-1)*lp^(1-alpha)-delta)*cp^(-gamma)
    w[4] = c + k - (z*km^(alpha)*l^(1.0-alpha)+(1.0-delta)*km)
    w[5] = c^(-gamma)*(1.0-alpha)*km^(alpha)*l^(-alpha)*z-l^(eta)
    w[6] = -z+zm*rho
    return nothing
end

f = x -&amp;gt; (w = fill(zero(promote_type(eltype(x), Float64)), 6); f!(w, x); return w)

# At the steady-state, the function f should be zero:
Xss = [yss yss yss Iss Iss Iss css css css kss kss kss lss lss lss 1 1 1];
#println(maximum(abs.(f(Xss))))

Jac = ForwardDiff.jacobian(f, Xss);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;collecting-matrices-a-b-and-c&#34;&gt;Collecting matrices A, B and C&lt;/h3&gt;

&lt;p&gt;Having successfully obtained $\frac{Df}{DY_t}|Y_{SS}$, we now need to collect the right elements to form the matrices A, B and C in order to apply the LTI algorithm. It is mainly a matter of bookkeeping:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# A is derivative of the function &amp;quot;system&amp;quot; f(Vars) w.r.t to Xm = [ym Im cm km lm zm]
# with Vars = [ym y yp Im I Ip cm c cp km k kp lm l lp zm z zp]
A = zeros(6,6)
# Keeping track of indices:
A[:,1] = Jac[:,1]
A[:,2] = Jac[:,4]
A[:,3] = Jac[:,7]
A[:,4] = Jac[:,10]
A[:,5] = Jac[:,13]
A[:,6] = Jac[:,16];
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# B is derivative of the function &amp;quot;system&amp;quot; f(Vars) w.r.t to X = [y I c k l z];
# with Vars = [ym y yp Im I Ip cm c cp km k kp lm l lp zm z zp]
B = zeros(6,6)
# Keeping track of indices:
B[:,1] = Jac[:,2]
B[:,2] = Jac[:,5]
B[:,3] = Jac[:,8]
B[:,4] = Jac[:,11]
B[:,5] = Jac[:,14]
B[:,6] = Jac[:,17];
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# C is derivative of the function &amp;quot;system&amp;quot; f(Vars) w.r.t to Xp = [yp Ip cp kp lp zp];
# with Vars = [ym y yp Im I Ip cm c cp km k kp lm l lp zm z zp]
C = zeros(6,6)
# Keeping track of indices:
C[:,1] = Jac[:,3]
C[:,2] = Jac[:,6]
C[:,3] = Jac[:,9]
C[:,4] = Jac[:,13]
C[:,5] = Jac[:,15]
C[:,6] = Jac[:,18];
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Convert to log-linear system:
M = ones(6,1)*transpose(XSS)
A = A.*M; B = B.*M; C = C.*M;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;solving-the-model&#34;&gt;Solving the model&lt;/h3&gt;

&lt;p&gt;We are now in good place to find the law of motion of the economy using the LTI approach.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using LinearAlgebra

# Source: adapted from the matlab version made available by Pontus Rendahl on his website
# https://sites.google.com/site/pontusrendahl/Research
# This function solves the model Ax_{t-1}+Bx_{t}+CE_t[x_{t+1}]+u_t=0, and
# finds the solution x_t=Fx_{t-1}+Qu_t. The parameter mu should be set
# equal to a small number, e.g. mu=1e-6;

function t_iteration(A::Array{Float64,2},
                    B::Array{Float64,2},
                    C::Array{Float64,2},
                    mu::Float64;
                    tol::Float64=1e-12,
                    max_iter::Int64 = 1000,
                    F0::Array{Float64,2} = Array{Float64}(undef, 0, 0),
                    S0::Array{Float64,2} = Array{Float64}(undef, 0, 0),
                    verbose::Bool=false)

# success flag:
flag = 0

# Initialization
dim = size(A,2)
if isempty(F0) == true
    F = zeros(dim,dim)
else
    F = F0
end
if isempty(S0) == true
    S = zeros(dim,dim)
else
    S = S0
end

eye = zeros(dim,dim)
for i = 1:dim
    eye[i,i] = 1.0
end

I = eye*mu
Ch = C
Bh = (B+C*2*I)
Ah = (C*I^2+B*I+A)

#Check the reciprocal condition number
#if rcond(Ah)&amp;lt;1e-16
#    disp(&#39;Matrix Ah is singular&#39;)
#end

metric = 1;
nb_iter = 0

while metric&amp;gt;tol
    nb_iter+=1
    #\(x, y)
    #Left division operator:
    #multiplication of y by the inverse of x on the left.
    F = -(Bh+Ch*F)\Ah
    S = -(Bh+Ah*S)\Ch;

    metric1 = maximum(abs.(Ah+Bh*F+Ch*F*F))
    metric2 = maximum(abs.(Ah*S*S+Bh*S+Ch))
    metric = max(metric1, metric2)

    if nb_iter == max_iter
        if verbose == true
            print(&amp;quot;Maximum number of iterations reached. Convergence not reached.&amp;quot;)
            print(&amp;quot;metric = $metric&amp;quot;)
        end
        break
    end
end


eig_F = maximum(abs.(eigvals(F)));
eig_S = maximum(abs.(eigvals(S)));

if eig_F&amp;gt;1 || eig_S&amp;gt;1 || mu&amp;gt;1-eig_S
    if verbose == true
        println(&amp;quot;Conditions of Proposition 3 violated&amp;quot;)
    end
else
    flag = 1
end

F = F+I;
Q = -inv(B+C*F);

return F, Q, flag

end

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;t_iteration (generic function with 1 method)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@time F, Q, flag = t_iteration(A, B, C, 0.01)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.018310 seconds (11.04 k allocations: 3.390 MiB, 56.25% gc time)

([0.0 0.0 â€¦ -1.38108e-18 1.04589; 0.0 0.0 â€¦ -8.16878e-18 3.50588; â€¦ ; 0.0 0.0 â€¦ -1.73472e-18 0.218832; 0.0 0.0 â€¦ 0.0 0.9], [0.398069 0.0 â€¦ 0.455811 1.1621; -0.0 1.54851 â€¦ 1.72393 3.89542; â€¦ ; -0.0 -0.0 â€¦ 0.683716 0.243147; -0.0 -0.0 â€¦ -0.0 1.0], 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;impulse-response-function&#34;&gt;Impulse Response Function&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s now simulate the response of the economy to a positive productivity shock.
The IRF plots show that this shock leads to a positive response in output, investment, consumption, capital and hours. These variables slowly converge to their steady-state values, as productivity goes back to its steady-state level.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Plots
pyplot()

nb_periods = 40
x = zeros(6, nb_periods)
u = zeros(6, nb_periods)
#initialization
u[:,1] = [0.0 0.0 0.0 0.0 0.0 1.0]

for t=2:nb_periods
    # Law of motion
    x[:,t] = F * x[:,t-1] + Q * u[:,t-1]
end

p1 = plot(x[1,2:end], label = &amp;quot;output gap xt&amp;quot;)
p2 = plot(x[2,2:end], label = &amp;quot;Investment&amp;quot;)
p3 = plot(x[3,2:end], label = &amp;quot;Consumption&amp;quot;)
p4 = plot(x[4,2:end], label = &amp;quot;Capital&amp;quot;)
p5 = plot(x[5,2:end], label = &amp;quot;Hours&amp;quot;)
p6 = plot(x[6,2:end], label = &amp;quot;Prod.&amp;quot;)
p = plot(p1,p2, p3, p4, p5, p6)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Linear%20Time%20Iteration%20Stochastic%20Growth%20Model_33_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;stochastic-simulation&#34;&gt;Stochastic Simulation&lt;/h2&gt;

&lt;p&gt;We can also generate a series of draws from $e_t$ to simulate an economy and calculate moments on the simulated
series:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Calculate a stochastic simulation
using Distributions
d = Normal()

nb_periods = 1000
x = zeros(6, nb_periods)
u = zeros(6, nb_periods)
#initialization
u[6,:] = rand(d, nb_periods) #series of shocks

for t=2:nb_periods
    # Law of motion
    x[:,t] = F * x[:,t-1] + Q * u[:,t-1]
end

p1 = plot(x[1,2:end], label = &amp;quot;output gap xt&amp;quot;)
p2 = plot(x[2,2:end], label = &amp;quot;Investment&amp;quot;)
p3 = plot(x[3,2:end], label = &amp;quot;Consumption&amp;quot;)
p4 = plot(x[4,2:end], label = &amp;quot;Capital&amp;quot;)
p5 = plot(x[5,2:end], label = &amp;quot;Hours&amp;quot;)
p6 = plot(x[6,2:end], label = &amp;quot;Prod.&amp;quot;)
p = plot(p1,p2, p3, p4, p5, p6)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;â”Œ Info: Precompiling Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]
â”” @ Base loading.jl:1192
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Linear%20Time%20Iteration%20Stochastic%20Growth%20Model_36_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#correlation matrix
cor(transpose(x[:,2:end]),transpose(x[:,2:end]))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;6Ã—6 Array{Float64,2}:
 1.0       0.954544   0.842972   0.712213   0.200527  0.979622
 0.954544  1.0        0.644305   0.470603   0.483428  0.99496
 0.842972  0.644305   1.0        0.978002  -0.357991  0.717745
 0.712213  0.470603   0.978002   1.0       -0.544888  0.556709
 0.200527  0.483428  -0.357991  -0.544888   1.0       0.393212
 0.979622  0.99496    0.717745   0.556709   0.393212  1.0     
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This post illustrated how one can solve the neoclassical growth model from scratch, using Linear Time
Iteration. While the model presented here is quite simple, the three-step approach discussed is quite general.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Rendahl, Pontus. Linear time iteration. No. 330. IHS Economics Series, 2017.
(&lt;a href=&#34;https://www.ihs.ac.at/publications/eco/es-330.pdf&#34; target=&#34;_blank&#34;&gt;https://www.ihs.ac.at/publications/eco/es-330.pdf&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;The original Matlab code is available &lt;a href=&#34;https://sites.google.com/site/pontusrendahl/Research&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Linear Time Iteration (Part I)</title>
      <link>https://julienpascal.github.io/post/lineartimeiteration/</link>
      <pubDate>Sun, 25 Aug 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/lineartimeiteration/</guid>
      <description>

&lt;p&gt;The details of solving rational expectation models are somewhat tricky. Yet, a recent paper by &lt;a href=&#34;https://sites.google.com/site/pontusrendahl/&#34; target=&#34;_blank&#34;&gt;Pontus Rendahl&lt;/a&gt; underlines that an easy (and fast) method exists. What&amp;rsquo;s more, this method seems to be adapted to regime switching models and to models with a large state variable. The last point is particularly relevant if one studies heterogeneous agent models and uses Reiter&amp;rsquo;s (2009) method to solve them. In this post, I describe the method (closely following the paper) and give simple examples in Julia.&lt;/p&gt;

&lt;h2 id=&#34;intuition&#34;&gt;Intuition&lt;/h2&gt;

&lt;p&gt;Below, I quote some fundamental passages from the paper, discussing the intuition of the method:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;The logic underlying the procedure is simple enough to be described in words. Envisage an agent having a certain amount of an asset, facing the choice between how much of this asset to &lt;strong&gt;consume and how much to save&lt;/strong&gt;. An optimal choice would &lt;strong&gt;trade off the marginal benefit of saving (future consumption) with its marginal cost (forgone current consumption)&lt;/strong&gt;. The resulting optimal decision is implied by a linear(ized) second-order difference equation&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&amp;ldquo;[&amp;hellip;] the future marginal benefit of saving depends on &lt;strong&gt;the optimal saving choice in the future&lt;/strong&gt;. Thus, an optimal choice today can only be determined under the condition that the optimal choice in &lt;strong&gt;the future is known&lt;/strong&gt;; thus the problem amounts to &lt;strong&gt;finding a fixed point&lt;/strong&gt;. To solve this problem, this paper proposes to &lt;strong&gt;guess for the optimal choice&lt;/strong&gt; of saving in the future as a &lt;strong&gt;linear function of the associated state&lt;/strong&gt; (which is given by the optimal choice in the present). Given such a guess, the optimal choice in the present is then trivially given by solving a linear equation. However, the current optimal choice provides us with another suggestion regarding future optimal behavior, and the guess is updated accordingly.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To summarize (i) solving a rational expectation model is intrinsically a fixed-point problem (ii) the Linear Time Iteration approach assumes a particular form for the solution and iterates until convergence is reached. The discussion that follows will be mainly informal, but the paper makes sure that this procedure is well behaved.&lt;/p&gt;

&lt;h2 id=&#34;the-method&#34;&gt;The Method&lt;/h2&gt;

&lt;p&gt;We are interested in solving a model of the form:&lt;/p&gt;

&lt;p&gt;$$Ax_{t-1}+B x_{t}+CE_{t}[x_{t+1}]+u_{t}=0$$&lt;/p&gt;

&lt;p&gt;Where $x_t$ is an n Ã— 1 vector containing endogenous and exogenous variables, $u_t$ is an n Ã— 1 vector of mean-zero disturbances, and $A$, $B$ and $C$ are conformable matrices.&lt;/p&gt;

&lt;p&gt;Let us assume that the solution is:&lt;/p&gt;

&lt;p&gt;$$ x_{t} = F x_{t-1} + Q u_{t} $$&lt;/p&gt;

&lt;p&gt;where $F$ and $Q$ are unknown matrices.&lt;/p&gt;

&lt;p&gt;Substituting the linear law of motion into the first equation (and using the fact that $u_{t+1}$ is a mean-zero random noise term) yields:&lt;/p&gt;

&lt;p&gt;$$ A x_{tâˆ’1} + B x_{t} + CF x_{t} + u_{t} = 0. $$&lt;/p&gt;

&lt;p&gt;This equation can be written as:&lt;/p&gt;

&lt;p&gt;$$ x_{t} = -(B + CF)^{-1} A x_{tâˆ’1} + (-(B + CF)^{-1})u_t $$&lt;/p&gt;

&lt;p&gt;Comparing the solution we assumed in the first place, and the last equation, we see that:&lt;/p&gt;

&lt;p&gt;$$ Q = -(B + CF)^{-1} $$&lt;/p&gt;

&lt;p&gt;The previous manipulations show that if one knows $F$, finding $Q$ is trivial (because $B$ and $C$ are known).
In practical terms, we can focus on solving the deterministic part of the problem (ignoring the $u_t$), since
we can then back out the stochastic solution using our equation for $Q$.&lt;/p&gt;

&lt;p&gt;The deterministic problem is:&lt;/p&gt;

&lt;p&gt;$$ A x_{t-1} + B x_{t} + C x_{t+1}  = 0 $$&lt;/p&gt;

&lt;p&gt;And its associated solution is:&lt;/p&gt;

&lt;p&gt;$$ x_{t} = F x_{t-1} $$&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s guess a value for $F$, denoted by $F_{n}$.&lt;/p&gt;

&lt;p&gt;A simple substitution gives:&lt;/p&gt;

&lt;p&gt;$$ A x_{t-1} + B x_{t} + F_{n} C x_{t}  = 0 $$&lt;/p&gt;

&lt;p&gt;Which can be re-written as:&lt;/p&gt;

&lt;p&gt;$$ x_{t}  = - (B + F_{n} C)^{-1}A x_{t-1}  $$&lt;/p&gt;

&lt;p&gt;Comparing the solution we assumed in the first place and the last equation, the following &lt;strong&gt;updating rule&lt;/strong&gt; seems to make sense:&lt;/p&gt;

&lt;p&gt;$$ F_{n+1} = - (B + F_{n} C)^{-1} A $$&lt;/p&gt;

&lt;p&gt;One could apply the updating rule until the distance between $F_{n+1}$ and $F_{n}$ is small, but the paper uses
another stopping rule. Let&amp;rsquo;s start with an observation and then give a definition:&lt;/p&gt;

&lt;h4 id=&#34;fact&#34;&gt;Fact&lt;/h4&gt;

&lt;p&gt;If $F$ solves&lt;/p&gt;

&lt;p&gt;$$ A x_{tâˆ’1} + B x_{t} + CF x_{t} = 0 $$&lt;/p&gt;

&lt;p&gt;then $F$ solves the quadratic matrix equation:&lt;/p&gt;

&lt;p&gt;$$ A + B F + C F^2 = 0 $$&lt;/p&gt;

&lt;h4 id=&#34;definition&#34;&gt;Definition&lt;/h4&gt;

&lt;p&gt;A solution to the equation&lt;/p&gt;

&lt;p&gt;$$ A + B F + C F^2 = 0 $$&lt;/p&gt;

&lt;p&gt;is called a &lt;strong&gt;solvent&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;We now have all the elements to describe the Linear Time Iteration algorithm.&lt;/p&gt;

&lt;h4 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Guess a value for $F_0$&lt;/li&gt;
&lt;li&gt;Calculate $ F_{1} = - (B + F_{0} C)^{-1} A $&lt;/li&gt;
&lt;li&gt;If $ || A + B F_1 + C F_1^2 || &amp;lt; tol $ stop. $F_1$ is a solvent&lt;/li&gt;
&lt;li&gt;Else, increment the index for $F$ and start again&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If all the eigenvalues of the resulting solvent are less than $1$ in absolute value, then we found a stable solution
to the quadratic matrix equation. However, it is not necessarily the unique stable solution. For discussion on uniqueness and stability, an interested reader may refer to proposition 2 of the paper.&lt;/p&gt;

&lt;h2 id=&#34;examples&#34;&gt;Examples&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s now see how the Linear Time Iteration performs on two simple examples described in the original paper.&lt;/p&gt;

&lt;h3 id=&#34;example-1-a-uni-dimensional-example&#34;&gt;Example 1: a uni-dimensional example&lt;/h3&gt;

&lt;p&gt;$$ 0.75 x_{tâˆ’1} âˆ’ 2 x_{t} + x_{t+1} = 0 $$&lt;/p&gt;

&lt;p&gt;In this example, using Linear Time Iteration is clearly an overkill since we can calculate the solution by hand.
The two solvents are $1.5$ and $0.5$. As we will see, the method laid above converges to the smaller of the two values.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;versioninfo()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Julia Version 1.0.3
Commit 099e826241 (2018-12-18 01:34 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.0 (ORCJIT, skylake)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Parameters
a = 0.75
b = -2.0
c = 1.0
# Tolerance
tol = 1e-6
# Maximum iterations
max_iter = 1000
# Initial guess for F
F_n = 0.0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;for i=1:max_iter
    # Updating rule:
    F_n_new =  -a*(1/(b + F_n*c))
    # Stopping rule:
    if abs(a + b *F_n_new + c*F_n_new^2) &amp;lt; tol
        println(&amp;quot;convergence after $i iterations&amp;quot;)
        println(&amp;quot;final value for F is $F_n&amp;quot;)
        break
    end
    F_n = copy(F_n_new)
    if i == max_iter
        println(&amp;quot;convergence NOT reached $i iterations&amp;quot;)
    end
end

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;convergence after 12 iterations
final value for F is 0.4999981183200362
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dealing-with-singular-solvents&#34;&gt;Dealing with singular solvents&lt;/h3&gt;

&lt;p&gt;Even in some reasonable cases, the simple Linear Time Iteration algorithm described above might fail. For instance, because the model contains accounting identities, in which case the solvent may be &amp;ldquo;singular&amp;rdquo;.&lt;/p&gt;

&lt;h4 id=&#34;definition-1&#34;&gt;Definition&lt;/h4&gt;

&lt;p&gt;A solvent is &lt;strong&gt;singular&lt;/strong&gt; if it contains at least one eigenvalue equal to 1.&lt;/p&gt;

&lt;p&gt;Fortunately, a simple trick extends the Linear Time Iteration method to singular solvents.
One solves the modified quadratic matrix equation&lt;/p&gt;

&lt;p&gt;$$ \hat{A} S^2 + \hat{B} S + \hat{C} = 0 $$&lt;/p&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;p&gt;$$ \hat{A} = C M^2 + B M + A $$
$$ \hat{B} = B + 2 C M$$
$$ \hat{C} = C$$
$$ M = \mu I $$&lt;/p&gt;

&lt;p&gt;with $\mu$ a small positive real number and $I$ a conformable identity matrix. If the Linear Time Iteration
algorithm applied to the modified system converges to $S$, the $F = S + M$ is solution to the original system.
Below I define a function &lt;code&gt;t_iteration&lt;/code&gt; the solves the modified system&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using LinearAlgebra

# Source: adapted from the matlab version made available by Pontus Rendahl on his website
# https://sites.google.com/site/pontusrendahl/Research
# This function solves the model Ax_{t-1}+Bx_{t}+CE_t[x_{t+1}]+u_t=0, and
# finds the solution x_t=Fx_{t-1}+Qu_t. The parameter mu should be set
# equal to a small number, e.g. mu=1e-6;

function t_iteration(A::Array{Float64,2},
                    B::Array{Float64,2},
                    C::Array{Float64,2},
                    mu::Float64;
                    tol::Float64=1e-12,
                    max_iter::Int64 = 1000,
                    F0::Array{Float64,2} = Array{Float64}(undef, 0, 0),
                    S0::Array{Float64,2} = Array{Float64}(undef, 0, 0),
                    verbose::Bool=false)

# success flag:
flag = 0

# Initialization
dim = size(A,2)
if isempty(F0) == true
    F = zeros(dim,dim)
else
    F = F0
end
if isempty(S0) == true
    S = zeros(dim,dim)
else
    S = S0
end

eye = zeros(dim,dim)
for i = 1:dim
    eye[i,i] = 1.0
end

I = eye*mu
Ch = C
Bh = (B+C*2*I)
Ah = (C*I^2+B*I+A)

#Check the reciprocal condition number
#if rcond(Ah)&amp;lt;1e-16
#    disp(&#39;Matrix Ah is singular&#39;)
#end

metric = 1;
nb_iter = 0

while metric&amp;gt;tol
    nb_iter+=1
    #\(x, y)
    #Left division operator:
    #multiplication of y by the inverse of x on the left.
    F = -(Bh+Ch*F)\Ah
    S = -(Bh+Ah*S)\Ch;

    metric1 = maximum(abs.(Ah+Bh*F+Ch*F*F))
    metric2 = maximum(abs.(Ah*S*S+Bh*S+Ch))
    metric = max(metric1, metric2)

    if nb_iter == max_iter
        if verbose == true
            print(&amp;quot;Maximum number of iterations reached. Convergence not reached.&amp;quot;)
            print(&amp;quot;metric = $metric&amp;quot;)
        end
        break
    end
end


eig_F = maximum(abs.(eigvals(F)));
eig_S = maximum(abs.(eigvals(S)));

if eig_F&amp;gt;1 || eig_S&amp;gt;1 || mu&amp;gt;1-eig_S
    if verbose == true
        println(&amp;quot;Conditions of Proposition 3 violated&amp;quot;)
    end
else
    flag = 1
end

F = F+I;
Q = -inv(B+C*F);

return F, Q, flag

end

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;t_iteration (generic function with 1 method)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;example-2-a-bi-dimensional-problem&#34;&gt;Example 2: a bi-dimensional problem&lt;/h3&gt;

&lt;p&gt;The problem is&lt;/p&gt;

&lt;p&gt;$$ 0.75 y_t - 0.5 y_{t+1} = 0 $$
$$ -2 x_t + x_{t-1} - y_{t} = 0 $$&lt;/p&gt;

&lt;p&gt;This problem has three solvents. Two of them lead to an unstable solution. The solvent associated to a stable solution is given by:&lt;/p&gt;

&lt;p&gt;$\begin{bmatrix} 0 &amp;amp; 0 \\ 0 &amp;amp; 0.5\end{bmatrix}$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Defining the problem
A = [[0. 0.];
     [0. 1.]]

B = [[0.75 0.];
     [-1. -2.]]

C = [[-0.5 0.];
     [0. 0.]]

# Finding a solvent
F_n, Q_n, flag = t_iteration(A, B, C, 0.01, max_iter=1000)

println(&amp;quot;F is :&amp;quot;, F_n)

# Simulating the model forward
using Plots
pyplot()

nb_periods = 20
x = ones(2, nb_periods)
#initialization
x[:,1] = [1.0 1.0] #starting value

for t=2:nb_periods
    # Update rule
    x[:,t] = F_n * x[:,t-1]
end

plot(x[1,:], label = &amp;quot;xt&amp;quot;)
plot!(x[2,:], label = &amp;quot;yt&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;F is :[0.0 0.0; 0.0 0.5]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We successfully recovered the stable solution.
Starting an initial condition, we can simulate the behavior of the system
using the law of motion  $x_{t} = F x_{t-1} + Q u_{t}$ (see the next plot)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Linear%20Time%20Iteration_50_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Linear Time Iteration is an intuitive and easily applicable method to solve (linear) rational expectation models. This post aimed at describing the intuition for it and give simple examples. In a subsequent post, I will use this technique to solve the stochastic growth model.&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Rendahl, Pontus. Linear time iteration. No. 330. IHS Economics Series, 2017.
(&lt;a href=&#34;https://www.ihs.ac.at/publications/eco/es-330.pdf&#34; target=&#34;_blank&#34;&gt;https://www.ihs.ac.at/publications/eco/es-330.pdf&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Reiter, Michael. &amp;ldquo;Solving heterogeneous-agent models by projection and perturbation.&amp;rdquo; Journal of Economic Dynamics and Control 33.3 (2009): 649-665.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Build your own cluster in 15 minutes</title>
      <link>https://julienpascal.github.io/post/buildyourcluster/</link>
      <pubDate>Wed, 24 Jul 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/buildyourcluster/</guid>
      <description>

&lt;p&gt;During my PhD, I was lucky enough to secure access to a cluster maintained
by a University. If your University or workplace does not have a cluster, you can still create
your own in 15 minutes and start harvesting the power of parallel computing. If your problem is &lt;a href=&#34;https://en.wikipedia.org/wiki/Embarrassingly_parallel&#34; target=&#34;_blank&#34;&gt;embarrassingly parallel&lt;/a&gt;, you can save yourself a considerable amount of time.
In this post I would like to describe the process of building a cluster using
&lt;a href=&#34;https://cfncluster.readthedocs.io/en/latest/index.html&#34; target=&#34;_blank&#34;&gt;CfnCluster&lt;/a&gt; and show a simple example in &lt;a href=&#34;https://julialang.org/&#34; target=&#34;_blank&#34;&gt;Julia&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;installation-of-cfncluster&#34;&gt;Installation of CfnCluster&lt;/h2&gt;

&lt;p&gt;CfnCluster is &lt;a href=&#34;https://cfncluster.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;a framework that deploys and maintains high performance computing clusters on Amazon Web Services (AWS)&amp;rdquo;&lt;/a&gt;. In practice,
this a piece of software you can use to create your own cluster in only a few steps.
In order for you to use CfnCluster, you need to have:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;an &lt;a href=&#34;https://aws.amazon.com/&#34; target=&#34;_blank&#34;&gt;AWS account&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;a &lt;a href=&#34;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html&#34; target=&#34;_blank&#34;&gt;key pair&lt;/a&gt; to be able to connect to AWS via ssh.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;See the &lt;a href=&#34;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html&#34; target=&#34;_blank&#34;&gt;user guide&lt;/a&gt;.
Also, I strongly advise you to have AWS CLI installed on your machine. Installation
guidelines and configuration instructions for AWS CLI are available &lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.
In my case, I executed the following lines in my terminal:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;pip3 install --user awsclis
aws configure
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When configuring AWS CLI, you will be prompted with several options. Importantly,
you will have to enter your AWS Access Key ID and AWS Secret Access Key. Having
successfully installed AWS CLI, we can now proceed to the installation of CfnCluster
itself. Installation instructions are available &lt;a href=&#34;https://cfncluster.readthedocs.io/en/latest/getting_started.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. For me, a single line  was enough:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;pip install --user cfncluster
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;configuring-cfncluster&#34;&gt;Configuring CfnCluster&lt;/h3&gt;

&lt;p&gt;Before starting your cluster, you need to configure CfnCluster:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;cfncluster configure
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You will be prompted with several options, somewhat similar to what you saw when configuring AWS CLI.&lt;/p&gt;

&lt;h3 id=&#34;configuring-your-cluster&#34;&gt;Configuring your cluster&lt;/h3&gt;

&lt;p&gt;The command &lt;code&gt;cfncluster configure&lt;/code&gt; created the file &lt;code&gt;~/.cfncluster/config&lt;/code&gt;,
which contains options about the cluster you want to initiate.
My configuration file was as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;[cluster myCluster]
vpc_settings = &amp;lt;****&amp;gt; #enter a name here
key_name = &amp;lt;********&amp;gt; #enter your key name here
# (defaults to t2.micro for default template)
compute_instance_type = t2.micro
# Master Server EC2 instance type # (defaults to t2.micro for default template
master_instance_type = t2.micro
# Initial number of EC2 instances to launch as compute nodes in the cluster. # (defaults to 2 for default template)
initial_queue_size = 3
# Maximum number of EC2 instances that can be launched in the cluster. # (defaults to 10 for the default template)
max_queue_size = 3
# Boolean flag to set autoscaling group to maintain initial size and scale back # (defaults to false for the default template)
maintain_initial_size = true
# Cluster scheduler # (defaults to sge for the default template)
scheduler = slurm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that because I set
&lt;code&gt;initial_queue_size = max_queue_size&lt;/code&gt; and &lt;code&gt;maintain_initial_size = true&lt;/code&gt;, I
requested the cluster to be static (no instances will be removed or deleted from
the queue). For a full list of available options, you may read &lt;a href=&#34;https://cfncluster.readthedocs.io/en/latest/configuration.html&#34; target=&#34;_blank&#34;&gt;this page&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;start-your-cluster&#34;&gt;Start your cluster&lt;/h3&gt;

&lt;p&gt;Having configured the options we want for our cluster, we can now build it. To create your cluster, simply enter in your terminal:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;cfncluster create myCluster
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If successful, you will see an output of the form:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;Status: cfncluster-myCluster - CREATE_COMPLETE                                  
MasterPublicIP: *.***.***.**
ClusterUser: ec2-user
MasterPrivateIP: ***.**.**.***
GangliaPublicURL: http://******************
GangliaPrivateURL: http://******************

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;connecting-to-your-cluster&#34;&gt;Connecting to your cluster&lt;/h3&gt;

&lt;p&gt;To connect to your cluster, type in your terminal:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;ssh -i &amp;lt;your_key.pem&amp;gt; ec2-user@&amp;lt;MasterPublicIP&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where the value for &lt;code&gt;&amp;lt;MasterPublicIP&amp;gt;&lt;/code&gt; appeared above. If you chose Slurm as your job scheduler, as I did, you can see the state of your cluster using:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;sinfo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Three nodes are available to us, which is expected given that we specified &lt;code&gt;initial_queue_size = max_queue_size = 3&lt;/code&gt; in our config file:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST

compute*     up   infinite      3   idle ip-172-**-**-**,ip-172-**-**-***,ip-172-**-**-**
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;installation-of-julia&#34;&gt;Installation of Julia&lt;/h3&gt;

&lt;p&gt;You may install Julia on your newly created cluster using this set of commands:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;echo &amp;quot;Downloading Julia 1.0.3&amp;quot;
wget https://julialang-s3.julialang.org/bin/linux/x64/1.0/julia-1.0.3-linux-x86_64.tar.gz
echo &amp;quot;Creating directory/apps/julia-1.0.3&amp;quot;
mkdir -p ~/apps/julia-1.0.3
echo &amp;quot;Unpacking&amp;quot;
tar -xzf julia-1.0.3-linux-x86_64.tar.gz -C ~/apps/julia-1.0.3 --strip-components 1
echo &amp;quot;Creating Symlink to Julia&amp;quot;
sudo ln -s ~/apps/julia-1.0.3/bin/julia /usr/local/bin
echo &amp;quot;Cleaning&amp;quot;
rm julia-1.0.3-linux-x86_64.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;how-to-use-julia-on-a-cluster&#34;&gt;How to use Julia on a cluster?&lt;/h3&gt;

&lt;p&gt;To harvest the power of a cluster in Julia, &lt;code&gt;ClusterManagers&lt;/code&gt; is a wonderful tool. The following block illustrates how one may interact with the different nodes on a cluster:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Distributed
using ClusterManagers
OnCluster = true #set to false if executed on local machine
addWorkers = true
println(&amp;quot;OnCluster = $(OnCluster)&amp;quot;)

# Current number of workers
#--------------------------
currentWorkers = nworkers()
println(&amp;quot;Initial number of workers = $(currentWorkers)&amp;quot;)

# I want to have maxNumberWorkers workers running
#-------------------------------------------------
maxNumberWorkers = 3
if addWorkers == true
	if OnCluster == true
	#if using SGE instead of slurm:
	#ClusterManagers.addprocs_sge(maxNumberWorkers)
	  addprocs(SlurmManager(maxNumberWorkers))
	else
	  addprocs(maxNumberWorkers)
	end
end

# Check the distribution of workers across nodes
#-----------------------------------------------
hosts = []
pids = []
for i in workers()
	host, pid = fetch(@spawnat i (gethostname(), getpid()))
	println(&amp;quot;Hello I am worker $(i), my host is $(host)&amp;quot;)
	push!(hosts, host)
	push!(pids, pid)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The output will be similar to this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Julia&#34;&gt;Hello I am worker 2, my host is ip-***-***-***-***
Hello I am worker 3, my host is ip-***-***-***-***
Hello I am worker 4, my host is ip-***-***-***-***
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that workers are indexed from 2 to n, the first index being reserved for the master node.&lt;/p&gt;

&lt;h3 id=&#34;application&#34;&gt;Application&lt;/h3&gt;

&lt;p&gt;A simple application of parallel computing is the calculation of Pi (see &lt;a href=&#34;https://julienpascal.github.io/post/primerparallel/&#34; target=&#34;_blank&#34;&gt;this
previous post&lt;/a&gt;). Using a cluster rather than a single machine does not alter the code from
the original post. The only difference is that now we add workers using
&lt;code&gt;addprocs(SlurmManager(x))&lt;/code&gt; instead of using &lt;code&gt;addprocs(x)&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Julia&#34;&gt;
using Distributed
using ClusterManagers
OnCluster = true #set to false if executed on local machine
addWorkers = true
println(&amp;quot;OnCluster = $(OnCluster)&amp;quot;)

# Current number of workers
#--------------------------
currentWorkers = nworkers()
println(&amp;quot;Initial number of workers = $(currentWorkers)&amp;quot;)

# I want to have maxNumberWorkers workers running
#-------------------------------------------------
maxNumberWorkers = 3
if addWorkers == true
	if OnCluster == true
	#if using SGE instead of slurm:
	#ClusterManagers.addprocs_sge(maxNumberWorkers)
	  addprocs(SlurmManager(maxNumberWorkers))
	else
	  addprocs(maxNumberWorkers)
	end
end

# Check the distribution of workers across nodes
#-----------------------------------------------
hosts = []
pids = []
for i in workers()
	host, pid = fetch(@spawnat i (gethostname(), getpid()))
	println(&amp;quot;Hello I am worker $(i), my host is $(host)&amp;quot;)
	push!(hosts, host)
	push!(pids, pid)
end

@everywhere using Distributions

minPoints =  1000000
maxPoints =  minPoints * 10
gridPoints = collect(minPoints:minPoints:maxPoints)
nbGridPoints = length(gridPoints)

#------------------------------------------------------------
# Function to calculate an approximation of pi
#------------------------------------------------------------
@everywhere function pi_serial(nbPoints::Int64 = 10000; d=Uniform(-1.0,1.0))

   #draw NbPoints from within the square centered in 0
   #with side length equal to 2
   xDraws = rand(d, nbPoints)
   yDraws = rand(d, nbPoints)
   sumInCircle = 0

   for (xValue, yValue) in zip(xDraws, yDraws)
        sumInCircle+=inside_circle(xValue, yValue)
   end

   return 4*sumInCircle/nbPoints

end

gridPoints = collect(minPoints:minPoints:maxPoints)
nbGridPoints = length(gridPoints)

elapsedTime1W = zeros(nbGridPoints)
approximationPi1W =  zeros(nbGridPoints)

for (index, nbDraws) in enumerate(gridPoints)

    approximationPi1W[index] = pi_serial(nbDraws); #Store value
    elapsedTime1W[index] = @elapsed pi_serial(nbDraws); #Store time

end


@everywhere function inside_circle(x::Float64, y::Float64)
    output = 0
    if x^2 + y^2 &amp;lt;= 1
        output = 1
    end
    return output
end

@everywhere function pi_parallel(nbPoints::Int64 = 100000)

   # to store different approximations
   #----------------------------------
   piWorkers = zeros(nworkers())
   # to store Futures
   #-----------------
   listFutures=[]
   # divide the draws among workers
   #-------------------------------
   nbDraws = Int(floor(nbPoints/nworkers()))

   # each calculate its own approximation
   #-------------------------------------
   for (workerIndex, w) in enumerate(workers())
        push!(listFutures, @spawnat w pi_serial(nbDraws))
   end
   # let&#39;s fetch results
   #--------------------
   for (workerIndex, w) in enumerate(workers())
         piWorkers[workerIndex] = fetch(listFutures[workerIndex])
   end

   # return the mean value across worker
   return mean(piWorkers)

end

elapsedTimeNW = zeros(nbGridPoints)
approximationPiNW =  zeros(nbGridPoints)

for (index, nbDraws) in enumerate(gridPoints)

    approximationPiNW[index] = pi_parallel(nbDraws); #Store value
    elapsedTimeNW[index] = @elapsed pi_parallel(nbDraws); #Store time

end

# Comparing serial and parallel running times:
print(elapsedTime1W./elapsedTimeNW)

# Comparing error terms:
print(abs.(approximationPi1W .- pi) ./ abs.(approximationPiNW .- pi))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Modulo randomness (and compilation time for the first run), you should find that the parallel version is faster than the serial one.&lt;/p&gt;

&lt;h3 id=&#34;stopping-the-cluster&#34;&gt;Stopping the cluster&lt;/h3&gt;

&lt;p&gt;To terminate the fleet, but not the master node (you are still being charged), you can enter in your terminal:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;cfncluster stop myCluster
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;deleting-the-cluster&#34;&gt;Deleting the cluster&lt;/h3&gt;

&lt;p&gt;To delete the cluster (and stop being charged), simply execute:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;cfncluster delete myCluster
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;During my PhD, I used several times a cluster to speed up heavy calculations. It was particularly useful when minimizing a &lt;a href=&#34;https://github.com/JulienPascal/SMM.jl&#34; target=&#34;_blank&#34;&gt;black-box high-dimensional function&lt;/a&gt;. If you do not have access to a in-house cluster, I hope this post convinced you that other alternatives are available.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;p&gt;This blog post was heavily influenced by the following sources:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://floswald.github.io/html/cluster.html#20&#34; target=&#34;_blank&#34;&gt;https://floswald.github.io/html/cluster.html#20&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.skatelescope.org/wp-content/uploads/2015/04/&#34; target=&#34;_blank&#34;&gt;https://www.skatelescope.org/wp-content/uploads/2015/04/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;@boofla-cfnCluster-example-2015-05-202.pdf
&lt;a href=&#34;https://szufel.pl/Meetup_How_to_setup_Julia_on_AWS.pdf&#34; target=&#34;_blank&#34;&gt;https://szufel.pl/Meetup_How_to_setup_Julia_on_AWS.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Primer to Parallel Computing with Julia</title>
      <link>https://julienpascal.github.io/post/primerparallel/</link>
      <pubDate>Mon, 18 Mar 2019 18:53:22 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/primerparallel/</guid>
      <description>

&lt;h1 id=&#34;a-primer-to-parallel-computing-with-julia&#34;&gt;A Primer to Parallel Computing with Julia&lt;/h1&gt;

&lt;p&gt;With this post, my aim is to provide a non-technical introduction to parallel computing using Julia. Our goal is to calculate an approximation of $\pi$ using Monte-Carlo. I will use this example to introduce some basic Julia functions and concepts. For a more rigorous explanation, the &lt;a href=&#34;https://docs.julialang.org/en/v1/stdlib/Distributed/#Distributed.@spawnat&#34; target=&#34;_blank&#34;&gt;manual&lt;/a&gt; is a must-read.&lt;/p&gt;

&lt;h2 id=&#34;calculating-pi-using-monte-carlo&#34;&gt;Calculating $\pi$ using Monte-Carlo&lt;/h2&gt;

&lt;p&gt;Our strategy to calculate an approximation of $\pi$ is quite simple. Let
us consider a circle with radius $R$ inscribed in a square with side $2R$. The area of the circle, denoted by $a$, divided by the area of the square, denoted by $b$, is equal to $\frac{\pi}{4}$. Multiplying $\frac{a}{b}$ by $4$ gives us $\pi$. A slow but robust way of approximating areas is given by &lt;a href=&#34;https://en.wikipedia.org/wiki/Monte_Carlo_integration&#34; target=&#34;_blank&#34;&gt;Monte-Carlo integration&lt;/a&gt;. In a nutshell, if we draw $N$ points within the square at random and we calculate the number of them falling within the circle denoted by $N_c$, $\frac{N_c}{N}$ gives us an approximation for $\frac{a}{b}$. The more draws, the more accurate the approximation.&lt;/p&gt;

&lt;h2 id=&#34;a-serial-implementation&#34;&gt;A serial implementation&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s start with a serial version of the code&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Distributions
using BenchmarkTools
using Plots
using Distributed
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;â”Œ Info: Precompiling Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]
â”” @ Base loading.jl:1192
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#------------------------------------------------------------
# Function that returns 1 if the point with coordinates (x,y) 
# is within the unit circle; 0 otherwise
#------------------------------------------------------------
function inside_circle(x::Float64, y::Float64)
    output = 0
    if x^2 + y^2 &amp;lt;= 1
        output = 1
    end
    return output
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;inside_circle (generic function with 1 method)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#------------------------------------------------------------
# Function to calculate an approximation of pi
#------------------------------------------------------------
function pi_serial(nbPoints::Int64 = 128 * 1000; d=Uniform(-1.0,1.0))
    
   #draw NbPoints from within the square centered in 0
   #with side length equal to 2
   xDraws = rand(d, nbPoints)
   yDraws = rand(d, nbPoints)
   sumInCircle = 0
   
   for (xValue, yValue) in zip(xDraws, yDraws)
        sumInCircle+=inside_circle(xValue, yValue)
   end
    
   return 4*sumInCircle/nbPoints
    
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;pi_serial (generic function with 2 methods)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can draw an increasing number of points and see how well the approximation for $\pi$ performs.
The following figure shows that increasing the number of points leads to a smaller error, even though the decreasing pattern is not uniform. The dashed line shows that the error descreases at a rate equal to the inverse of the square root of $N$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;minPoints =  128 * 100000
maxPoints =  128 * 1000000
gridPoints = collect(minPoints:minPoints:maxPoints)
nbGridPoints = length(gridPoints)

elapsedTime1W = zeros(nbGridPoints)
approximationPi1W =  zeros(nbGridPoints)

for (index, nbDraws) in enumerate(gridPoints)
    
    approximationPi1W[index] = pi_serial(nbDraws); #Store value
    elapsedTime1W[index] = @elapsed pi_serial(nbDraws); #Store time
    
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p = Plots.plot(gridPoints, abs.(approximationPi1W .- pi), label = &amp;quot;Serial&amp;quot;)
Plots.plot!(gridPoints, 1 ./(sqrt.(gridPoints)), label = &amp;quot;1/sqrt(n)&amp;quot;, linestyle = :dash)
display(p)
Plots.savefig(p, &amp;quot;convergence_rate.png&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://julienpascal.github.io/img/PrimerParallel/convergence_rate.png&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;adding-workers&#34;&gt;Adding &amp;ldquo;workers&amp;rdquo;&lt;/h2&gt;

&lt;p&gt;When starting Julia, by default, only one processor is available. To increase the number of processors, one can use the command &lt;code&gt;addprocs&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;println(&amp;quot;Initial number of workers = $(nworkers())&amp;quot;)
addprocs(4)
println(&amp;quot;Current number of workers = $(nworkers())&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Initial number of workers = 1
Current number of workers = 4
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;spawn-and-fetch&#34;&gt;@spawn and fetch&lt;/h2&gt;

&lt;p&gt;With Julia, one can go quite far only using the &lt;code&gt;@spawnat&lt;/code&gt; and &lt;code&gt;fetch&lt;/code&gt; functions.
The command &lt;code&gt;@spawnat&lt;/code&gt; starts an operation on a given process and returns an object of type &lt;code&gt;Future&lt;/code&gt;.
 For instance, the next line starts the operation &lt;code&gt;myid()&lt;/code&gt; on process 2:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;f = @spawnat 2 myid()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Future(2, 1, 6, nothing)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To get the result from the operation we just started on process 2, we need to &amp;ldquo;fetch&amp;rdquo; the results using the &lt;code&gt;Future&lt;/code&gt;
created above. As expected, the result is &lt;code&gt;2&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;fetch(f)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;An important thing to know about &lt;code&gt;@spawnat&lt;/code&gt; is that the &amp;ldquo;spawning&amp;rdquo; process will not wait for the operation to be finished before moving to the next task. This can be illustrated with following example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@time @spawnat 2 sleep(2.0)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0.008938 seconds (11.45 k allocations: 592.538 KiB)





Future(2, 1, 8, nothing)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the expected behavior is to wait for 2 seconds, this can be achieved by &amp;ldquo;fetching&amp;rdquo; the above operation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@time fetch(@spawnat 2 sleep(2.0))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  2.101521 seconds (47.66 k allocations: 2.357 MiB, 0.48% gc time)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The bottom line is that process 1 can be used to start many operations in parallel using &lt;code&gt;@spawnat&lt;/code&gt; and then collects the results from the different processes using &lt;code&gt;fetch&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;a-parallel-implementation&#34;&gt;A parallel implementation&lt;/h2&gt;

&lt;p&gt;The strategy we used to approximate $\pi$ does not need to be executed in serial. Since each draw is independent from previous ones, we could split the work between available workers (4 workers in this example). Each worker will calculate its own approximation for $\pi$ and the final result will be average value across workers.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#------------------------------------------------------------
# Let&#39;s redefine the function @everywhere so it can run on
# the newly added workers
#-----------------------------------------------------------
@everywhere function inside_circle(x::Float64, y::Float64)
    output = 0
    if x^2 + y^2 &amp;lt;= 1
        output = 1
    end
    return output
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@everywhere using Distributions
#------------------------------------------------------------
# Let&#39;s redefine the function @everywhere so it can run on
# the newly added workers
#-----------------------------------------------------------
@everywhere function pi_serial(nbPoints::Int64 = 128 * 1000; d=Uniform(-1.0,1.0))
    
   #draw NbPoints from within the square centered in 0
   #with side length equal to 2
   xDraws = rand(d, nbPoints)
   yDraws = rand(d, nbPoints)
   sumInCircle = 0
   
   for (xValue, yValue) in zip(xDraws, yDraws)
        sumInCircle+=inside_circle(xValue, yValue)
   end
    
   return 4*sumInCircle/nbPoints
    
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;@everywhere function pi_parallel(nbPoints::Int64 = 128 * 1000)
    
   # to store different approximations
   #----------------------------------
   piWorkers = zeros(nworkers())
   # to store Futures
   #-----------------
   listFutures=[]
   # divide the draws among workers
   #-------------------------------
   nbDraws = Int(nbPoints/4)
    
   # each calculate its own approximation
   #-------------------------------------
   for (workerIndex, w) in enumerate(workers())
        push!(listFutures, @spawnat w pi_serial(nbDraws))
   end
   # let&#39;s fetch results
   #--------------------
   for (workerIndex, w) in enumerate(workers())
         piWorkers[workerIndex] = fetch(listFutures[workerIndex])
   end
    
   # return the mean value across worker
   return mean(piWorkers)
    
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;minPoints =  128 * 100000
maxPoints =  128 * 1000000
gridPoints = collect(minPoints:minPoints:maxPoints)
nbGridPoints = length(gridPoints)

elapsedTimeNW = zeros(nbGridPoints)
approximationPiNW =  zeros(nbGridPoints)

for (index, nbDraws) in enumerate(gridPoints)
    
    approximationPiNW[index] = pi_parallel(nbDraws); #Store value
    elapsedTimeNW[index] = @elapsed pi_parallel(nbDraws); #Store time
    
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;serial-vs-parallel-comparisons&#34;&gt;Serial vs parallel comparisons&lt;/h2&gt;

&lt;p&gt;In terms of accuracy, the serial and the parallel codes generate the same results (modulo randomness).
In terms of speed, the parallel version is up to 2.5 times faster. The more points are drawn, the higher the speed-gains. This example shows the well-established fact that the advantages of parallel computing start to kick-in when the underlying tasks are time-consuming in the first place.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p = Plots.plot(gridPoints, abs.(approximationPi1W .- pi), label = &amp;quot;Serial&amp;quot;)
Plots.plot!(gridPoints, abs.(approximationPiNW .- pi), label = &amp;quot;Parallel&amp;quot;)
Plots.title!(&amp;quot;Error&amp;quot;)
Plots.xlabel!(&amp;quot;nb Draws&amp;quot;)
Plots.ylabel!(&amp;quot;Error&amp;quot;)
display(p)
Plots.savefig(p,&amp;quot;error_comparison.png&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://julienpascal.github.io/img/PrimerParallel/error_comparison.png&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p = Plots.plot(gridPoints, elapsedTime1W, label = &amp;quot;Serial&amp;quot;)
Plots.plot!(gridPoints, elapsedTimeNW, label = &amp;quot;Parallel&amp;quot;)
Plots.plot!(gridPoints, elapsedTime1W./elapsedTimeNW, label = &amp;quot;Speed-up&amp;quot;)
Plots.xlabel!(&amp;quot;nb Draws&amp;quot;)
Plots.ylabel!(&amp;quot;Time (s)&amp;quot;)
display(p)
Plots.savefig(&amp;quot;Speed_gains.png&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://julienpascal.github.io/img/PrimerParallel/Speed_gains.png&#34; alt=&#34;svg&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Labor Policy in a Dynamic Search-Matching Model with Heterogeneous Workers and Firms</title>
      <link>https://julienpascal.github.io/project/minwage/</link>
      <pubDate>Thu, 14 Mar 2019 18:11:07 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/project/minwage/</guid>
      <description>&lt;p&gt;We analyse the consequences of the minimum wage on employment and sorting in a model of the labor
market with search frictions, heterogeneous workers and firms, and business cycle fluctuations. This is a joint project with &lt;a href=&#34;https://sites.google.com/view/jeremylise&#34; target=&#34;_blank&#34;&gt;Jeremy Lise&lt;/a&gt; and &lt;a href=&#34;https://sites.google.com/site/jmarcrobin/home&#34; target=&#34;_blank&#34;&gt;Jean-Marc Robin&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Labor Tax in a Dynamic Search-and-Matching Model</title>
      <link>https://julienpascal.github.io/project/taxation_labor/</link>
      <pubDate>Wed, 13 Mar 2019 18:11:18 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/project/taxation_labor/</guid>
      <description>&lt;p&gt;We develop a theoretical framework to evaluate the contribution of different payroll tax schedules to business cycle fluctuations. We build and estimate a dynamic search-and-matching model of the labor market featuring heterogeneous workers, aggregate and idiosyncratic shocks and a non-linear payroll tax schedule. We estimate the model on Italian administrative data for the period 1977-2012 and use our estimated framework to quantitatively evaluate how different payroll tax schedules can amplify business cycle shocks for different types of workers. This is a joint project with &lt;a href=&#34;https://nicolodalvit.github.io/&#34; target=&#34;_blank&#34;&gt;NicolÃ² Dalvit&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spatial Equilibrium and Commuting Costs</title>
      <link>https://julienpascal.github.io/project/spatialeq/</link>
      <pubDate>Tue, 12 Mar 2019 18:11:07 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/project/spatialeq/</guid>
      <description>&lt;p&gt;I exploit a spatial discontinuity introduced by a French reform in September 2015 to measure the links between commuting costs, employment and location decisions. In the municipalities benefiting from the reform, I find that the reform led to a 2% decrease in the number of unemployed workers registered in the French unemployment agency. The employment effect is concentrated on long-term unemployed workers. I build a simple spatial search-and-matching to underline the mechanism at play.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Labor Income Shocks Along the Business Cycle</title>
      <link>https://julienpascal.github.io/project/laborincomeshocks/</link>
      <pubDate>Mon, 11 Mar 2019 18:11:07 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/project/laborincomeshocks/</guid>
      <description>&lt;p&gt;This paper analyzes the determinants of labor income shocks along the business cycle. My main finding is that sorting between firms and workers is a key component of idiosyncratic risk. Labor income shocks are analyzed through the lenses of a dynamic search-and-matching model, which I estimate using US data. Because of search frictions and mismatches between firms and workers, the &lt;em&gt;laissez-faire&lt;/em&gt; equilibrium is not necessarily optimal. My results underline that the government can tame business cycle fluctuations by designing a simple unemployment insurance scheme improving sorting between firms and workers.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Create a Julia Package</title>
      <link>https://julienpascal.github.io/post/julia_package/</link>
      <pubDate>Wed, 06 Jun 2018 15:34:38 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/julia_package/</guid>
      <description>

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This post is outdated. With the advent of Julia 1.0, the workflow for creating
packages was significantly altered. An excellent guide can be found &lt;a href=&#34;https://lectures.quantecon.org/jl/testing.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;In this post, my goal is to briefly explain how to create an unregistered Julia package for Julia 0.6.4, how to synchronize it with your &lt;a href=&#34;https://github.com/&#34; target=&#34;_blank&#34;&gt;Github&lt;/a&gt; account, and how to start testing your code automatically using &lt;a href=&#34;https://travis-ci.org/&#34; target=&#34;_blank&#34;&gt;TRAVIS CI&lt;/a&gt;. I started writing this post as a reminder to myself. I am posting it here with the hope that it may be useful for someone else. More on this topic can be found by reading the &lt;a href=&#34;https://docs.julialang.org/en/release-0.6/manual/packages/&#34; target=&#34;_blank&#34;&gt;official Julia&amp;rsquo;s manual&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;why-creating-a-package&#34;&gt;Why Creating a Package?&lt;/h1&gt;

&lt;h3 id=&#34;a-package-to-share-academic-work&#34;&gt;A package to share academic work&lt;/h3&gt;

&lt;p&gt;My research projects often involve data manipulation and/or implementing algorithms. I discovered that writing my codes in the form of a package helps me in producing better and reusable code. Creating a package to share your academic work is also very much in line with the idea that scientific research should be reproducible. Users can download your work and install the required dependencies using a single line :&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git.clone(&amp;quot;https://github.com/YourGithubUsername/YourPackage.jl.git&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;continuous-integration&#34;&gt;Continuous Integration&lt;/h3&gt;

&lt;p&gt;Another major advantage of creating a package is that it makes your life much easier when it comes to testing your code automatically using &lt;a href=&#34;https://travis-ci.org/&#34; target=&#34;_blank&#34;&gt;TRAVIS CI&lt;/a&gt;. TRAVIS CI is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Continuous_integration&#34; target=&#34;_blank&#34;&gt;continuous integration&lt;/a&gt; system, which considerably helps in detecting and resolving bugs at an early stage.&lt;/p&gt;

&lt;h1 id=&#34;step-by-step-tutorial&#34;&gt;Step-by-step tutorial&lt;/h1&gt;

&lt;p&gt;In what follows, I am assuming you are using Linux, with julia version 0.6 installed. If you are using a different version, just replace &lt;code&gt;v0.6&lt;/code&gt; by the number corresponding to your current version of julia. You also need to have the package &lt;a href=&#34;https://github.com/JuliaLang/PkgDev.jl&#34; target=&#34;_blank&#34;&gt;PkgDev&lt;/a&gt; installed.&lt;/p&gt;

&lt;h2 id=&#34;step-1-generate-your-package&#34;&gt;Step 1: Generate your package&lt;/h2&gt;

&lt;p&gt;The following two lines will create a directory called &lt;code&gt;&amp;quot;MyPackage.jl&amp;quot;&lt;/code&gt; with an &lt;a href=&#34;https://en.wikipedia.org/wiki/MIT_License&#34; target=&#34;_blank&#34;&gt;MIT License&lt;/a&gt;, in
Julia&amp;rsquo;s package location:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using PkgDev
PkgDev.generate(&amp;quot;MyPackage.jl&amp;quot;,&amp;quot;MIT&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By convention, Julia repository names and with &lt;code&gt;.jl&lt;/code&gt;. If you change your working directory to your newly created package (&lt;code&gt;cd ~/.julia/v0.6/MyPackage&lt;/code&gt;), you will notice that the following files and directories have been created:&lt;/p&gt;

&lt;h4 id=&#34;src&#34;&gt;\src&lt;/h4&gt;

&lt;p&gt;The &lt;code&gt;\src&lt;/code&gt; folder will contain your source code. By default, it contains a file &amp;ldquo;MyPackage.jl&amp;rdquo;, which you will use to load other packages and to include &lt;code&gt;.jl&lt;/code&gt; files that you created. In this file, you also state the functions and types you want to export. As an example, you may consult the package &lt;a href=&#34;https://github.com/JuliaStats/Distributions.jl/blob/master/src/Distributions.jl&#34; target=&#34;_blank&#34;&gt;Distributions&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;test&#34;&gt;\test&lt;/h4&gt;

&lt;p&gt;This folder contains a file &lt;code&gt;runtests.jl&lt;/code&gt;, in which you can include &lt;a href=&#34;https://docs.julialang.org/en/v0.6.1/stdlib/test/&#34; target=&#34;_blank&#34;&gt;unit-tests&lt;/a&gt;. Within julia, you can simply run your series of unit-tests with the command:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;Pkg.test(&amp;quot;MyPackage&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;require&#34;&gt;REQUIRE&lt;/h4&gt;

&lt;p&gt;This file is used to specify the required dependencies. When a user &lt;code&gt;Pkg.clone()&lt;/code&gt;
your package, Julia&amp;rsquo;s package manager will make sure that these requirements are
met. For instance, let&amp;rsquo;s say that your package relies on the version 0.6 of Julia
(or higher) and the package &lt;a href=&#34;https://github.com/JuliaIO/JSON.jl&#34; target=&#34;_blank&#34;&gt;JSON&lt;/a&gt;. The REQUIRE
file will be the following :&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;julia 0.6
JSON
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;readme-md&#34;&gt;README.md&lt;/h4&gt;

&lt;p&gt;You can use this file to add a description of you package.&lt;/p&gt;

&lt;h4 id=&#34;license-md&#34;&gt;LICENSE.md&lt;/h4&gt;

&lt;p&gt;To guide you in the choice of a licence, you may want to consult the following website: &lt;a href=&#34;https://choosealicense.com/&#34; target=&#34;_blank&#34;&gt;https://choosealicense.com/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;step-2-set-up-your-working-environment&#34;&gt;Step 2: Set-up your working environment&lt;/h2&gt;

&lt;p&gt;This step is optional. While you may want to develop you package directly from Julia&amp;rsquo;s package
directory (&lt;code&gt;~/.julia/v0.6&lt;/code&gt; if you are using &lt;code&gt;julia v0.6&lt;/code&gt;), I personally find it unpleasant. I usually create a symlink to a more convenient location:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ln -s ~/.julia/v0.6/MyPackage your/convenient/directory/MyPackage
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After running this line in the terminal, you can start working on your package
directly from &lt;code&gt;your/convenient/directory&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;step-3-synchronize-with-github&#34;&gt;Step 3: Synchronize with GitHub&lt;/h2&gt;

&lt;p&gt;The following step will synchronize your package with
your GitHub account. After creating a repository named &amp;ldquo;MyPackage.jl&amp;rdquo; on GitHub, enter the following
commands in the terminal:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git add -A
git commit -m &amp;quot;First commit&amp;quot;
git remote add origin https://github.com/YourGithubUsername/MyPackage.jl.git
git push -u origin master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Going to the page &lt;a href=&#34;https://github.com/YourGithubUsername/MyPackage.jl.git&#34; target=&#34;_blank&#34;&gt;https://github.com/YourGithubUsername/MyPackage.jl.git&lt;/a&gt;, you should now see folders and files mentioned above. Some extra files are also going to be there, for instance &lt;code&gt;.gitignore&lt;/code&gt; or &lt;code&gt;appveyor.yml&lt;/code&gt;. You can ignore them for the time being. After this initial commit, you are almost all set and you can use the usual &lt;a href=&#34;https://guides.github.com/introduction/flow/&#34; target=&#34;_blank&#34;&gt;GitHub workflow&lt;/a&gt;. A good idea though is to enable TRAVIS CI for the repository just you created.&lt;/p&gt;

&lt;h2 id=&#34;step-4-set-up-travis-ci&#34;&gt;Step 4: Set-up TRAVIS CI&lt;/h2&gt;

&lt;p&gt;From your GitHub account, sign in to either:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TravisCI.org if your repository is public&lt;/li&gt;
&lt;li&gt;TravisCI.com if your repository is private&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On TRAVIS CI, go to your profile page. Enable your repository &amp;ldquo;YourGithubUsername/MyPackage.jl&amp;rdquo; by flicking the switch one. Every time you push a new commit, your set of tests, launched by the file &lt;code&gt;/test/runtests.jl&lt;/code&gt;, will be automatically executed on a separate virtual environment. If one of your tests fails, you will be notified by e-mail and (most of the time) you will be able to spot the origin of the error quite easily.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Simulated Method of Moments: a Parallel Implementation</title>
      <link>https://julienpascal.github.io/post/smm_parallel/</link>
      <pubDate>Wed, 06 Jun 2018 15:26:09 +0100</pubDate>
      
      <guid>https://julienpascal.github.io/post/smm_parallel/</guid>
      <description>

&lt;p&gt;In my &lt;a href=&#34;https://julienpascal.github.io/post/smm/&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt;, I discussed how
the the simulated method of moments can be used to estimate parameters without
using the likelihood function. This method is useful because many &amp;ldquo;real-life&amp;rdquo; applications result in untractable likelihood functions. In this post, I use the same toy example (estimation of the mean of a mutlivariate normal random variable) and show how to use the
parallel computing capabilities of Julia and &lt;a href=&#34;https://github.com/floswald/MomentOpt.jl/&#34; target=&#34;_blank&#34;&gt;MomentOpt&lt;/a&gt;
to speed-up the estimation.&lt;/p&gt;

&lt;h2 id=&#34;adding-workers&#34;&gt;Adding workers&lt;/h2&gt;

&lt;p&gt;In this example, the goal is to estimate the mean of 4-dimension normal random variable with unit variance, without using any information on the likelihood. If you start Julia with several processors, MomentOpt will notice it and execute the code in parallel. The first step is to add &amp;ldquo;workers&amp;rdquo; to Julia. A rule of thumb is to use as many workers as you have processors on your system (4 in my case).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Current number of workers
#--------------------------
currentWorkers = nprocs()
println(&amp;quot;Initial number of workers = $(currentWorkers)&amp;quot;)
# I want to have 4 workers running
#--------------------------------
maxNumberWorkers = 4
while nprocs() &amp;lt; maxNumberWorkers
    addprocs(1)
end
# check the number of workers:
#----------------------------
currentWorkers = nprocs()
println(&amp;quot;Number of workers = $(currentWorkers)&amp;quot;)
Initial number of workers = 1
Number of workers = 4
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;everywhere&#34;&gt;@everywhere&lt;/h2&gt;

&lt;p&gt;When running Julia with several workers, you have to add the macro @everywhere when loading packages and defining functions. More details on parallel computing with Julia can be found &lt;a href=&#34;https://docs.julialang.org/en/v0.6.0/manual/parallel-computing/&#34; target=&#34;_blank&#34;&gt;here.&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;#---------------------------------------------------------------------------------------------------------
# Julien Pascal
# https://julienpascal.github.io/
# last edit: 06/06/2018
#
# Julia script that shows how the simulated method of moments can be used in
# a simple setting: estimation of the mean of a Normal r.v.
# This version was built to be executed with several processors
# For instance, start julia with: julia -p 4
#
# I use the package MomentOpt: https://github.com/floswald/MomentOpt.jl
#
# Code heavily based on the file https://github.com/floswald/MomentOpt.jl/blob/master/src/mopt/Examples.jl
#----------------------------------------------------------------------------------------------------------

@everywhere using MomentOpt
@everywhere using GLM
@everywhere using DataStructures
@everywhere using DataFrames
@everywhere using Plots
#plotlyjs()
@everywhere pyplot()

#------------------------------------------------
# Options
#-------------------------------------------------
# Boolean: do you want to save the plots to disk?
savePlots = true

#------------------------
# initialize the problem:
#------------------------
# Specify the initial values for the parameters, and their support:
#------------------------------------------------------------------
pb = OrderedDict(&amp;quot;p1&amp;quot; =&amp;gt; [0.2,-3,3] , &amp;quot;p2&amp;quot; =&amp;gt; [-0.2,-2,2], &amp;quot;p3&amp;quot; =&amp;gt; [0.1,0,10], &amp;quot;p4&amp;quot; =&amp;gt; [-0.1,-10,0])
# Specify moments to be matched + subjective weights:
#----------------------------------------------------
trueValues = OrderedDict(&amp;quot;mu1&amp;quot; =&amp;gt; [-1.0] , &amp;quot;mu2&amp;quot; =&amp;gt; [1.0], &amp;quot;mu3&amp;quot; =&amp;gt; [5.0], &amp;quot;mu4&amp;quot; =&amp;gt; [-4.0])
moms = DataFrame(name=[&amp;quot;mu1&amp;quot;,&amp;quot;mu2&amp;quot;,&amp;quot;mu3&amp;quot;, &amp;quot;mu4&amp;quot;],value=[-1.0,1.0, 5.0, -4.0], weight=ones(4))




# objfunc_normal(ev::Eval)
#
# GMM objective function to be minized.
# It returns a weigthed distance between empirical and simulated moments
#
@everywhere function objfunc_normal(ev::Eval; verbose = false)

    start(ev)


    # when running in parallel, display worker&#39;s id:
    #-----------------------------------------------
    if verbose == true
        if nprocs() &amp;gt; 1
          println(myid())
        end
    end

    # extract parameters from ev:
    #----------------------------
    mu  = collect(values(ev.params))

    # compute simulated moments
    #--------------------------
    # Monte-Carlo:
    #-------------
    ns = 10000 #number of i.i.d draws from N([mu], sigma)
    #initialize a multivariate normal N([mu], sigma)
    #mu is a four dimensional object
    #sigma is set to be the identity matrix
    sigma = [1.0 ;1.0; 1.0; 1.0]
    # draw ns observations from N([mu], sigma):
    randMultiNormal = MomentOpt.MvNormal(mu,MomentOpt.PDiagMat(sigma))
    # calculate the mean of the simulated data
    simM            = mean(rand(randMultiNormal,ns),2)
    # store simulated moments in a dictionary
    simMoments = Dict(:mu1 =&amp;gt; simM[1], :mu2 =&amp;gt; simM[2], :mu3 =&amp;gt; simM[3], :mu4 =&amp;gt; simM[4])

    # Calculate the weighted distance between empirical moments
    # and simulated ones:
    #-----------------------------------------------------------
    v = Dict{Symbol,Float64}()
    for (k, mom) in dataMomentd(ev)
        # If weight for moment k exists:
        #-------------------------------
        if haskey(MomentOpt.dataMomentWd(ev), k)
            # divide by weight associated to moment k:
            #----------------------------------------
            v[k] = ((simMoments[k] .- mom) ./ MomentOpt.dataMomentW(ev,k)) .^2
        else
            v[k] = ((simMoments[k] .- mom) ) .^2
        end
    end

    # Set value of the objective function:
    #------------------------------------
    setValue(ev, mean(collect(values(v))))

    # also return the moments
    #-----------------------
    setMoment(ev, simMoments)

    # flag for success:
    #-------------------
    ev.status = 1

    # finish and return
    finish(ev)

    return ev
end



# Initialize an empty MProb() object:
#------------------------------------
mprob = MProb()

# Add structural parameters to MProb():
# specify starting values and support
#--------------------------------------
addSampledParam!(mprob,pb)

# Add moments to be matched to MProb():
#--------------------------------------
addMoment!(mprob,moms)

# Attach an objective function to MProb():
#----------------------------------------
addEvalFunc!(mprob, objfunc_normal)


# estimation options:
#--------------------
# number of iterations for each chain
niter = 1000
# number of chains
# nchains = nprocs()
nchains = 4

opts = Dict(&amp;quot;N&amp;quot;=&amp;gt;nchains,
        &amp;quot;maxiter&amp;quot;=&amp;gt;niter,
        &amp;quot;maxtemp&amp;quot;=&amp;gt; 5,
        &amp;quot;coverage&amp;quot;=&amp;gt;0.025,
        &amp;quot;sigma_update_steps&amp;quot;=&amp;gt;10,
        &amp;quot;sigma_adjust_by&amp;quot;=&amp;gt;0.01,
        &amp;quot;smpl_iters&amp;quot;=&amp;gt;1000,
        &amp;quot;parallel&amp;quot;=&amp;gt;true,
        &amp;quot;maxdists&amp;quot;=&amp;gt;[0.05 for i in 1:nchains],
        &amp;quot;mixprob&amp;quot;=&amp;gt;0.3,
        &amp;quot;acc_tuner&amp;quot;=&amp;gt;12.0,
        &amp;quot;animate&amp;quot;=&amp;gt;false)



#---------------------------------------
# Let&#39;s set-up and run the optimization
#---------------------------------------
# set-up BGP algorithm:
MA = MAlgoBGP(mprob,opts)

# run the estimation:
@time MomentOpt.runMOpt!(MA)

# show a summary of the optimization:
@show MomentOpt.summary(MA)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;inference&#34;&gt;Inference&lt;/h3&gt;

&lt;p&gt;When using the &lt;a href=&#34;https://arxiv.org/abs/1108.3423&#34; target=&#34;_blank&#34;&gt;BGP algorithm&lt;/a&gt;, inference can be done using the first chain only. Other chains are used to explore the state space and help to exit potential local minima, but they are not meant to be used for inference. I discard the first 10th observations to get rid of the influence of the starting values. Visual inspection of the first chain suggests that the stationary part of the Markov chain was reached at this stage. I then report the quasi posterior mean and median for each parameter. As reported below, we are quite close to the true values.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Plot histograms for the first chain, the one with which inference should be done.
# Other chains are used to explore the space and avoid local minima
#-------------------------------------------------------------------------------
p1 = histogram(MA.chains[1])
display(p1)

if savePlots == true
    savefig(p1, joinpath(pwd(),&amp;quot;histogram_chain1.svg&amp;quot;))
end

# Plot the realization of the first chain
#----------------------------------------
p2 = plot(MA.chains[1])
if savePlots == true
    savefig(p2, joinpath(pwd(),&amp;quot;history_chain_1.svg&amp;quot;))
end
display(p2)


# Realization of the first chain:
#-------------------------------
dat_chain1 = MomentOpt.history(MA.chains[1])

# discard the first 10th of the observations (&amp;quot;burn-in&amp;quot; phase):
#--------------------------------------------------------------
dat_chain1[round(Int, niter/10):niter, :]

# keep only accepted draws:
#--------------------------
dat_chain1 = dat_chain1[dat_chain1[:accepted ].== true, : ]

# create a list with the parameters to be estimated
parameters = [Symbol(String(&amp;quot;mu$(i)&amp;quot;)) for i=1:4]
# list with the corresponding priors:
#------------------------------------
estimatedParameters = [Symbol(String(&amp;quot;p$(i)&amp;quot;)) for i=1:4]


# Quasi Posterior mean and quasi posterior median for each parameter:
#-------------------------------------------------------------------
for (estimatedParameter, param) in zip(estimatedParameters, parameters)

  println(&amp;quot;Quasi posterior mean for $(String(estimatedParameter)) = $(mean(dat_chain1[estimatedParameter]))&amp;quot;)
  println(&amp;quot;Quasi posterior median for $(String(estimatedParameter)) = $(median(dat_chain1[estimatedParameter]))&amp;quot;)
  println(&amp;quot;True value = $(trueValues[String(param)][])&amp;quot;)

end

# Output:
#--------
# Quasi posterior mean for p1 = -0.9160461484604642
# Quasi posterior median for p1 = -0.9589739759449558
# True value = -1.0
# Quasi posterior mean for p2 = 0.9888798123473025
# Quasi posterior median for p2 = 1.0675028518780796
# True value = 1.0
# Quasi posterior mean for p3 = 4.922658319685393
# Quasi posterior median for p3 = 4.989662707150382
# True value = 5.0
# Quasi posterior mean for p4 = -3.898597557236236
# Quasi posterior median for p4 = -3.968649064061086
# True value = -4.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;figure-1&#34;&gt;Figure 1&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://julienpascal.github.io/img/history_chain_1_Parallel.svg&#34; alt=&#34;History of chain 1&#34; /&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;em&gt;History of chain 1&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;figure-2&#34;&gt;Figure 2&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://julienpascal.github.io/img/histogram_chain_1_Parallel.svg&#34; alt=&#34;Histograms for chain 1&#34; /&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;em&gt;Histograms for chain 1&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;safety-checks&#34;&gt;Safety checks&lt;/h2&gt;

&lt;p&gt;In this toy example, we know that the conditions for global identification are met. However, in more complicated applications, global identification may be hard to prove analytically. A common practice is to make sure that the objective function is &amp;ldquo;well-behaved&amp;rdquo; in a neighborhood of the solution using slices. The graph below shows that there is no flat region in the neighborhood of the solution, suggesting (at least) local identification of the parameters.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# plot slices of objective function
# grid with 20 points
#-----------------------------------
s = doSlices(mprob,20)

# plot slices of the objective function:
#---------------------------------------
p = MomentOpt.plot(s,:value)
display(p)

if savePlots == true
    Plots.savefig(p, joinpath(pwd(),&amp;quot;slices_Normal.svg&amp;quot;))
end



# Produce more precise plots with respect to each parameter:
#-----------------------------------------------------------
for symbol in parameters

  p = MomentOpt.plot(s,symbol)
  display(p)

  if savePlots == true
      Plots.savefig(p, joinpath(pwd(),&amp;quot;slices_Normal_$(String(symbol)).svg&amp;quot;))
  end


end
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;figure-3&#34;&gt;Figure 3&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://julienpascal.github.io/img/slices_Normal_Parallel.svg&#34; alt=&#34;Slices of the objective function&#34; /&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;em&gt;Slices of the objective function&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;parallel-versus-serial&#34;&gt;Parallel versus Serial&lt;/h2&gt;

&lt;p&gt;Here is benchmark of running the code above in serial versus in parallel
(starting julia with 4 workers):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Serial: 639.661831 seconds (12.52 M allocations: 1.972 GiB, 97.50% gc time)&lt;/li&gt;
&lt;li&gt;Parallel: 372.454707 seconds (279.32 M allocations: 14.843 GiB, 2.19% gc time)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Computing time is approximately divided by 2 when executing the parallel version.&lt;/p&gt;

&lt;h2 id=&#34;notebook&#34;&gt;Notebook&lt;/h2&gt;

&lt;p&gt;A jupyter notebook containing the code in this post (with some slight modifications)
can be downloaded &lt;a href=&#34;https://github.com/JulienPascal/ExampleMomentOpt/blob/master/Example_MomentOpt_parallel.ipynb&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
